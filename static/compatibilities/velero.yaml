icon: https://velero.io/img/Velero.svg
git_url: https://github.com/vmware-tanzu/velero
release_url: https://github.com/vmware-tanzu/velero/releases/tag/v{vsn}
helm_repository_url: https://vmware-tanzu.github.io/helm-charts
versions:
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "### Helm/values changes to account for in the upgrade\n\n> Note:\
      \ you provided *application* release notes (Velero v1.17.0), not the Helm chart\
      \ changelog. The items below are the most likely Helm **values/args** impacts\
      \ based on the Velero server/node-agent flags and config behavior described\
      \ in the release notes.\n\n- **Remove any Restic uploader configuration**\n\
      \  - If your Helm values set anything equivalent to `--uploader-type=restic`\
      \ (or a chart value that selects `restic`), **remove it**. Restic as an uploader\
      \ type is no longer valid for new backups in v1.17.\n  - You may keep legacy\
      \ restores from existing Restic-based backups until v1.19.\n\n- **Repository\
      \ maintenance job settings moved to ConfigMap (server flags removed)**\n  -\
      \ If your Helm chart previously set server args:\n    - `--keep-latest-maintenance-jobs`\n\
      \    - `--maintenance-job-cpu-request`\n    - `--maintenance-job-mem-request`\n\
      \    - `--maintenance-job-cpu-limit`\n    - `--maintenance-job-mem-limit`\n\
      \  - \u2026then you must **migrate these to the repository maintenance job ConfigMap**\
      \ (often chart-managed). Ensure your values now render/configure that ConfigMap\
      \ instead of server args.\n  - v1.17 adds **ConfigMap parameter validation**\
      \ at install/server start; invalid keys/values will now fail fast.\n\n- **PriorityClass\
      \ support (optional new values)**\n  - v1.17 allows setting PriorityClass separately\
      \ for:\n    - velero server\n    - node-agent\n    - data mover pods\n    -\
      \ repository maintenance jobs\n  - If your chart exposes values for `priorityClassName`,\
      \ you can now/should set them consistently (especially in constrained clusters).\n\
      \n- **Node-agent/data mover scaling control (optional new config)**\n  - A node-agent\
      \ config parameter `PrepareQueueLength` can throttle creation of data mover\
      \ pods to avoid many Pending pods.\n  - If your chart manages the node-agent\
      \ ConfigMap, consider exposing/setting this for large environments.\n\n- **Windows\
      \ tolerations / scheduling (if applicable)**\n  - v1.17 adds `os=windows:NoSchedule`\
      \ toleration for Windows pods; verify your Helm values don\u2019t override tolerations/nodeSelectors\
      \ in a way that blocks Windows support.\n\n- **Kubelet mount path now parameterized\
      \ (node-agent install)**\n  - If you have non-standard kubelet paths (common\
      \ in some distros), ensure your chart values align with the new parameterization\
      \ and your existing hostPath mounts."
    chart_updates: ['No Helm chart changelog was provided, so chart-template changes
        (new/removed values, renamed keys, new manifests) cannot be stated with certainty.',
      'Operationally relevant changes from the application that commonly affect chart
        templates/config include: removal of Restic uploader type, migration of maintenance-job
        configuration to a ConfigMap, and expanded PriorityClass wiring across components.',
      'v1.17 introduces stronger ConfigMap parameter validation, which can surface
        misconfigurations in chart-rendered ConfigMaps that previously went unnoticed.']
    features: ['Modernized fs-backup to a micro-service architecture, improving robustness
        (survives node-agent restarts), adding concurrency control, and enabling cancel/resume
        behaviors.', 'fs-backup now supports Windows workloads by allowing data mover
        pods to run on Windows nodes, completing end-to-end Windows backup/restore
        scenarios.', 'Adds support for Kubernetes Volume Group Snapshots (beta upstream),
        enabling crash-consistent snapshots across multiple related volumes.', 'PriorityClass
        support across Velero modules (server, node-agent, data movers, maintenance
        jobs) for better scheduling control.', 'Data mover scalability/resiliency
        improvements: throttling pod creation via PrepareQueueLength, better restart-resume
        behavior, and improved node-selection (including per-storage-class).', 'Resource
        policy enhancement: reusable include/exclude filters (`includeExcludePolicy`)
        in resource policy ConfigMaps.', CLI can auto-discover and use CA certs from
        the BackupStorageLocation for download requests; improved BSL availability
        metrics and checks.]
    breaking_changes: ['Restic uploader path removed: `--uploader-type=restic` is
        no longer valid for installation/new backups (restores from existing Restic
        backups still supported until v1.19).', Repository maintenance job configuration
        flags were removed from the Velero server; these settings must be configured
        via the maintenance-job ConfigMap going forward., 'PVC restore behavior change:
        when no node mapping exists, Velero always removes the `selected-node` annotation
        (previously it could be preserved if the node existed), which may change scheduling
        outcomes on restore.']
  chart_version: 11.2.0
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "### Helm values / install-time changes to review\n\n- **Restic\
      \ uploader removed (breaking):** `--uploader-type=restic` is no longer valid\
      \ in v1.17. If your Helm chart exposes this (or equivalent values), remove/replace\
      \ it (use **kopia**/default fs-backup mechanisms). You can still **restore**\
      \ from legacy Restic-path backups until v1.19.\n- **Repository maintenance job\
      \ settings moved to a ConfigMap (breaking):** the following **Velero server\
      \ flags are removed** in v1.17, so any Helm values that set them must be deleted/migrated\
      \ to the **repo maintenance job ConfigMap**:\n  - `--keep-latest-maintenance-jobs`\n\
      \  - `--maintenance-job-cpu-request`\n  - `--maintenance-job-mem-request`\n\
      \  - `--maintenance-job-cpu-limit`\n  - `--maintenance-job-mem-limit`\n  v1.17\
      \ adds **ConfigMap support** for `keepLatestMaintenanceJobs` (with CLI parameter\
      \ fallback).\n- **New optional tuning knobs you may want to surface via values:**\n\
      \  - **fs-backup micro-service architecture** (behavior changes; check node-agent/data\
      \ mover resources and configs).\n  - **`PrepareQueueLength`** in **node-agent**\
      \ config to throttle data mover pod creation (prevents many Pending pods).\n\
      \  - **PriorityClass name support** for server, node-agent, data movers, and\
      \ maintenance jobs.\n  - **Node-selection for restore + per-storage-class node\
      \ selection** for CSI snapshot data movement.\n  - **Parameterized kubelet mount\
      \ path** for node-agent installation (if your distro uses a non-standard kubelet\
      \ root).\n"
    chart_updates: [Ensure Helm chart templates no longer set removed Velero server
        flags for repository maintenance jobs; instead template the new maintenance
        job ConfigMap., 'If your chart previously configured Restic as an uploader
        type, remove those options and update docs/values schema accordingly.', Consider
        adding values to set `priorityClassName` for each Velero component (server/node-agent/data
        movers/maintenance)., Consider adding values to manage node-agent `PrepareQueueLength`
        and CSI data-mover node selection (including per-storage-class rules)., 'If
        you run Windows nodes, validate chart tolerations/affinity: v1.17 adds `os=windows:NoSchedule`
        toleration and expands Windows fs-backup support; ensure node-agent/data mover
        scheduling rules match your cluster.', 'If your clusters use non-default kubelet
        paths, verify the chart can set the kubelet mount path for node-agent per
        the new parameterized support.']
    features: ['Modernized **fs-backup** to a micro-service architecture (better concurrency
        control, cancellation, and resiliency across restarts; steadier node-agent
        memory usage).', '**fs-backup now supports Windows workloads**, enabling full
        Windows backup/restore scenarios when combined with CSI snapshot data movement.',
      'Added **Volume Group Snapshot (VGS)** support for CSI snapshot backup and CSI
        snapshot data movement, enabling point-in-time consistency across multiple
        volumes.', 'Added **PriorityClass support** across Velero modules (server,
        node-agent, data movers, and maintenance jobs).', 'Data mover scalability/resiliency
        improvements: **PrepareQueueLength** throttling to avoid many Pending pods,
        and improved restart handling (resume/cancel appropriately).', 'Improved CSI
        snapshot data movement restore scheduling: restore now supports **node-selection**,
        including **per-storage-class node selection**.', Resource policies now support
        reusable **include/exclude filters** via `includeExcludePolicy` in addition
        to `volumePolicy`., 'Runtime bumps: Go **1.24.6** and Kopia **0.21.1**.']
    breaking_changes: ['**Restic deprecation/removal for fs-backup creation:** v1.17
        removes the ability to create backups using the Restic uploader (`--uploader-type=restic`
        invalid). Restores from existing Restic-path backups remain supported until
        v1.19.', '**Repository maintenance job config flags removed from the Velero
        server:** maintenance job retention and resource flags must be configured
        via the maintenance job ConfigMap; any Helm values/args that set these flags
        will break startup.', '**PVC restore behavior change:** Velero now always
        removes the `selected-node` annotation during PVC restore when no node mapping
        exists (previously it could be preserved if the node existed). This can affect
        scheduling outcomes in some restore workflows.']
  chart_version: 11.2.0
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.16.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Windows cluster support (hybrid/multi-arch build, Velero components
        can run on both Linux and Windows nodes, and built-in data mover supports
        Windows workload backup/restore end-to-end).', Parallel ItemBlock backups
        via a new server flag `--item-block-worker-count` to increase backup throughput
        by processing correlated resource groups concurrently., 'Data mover restore
        scalability: new node-agent setting `ignoreDelayBinding` can spread restores
        across nodes for WaitForFirstConsumer volumes instead of pinning to the attached
        node.', 'Improved data mover observability: additional status/error logging
        for intermediate objects and cleanup failures (enabled by default in node-agent
        logs).', 'CSI usability improvement: VolumeSnapshotContent artifacts are no
        longer retained in backups, reducing unnecessary CSI objects synced/restored
        across clusters.', 'Backup repository maintenance improvements: maintenance
        history recorded in `BackupRepository.status.RecentMaintenance`, jobs are
        recaptured after server restart, and maintenance/init is skipped for read-only
        BSLs; configurable `fullMaintenanceInterval` (normalGC/fastGC/eagerGC).',
      'Volume policy enhancement: can filter volumes by PVC labels (and additional
        CSI volume attributes support).', Per-object restore of resource status via
        annotation `velero.io/restore-status` on objects., 'Velero image now contains
        `velero`, `velero-helper`, and `velero-restore-helper` binaries (single image).']
    breaking_changes: []
  chart_version: 10.1.3
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.16.2']
- version: 1.15.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Data mover microservice: CSI snapshot data movement is performed by
        dedicated per-backup/per-restore pods instead of the node-agent, improving
        security (no hostPath), allowing granular resource tuning, and improving resilience.',
      "Item Block + ItemBlockAction (IBA) plugins: Velero can group related resources\
        \ (e.g., Pods/PVCs) into \u201Citem blocks\u201D for future concurrent processing;\
        \ built-in IBAs are provided, and custom IBAs are supported (concurrency not\
        \ yet enabled in 1.15).", 'Node selection for repository maintenance jobs:
        a new repository maintenance configMap allows pinning maintenance jobs to
        specific nodes (e.g., idle nodes) and avoiding critical workload nodes.',
      'Backup PVC configuration: new configMap options to mount backup PVCs read-only
        (can accelerate exposes for some storage like Ceph) and to choose the storage
        class used for backupPVCs.', 'Backup repository cache configuration: new configMap
        allows setting per-repository client-side cache size to prevent eviction due
        to ephemeral storage pressure.', 'Performance improvements: fixes a post-plugin-call
        memory leak, passes client-qps/client-burst settings through to plugins, and
        includes upstream Kopia improvements for high-file-count maintenance memory
        usage.']
    breaking_changes: ['Restic is deprecated for filesystem backups starting in 1.15:
        restic-based uploads still work but generate warnings when installed with
        --uploader-type=restic or when restic path is used for fs-backup.', node-agent
        configMap name is no longer fixed; if you use a non-default configMap name
        you must set the node-agent server parameter node-agent-configmap accordingly.,
      'Repository maintenance job settings are moving from Velero server flags to
        the new repository maintenance configMap; if both are set, the configMap values
        take precedence (flags still work for backward compatibility).', "The \u201C\
        Changing PVC selected-node\u201D restore feature is deprecated and should\
        \ not be relied on; it will be removed in a future release."]
  chart_version: 8.7.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.15.2']
- version: 1.14.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: [CSI plugin is now bundled/installed by default as an internal
        plugin (no longer installed separately via the `--plugins` flag in `velero
        install`)., Restore workflow now includes a new `Finalizing` phase; some PV
        label restoration and post-restore hooks happen later in the process., Kopia/restic
        repository maintenance is moved out of the main Velero server pod into separate
        Kubernetes Jobs to avoid OOM issues., 'Node-agent default resource requests/limits
        are removed, making node-agent pods BestEffort unless you set resources explicitly.',
      Namespace filtering behavior during backup changes when using label selectors
        without explicit include/exclude namespace lists., Velero now persists VolumeInfo
        metadata for restores (in addition to backups) and `velero restore describe`
        shows more volume details., Azure authentication gains certificate-based service
        principal support; Azure SDK and storage libraries were migrated/updated.,
      'Runtime bumps: Go 1.22.2 and Kopia 0.17.0.']
    features: ['Repository maintenance for kopia/restic now runs as Kubernetes Jobs,
        reducing risk of the velero server pod being OOM-killed.', 'VolumePolicies
        now support actions (e.g., `fs-backup` or `snapshot`) for fine-grained per-volume
        backup behavior.', Data mover pods can be node-selected via a ConfigMap to
        constrain where high-resource data movement runs., Restore VolumeInfo metadata
        is now captured and exposed in `velero restore describe` output., Restores
        add a `Finalizing` phase to fix ordering issues (PV label restore timing;
        post-restore hooks after data movement)., Azure now supports certificate-based
        service principal authentication for improved security posture.]
    breaking_changes: [Do not install the Velero CSI plugin separately anymore; it
        is merged into Velero and installed by default as an internal plugin in v1.14.,
      Node-agent pods no longer have default CPU/memory requests/limits; clusters
        relying on those must set them explicitly to avoid BestEffort scheduling/eviction
        behavior changes., 'Backup namespace selection changes when `includedNamespaces`/`excludedNamespaces`
        are empty but label selectors are set: only namespaces containing matching
        resources are included (previously all namespaces were included).', 'PV patching
        during the new Restore `Finalizing` phase can surface as `PartiallyFailed`
        (e.g., when PVs are stuck `Pending`) where earlier versions might report `Complete`.']
  chart_version: 7.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.14.1']
- version: 1.13.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Resource Modifiers enhanced to support JSON Merge Patch and Strategic
        Merge Patch in addition to JSON Patch, allowing more flexible restore-time
        mutations via a single ConfigMap.', Node-agent concurrency controls let you
        limit/shape how many filesystem backup/restore and CSI snapshot data movement
        jobs run per node (globally or per-node)., Kopia uploader gains tunables for
        parallel file uploads to speed up fs-backups and CSI snapshot data movement
        backups., Restores can optionally write sparse files during fs-restore or
        CSI snapshot data movement restores., "`velero backup describe` now includes\
        \ a dedicated \u201CBackup Volumes\u201D section and can display CSI snapshot\
        \ data movement details without relying on client-side CSI feature-gate checks.",
      'Backups now write a new VolumeInfo metadata file that records PV/PVC volume
        method, snapshot info, and status; this guides PV restore behavior and is
        consumable by downstream tooling.', Improved resilience of CSI snapshot data
        movement backup/restore so operations are less likely to get stuck when the
        Velero server pod or node-agent restarts under exceptional conditions., Hook
        execution status is now recorded in Backup/Restore CR status (HooksAttempted/HooksFailed)
        and surfaced in `velero backup/restore describe`., AWS SDK for Go bumped to
        v2 for improved CPU/memory performance versus v1., 'Azure AD/Workload Identity
        is now supported for Kopia operations (filesystem backup/data mover), extending
        earlier Azure plugin support.', 'Runtime/deps updated: Go 1.21.6 and Kopia
        0.15.0, plus dependency bumps for CVE fixes.']
    breaking_changes: ["`velero backup describe` output format changed: some existing\
        \ snapshot/fs-backup details moved into the new \u201CBackup Volumes\u201D\
        \ section, which may break scripts parsing the output.", 'API type change
        in DataUploadSpec: `DataMoverConfig` changed from `*map[string][string]` to
        `map[string]string`, which can break custom tooling or manifests relying on
        the old schema.', Informer cache is now enabled by default (previously disabled)
        to improve performance; this can increase memory usage and may require raising
        Velero pod memory limits or explicitly disabling the cache during install
        (`--disable-informer-cache`).]
  chart_version: 6.7.0
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.13.2']
- version: 1.12.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "### Helm chart / values changes to plan for\n\n- **Breaking: `configuration.backupStorageLocation`\
      \ and `configuration.volumeSnapshotLocation` change from map \u2192 list (slice)**\
      \ (Velero Helm chart **v4.0.0**).\n  - **Action before upgrade:** convert existing\
      \ values from:\n    - `configuration.backupStorageLocation: { <name>: {...}\
      \ }` to `configuration.backupStorageLocation: [ { name: <name>, ... } ]`\n \
      \   - `configuration.volumeSnapshotLocation: { <name>: {...} }` to `configuration.volumeSnapshotLocation:\
      \ [ { name: <name>, ... } ]`\n  - This is required even if you only have a single\
      \ BSL/VSL today.\n\n- **Installer default uploader changed** (Velero v1.12):\
      \ default `uploader-type` becomes **`kopia`** (was `restic`).\n  - In Helm this\
      \ typically maps to values that control **file system backup / node-agent uploader**\
      \ behavior (chart/value names vary by chart version).\n  - **Action:** if you\
      \ require Restic behavior for compatibility/operational reasons, explicitly\
      \ set uploader type to `restic`; otherwise validate Kopia prerequisites and\
      \ performance.\n\n- **CSI snapshot timeout behavior changed** (Velero v1.12):\
      \ snapshot wait time is no longer a fixed 10 minutes.\n  - **Action:** if you\
      \ rely on CSI snapshots, review and (if needed) set `backup.spec.csiSnapshotTimeout`\
      \ (new behavior) and ensure operation timeouts align with your environment;\
      \ default async readiness timeout is now **4h**."
    chart_updates: ['Helm chart v4.0.0 supports **multiple** BackupStorageLocations
        (BSL) and VolumeSnapshotLocations (VSL). As part of that, their configuration
        schema changed from a map to a list (not backward compatible).']
    features: ['CSI Snapshot Data Movement: ability to move CSI snapshot data into
        durable backup storage and restore across environments/clouds.', 'Resource
        Modifiers (JSON substitutions): apply JSON patch-style modifications to selected
        resources during restore without writing a custom RestoreItemAction plugin.',
      'Multiple VolumeSnapshotClasses support in the Velero CSI plugin: choose a specific
        VolumeSnapshotClass per backup instead of relying on a single labeled class.',
      'Restore finalizer: `velero restore delete` now also cleans up associated restore
        data in the backup storage location.', Metrics and controller enhancements
        around data upload/download and async operations (data mover).]
    breaking_changes: ['Default uploader type changes from `restic` to `kopia`, affecting
        file system backups unless you explicitly pin the uploader type.', 'CSI snapshot
        timing/timeout semantics changed: snapshot handle wait is configurable via
        `backup.spec.csiSnapshotTimeout`, and async readiness waits use operation
        timeouts (default 4h).', Helm chart v4.0.0 changes BSL/VSL values from map
        to list (slice); old values format will break upgrades unless migrated first.,
      "Velero CRs (restore/dataupload/datadownload) now have finalizers; deleting\
        \ the Velero namespace directly may hang\u2014use `velero uninstall` or handle\
        \ finalizers first."]
  chart_version: 5.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.12.3']
- version: 1.11.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary: null
  chart_version: 5.0.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.11.1']
- version: 1.10.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.9.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.8.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
