icon: https://velero.io/img/Velero.svg
git_url: https://github.com/vmware-tanzu/velero
release_url: https://github.com/vmware-tanzu/velero/releases/tag/v{vsn}
helm_repository_url: https://vmware-tanzu.github.io/helm-charts
versions:
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "## Helm values / install-time config changes to check\n\n### 1)\
      \ **Restic uploader removed (breaking)**\n* `--uploader-type=restic` is **no\
      \ longer valid** in v1.17.\n  * If your Helm chart values set anything equivalent\
      \ (commonly `configuration.uploaderType`, `uploaderType`, `deployRestic`, `deployNodeAgent`/`restic`\
      \ toggles, etc.), remove/disable Restic and use the current fs-backup path.\n\
      \  * You can **still restore old Restic-based backups until v1.19**, but you\
      \ cannot create new ones.\n\n### 2) **Repository maintenance job flags removed\
      \ from velero server (breaking)**\nThe following server parameters were removed\
      \ and must be configured via the **repository maintenance job ConfigMap** instead:\n\
      * `--keep-latest-maintenance-jobs`\n* `--maintenance-job-cpu-request`\n* `--maintenance-job-mem-request`\n\
      * `--maintenance-job-cpu-limit`\n* `--maintenance-job-mem-limit`\n\nIf you previously\
      \ set these via chart values that map to `server.extraArgs`, move them to the\
      \ chart\u2019s maintenance-job configmap values (name varies by chart).\n\n\
      ### 3) New/updated **node-agent** configuration knobs worth reviewing\nThese\
      \ are additive but may require Helm values if you want to use them:\n* `PrepareQueueLength`\
      \ (node-agent): throttles creation of data mover pods to avoid large numbers\
      \ stuck Pending.\n* `priorityClassName` support across modules (server, node-agent,\
      \ data mover pods, maintenance jobs): you may want to set these explicitly.\n\
      * Parameterized kubelet mount path for node-agent install (only if you run non-standard\
      \ kubelet paths).\n\n### 4) Modernized fs-backup (architecture change)\nfs-backup\
      \ is now micro-service based. In Helm terms this may translate into:\n* more/changed\
      \ pod templates for data mover / fs-backup components,\n* potential new configmaps/args\
      \ for concurrency/cancel/resume behavior.\n\n(Exact value keys depend on your\
      \ chart; validate rendered manifests before applying.)"
    chart_updates: ['fs-backup moved to a micro-service architecture (better concurrency
        control, cancel/resume, and resiliency across node-agent restarts).', 'Windows
        support expands: fs-backup now supports Windows workloads; data mover pods
        can run on Windows nodes with required tolerations.', Volume Group Snapshots
        support added (Kubernetes beta feature) for CSI snapshot backup and CSI snapshot
        data movement., 'PriorityClass support added across Velero components (server,
        node-agent, data mover pods, maintenance jobs).', 'Data mover scalability
        improvements: throttled pod creation via node-agent `PrepareQueueLength`,
        improved restart/orphan handling, expanded node-selection for restore and
        per-storageclass node-selection.', Resource policy enhanced with reusable
        include/exclude filters via `includeExcludePolicy`., 'Operational changes:
        repository maintenance job configuration moved from server flags to a ConfigMap;
        additional config validation added for install CLI and server start.']
    features: [Modernized fs-backup into a micro-service architecture with concurrency
        control plus cancel/resume and improved resiliency across node-agent restarts.,
      'fs-backup now supports Windows workloads, enabling full Windows backup/restore
        scenarios (with CSI data movement support introduced earlier).', Adds support
        for Kubernetes Volume Group Snapshots to take point-in-time consistent snapshots
        across multiple related volumes., 'Adds PriorityClass support so you can control
        scheduling priority for server, node-agent, data movers, and maintenance jobs.',
      'Improves data mover scalability with a node-agent prepare queue to avoid flooding
        the cluster with Pending pods, plus better restart/orphan handling and node-selection
        (including per-storageclass).', Adds reusable resource include/exclude filtering
        via `includeExcludePolicy` in resource policies.]
    breaking_changes: ["Restic uploader path is removed: `--uploader-type=restic`\
        \ is no longer a valid install configuration; you can\u2019t create new Restic-based\
        \ backups (restores remain supported until v1.19).", Repository maintenance
        job settings are no longer configured via Velero server flags; the maintenance
        job CPU/memory and keep-latest settings must be moved to the repository maintenance
        job ConfigMap., 'PVC restore behavior change: selected-node annotation is
        now removed during PVC restore when no node mapping exists (previously it
        could be preserved in some cases).']
  chart_version: 11.2.0
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "### Helm values / install-time changes to review\n\n- **Restic\
      \ is no longer a valid uploader type in 1.17**\n  - If your Helm values or `velero\
      \ install` args set `--uploader-type=restic` (or any equivalent chart value\
      \ that renders that arg), **remove it**.\n  - You can **still restore** from\
      \ existing Restic-based backups until **v1.19**, but you **cannot create new**\
      \ Restic-path backups in 1.17.\n\n- **Repository maintenance job settings moved\
      \ out of Velero server args**\n  - The following Velero server parameters are\
      \ **removed** in 1.17 and must not be set by the chart/values anymore:\n   \
      \ - `--keep-latest-maintenance-jobs`\n    - `--maintenance-job-cpu-request`\n\
      \    - `--maintenance-job-mem-request`\n    - `--maintenance-job-cpu-limit`\n\
      \    - `--maintenance-job-mem-limit`\n  - These settings are now expected to\
      \ be configured via the **repository maintenance job ConfigMap** (chart may\
      \ have new values to populate it).\n\n- **PriorityClass configuration is now\
      \ supported across components**\n  - If you need it, you can start setting PriorityClass\
      \ for **server**, **node-agent**, **data mover pods**, and **repository maintenance\
      \ jobs** separately (expect new chart values for these).\n\n- **Node-agent load\
      \ soothing / queueing (PrepareQueueLength)**\n  - There is a new node-agent\
      \ configuration knob `PrepareQueueLength` to prevent creating too many pending\
      \ data mover pods.\n  - Consider exposing it via chart values (if available)\
      \ for large-scale clusters.\n\n- **Kubelet mount path is parameterized for node-agent\
      \ install**\n  - If you previously relied on a non-standard kubelet root dir\
      \ and had custom hostPath mounts, check whether the chart now exposes a value\
      \ for kubelet mount path.\n\n- **Optional node-agent hostPath mount disable**\n\
      \  - 1.17 adds the ability to disable the pod volume hostPath mount for node-agent.\
      \ If your security posture disallows hostPath, review chart values for this\
      \ option.\n"
    chart_updates: ['Expect chart templates/values to change around repository maintenance
        job configuration: server args removed and replaced with a ConfigMap-driven
        configuration.', Chart may add new values to set PriorityClass names per component
        (server/node-agent/data movers/maintenance)., 'Chart may add or adjust node-agent
        configuration plumbing for new scaling knobs such as `PrepareQueueLength`,
        and for optional hostPath mount disable / kubelet mount path parameterization.']
    features: ['Modernized fs-backup to a micro-service architecture, improving robustness
        (resume/cancel), resource isolation, and steadier node-agent resource usage.',
      fs-backup now supports Windows workloads by allowing data mover pods to run
        on Windows nodes (complements 1.16 Windows support)., 'Adds support for Kubernetes
        Volume Group Snapshots (beta upstream), enabling crash-consistent point-in-time
        snapshots across multiple volumes.', 'PriorityClass support across Velero
        modules so you can prioritize server, node-agent, data movers, and maintenance
        jobs independently.', 'Scalability/resiliency improvements for data movers:
        queueing to limit pending pods, better resume/cancel behavior across restarts,
        and improved node selection for restores (including per-storage-class selection).',
      'Resource policy enhancements: `includeExcludePolicy` allows reusable include/exclude
        filters via a resource policy ConfigMap.']
    breaking_changes: ['Restic uploader path removed: `--uploader-type=restic` is
        no longer valid; new Restic-based fs-backups cannot be created (restores from
        old Restic backups still supported until v1.19).', Repository maintenance
        job configuration flags removed from `velero server`; any chart values rendering
        these args must be migrated to the maintenance job ConfigMap., 'PVC restore
        behavior change: Velero now always removes the `selected-node` annotation
        during PVC restore when no node mapping exists (previously it was preserved
        if the node existed).']
  chart_version: 11.3.1
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.16.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: ["No Helm chart changelog was provided in the notes you pasted,\
        \ so I can\u2019t call out chart-template or values.yaml changes specific\
        \ to the Velero Helm chart from these sources alone.", 'From the application
        notes, expect the chart to expose new/updated server flags and configmaps
        (node-agent config, backup-repository config, repository-maintenance config)
        if you choose to use the new 1.16 features; validate your chart version supports
        wiring these into Deployments/DaemonSets/Jobs.']
    features: ['Windows cluster support (hybrid images, scheduling node-agent/data
        mover/maintenance jobs on Windows nodes; data mover supports Windows workloads
        end-to-end).', Parallel Item Block backup with configurable concurrency via
        the new server flag `--item-block-worker-count` (default 1)., 'Data mover
        restore scalability improvement: for WaitForFirstConsumer volumes you can
        spread restores across nodes via new node-agent config `ignoreDelayBinding`.',
      Improved observability for data mover failures and cleanup issues via additional
        automatic node-agent log output., 'CSI snapshot backup/restore usability:
        stop retaining unnecessary VolumeSnapshotContent objects in backups, reducing
        cross-cluster sync/restore noise.', 'Backup repository maintenance improvements:
        maintenance history recorded on BackupRepository (`RecentMaintenance`), restart
        recapture of running jobs, and readOnly BSL protections; configurable kopia
        maintenance cadence via `fullMaintenanceInterval` (normalGC/fastGC/eagerGC).',
      VolumePolicy can now filter volumes by PVC labels., Per-object resource status
        restore control via annotation `velero.io/restore-status`., Velero restore
        helper binary is now included in the main Velero image (single image contains
        velero/velero-helper/velero-restore-helper).]
    breaking_changes: ['No explicit breaking changes were called out in the v1.16.0
        notes you pasted; however, behavior changes to be aware of include parallel
        item-block processing (different ordering/timing of hooks and backups) and
        removal of retained VolumeSnapshotContent from backups (may affect any downstream
        expectations/tools that relied on those objects being present).']
  chart_version: 10.1.3
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.16.2']
- version: 1.15.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Data mover micro service: CSI Snapshot Data Movement transfers run
        in dedicated backup/restore pods instead of node-agent pods, improving security
        (no hostPath), resource isolation, and resiliency.', "Item Block concepts\
        \ and ItemBlockAction (IBA) plugins: resources can be grouped into \u2018\
        item blocks\u2019 to enable future multi-threaded backups; built-in IBAs exist\
        \ for Pods and PVCs and custom IBAs are supported.", 'Node selection for repository
        maintenance jobs: repository maintenance can be scheduled onto selected nodes
        via a new repository maintenance configMap.', 'Backup PVC configuration for
        data mover: supports read-only mounting of backupPVCs (can speed up expose
        for some storage like Ceph) and setting a dedicated StorageClass for backupPVCs.',
      'Backup repository client-side cache size limit: configurable cache per repository
        via a new backup repository configuration configMap to avoid ephemeral-storage
        eviction.', 'Performance improvements: fixes a server memory leak after plugin
        calls; inherits client-qps/client-burst settings into plugins; includes upstream
        Kopia improvements for large-repository maintenance memory usage.', 'Operational
        improvements: additional labels on maintenance job pods and better handling/retries
        in various patch/state transitions.']
    breaking_changes: ['Restic is deprecated for filesystem backups: backups/restores
        still succeed but you will get warnings when using --uploader-type=restic
        or when Restic path is used; plan migration away from Restic.', "Node-agent\
        \ configMap name is no longer fixed: you must pass the node-agent configMap\
        \ name via the node-agent server parameter node-agent-configmap if you don\u2019\
        t use the default naming.", Repository maintenance job settings are moving
        from Velero server flags to a repository maintenance configuration configMap
        (the configMap takes precedence when both are set)., Changing PVC selected-node
        during restore is deprecated and will be removed in a future release; new
        usage is not recommended.]
  chart_version: 8.7.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.15.2']
- version: 1.14.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Repository maintenance for kopia/restic is moved out of the Velero
        server pod into separate Kubernetes Jobs, reducing Velero pod memory pressure
        and OOM risk.', 'VolumePolicies now support actions (e.g., `fs-backup` vs
        `snapshot`) to control how volumes are protected without modifying workloads.',
      Data movement backup pods (datamovers) can be constrained to specific eligible
        nodes via a ConfigMap-based node selection mechanism., Restore operations
        now persist VolumeInfo metadata for restored volumes and `velero restore describe`
        surfaces this additional volume-level detail., A new `Finalizing` restore
        phase was added to ensure PV labeling and post-restore hooks happen after
        volume restore/data movement completes., Azure authentication adds support
        for service principals using certificate-based auth in addition to client-secret
        auth.]
    breaking_changes: [CSI plugin is now merged into the main Velero repo and installed
        by default as an internal plugin; you should no longer install it via `--plugins`
        during `velero install`/Helm., 'Default resource requests/limits for the node-agent
        were removed, making node-agent pods BestEffort unless you set resources explicitly.',
      'Namespace filtering behavior changed: if `includedNamespaces`/`excludedNamespaces`
        are unset but label selectors are set, only namespaces containing matching
        resources are included (previously all namespaces were included).', "Restores\
        \ may now end `PartiallyFailed` when PV patching during the new Finalizing\
        \ phase can\u2019t proceed (e.g., PV stuck Pending), where older versions\
        \ might have reported `Complete`."]
  chart_version: 7.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.14.1']
- version: 1.13.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "### Helm chart / values changes to plan for\n*No Helm chart changelog\
      \ was provided in the notes you pasted.* However, **Velero v1.12 introduced\
      \ a Helm chart breaking change (chart v4.0.0)** that still affects anyone upgrading\
      \ from earlier chart versions:\n- **`configuration.backupStorageLocation` (BSL)\
      \ and `configuration.volumeSnapshotLocation` (VSL) changed from a map to a list/slice**\
      \ to support multiple BSLs/VSLs. This is **not backward compatible**.\n  - **Action:**\
      \ Before/while upgrading, convert single entries into a one-element list.\n\n\
      ### Install/upgrade CLI behavior that may impact Helm-based installs\n- **Informer\
      \ cache is enabled by default in v1.13** (flag default changed; previously effectively\
      \ disabled). This can increase memory usage.\n  - **Action:** ensure Velero\
      \ server pod memory limits are sufficient, or explicitly disable via `--disable-informer-cache`\
      \ (Helm values may expose an equivalent extraArgs/flags setting depending on\
      \ chart)."
    chart_updates: []
    features: ['Resource Modifiers now support JSON Merge Patch and Strategic Merge
        Patch in addition to JSON Patch, increasing flexibility for restore-time mutations.',
      Node-agent concurrency controls let you cap data-movement workloads per node
        (globally or per-node) to balance performance vs. cluster resource consumption.,
      Kopia parallel file upload options can speed up filesystem backups and CSI snapshot
        data movement by uploading files in parallel., 'Restore can optionally write
        sparse files for fs-restore and CSI snapshot data movement restores, reducing
        space/time for sparse data.', '`velero backup describe` now includes a Backup
        Volumes section and better CSI snapshot data movement visibility; hook execution
        details are now surfaced in CR status and describe output.', New per-backup
        `VolumeInfo` metadata is written to the backup repository to drive PV/PVC
        restore decisions and provide better volume-level summaries., Resilience improvements
        reduce the chance backups/restores get stuck if the Velero server pod or node-agent
        restarts mid-operation., AWS SDK for Go moved to v2 for better CPU/memory
        performance; Azure AD/Workload Identity is now supported for Kopia operations
        (fs backups/data mover) with the Azure plugin.]
    breaking_changes: ["`velero backup describe` output format changed: native snapshot/CSI\
        \ snapshot/fs-backup info moved into a new \u201CBackup Volumes\u201D section;\
        \ any scripts parsing output may break.", 'API change: `DataUploadSpec.DataMoverConfig`
        changed type from `*map[string]string` to `map[string]string` (clients/controllers
        that create DataUpload CRs must be updated).', 'Installer behavior: informer
        cache is now enabled by default, which can increase memory usage and may require
        raising Velero pod memory limits or explicitly disabling the cache.']
  chart_version: 6.7.0
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.13.2']
- version: 1.12.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "## Helm chart / values changes (Velero chart v4.0.0+)\n\n> **Key\
      \ action:** update your `values.yaml` **before** upgrading.\n\n- **`configuration.backupStorageLocation`\
      \ and `configuration.volumeSnapshotLocation` change type:**\n  - **Before:**\
      \ map/object\n  - **Now:** **slice/array** (to support **multiple BSLs and VSLs**).\n\
      \  - This is **not backwards compatible**; update your values to list format\
      \ prior to the upgrade.\n\nExample (illustrative):\n```yaml\nconfiguration:\n\
      \  backupStorageLocation:\n    - name: default\n      provider: aws\n      bucket:\
      \ my-bucket\n      # ...\n  volumeSnapshotLocation:\n    - name: default\n \
      \     provider: aws\n      # ...\n```\n\n- Review any automation/templates (Helmfile,\
      \ Kustomize overlays, CI pipelines) that assume BSL/VSL are maps; they will\
      \ break when indexing keys directly.\n"
    chart_updates: [Helm chart now supports configuring **multiple** BackupStorageLocations
        (BSLs) and VolumeSnapshotLocations (VSLs)., Associated schema/templates changed
        to reflect BSL/VSL being lists instead of maps (breaking for existing values).]
    features: ['CSI Snapshot Data Movement: enables moving CSI snapshot data to durable
        backup storage and restoring across environments/clouds via the data mover
        workflow.', 'Resource Modifiers (JSON substitutions): allows patching resources
        during restore using filter + JSON patch rules without writing a custom RestoreItemAction.',
      'Multiple VolumeSnapshotClasses support in CSI plugin: lets you choose a specific
        VolumeSnapshotClass per backup rather than relying on driver-name matching.',
      'Restore deletion finalizer: `velero restore delete` now cleans up restore-associated
        external data in the backup storage location. ', 'Dependency/runtime updates:
        Go runtime bumped to 1.20.7 and Kopia bumped to 0.13.x for security and compatibility.']
    breaking_changes: ['Default `uploader-type` changed from **restic** to **kopia**,
        affecting filesystem backup behavior and potentially performance/compatibility
        in your environment.', 'CSI snapshot timeout behavior changed: snapshot handle
        wait time is now `backup.spec.csiSnapshotTimeout` (not fixed 10m) and async
        ReadyToUse waits use operation timeout (default 4h).', Helm chart v4.0.0+
        changes BSL/VSL from map to slice to support multiple locations; you must
        migrate `values.yaml` accordingly before upgrading., 'Finalizers added to
        Velero CRs (e.g., Restore/DataUpload/DataDownload) can cause **namespace deletion
        to hang**; use `velero uninstall` or remove finalizers safely instead of deleting
        the namespace directly.']
  chart_version: 5.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.12.3']
- version: 1.11.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary: null
  chart_version: 5.0.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.11.1']
- version: 1.10.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.9.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.8.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
