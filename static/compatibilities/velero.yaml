icon: https://velero.io/img/Velero.svg
git_url: https://github.com/vmware-tanzu/velero
release_url: https://github.com/vmware-tanzu/velero/releases/tag/v{vsn}
helm_repository_url: https://vmware-tanzu.github.io/helm-charts
versions:
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Modernized fs-backup to a micro-service architecture, improving robustness
        (survives node-agent restarts), adding concurrency control, cancel/resume,
        and steadier resource usage.', fs-backup now supports Windows workloads by
        running data mover pods on Windows nodes., Added (beta) Kubernetes VolumeGroupSnapshot
        support for point-in-time consistent snapshots across multiple volumes (for
        CSI snapshot backup and CSI snapshot data movement)., 'PriorityClass support
        across Velero components (server, node-agent, data mover pods, repo maintenance
        jobs) for scheduling control.', 'Scalability/resiliency improvements for data
        movers: configurable PrepareQueueLength to prevent excessive Pending pods;
        resume/cancel behavior across node-agent restarts; node selection for restore
        and per-storage-class node selection.', Resource policy now supports reusable
        include/exclude filters via includeExcludePolicy in addition to volumePolicy.,
      'Operational improvements: BSL availability metric and stronger BSL status checking
        for backup/restore; imagePullSecrets inheritance for data mover/maintenance
        job; various CSI/restore correctness fixes and documentation updates.']
    breaking_changes: ['Restic deprecation enforced: `--uploader-type=restic` is no
        longer valid in v1.17 (cannot create new restic-path backups). Restores from
        older restic backups are supported only until v1.19.', 'Repository maintenance
        job settings removed from Velero server flags (must be configured via the
        maintenance job ConfigMap instead): `--keep-latest-maintenance-jobs`, `--maintenance-job-*-request/limit`
        flags are removed.', 'Behavior change: during PVC restore, Velero always removes
        the `selected-node` annotation when no node mapping exists (previously it
        was preserved if the node existed).']
  chart_version: 11.3.2
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "## Helm values / install-time config changes to check\n\n### 1)\
      \ **Restic uploader removed (breaking)**\n* `--uploader-type=restic` is **no\
      \ longer valid** in v1.17.\n  * If your Helm chart values set anything equivalent\
      \ (commonly `configuration.uploaderType`, `uploaderType`, `deployRestic`, `deployNodeAgent`/`restic`\
      \ toggles, etc.), remove/disable Restic and use the current fs-backup path.\n\
      \  * You can **still restore old Restic-based backups until v1.19**, but you\
      \ cannot create new ones.\n\n### 2) **Repository maintenance job flags removed\
      \ from velero server (breaking)**\nThe following server parameters were removed\
      \ and must be configured via the **repository maintenance job ConfigMap** instead:\n\
      * `--keep-latest-maintenance-jobs`\n* `--maintenance-job-cpu-request`\n* `--maintenance-job-mem-request`\n\
      * `--maintenance-job-cpu-limit`\n* `--maintenance-job-mem-limit`\n\nIf you previously\
      \ set these via chart values that map to `server.extraArgs`, move them to the\
      \ chart\u2019s maintenance-job configmap values (name varies by chart).\n\n\
      ### 3) New/updated **node-agent** configuration knobs worth reviewing\nThese\
      \ are additive but may require Helm values if you want to use them:\n* `PrepareQueueLength`\
      \ (node-agent): throttles creation of data mover pods to avoid large numbers\
      \ stuck Pending.\n* `priorityClassName` support across modules (server, node-agent,\
      \ data mover pods, maintenance jobs): you may want to set these explicitly.\n\
      * Parameterized kubelet mount path for node-agent install (only if you run non-standard\
      \ kubelet paths).\n\n### 4) Modernized fs-backup (architecture change)\nfs-backup\
      \ is now micro-service based. In Helm terms this may translate into:\n* more/changed\
      \ pod templates for data mover / fs-backup components,\n* potential new configmaps/args\
      \ for concurrency/cancel/resume behavior.\n\n(Exact value keys depend on your\
      \ chart; validate rendered manifests before applying.)"
    chart_updates: ['fs-backup moved to a micro-service architecture (better concurrency
        control, cancel/resume, and resiliency across node-agent restarts).', 'Windows
        support expands: fs-backup now supports Windows workloads; data mover pods
        can run on Windows nodes with required tolerations.', Volume Group Snapshots
        support added (Kubernetes beta feature) for CSI snapshot backup and CSI snapshot
        data movement., 'PriorityClass support added across Velero components (server,
        node-agent, data mover pods, maintenance jobs).', 'Data mover scalability
        improvements: throttled pod creation via node-agent `PrepareQueueLength`,
        improved restart/orphan handling, expanded node-selection for restore and
        per-storageclass node-selection.', Resource policy enhanced with reusable
        include/exclude filters via `includeExcludePolicy`., 'Operational changes:
        repository maintenance job configuration moved from server flags to a ConfigMap;
        additional config validation added for install CLI and server start.']
    features: [Modernized fs-backup into a micro-service architecture with concurrency
        control plus cancel/resume and improved resiliency across node-agent restarts.,
      'fs-backup now supports Windows workloads, enabling full Windows backup/restore
        scenarios (with CSI data movement support introduced earlier).', Adds support
        for Kubernetes Volume Group Snapshots to take point-in-time consistent snapshots
        across multiple related volumes., 'Adds PriorityClass support so you can control
        scheduling priority for server, node-agent, data movers, and maintenance jobs.',
      'Improves data mover scalability with a node-agent prepare queue to avoid flooding
        the cluster with Pending pods, plus better restart/orphan handling and node-selection
        (including per-storageclass).', Adds reusable resource include/exclude filtering
        via `includeExcludePolicy` in resource policies.]
    breaking_changes: ["Restic uploader path is removed: `--uploader-type=restic`\
        \ is no longer a valid install configuration; you can\u2019t create new Restic-based\
        \ backups (restores remain supported until v1.19).", Repository maintenance
        job settings are no longer configured via Velero server flags; the maintenance
        job CPU/memory and keep-latest settings must be moved to the repository maintenance
        job ConfigMap., 'PVC restore behavior change: selected-node annotation is
        now removed during PVC restore when no node mapping exists (previously it
        could be preserved in some cases).']
  chart_version: 11.2.0
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.16.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Windows cluster support: Velero can run in Windows clusters and back
        up/restore Windows workloads; node-agent, data mover pods, and maintenance
        jobs can schedule onto Windows nodes using a hybrid/all-in-one image.', 'Parallel
        ItemBlock backup: backup engine can process item blocks concurrently via a
        worker pool, configurable with `--item-block-worker-count` (default 1), improving
        backup throughput.', 'Data mover restore scaling for WaitForFirstConsumer
        volumes: optional `ignoreDelayBinding` in node-agent config lets restores
        spread across nodes instead of being pinned to the attachment node.', 'Improved
        data mover observability: node-agent logs now include intermediate object
        statuses and cleanup deletion errors automatically.', 'CSI snapshot usability
        improvement: VolumeSnapshotContent is no longer unnecessarily retained/synced/restored
        with backups, reducing cross-cluster noise.', 'BackupRepository maintenance
        improvements: maintenance history (`RecentMaintenance`) added to BackupRepository
        CR; jobs are recaptured after server restarts; maintenance/init suppressed
        for read-only BSLs; configurable kopia GC cadence via `fullMaintenanceInterval`
        (normalGC/fastGC/eagerGC).', 'Volume Policy enhancement: filter volumes by
        PVC labels.', 'Per-object restore status control: annotate objects with `velero.io/restore-status`
        to restore or skip status per object.', 'Velero restore helper merged into
        main image: `velero`, `velero-helper`, and `velero-restore-helper` are shipped
        in one image.', 'CLI supports `--annotations` for backup/restore create to
        tag resources. ']
    breaking_changes: []
  chart_version: 10.1.3
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.16.2']
- version: 1.15.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Data mover micro service moves CSI snapshot data movement from node-agent
        to dedicated per-backup/restore pods, improving security (no hostPath), isolation,
        and tunable resources.', Item Block concepts and new ItemBlockAction (IBA)
        plugin type to group correlated resources for future concurrent backup processing;
        built-in IBAs for Pods and PVCs (multi-thread execution not yet enabled).,
      Node selection for repository maintenance jobs via a new repo maintenance configMap
        so you can schedule heavy maintenance on specific/idle nodes., 'BackupPVC
        configuration via configMap: support read-only mounting (can speed expose
        on some storage like Ceph) and selecting a different StorageClass for backupPVCs.',
      Backup repository cache limit configuration via a new configMap to cap client-side
        cache usage and avoid ephemeral-storage eviction., 'Performance fixes: plugin-call
        memory leak fixed; server client-qps/burst inherited by plugins; kopia upstream
        improvements reduce maintenance memory usage.']
    breaking_changes: ['Restic uploader path is deprecated starting 1.15: backups/restores
        still work but emit warnings when restic is selected/used; plan migration
        toward kopia.', Node-agent configMap name is no longer fixed; if you use a
        custom configMap you must pass `--node-agent-configmap` to the node-agent.,
      Repository maintenance job tuning flags are moved to a repository maintenance
        job configMap; existing server flags still work but configMap values take
        precedence and are recommended., Changing PVC selected-node feature is deprecated
        in 1.15 and will be removed in a future release; avoid relying on it., Read-only
        backupPVC has a known SELinux limitation; enabling the workaround may require
        running a super-privileged container which can conflict with Pod Security
        Admission policies.]
  chart_version: 8.7.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.15.2']
- version: 1.14.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "### Helm/installation values & flags to review (v1.13 \u2192 v1.14)\n\
      - **CSI plugin install behavior changed (breaking):** CSI plugin is now **built-in**\
      \ to Velero in v1.14 and is installed by default as an internal plugin. **Remove**\
      \ any `--plugins .../velero-plugin-for-csi` from `velero install` / Helm chart\
      \ plugin lists to avoid duplicate/conflicting plugin installs.\n- **Node-agent\
      \ resources (breaking):** v1.14 **removes default resource requests/limits**\
      \ for the node-agent, making pods `BestEffort`. If you rely on guaranteed/burstable\
      \ QoS or want predictable scheduling, **set explicit `resources.requests/limits`\
      \ for node-agent** in Helm values.\n- **Repository maintenance jobs (new):**\
      \ maintenance for kopia/restic repositories now runs in **separate Kubernetes\
      \ Jobs** to avoid OOM in the main velero pod. Ensure your chart values cover:\n\
      \  - resource requests/limits for these maintenance Jobs (if exposed by the\
      \ chart)\n  - any PodSecurity/PSA, node selectors, tolerations, and RBAC constraints\
      \ that might block Job creation.\n- **Data mover node selection (new):** v1.14\
      \ adds node selection for datamover pods via a ConfigMap. If you need to constrain\
      \ where data movement runs, plan to **create/manage that ConfigMap** and ensure\
      \ Helm does not overwrite it unexpectedly.\n"
    chart_updates: [CSI plugin is now shipped/installed as an internal plugin by default;
        external CSI plugin installation should be removed to prevent duplicate plugin
        loading., Node-agent pods no longer get default resource requests/limits;
        clusters with strict scheduling/quotas may require you to define them explicitly.,
      'Repository maintenance now uses Jobs; clusters with restrictive policies (PSA,
        quotas, restricted namespaces) must allow Job creation and resources for these
        Jobs.', Restore workflow includes a new `Finalizing` phase; monitoring/alerting
        and runbooks that assume restore phases should be updated., Namespace filtering
        semantics change when label selectors are used without explicit include/exclude
        namespaces; backup selection expectations/tests should be updated.]
    features: [Moves kopia/restic repository maintenance out of the velero server
        pod into dedicated Kubernetes Jobs to reduce OOM risk and let you tune resources.,
      'Extends VolumePolicies to allow choosing per-volume actions (e.g., `fs-backup`
        vs `snapshot`) for finer-grained volume handling without changing workloads.',
      Adds node selection controls for data mover (datamover) pods via a ConfigMap
        so heavy backup/restore workloads can be constrained to specific nodes., Persists
        VolumeInfo metadata for restores and enhances `velero restore describe` output
        for better visibility into how volumes were restored., Introduces a Restore
        `Finalizing` phase to ensure PV label restoration and post-restore hooks occur
        after data movement completes., Adds Azure service principal certificate-based
        authentication support for more phishing-resistant Azure auth flows.]
    breaking_changes: [CSI plugin is now merged into the Velero repo and installed
        by default as an internal plugin; do not install the CSI plugin via `--plugins`
        (or equivalent Helm plugin lists)., 'Default resource requests/limits for
        node-agent are removed; node-agent pods become `BestEffort` unless you set
        explicit resources, which may affect scheduling and reliability under contention.',
      'Backup namespace filtering behavior changes when `labelSelector`/`orLabelSelectors`
        are set and `includedNamespaces`/`excludedNamespaces` are omitted: namespaces
        with no selected items are excluded (previously all namespaces were included).',
      'Restore workflow phase changes: patching PVs in the new `Finalizing` phase
        can result in restores ending `PartiallyFailed` in cases where previously
        they might have been `Complete` (e.g., PV blocked Pending).']
  chart_version: 7.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.14.1']
- version: 1.13.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Resource Modifiers enhanced: in addition to JSON Patch (added in 1.12),
        1.13 adds JSON Merge Patch and Strategic Merge Patch for more flexible restore-time
        mutations.', 'Node-agent concurrency controls let you cap/shape how many filesystem
        backup / CSI snapshot data-mover activities run per node, reducing resource
        contention.', Kopia parallel file upload tuning options can speed up filesystem
        backups and CSI snapshot data movement., Sparse file restore option for fs-restore
        and CSI snapshot data movement reduces space usage and can improve restore
        performance in some filesystems., "`velero backup describe` now includes a\
        \ dedicated \u201CBackup Volumes\u201D section and better reporting for CSI\
        \ snapshot data movement.", Backups now include a new VolumeInfo metadata
        file in the repository that records PV/PVC volume backup method/snapshot/status
        and guides PV restore behavior., Improved resiliency so backups/restores are
        less likely to get stuck if velero server pods or node-agent pods restart
        mid-operation., Hook execution details are now surfaced in Backup/Restore
        CR status (HooksAttempted/HooksFailed) and shown in describe output., AWS
        SDK for Go bumped to v2 for better CPU/memory performance., 'Azure AD/Workload
        Identity support extended to Kopia operations (filesystem backup/data mover),
        not just native snapshots.', 'Runtime/deps updated: Go 1.21.6 and Kopia 0.15.0.']
    breaking_changes: ['`velero backup describe` output format changed; some existing
        snapshot/fs-backup details moved into the new Backup Volumes section, which
        may break scripts parsing the old output.', 'API change: `DataUploadSpec.DataMoverConfig`
        type changed from `*map[string]string` to `map[string]string`; any clients/controllers
        using this field must be updated/recompiled.', 'Installer behavior change:
        informer cache is now enabled by default; this can increase memory usage and
        may require raising Velero pod memory limits or explicitly disabling with
        `--disable-informer-cache`.']
  chart_version: 6.7.0
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.13.2']
- version: 1.12.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "## Helm chart impact (Velero chart v4.x)\n\n- **BackupStorageLocation\
      \ (BSL) and VolumeSnapshotLocation (VSL) values format change (breaking)**:\
      \ starting with **Helm chart v4.0.0**, `configuration.backupStorageLocation`\
      \ and `configuration.volumeSnapshotLocation` **changed from a map/object to\
      \ a list (slice/array)** to support **multiple BSLs/VSLs**. This is **not backward\
      \ compatible**.\n  - **Action**: convert existing single BSL/VSL configs to\
      \ arrays *before* upgrading.\n  - **What to look for**: any values like:\n \
      \   - `configuration.backupStorageLocation: { name: default, bucket: ..., config:\
      \ ... }`\n    - should become:\n    - `configuration.backupStorageLocation:\
      \ [ { name: default, bucket: ..., config: ... } ]`\n\n- **Uploader default changed**:\
      \ `uploader-type` default is now **kopia** (was **restic**).\n  - **Action**:\
      \ explicitly set `configuration.uploaderType` / install arg equivalent (chart\
      \ value depends on your chart) if you need to keep restic behavior for compatibility/operations.\n\
      \n- **CSI snapshot timeout knobs changed** (app-level, but may be exposed via\
      \ chart values/extraArgs):\n  - `backup.spec.csiSnapshotTimeout` now controls\
      \ sync wait for snapshot handle creation (was fixed at 10m).\n  - async wait\
      \ for `VolumeSnapshot` / `VolumeSnapshotContent` `ReadyToUse` uses the operation\
      \ timeout (default 4h).\n  - **Action**: review any existing snapshot timeout\
      \ assumptions/overrides and set explicit values if you have large/slow storage\
      \ backends.\n\n- **Namespace deletion/uninstall process**: new finalizers can\
      \ cause `kubectl delete ns velero` to hang.\n  - **Action**: prefer `velero\
      \ uninstall` (or clean up CRs/finalizers) during teardown procedures; ensure\
      \ controllers are running when deleting restores/uploads/downloads.\n"
    chart_updates: [Velero Helm chart v4.0.0+ supports **multiple** BackupStorageLocations
        (BSL) and VolumeSnapshotLocations (VSL)., Values schema for BSL/VSL changed
        from **map** to **slice** (breaking / not backward compatible).]
    features: ['CSI Snapshot Data Movement: move CSI snapshot data into durable backup
        storage and restore it later, enabling long-term retention and cross-cloud
        restores.', 'Resource Modifiers (JSON substitutions): apply JSON patches during
        restore for common changes like namespace/storageClass without writing custom
        RestoreItemAction plugins.', 'Multiple VolumeSnapshotClasses: choose a specific
        VolumeSnapshotClass per backup instead of relying on driver-name + label selection.',
      'Restore deletion finalizer: `velero restore delete` now also cleans up restore-associated
        data in the backup storage location.']
    breaking_changes: ['Default `uploader-type` changed from `restic` to `kopia`,
        which can affect filesystem backup behavior and operational expectations if
        you relied on restic defaults.', 'CSI snapshot timing/timeout behavior changed:
        snapshot handle creation uses `backup.spec.csiSnapshotTimeout`, and ReadyToUse
        waits use operation timeouts (default 4h).', Helm chart v4.0.0 values for
        BSL/VSL changed from map to list (not backward compatible); you must migrate
        values before upgrading., 'Finalizers on Velero CRs (e.g., restore/dataupload/datadownload)
        can cause Velero namespace deletion to hang if controllers are removed before
        finalizers are processed; use `velero uninstall` or remove finalizers safely.']
  chart_version: 5.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.12.3']
- version: 1.11.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary: null
  chart_version: 5.0.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.11.1']
- version: 1.10.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.9.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.8.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
