icon: https://velero.io/img/Velero.svg
git_url: https://github.com/vmware-tanzu/velero
release_url: https://github.com/vmware-tanzu/velero/releases/tag/v{vsn}
helm_repository_url: https://vmware-tanzu.github.io/helm-charts
versions:
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Modernized file-system backup (fs-backup) to a micro-service architecture,
        enabling concurrency control, cancel/resume, better robustness across node-agent
        restarts, and steadier resource usage.', 'Windows support for fs-backup: data
        mover pods can run on Windows nodes to back up/restore Windows volumes, complementing
        CSI snapshot data movement support.', 'Volume Group Snapshots support (Kubernetes
        beta) for CSI snapshot backup and CSI snapshot data movement, enabling crash-consistent,
        write-order-consistent snapshots across multiple volumes.', 'PriorityClass
        support across Velero components (server, node-agent, data mover pods, and
        maintenance jobs) so you can control scheduling priority.', 'Scalability/resiliency
        improvements for data movers: configurable prepare queue length to avoid excessive
        pending pods, improved restart/orphan handling, and restore node-selection
        (including per storage class).', 'Resource policy enhancement: reusable include/exclude
        filters via includeExcludePolicy in resource policy ConfigMaps.', 'Operational
        enhancements: BSL availability gauge metric, better BSL status checks during
        backup/restore, imagePullSecrets inheritance for data mover/maintenance jobs,
        parameterized kubelet mount path, and third-party tolerations for data mover
        pods.']
    breaking_changes: ['Restic uploader path removed: `--uploader-type=restic` is
        no longer valid for new installs/backups; restores from existing Restic-based
        backups are supported only until v1.19.', 'Repository maintenance job settings
        removed from Velero server flags; you must configure them via the repository
        maintenance job ConfigMap instead (flags like `--keep-latest-maintenance-jobs`,
        `--maintenance-job-*-request/limit` are gone).', 'PVC restore behavior change:
        selected-node annotation is always removed when no node mapping exists (previously
        it could be preserved if the node existed).']
  chart_version: 11.3.2
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "## Helm values / install-time config changes to check\n\n### 1)\
      \ **Restic uploader removed (breaking)**\n* `--uploader-type=restic` is **no\
      \ longer valid** in v1.17.\n  * If your Helm chart values set anything equivalent\
      \ (commonly `configuration.uploaderType`, `uploaderType`, `deployRestic`, `deployNodeAgent`/`restic`\
      \ toggles, etc.), remove/disable Restic and use the current fs-backup path.\n\
      \  * You can **still restore old Restic-based backups until v1.19**, but you\
      \ cannot create new ones.\n\n### 2) **Repository maintenance job flags removed\
      \ from velero server (breaking)**\nThe following server parameters were removed\
      \ and must be configured via the **repository maintenance job ConfigMap** instead:\n\
      * `--keep-latest-maintenance-jobs`\n* `--maintenance-job-cpu-request`\n* `--maintenance-job-mem-request`\n\
      * `--maintenance-job-cpu-limit`\n* `--maintenance-job-mem-limit`\n\nIf you previously\
      \ set these via chart values that map to `server.extraArgs`, move them to the\
      \ chart\u2019s maintenance-job configmap values (name varies by chart).\n\n\
      ### 3) New/updated **node-agent** configuration knobs worth reviewing\nThese\
      \ are additive but may require Helm values if you want to use them:\n* `PrepareQueueLength`\
      \ (node-agent): throttles creation of data mover pods to avoid large numbers\
      \ stuck Pending.\n* `priorityClassName` support across modules (server, node-agent,\
      \ data mover pods, maintenance jobs): you may want to set these explicitly.\n\
      * Parameterized kubelet mount path for node-agent install (only if you run non-standard\
      \ kubelet paths).\n\n### 4) Modernized fs-backup (architecture change)\nfs-backup\
      \ is now micro-service based. In Helm terms this may translate into:\n* more/changed\
      \ pod templates for data mover / fs-backup components,\n* potential new configmaps/args\
      \ for concurrency/cancel/resume behavior.\n\n(Exact value keys depend on your\
      \ chart; validate rendered manifests before applying.)"
    chart_updates: ['fs-backup moved to a micro-service architecture (better concurrency
        control, cancel/resume, and resiliency across node-agent restarts).', 'Windows
        support expands: fs-backup now supports Windows workloads; data mover pods
        can run on Windows nodes with required tolerations.', Volume Group Snapshots
        support added (Kubernetes beta feature) for CSI snapshot backup and CSI snapshot
        data movement., 'PriorityClass support added across Velero components (server,
        node-agent, data mover pods, maintenance jobs).', 'Data mover scalability
        improvements: throttled pod creation via node-agent `PrepareQueueLength`,
        improved restart/orphan handling, expanded node-selection for restore and
        per-storageclass node-selection.', Resource policy enhanced with reusable
        include/exclude filters via `includeExcludePolicy`., 'Operational changes:
        repository maintenance job configuration moved from server flags to a ConfigMap;
        additional config validation added for install CLI and server start.']
    features: [Modernized fs-backup into a micro-service architecture with concurrency
        control plus cancel/resume and improved resiliency across node-agent restarts.,
      'fs-backup now supports Windows workloads, enabling full Windows backup/restore
        scenarios (with CSI data movement support introduced earlier).', Adds support
        for Kubernetes Volume Group Snapshots to take point-in-time consistent snapshots
        across multiple related volumes., 'Adds PriorityClass support so you can control
        scheduling priority for server, node-agent, data movers, and maintenance jobs.',
      'Improves data mover scalability with a node-agent prepare queue to avoid flooding
        the cluster with Pending pods, plus better restart/orphan handling and node-selection
        (including per-storageclass).', Adds reusable resource include/exclude filtering
        via `includeExcludePolicy` in resource policies.]
    breaking_changes: ["Restic uploader path is removed: `--uploader-type=restic`\
        \ is no longer a valid install configuration; you can\u2019t create new Restic-based\
        \ backups (restores remain supported until v1.19).", Repository maintenance
        job settings are no longer configured via Velero server flags; the maintenance
        job CPU/memory and keep-latest settings must be moved to the repository maintenance
        job ConfigMap., 'PVC restore behavior change: selected-node annotation is
        now removed during PVC restore when no node mapping exists (previously it
        could be preserved in some cases).']
  chart_version: 11.2.0
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.16.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: [Windows cluster support for running Velero components on Windows nodes
        and backing up/restoring Windows workloads (with noted limitations around
        fs-backup and NTFS security metadata)., 'Parallel ItemBlock backup processing
        to improve backup throughput, configurable via the new `--item-block-worker-count`
        server parameter.', 'Data mover restore scalability improvement: optional
        spreading of restores for WaitForFirstConsumer volumes across nodes via node-agent
        `ignoreDelayBinding` setting.', Improved observability for data mover by logging
        intermediate object statuses and cleanup failures in node-agent logs., CSI
        snapshot usability improvement by excluding unnecessary retained `VolumeSnapshotContent`
        objects from backups to prevent syncing/restoring them across clusters., 'BackupRepository
        maintenance resiliency/observability improvements: maintenance history on
        BackupRepository CRs, recapture running jobs after server restart, and honoring
        readOnly BackupStorageLocations; configurable maintenance cadence via `fullMaintenanceInterval`
        (normalGC/fastGC/eagerGC).', 'Volume Policy enhancement: filter volumes by
        PVC labels.', Object-level control of restoring resource status via `velero.io/restore-status`
        annotation., 'Velero restore helper binaries merged into the main Velero image
        (single image contains velero, velero-helper, velero-restore-helper).']
    breaking_changes: []
  chart_version: 10.1.3
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.16.2']
- version: 1.15.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Data mover micro service: CSI Snapshot Data Movement now runs in dedicated
        backup/restore pods instead of node-agent, improving security (no hostPath),
        resource control per operation, and resiliency.', Item Block concepts and
        new ItemBlockAction (IBA) plugin type to group related resources for future
        concurrent backups; built-in IBAs for Pods and PVCs (multi-threading not yet
        enabled)., Configurable node selection for repository maintenance jobs via
        new configMap to steer maintenance workloads to specific/idle nodes., 'Backup
        PVC configuration via new configMap: support read-only mounts (can speed up
        expose for some storage like Ceph) and configurable storageClass for backupPVCs.',
      Backup repository client-side cache size limit per repository via new configMap
        to avoid ephemeral storage exhaustion/evictions., 'Performance improvements:
        fix plugin-call memory leak, pass client QPS/burst settings to plugins automatically,
        and Kopia upstream fixes for high-memory maintenance scenarios.']
    breaking_changes: ['Restic uploader path is deprecated starting in 1.15: backups/restores
        still work but emit warnings when `--uploader-type=restic` is used or restic
        path is exercised; plan migration to Kopia.', 'node-agent configMap name is
        no longer fixed; if you use a custom node-agent config, you must pass `--node-agent-configmap=<name>`
        (or the Helm equivalent).', Repository maintenance job settings move from
        Velero server flags to a dedicated repository maintenance configMap; configMap
        values take precedence when both are set., Changing PVC selected-node feature
        is deprecated and should not be relied on; expect removal in a future release.,
      Read-only backup PVC has a known SELinux limitation; enabling the workaround
        runs a highly privileged container (may conflict with Pod Security Admission
        policies).]
  chart_version: 8.7.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.15.2']
- version: 1.14.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Repository maintenance (kopia/restic) now runs in separate Kubernetes
        Jobs to avoid Velero server pod OOM during maintenance, and lets you set job
        resource requests during install.', 'VolumePolicies now support actions beyond
        skipping volumes: you can force per-volume backup method (e.g., `fs-backup`
        vs `snapshot`) for finer-grained control without changing workloads.', 'Data
        mover backups can be constrained to eligible nodes via a ConfigMap, allowing
        you to control placement of long-running, resource-heavy datamover pods.',
      Restore operations now persist VolumeInfo metadata similar to backup VolumeInfo;
        `velero restore describe` shows richer per-volume details., Restores gain
        a new `Finalizing` phase so PV label restoration and post-restore hooks happen
        after volume data movement/snapshot restore completes., 'Azure plugin adds
        certificate-based service principal authentication, in addition to secret-based
        SP auth.', 'Dependencies updated: Go 1.22.2 and Kopia 0.17.0; Azure storage
        SDK migrated to newer `azblob` library.']
    breaking_changes: [CSI plugin code is merged into the core Velero repo and installed
        by default as an internal plugin; you must stop installing the CSI plugin
        via the `--plugins` parameter during `velero install`., 'Default resource
        requests/limits for the node-agent are removed, making node-agent pods BestEffort
        by default; you likely need to set explicit requests/limits if you relied
        on the old defaults for scheduling or stability.', 'Namespace filtering behavior
        changes when `includedNamespaces`/`excludedNamespaces` are unset but `labelSelector`/`orLabelSelectors`
        are set: only namespaces containing matching resources are backed up (previously
        all namespaces were included).', 'PV patching in the new Restore `Finalizing`
        phase can cause restores to end `PartiallyFailed` if a PV is blocked in `Pending`,
        whereas previous versions might have reported `Complete`.']
  chart_version: 7.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.14.1']
- version: 1.13.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Resource Modifiers now support JSON Merge Patch and Strategic Merge
        Patch in addition to JSON Patch, enabling more flexible restore-time mutations
        using the same ConfigMap rules.', Node-agent concurrency controls let you
        limit data-movement (fs-backups and CSI snapshot data mover) loads per node
        globally and/or per-node to manage CPU/memory/network usage., Kopia parallel
        file upload options are now configurable to speed up filesystem backups and
        CSI snapshot data movement uploads., 'Restores can optionally write sparse
        files for fs-restore and CSI snapshot data movement restores, reducing space/time
        for sparse disk images where supported.', "`velero backup describe` now includes\
        \ a dedicated \u201CBackup Volumes\u201D section covering native snapshots,\
        \ fs-backups, CSI snapshots, and CSI snapshot data movement; it also shows\
        \ CSI info regardless of the EnableCSI feature gate on the client side.",
      'Backups now write a new VolumeInfo metadata file in the repository to record
        PVC/PV backup method, snapshot info, and status; this metadata is used to
        determine PV restore behavior and can be consumed by downstream tooling.',
      'Improved resilience for CSI snapshot data movement and other operations when
        Velero server pods or node-agents restart, reducing chances of stuck/Interrupted
        workflows.', 'Backup/restore CR status now tracks hook execution details (HooksAttempted,
        HooksFailed) and `describe` surfaces this information.', 'AWS SDK for Go was
        bumped to v2, improving CPU/memory utilization for AWS interactions.', Azure
        AD/Workload Identity support is extended to Kopia operations (filesystem backup/data
        mover/etc.) when using the Azure plugin., 'Runtime/dependency bumps: Go 1.21.6
        and Kopia 0.15.0 plus various library updates for CVE fixes.']
    breaking_changes: ["`velero backup describe` output format changed: several existing\
        \ snapshot/fs-backup fields were moved into the new \u201CBackup Volumes\u201D\
        \ section and may require updates to scripts/parsers.", 'API type change:
        `DataMoverConfig` in `DataUploadSpec` changed from `*map[string]string` to
        `map[string]string`, which can break clients/controllers expecting a pointer
        or nullability semantics.', '`velero install` behavior change: informer cache
        is now enabled by default (previously effectively disabled), which can increase
        memory usage and may require raising Velero pod memory limits or explicitly
        disabling it.']
  chart_version: 6.7.0
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.13.2']
- version: 1.12.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "- **Helm chart v4.0.0+ breaking change:** `configuration.backupStorageLocation`\
      \ (BSL) and `configuration.volumeSnapshotLocation` (VSL) values changed from\
      \ **map/object** to **slice/array** to support multiple locations. This is **not\
      \ backward-compatible**; convert your values to arrays **before** upgrading.\n\
      - **Uploader default changes:** Velero\u2019s default `uploader-type` changed\
      \ from **`restic`** to **`kopia`** in v1.12. If your chart values or install\
      \ args relied on the implicit default, decide whether to:\n  - explicitly set\
      \ `uploaderType: restic` (or the equivalent chart value/extraArgs), or\n  -\
      \ accept the new default and ensure Kopia repositories/permissions are configured.\n"
    chart_updates: [Introduces/aligns with Velero Helm chart v4.0.0 which supports
        multiple BackupStorageLocations (BSL) and VolumeSnapshotLocations (VSL) and
        changes their values schema from map to list., Expect CRDs/controllers to
        include additional resources around data movement (DataUpload/DataDownload)
        and restore finalizers; ensure your chart upgrade includes CRD updates where
        applicable. (Exact CRD handling depends on your deployment method.)]
    features: ['CSI Snapshot Data Movement: move CSI snapshot data from production/volatile
        storage to durable backup storage and restore across environments/clouds.',
      'Resource Modifiers (JSON substitutions): apply JSON patches to selected resources
        during restore without writing a custom RestoreItemAction plugin.', 'Multiple
        VolumeSnapshotClasses: choose a specific VolumeSnapshotClass per backup instead
        of relying on driver-name/label selection.', 'Restore finalizer: `velero restore
        delete` now cleans up associated restore data in the backup storage location
        instead of only deleting the Kubernetes Restore object.', 'Runtime/dependencies
        updated (Go 1.20.7, Kopia 0.13.x and other libs) to address CVEs and stay
        current.']
    breaking_changes: [Default uploader-type changed from `restic` to `kopia`; existing
        environments that assumed restic by default may see different repository behavior
        and requirements after upgrade., 'CSI snapshot timing/timeout behavior changed:
        sync wait is now `backup.spec.csiSnapshotTimeout` (instead of fixed 10m) and
        async readiness uses operation timeout (default 4h). This can affect long-running
        snapshot backups/restores.', 'Helm chart v4.0.0 schema change: BSL/VSL config
        must be migrated from map to slice; failing to do so will break Helm upgrades.',
      'Finalizers added to Velero CRs (restore/dataupload/datadownload): deleting
        the `velero` namespace directly can hang; use `velero uninstall` or remove
        finalizers carefully before namespace deletion.']
  chart_version: 5.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.12.3']
- version: 1.11.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary: null
  chart_version: 5.0.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.11.1']
- version: 1.10.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.9.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.8.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
