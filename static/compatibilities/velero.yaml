icon: https://velero.io/img/Velero.svg
git_url: https://github.com/vmware-tanzu/velero
release_url: https://github.com/vmware-tanzu/velero/releases/tag/v{vsn}
helm_repository_url: https://vmware-tanzu.github.io/helm-charts
versions:
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "## Helm / values changes to plan for (1.16 \u2192 1.17)\n\n> These\
      \ come from the **Velero 1.17 application notes you provided**; validate the\
      \ exact Helm keys in your chart\u2019s `values.yaml`.\n\n- **Restic uploader\
      \ removed**\n  - `--uploader-type=restic` is **no longer valid** in 1.17.\n\
      \  - Action: remove/avoid any Helm values that set `uploaderType: restic` (or\
      \ equivalent extra args/env). Use kopia / CSI data mover / fs-backup path instead.\n\
      \n- **Repository maintenance job flags removed from velero server args**\n \
      \ - These server parameters are removed in 1.17:\n    - `--keep-latest-maintenance-jobs`\n\
      \    - `--maintenance-job-cpu-request`\n    - `--maintenance-job-mem-request`\n\
      \    - `--maintenance-job-cpu-limit`\n    - `--maintenance-job-mem-limit`\n\
      \  - Action: remove them from any Helm `server.extraArgs`/`configuration.extraArgs`\
      \ you set.\n  - New approach: configure maintenance job settings via the **repository\
      \ maintenance job ConfigMap** (the feature is explicitly called out in 1.17).\n\
      \n- **New node-agent ConfigMap knobs you may want to set**\n  - `PrepareQueueLength`\
      \ (called `PrepareQueueLength` in notes) to limit how many data mover pods/volumes\
      \ queue up before creating more.\n  - If you use CSI snapshot data movement:\
      \ new node selection options for restore and per-storageClass selection.\n\n\
      - **New optional PriorityClass support**\n  - You can now set PriorityClass\
      \ for: Velero server, node-agent, data mover pods, and repo maintenance jobs.\n\
      \n- **If you run Windows workloads**\n  - 1.17 adds fs-backup on Windows; ensure\
      \ Helm values for tolerations/nodeSelectors/affinity don\u2019t prevent Windows\
      \ scheduling where intended (notes mention `os=windows:NoSchedule` toleration\
      \ was added)."
    chart_updates: [Velero fs-backup architecture changed to a micro-service model
        (impacts how fs-backup workloads run and survive node-agent restarts)., 'Windows
        support expanded: fs-backup now supports backup/restore for Windows workloads
        (1.16 already enabled CSI snapshot data movement on Windows; 1.17 completes
        fs-backup coverage).', Added support for Kubernetes Volume Group Snapshots
        (beta upstream feature) for CSI snapshot backup and CSI snapshot data movement.,
      'PriorityClass support added across Velero components (server, node-agent, data
        movers, repository maintenance jobs).', 'Data mover scalability/resiliency
        improvements: configurable prepare queue length to prevent many pending pods;
        better resume/cancel behavior across node-agent restarts; restore node selection
        plus per-storageClass node selection.', Resource policies extended with reusable
        include/exclude filtering (`includeExcludePolicy`) in addition to volumePolicy.,
      'Dependency bumps: Go 1.24.6; kopia 0.21.1.']
    features: [Modernized fs-backup to a micro-service architecture with concurrency
        control and better robustness (survives node-agent restarts)., 'fs-backup
        now supports Windows workloads, enabling full Windows backup/restore scenarios
        together with CSI snapshot data movement.', 'Support for Volume Group Snapshots,
        enabling point-in-time consistency across multiple correlated volumes.', 'PriorityClass
        support for Velero server, node-agent, data mover pods, and maintenance jobs
        to influence scheduling/preemption.', 'Data mover load-soothing and resiliency:
        configurable PrepareQueueLength and improved resume/cancel behavior on node-agent
        restart; restore now supports node selection including per-storageClass rules.',
      Resource policy now supports reusable include/exclude filters via `includeExcludePolicy`.]
    breaking_changes: ['Restic fs-backup path removed: `--uploader-type=restic` is
        no longer a valid install configuration. You can still restore from existing
        Restic-path backups until v1.19, but you cannot create new ones in 1.17.',
      Repository maintenance job configuration flags were removed from velero server
        args and must be configured via a maintenance job ConfigMap instead., 'PVC
        restore behavior change: selected-node annotation is now always removed during
        PVC restore when no node mapping exists (previously it could be preserved
        if the node existed).']
  chart_version: 11.2.0
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "### Helm/values changes to account for in the upgrade\n\n> Note:\
      \ you provided *application* release notes (Velero v1.17.0), not the Helm chart\
      \ changelog. The items below are the most likely Helm **values/args** impacts\
      \ based on the Velero server/node-agent flags and config behavior described\
      \ in the release notes.\n\n- **Remove any Restic uploader configuration**\n\
      \  - If your Helm values set anything equivalent to `--uploader-type=restic`\
      \ (or a chart value that selects `restic`), **remove it**. Restic as an uploader\
      \ type is no longer valid for new backups in v1.17.\n  - You may keep legacy\
      \ restores from existing Restic-based backups until v1.19.\n\n- **Repository\
      \ maintenance job settings moved to ConfigMap (server flags removed)**\n  -\
      \ If your Helm chart previously set server args:\n    - `--keep-latest-maintenance-jobs`\n\
      \    - `--maintenance-job-cpu-request`\n    - `--maintenance-job-mem-request`\n\
      \    - `--maintenance-job-cpu-limit`\n    - `--maintenance-job-mem-limit`\n\
      \  - \u2026then you must **migrate these to the repository maintenance job ConfigMap**\
      \ (often chart-managed). Ensure your values now render/configure that ConfigMap\
      \ instead of server args.\n  - v1.17 adds **ConfigMap parameter validation**\
      \ at install/server start; invalid keys/values will now fail fast.\n\n- **PriorityClass\
      \ support (optional new values)**\n  - v1.17 allows setting PriorityClass separately\
      \ for:\n    - velero server\n    - node-agent\n    - data mover pods\n    -\
      \ repository maintenance jobs\n  - If your chart exposes values for `priorityClassName`,\
      \ you can now/should set them consistently (especially in constrained clusters).\n\
      \n- **Node-agent/data mover scaling control (optional new config)**\n  - A node-agent\
      \ config parameter `PrepareQueueLength` can throttle creation of data mover\
      \ pods to avoid many Pending pods.\n  - If your chart manages the node-agent\
      \ ConfigMap, consider exposing/setting this for large environments.\n\n- **Windows\
      \ tolerations / scheduling (if applicable)**\n  - v1.17 adds `os=windows:NoSchedule`\
      \ toleration for Windows pods; verify your Helm values don\u2019t override tolerations/nodeSelectors\
      \ in a way that blocks Windows support.\n\n- **Kubelet mount path now parameterized\
      \ (node-agent install)**\n  - If you have non-standard kubelet paths (common\
      \ in some distros), ensure your chart values align with the new parameterization\
      \ and your existing hostPath mounts."
    chart_updates: ['No Helm chart changelog was provided, so chart-template changes
        (new/removed values, renamed keys, new manifests) cannot be stated with certainty.',
      'Operationally relevant changes from the application that commonly affect chart
        templates/config include: removal of Restic uploader type, migration of maintenance-job
        configuration to a ConfigMap, and expanded PriorityClass wiring across components.',
      'v1.17 introduces stronger ConfigMap parameter validation, which can surface
        misconfigurations in chart-rendered ConfigMaps that previously went unnoticed.']
    features: ['Modernized fs-backup to a micro-service architecture, improving robustness
        (survives node-agent restarts), adding concurrency control, and enabling cancel/resume
        behaviors.', 'fs-backup now supports Windows workloads by allowing data mover
        pods to run on Windows nodes, completing end-to-end Windows backup/restore
        scenarios.', 'Adds support for Kubernetes Volume Group Snapshots (beta upstream),
        enabling crash-consistent snapshots across multiple related volumes.', 'PriorityClass
        support across Velero modules (server, node-agent, data movers, maintenance
        jobs) for better scheduling control.', 'Data mover scalability/resiliency
        improvements: throttling pod creation via PrepareQueueLength, better restart-resume
        behavior, and improved node-selection (including per-storage-class).', 'Resource
        policy enhancement: reusable include/exclude filters (`includeExcludePolicy`)
        in resource policy ConfigMaps.', CLI can auto-discover and use CA certs from
        the BackupStorageLocation for download requests; improved BSL availability
        metrics and checks.]
    breaking_changes: ['Restic uploader path removed: `--uploader-type=restic` is
        no longer valid for installation/new backups (restores from existing Restic
        backups still supported until v1.19).', Repository maintenance job configuration
        flags were removed from the Velero server; these settings must be configured
        via the maintenance-job ConfigMap going forward., 'PVC restore behavior change:
        when no node mapping exists, Velero always removes the `selected-node` annotation
        (previously it could be preserved if the node existed), which may change scheduling
        outcomes on restore.']
  chart_version: 11.2.0
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.16.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Windows cluster support (hybrid Linux/Windows nodes): node-agent,
        data mover, and maintenance jobs can run on Windows nodes; Velero can backup/restore
        Windows workloads with built-in data mover (with noted limitations).', 'Parallel
        Item Block backup: item blocks (and pre/post hooks within them) can now be
        processed concurrently; parallelism is configurable via the new `--item-block-worker-count`
        server flag (default 1).', 'Data mover restore scalability improvement for
        WaitForFirstConsumer volumes: new node-agent config flag `ignoreDelayBinding`
        allows restores to spread evenly across nodes instead of being pinned to the
        attached node.', 'Improved data mover observability: node-agent logs now include
        additional intermediate object status and cleanup failure details automatically.',
      'CSI snapshot usability improvement: retained VolumeSnapshotContent objects
        are no longer included in backups, reducing unnecessary CSI object sync/restore
        across clusters.', 'Backup repository maintenance improvements: maintenance
        history (`RecentMaintenance`) recorded on BackupRepository CRs, running jobs
        are re-captured after server restart, maintenance/repo init avoided for readOnly
        BSLs, and configurable `fullMaintenanceInterval` (normalGC/fastGC/eagerGC)
        in backup-repository config.', 'Volume Policy enhancement: filtering volumes
        by PVC labels is supported.', 'Per-object resource status restore: objects
        can opt in/out via `velero.io/restore-status` annotation.', 'Restore helper
        consolidation: `velero`, `velero-helper`, and `velero-restore-helper` binaries
        are now shipped in the single Velero image.']
    breaking_changes: []
  chart_version: 10.1.3
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.16.2']
- version: 1.15.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ["Data mover \u201Cmicro service\u201D (backupPod/restorePod) replaces\
        \ node-agent for CSI Snapshot Data Movement, improving security (no hostPath),\
        \ resilience, and per-operation resource control.", Introduces Item Block
        concepts and the ItemBlockAction (IBA) plugin type; Velero ships built-in
        IBAs for Pods and PVCs (multi-threaded execution not yet enabled)., Adds node
        selection for repository maintenance jobs via a new repository-maintenance
        configuration ConfigMap., Adds backup PVC configuration (read-only mounts
        and selectable StorageClass) to speed up data mover operations and decouple
        backup PVC provisioning from workload PVC patterns., Adds backup repository
        client-side cache size limiting via a new backup-repository configuration
        ConfigMap to reduce eviction risk from ephemeral storage pressure., 'Performance
        fixes/improvements: plugin-call memory leak fixed; client QPS/burst automatically
        passed to plugins; Kopia maintenance memory improvements. ']
    breaking_changes: ['Restic uploader path for filesystem backups enters deprecation;
        backups/restores still succeed but emit warnings when restic is used (e.g.,
        --uploader-type=restic).', Node-agent configuration ConfigMap name is no longer
        fixed; must be provided via the node-agent server parameter node-agent-configmap
        if you customize it., Repository maintenance job settings are moving from
        Velero server flags to a repository-maintenance job ConfigMap; ConfigMap values
        take precedence if both are set., Changing PVC selected-node feature is deprecated
        and will be removed in a future release; avoid relying on it.]
  chart_version: 8.7.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.15.2']
- version: 1.14.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: [Repository maintenance for Kopia/Restic backup repositories is moved
        out of the Velero server pod into a separate Kubernetes Job to reduce Velero
        pod memory spikes/OOM risk., 'VolumePolicies now support an `action` to control
        how volumes are protected (e.g., `fs-backup` vs `snapshot`), enabling opt-in/opt-out
        behavior without changing workloads.', 'Data movement backups can restrict
        where datamover pods run via a ConfigMap-based node selection mechanism, helping
        control resource placement.', 'Restore output now includes persisted VolumeInfo
        metadata for restored volumes, and `velero restore describe` shows more volume-level
        detail.', 'Restores gain a new `Finalizing` phase so certain operations occur
        after data restore (e.g., PV label restoration after snapshot restore, and
        post-restore hooks after data movement).', Azure authentication adds support
        for service principal certificate-based auth as an alternative to client-secret
        auth.]
    breaking_changes: [CSI plugin is now merged into the main Velero repo and installed
        by default as an internal plugin; it should no longer be installed via `velero
        install --plugins`., Default resource requests/limits for the node-agent are
        removed so node-agent pods run as BestEffort; you must set explicit resources
        yourself if you relied on the old defaults., 'Backup namespace filtering changes
        when `includedNamespaces`/`excludedNamespaces` are unset but label selectors
        are used: namespaces with no selected resources are now excluded (previously
        all namespaces were included).', 'During restores, PV patching in the new
        `Finalizing` phase can cause a restore to end as `PartiallyFailed` if a PV
        is stuck `Pending`, whereas earlier versions might have reported `Complete`.']
  chart_version: 7.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.14.1']
- version: 1.13.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Resource Modifiers now support JSON Merge Patch and Strategic Merge
        Patch in addition to JSON Patch, enabling more flexible restore-time mutations.',
      Node-agent concurrency is configurable globally or per node to control how many
        filesystem backup/restore and CSI snapshot data-mover operations run simultaneously.,
      Kopia uploader adds configurable parallel file upload options to speed up filesystem
        backups and CSI snapshot data movement., Restores can optionally write sparse
        files for fs-restore and CSI snapshot data movement to reduce IO and disk
        usage for sparse data., '`velero backup describe` adds a Backup Volumes section
        with richer volume details, including CSI snapshot data movement info even
        without client-side CSI feature-gate checks.', 'Backups now write a new VolumeInfo
        metadata file in the repository to record PV/PVC backup method, snapshot info,
        and status to drive PV restore behavior.', Improved resilience for CSI snapshot
        data movement and other operations when the Velero server pod or node-agent
        restarts to avoid stuck/incomplete operations., Backup/Restore CR status now
        includes hook execution details (HooksAttempted/HooksFailed) and they show
        in describe output., AWS SDK for Go is upgraded to v2 for better CPU/memory
        performance., 'Azure AD/Workload Identity is now supported for Kopia operations
        (filesystem backup/data mover), not just native snapshots.', 'Runtime/deps
        updated: Go 1.21.6 and Kopia 0.15.0.']
    breaking_changes: ['`velero backup describe` output format changes: some existing
        snapshot/fs-backup information moved under a new Backup Volumes section, which
        can break scripts/parsers.', 'API change in v2alpha1 DataUploadSpec: `DataMoverConfig`
        type changes from `*map[string]string` to `map[string]string` (impacts code
        or manifests that set this field).', '`velero install` now enables informer
        cache by default (previously disabled), which can increase memory usage and
        may require raising Velero pod limits or explicitly disabling with `--disable-informer-cache`.']
  chart_version: 6.7.0
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.13.2']
- version: 1.12.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: '## Helm values / install-time changes to plan for

      - **BSL/VSL values schema changed (Helm chart v4.0.0+)**: `configuration.backupStorageLocation`
      and `configuration.volumeSnapshotLocation` changed from **map/object** to **list/slice**.
      This is **not backward compatible**; convert your values **before** upgrading
      the chart.

      - **Default filesystem uploader changed to Kopia (Velero v1.12)**: if you relied
      on the implicit default `uploader-type=restic`, you must now **set it explicitly**
      (or validate Kopia works for you). In Helm, ensure your values (or extra args)
      explicitly set the uploader if you want to stay on Restic.

      - **CSI snapshot timeout behavior changed (Velero v1.12)**: snapshot sync timeout
      is now `backup.spec.csiSnapshotTimeout` (instead of fixed 10m). Async wait uses
      an operation timeout (default **4h**). Review any Helm values/extra args or
      Backup specs you template that control timeouts.

      - **Finalizers introduced on Velero CRs** (`restore`, `dataupload`, `datadownload`):
      avoid deleting the namespace directly; prefer `velero uninstall` or ensure the
      controller is running to remove finalizers.'
    chart_updates: ['If you are upgrading the Helm chart to **velero chart v4.0.0+**
        alongside app v1.12, update your values to the new **slice-based** BSL/VSL
        structure; otherwise Helm upgrade will fail or misconfigure locations.']
    features: ['CSI Snapshot Data Movement: move CSI snapshot data into durable backup
        storage and restore across environments/clouds; adds DataUpload/DataDownload
        concepts for the data mover path.', 'Resource Modifiers (JSON substitutions):
        apply JSON patch operations to selected resources during restore (e.g., change
        namespace or storage class) without writing a custom RestoreItemAction plugin.',
      'Multiple VolumeSnapshotClasses: choose a specific VolumeSnapshotClass per backup
        instead of relying on driver/label heuristics.', 'Restore finalizer: `velero
        restore delete` now also cleans up restore-related data in the backup storage
        location.']
    breaking_changes: [Default `uploader-type` changed from **restic** to **kopia**
        in v1.12; set it explicitly if you need Restic or validate Kopia path (also
        note known 2GiB file limitation)., 'CSI snapshot timing behavior changed:
        sync timeout is now configurable via `backup.spec.csiSnapshotTimeout`; async
        readiness waits use operation timeout (default 4h).', 'Helm chart v4.0.0+:
        BSL/VSL values changed from map to slice and are not backward compatible;
        convert values before upgrading.', New finalizers can cause **namespace deletion
        to hang** if you delete the Velero namespace directly; use `velero uninstall`
        or remove finalizers safely.]
  chart_version: 5.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.12.3']
- version: 1.11.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary: null
  chart_version: 5.0.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.11.1']
- version: 1.10.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.9.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.8.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
