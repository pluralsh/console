icon: https://velero.io/img/Velero.svg
git_url: https://github.com/vmware-tanzu/velero
release_url: https://github.com/vmware-tanzu/velero/releases/tag/v{vsn}
helm_repository_url: https://vmware-tanzu.github.io/helm-charts
versions:
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Modernized file-system backup (fs-backup) to a micro-service architecture,
        enabling better concurrency control, cancel/resume, and improved robustness
        across node-agent restarts with steadier resource usage.', File-system backup
        now supports Windows clusters by allowing data mover pods to run on Windows
        nodes for backup/restore of Windows volumes., Added support for Kubernetes
        Volume Group Snapshots (beta upstream) for both CSI snapshot backups and CSI
        snapshot data movement to improve multi-volume point-in-time consistency.,
      'PriorityClass is now supported across Velero components (server, node-agent,
        data movers, and repository maintenance jobs) so you can control scheduling/eviction
        priority.', 'Scalability/resiliency improvements for data movers: configurable
        node-agent PrepareQueueLength to throttle pod creation, better resume/cancel
        behavior across node-agent restarts, and enhanced node selection (including
        per StorageClass) for CSI snapshot data movement restores.', Resource policies
        now support reusable include/exclude filters via includeExcludePolicy in addition
        to volumePolicy., 'Operational improvements including BSL availability metric,
        better BSL readiness checking for backup/restore operations, imagePullSecrets
        inheritance for data mover/maintenance jobs, and parameterized kubelet mount
        path for node-agent installation.']
    breaking_changes: ['Restic uploader path for fs-backup is removed: --uploader-type=restic
        is no longer a valid install configuration; you cannot create new restic-path
        backups (restores from existing restic backups are supported until v1.19).',
      'Repository maintenance job configurations were removed from Velero server flags
        and must be provided via the repository maintenance job ConfigMap (flags removed:
        --keep-latest-maintenance-jobs, --maintenance-job-*-request/limit).', 'PVC
        restore behavior change: selected-node annotation is always removed during
        PVC restore when no node mapping exists; previously it was preserved if the
        node existed (could affect scheduling expectations after restore).']
  chart_version: 11.3.1
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "## Helm values / install-time config changes to check\n\n### 1)\
      \ **Restic uploader removed (breaking)**\n* `--uploader-type=restic` is **no\
      \ longer valid** in v1.17.\n  * If your Helm chart values set anything equivalent\
      \ (commonly `configuration.uploaderType`, `uploaderType`, `deployRestic`, `deployNodeAgent`/`restic`\
      \ toggles, etc.), remove/disable Restic and use the current fs-backup path.\n\
      \  * You can **still restore old Restic-based backups until v1.19**, but you\
      \ cannot create new ones.\n\n### 2) **Repository maintenance job flags removed\
      \ from velero server (breaking)**\nThe following server parameters were removed\
      \ and must be configured via the **repository maintenance job ConfigMap** instead:\n\
      * `--keep-latest-maintenance-jobs`\n* `--maintenance-job-cpu-request`\n* `--maintenance-job-mem-request`\n\
      * `--maintenance-job-cpu-limit`\n* `--maintenance-job-mem-limit`\n\nIf you previously\
      \ set these via chart values that map to `server.extraArgs`, move them to the\
      \ chart\u2019s maintenance-job configmap values (name varies by chart).\n\n\
      ### 3) New/updated **node-agent** configuration knobs worth reviewing\nThese\
      \ are additive but may require Helm values if you want to use them:\n* `PrepareQueueLength`\
      \ (node-agent): throttles creation of data mover pods to avoid large numbers\
      \ stuck Pending.\n* `priorityClassName` support across modules (server, node-agent,\
      \ data mover pods, maintenance jobs): you may want to set these explicitly.\n\
      * Parameterized kubelet mount path for node-agent install (only if you run non-standard\
      \ kubelet paths).\n\n### 4) Modernized fs-backup (architecture change)\nfs-backup\
      \ is now micro-service based. In Helm terms this may translate into:\n* more/changed\
      \ pod templates for data mover / fs-backup components,\n* potential new configmaps/args\
      \ for concurrency/cancel/resume behavior.\n\n(Exact value keys depend on your\
      \ chart; validate rendered manifests before applying.)"
    chart_updates: ['fs-backup moved to a micro-service architecture (better concurrency
        control, cancel/resume, and resiliency across node-agent restarts).', 'Windows
        support expands: fs-backup now supports Windows workloads; data mover pods
        can run on Windows nodes with required tolerations.', Volume Group Snapshots
        support added (Kubernetes beta feature) for CSI snapshot backup and CSI snapshot
        data movement., 'PriorityClass support added across Velero components (server,
        node-agent, data mover pods, maintenance jobs).', 'Data mover scalability
        improvements: throttled pod creation via node-agent `PrepareQueueLength`,
        improved restart/orphan handling, expanded node-selection for restore and
        per-storageclass node-selection.', Resource policy enhanced with reusable
        include/exclude filters via `includeExcludePolicy`., 'Operational changes:
        repository maintenance job configuration moved from server flags to a ConfigMap;
        additional config validation added for install CLI and server start.']
    features: [Modernized fs-backup into a micro-service architecture with concurrency
        control plus cancel/resume and improved resiliency across node-agent restarts.,
      'fs-backup now supports Windows workloads, enabling full Windows backup/restore
        scenarios (with CSI data movement support introduced earlier).', Adds support
        for Kubernetes Volume Group Snapshots to take point-in-time consistent snapshots
        across multiple related volumes., 'Adds PriorityClass support so you can control
        scheduling priority for server, node-agent, data movers, and maintenance jobs.',
      'Improves data mover scalability with a node-agent prepare queue to avoid flooding
        the cluster with Pending pods, plus better restart/orphan handling and node-selection
        (including per-storageclass).', Adds reusable resource include/exclude filtering
        via `includeExcludePolicy` in resource policies.]
    breaking_changes: ["Restic uploader path is removed: `--uploader-type=restic`\
        \ is no longer a valid install configuration; you can\u2019t create new Restic-based\
        \ backups (restores remain supported until v1.19).", Repository maintenance
        job settings are no longer configured via Velero server flags; the maintenance
        job CPU/memory and keep-latest settings must be moved to the repository maintenance
        job ConfigMap., 'PVC restore behavior change: selected-node annotation is
        now removed during PVC restore when no node mapping exists (previously it
        could be preserved in some cases).']
  chart_version: 11.2.0
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.16.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Windows cluster support: Velero components (server, node-agent, data
        mover, maintenance jobs) can run in hybrid Linux/Windows clusters and back
        up/restore Windows workloads (with limitations around fs-backup and NTFS security
        metadata).', 'Parallel ItemBlock backup: item blocks can now be processed
        in parallel to increase resource-backup throughput; controlled by new server
        flag `--item-block-worker-count` (default 1).', 'Data mover restore scalability:
        new node-agent flag `ignoreDelayBinding` allows restoring WaitForFirstConsumer
        volumes without being pinned to the attachment node, improving parallelism
        and balancing node resource usage.', 'Data mover observability improvements:
        richer logging for intermediate object statuses and cleanup failures, enabled
        by default in node-agent logs.', 'CSI snapshot usability improvement: Velero
        no longer retains/restores unnecessary `VolumeSnapshotContent` objects, reducing
        cross-cluster sync noise when sharing BSLs.', 'BackupRepository maintenance
        resiliency/observability: `RecentMaintenance` history added to BackupRepository;
        maintenance jobs are recaptured after server restart; maintenance/init skipped
        for readOnly BSLs; configurable `fullMaintenanceInterval` with normal/fast/eager
        GC options.', 'Volume Policy enhancements: can filter volumes by PVC labels
        (and additional CSI PV VolumeAttributes properties).', 'Resource status restore
        per object: annotation `velero.io/restore-status` controls whether status
        is restored for specific objects.', 'Single Velero image now includes velero,
        velero-helper, and velero-restore-helper binaries (simplifies image management).',
      'Runtime bumps: Go 1.23.7; kopia 0.19.0.']
    breaking_changes: []
  chart_version: 10.1.3
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.16.2']
- version: 1.15.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Data mover micro service: moves CSI Snapshot Data Movement transfers
        from node-agent pods to dedicated backup/restore pods, improving security
        (no hostPath), per-volume resource control, isolation, and resilience.', Item
        Block concepts and new ItemBlockAction (IBA) plugin type to group correlated
        resources (built-in for Pods and PVCs) in preparation for future multi-threaded
        backups; v1.15 supports the model/plugins but still runs single-threaded.,
      Repository maintenance jobs can be scheduled onto selected nodes via a new repository-maintenance
        configuration ConfigMap., 'Backup PVC configuration added via a new ConfigMap:
        supports read-only mounting for backup pods (can speed up expose on some storage
        like Ceph) and choosing a different storageClass for backup PVCs.', Backup
        repository client-side cache limit configurable per repository via a new backup-repository
        configuration ConfigMap to avoid evictions due to ephemeral storage pressure.,
      'Performance improvements including fixing a server memory leak after plugin
        calls, inheriting client-qps/burst settings to plugins, and upstream Kopia
        maintenance memory improvements.']
    breaking_changes: [Restic is deprecated for filesystem (fs-backup) operations
        starting in v1.15; backups/restores still work but emit warnings when installed
        with --uploader-type=restic or when restic path is used., Node-agent configuration
        ConfigMap name is no longer fixed; it must be provided via the Velero server
        parameter --node-agent-configmap if you customize it., Repository maintenance
        job resource/retention settings are moved from Velero server flags to the
        repository-maintenance ConfigMap (ConfigMap values take precedence; old flags
        remain for backward compatibility)., The 'changing PVC selected-node' restore
        feature is deprecated and not recommended; it will be removed in a future
        release per the deprecation policy.]
  chart_version: 8.7.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.15.2']
- version: 1.14.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Repository maintenance for kopia/restic runs as separate Kubernetes
        Jobs instead of inside the Velero server pod, reducing risk of Velero OOM
        during maintenance and allowing tuning job resources.', 'VolumePolicies can
        now choose the backup method per volume (e.g., force `fs-backup` vs `snapshot`),
        enabling finer opt-in/opt-out control without changing workloads.', Data-movement
        backups can restrict where datamover pods run via a ConfigMap-based node selection
        mechanism., 'Restore VolumeInfo metadata is now persisted and surfaced via
        `velero restore describe`, improving visibility into how each volume was restored.',
      Restores now include a distinct `Finalizing` phase so PV label restoration and
        post-restore hooks happen after volume restore/data movement completes., 'Azure
        plugin adds certificate-based service principal authentication, enabling phishing-resistant
        auth and better alignment with Azure conditional access recommendations.']
    breaking_changes: [CSI plugin is now merged into the Velero repo and installed
        by default as an internal plugin; you must stop installing it via `--plugins`
        during `velero install` (or equivalent Helm values/plugins list)., Default
        resource requests/limits for the node-agent are removed to make node-agent
        pods BestEffort; clusters that relied on previous defaults should explicitly
        set resources to avoid contention or eviction., 'Backup namespace filtering
        changes when `includedNamespaces`/`excludedNamespaces` are unset but `labelSelector`/`orLabelSelectors`
        are set: only namespaces containing matching resources are backed up (previously
        all namespaces were included).', 'With the new restore `Finalizing` behavior,
        patching PVs while they are `Pending` can cause restores to end `PartiallyFailed`
        where they might have shown `Complete` before; this can impact automation
        that keys off restore phase.']
  chart_version: 7.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.14.1']
- version: 1.13.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "- **Helm chart note (from v1.12 release notes):** If you are using\
      \ the Velero Helm chart **v4.0.0+**, `backupStorageLocation` (BSL) and `volumeSnapshotLocation`\
      \ (VSL) values changed from a **map** to a **slice/list**. This is **not backward\
      \ compatible**; convert your values to lists *before* upgrading if you still\
      \ have the old format.\n- **Informer cache default change (server behavior):**\
      \ In Velero **v1.13**, the **informer cache is enabled by default** (previously\
      \ effectively disabled). If you hit OOMs after upgrade, either raise Velero\
      \ pod memory limits/requests via Helm or disable it (CLI flag `--disable-informer-cache`;\
      \ check whether your chart exposes an equivalent value/extraArg).\n- **New/updated\
      \ tunables to consider adding to values (v1.13 features):**\n  - **Node-agent\
      \ concurrency** controls (global and per-node) for data-movement loads.\n  -\
      \ **Kopia parallel upload** options for fs-backups / CSI snapshot data movement.\n\
      \  - **Write sparse files** option for restores (fs-restore / CSI snapshot data\
      \ movement).\n\n*(No explicit Helm chart version-specific changelog for the\
      \ Velero chart itself was provided in the notes you shared beyond the v4.0.0\
      \ BSL/VSL format change.)*"
    chart_updates: [Velero server now writes a new per-backup **VolumeInfo** metadata
        file in the backup repository (used to drive PV restore decisions)., '`velero
        backup describe` output is reorganized: volume-related info moved into a new
        **Backup Volumes** section; format changes should be expected in scripts.',
      'Backup/Restore CR statuses now include **hook execution details** (HooksAttempted,
        HooksFailed) and they appear in `describe` output.', Velero adds resilience
        improvements so in-progress backup/restore operations (notably CSI snapshot
        data movement) are less likely to get stuck after **velero pod / node-agent
        restarts**., 'Runtime/deps updated: Go **1.21.6**, Kopia **0.15.0**, multiple
        dependency bumps; AWS SDK for Go moved to **v2**.']
    features: ['Resource Modifiers now support **JSON Merge Patch** and **Strategic
        Merge Patch** in addition to JSON Patch, enabling more flexible restore-time
        mutations without custom plugins.', Configurable **node-agent concurrency**
        lets you cap/shape data-movement workloads per node (globally or per-node)
        to balance speed vs. cluster resource usage., Kopia-based backups/data-movement
        can use configurable **parallel file uploads** to speed up backups in environments
        with sufficient bandwidth/CPU., 'Restores can optionally **write sparse files**
        for fs-restore / CSI snapshot data movement, potentially reducing IO and space
        when appropriate.', "`velero backup describe` now includes a **Backup Volumes**\
        \ section and can show CSI snapshot data movement details even if the client-side\
        \ CSI feature gate isn\u2019t enabled.", Backup/Restore objects now expose
        **hook execution status** (attempted/failed counts) in CR status and CLI output.,
      Azure plugin + Kopia now supports **Azure AD/Workload Identity** for filesystem
        backup/data mover operations (previously limited)., 'AWS interactions now
        use **aws-sdk-go-v2**, improving CPU/memory efficiency in many cases.']
    breaking_changes: ['`velero backup describe` output changed (volume info moved
        into **Backup Volumes** section with format changes). Any log-parsing/automation
        depending on the old layout must be updated.', 'API change: `DataUploadSpec.DataMoverConfig`
        changed from `*map[string][string]` to `map[string]string`; any code/controllers/templates
        depending on the old type will break.', 'Installer behavior change: **informer
        cache is enabled by default** in v1.13 (previously disabled). This can increase
        memory usage and may require raising limits or explicitly disabling it to
        avoid OOMs.']
  chart_version: 6.7.0
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.13.2']
- version: 1.12.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "- **Helm chart v4.0.0 (Velero app v1.12) changes BSL/VSL values\
      \ structure:** `configuration.backupStorageLocation` and `configuration.volumeSnapshotLocation`\
      \ change from **map** to **slice/list** to support **multiple** BSLs/VSLs. This\
      \ is **not backward compatible**.\n  - **Action before upgrade:** convert your\
      \ existing single BSL/VSL config to list form to avoid a failed/incorrect upgrade.\n\
      \  - Example conceptually:\n    - **Before (map/single):** `configuration.backupStorageLocation:\
      \ { name: default, provider: aws, bucket: ... }`\n    - **After (list):** `configuration.backupStorageLocation:\
      \ [ { name: default, provider: aws, bucket: ... } ]`\n"
    chart_updates: ['Helm chart for Velero 1.12 (noted as velero helm chart v4.0.0)
        adds support for **multiple BackupStorageLocations (BSL)** and **multiple
        VolumeSnapshotLocations (VSL)**, requiring values schema change from map to
        list.']
    features: ['**CSI Snapshot Data Movement**: ability to move CSI snapshot data
        out of the production storage into durable object storage, enabling long-term
        retention and cross-environment/cross-cloud restores.', '**Resource Modifiers
        (JSON substitutions)**: apply JSON patches to selected resources during restore
        to change things like namespaces, storage classes, etc., without writing a
        custom RestoreItemAction plugin.', '**Multiple VolumeSnapshotClasses (CSI
        plugin)**: select a specific VolumeSnapshotClass per backup instead of relying
        on driver-name matching plus a single label.', '**Restore finalizer cleanup**:
        `velero restore delete` now cleans up associated data in backup storage by
        using a finalizer-driven cleanup flow.', '**Runtime/dependency bumps**: Golang
        runtime to 1.20.7 and Kopia bumped to 0.13.x (plus other library updates).']
    breaking_changes: ['**Default uploader-type changed from `restic` to `kopia`**
        for filesystem backups. If you relied on restic defaults, explicitly set `uploader-type=restic`
        (or the equivalent Helm/CLI settings) to preserve behavior, or plan migration/testing
        for kopia.', '**CSI snapshot timeout behavior changed**: snapshot handle creation
        timeout is now controlled by `backup.spec.csiSnapshotTimeout` (instead of
        a fixed 10 minutes). ReadyToUse waiting is governed by operation timeout (default
        4 hours). This can affect backup/restore duration and failure modes; review
        and tune timeouts for your environment.', "**Helm chart values breaking change\
        \ (v4.0.0)**: BSL/VSL values change from map to list for multi-location support;\
        \ not backward compatible\u2014update values before upgrading.", '**Finalizers
        on Velero CRs (restore/dataupload/datadownload)** can cause `kubectl delete
        namespace velero` to hang. Use `velero uninstall` or ensure finalizers can
        complete before deleting the namespace.']
  chart_version: 5.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.12.3']
- version: 1.11.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary: null
  chart_version: 5.0.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.11.1']
- version: 1.10.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.9.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.8.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
