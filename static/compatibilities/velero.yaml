icon: https://velero.io/img/Velero.svg
git_url: https://github.com/vmware-tanzu/velero
release_url: https://github.com/vmware-tanzu/velero/releases/tag/v{vsn}
helm_repository_url: https://vmware-tanzu.github.io/helm-charts
versions:
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Modernized fs-backup to a micro-service architecture, enabling concurrency
        control, cancel/resume, better robustness across node-agent restarts, and
        steadier resource usage.', fs-backup now supports Windows workloads by running
        data mover pods on Windows nodes (complements Windows CSI snapshot data movement
        added in 1.16)., Added (beta) Kubernetes VolumeGroupSnapshot support for CSI
        snapshot backup and CSI snapshot data movement to get point-in-time consistent
        snapshots across multiple volumes., 'Added PriorityClassName support across
        Velero components (server, node-agent, data mover pods, and backup repository
        maintenance jobs).', 'Improved scalability/resiliency for data movers: configurable
        prepare queue length to throttle pod creation, better restart/orphan handling,
        and restore-side node selection (including per storage class).', Resource
        policies now support reusable include/exclude filters via includeExcludePolicy
        (in addition to volumePolicy).]
    breaking_changes: ['Restic uploader path is removed: --uploader-type=restic is
        no longer valid for new backups; restores from existing restic backups are
        still supported until v1.19.', 'Repository maintenance job settings were removed
        from velero server flags and moved to a ConfigMap: removed flags include --keep-latest-maintenance-jobs,
        --maintenance-job-{cpu,mem}-{request,limit}.', 'PVC restore behavior change:
        Velero now always removes the selected-node annotation during PVC restore
        when no node mapping exists; previously it could be preserved if the node
        existed.']
  chart_version: 11.3.2
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "## Helm values / install-time config changes to check\n\n### 1)\
      \ **Restic uploader removed (breaking)**\n* `--uploader-type=restic` is **no\
      \ longer valid** in v1.17.\n  * If your Helm chart values set anything equivalent\
      \ (commonly `configuration.uploaderType`, `uploaderType`, `deployRestic`, `deployNodeAgent`/`restic`\
      \ toggles, etc.), remove/disable Restic and use the current fs-backup path.\n\
      \  * You can **still restore old Restic-based backups until v1.19**, but you\
      \ cannot create new ones.\n\n### 2) **Repository maintenance job flags removed\
      \ from velero server (breaking)**\nThe following server parameters were removed\
      \ and must be configured via the **repository maintenance job ConfigMap** instead:\n\
      * `--keep-latest-maintenance-jobs`\n* `--maintenance-job-cpu-request`\n* `--maintenance-job-mem-request`\n\
      * `--maintenance-job-cpu-limit`\n* `--maintenance-job-mem-limit`\n\nIf you previously\
      \ set these via chart values that map to `server.extraArgs`, move them to the\
      \ chart\u2019s maintenance-job configmap values (name varies by chart).\n\n\
      ### 3) New/updated **node-agent** configuration knobs worth reviewing\nThese\
      \ are additive but may require Helm values if you want to use them:\n* `PrepareQueueLength`\
      \ (node-agent): throttles creation of data mover pods to avoid large numbers\
      \ stuck Pending.\n* `priorityClassName` support across modules (server, node-agent,\
      \ data mover pods, maintenance jobs): you may want to set these explicitly.\n\
      * Parameterized kubelet mount path for node-agent install (only if you run non-standard\
      \ kubelet paths).\n\n### 4) Modernized fs-backup (architecture change)\nfs-backup\
      \ is now micro-service based. In Helm terms this may translate into:\n* more/changed\
      \ pod templates for data mover / fs-backup components,\n* potential new configmaps/args\
      \ for concurrency/cancel/resume behavior.\n\n(Exact value keys depend on your\
      \ chart; validate rendered manifests before applying.)"
    chart_updates: ['fs-backup moved to a micro-service architecture (better concurrency
        control, cancel/resume, and resiliency across node-agent restarts).', 'Windows
        support expands: fs-backup now supports Windows workloads; data mover pods
        can run on Windows nodes with required tolerations.', Volume Group Snapshots
        support added (Kubernetes beta feature) for CSI snapshot backup and CSI snapshot
        data movement., 'PriorityClass support added across Velero components (server,
        node-agent, data mover pods, maintenance jobs).', 'Data mover scalability
        improvements: throttled pod creation via node-agent `PrepareQueueLength`,
        improved restart/orphan handling, expanded node-selection for restore and
        per-storageclass node-selection.', Resource policy enhanced with reusable
        include/exclude filters via `includeExcludePolicy`., 'Operational changes:
        repository maintenance job configuration moved from server flags to a ConfigMap;
        additional config validation added for install CLI and server start.']
    features: [Modernized fs-backup into a micro-service architecture with concurrency
        control plus cancel/resume and improved resiliency across node-agent restarts.,
      'fs-backup now supports Windows workloads, enabling full Windows backup/restore
        scenarios (with CSI data movement support introduced earlier).', Adds support
        for Kubernetes Volume Group Snapshots to take point-in-time consistent snapshots
        across multiple related volumes., 'Adds PriorityClass support so you can control
        scheduling priority for server, node-agent, data movers, and maintenance jobs.',
      'Improves data mover scalability with a node-agent prepare queue to avoid flooding
        the cluster with Pending pods, plus better restart/orphan handling and node-selection
        (including per-storageclass).', Adds reusable resource include/exclude filtering
        via `includeExcludePolicy` in resource policies.]
    breaking_changes: ["Restic uploader path is removed: `--uploader-type=restic`\
        \ is no longer a valid install configuration; you can\u2019t create new Restic-based\
        \ backups (restores remain supported until v1.19).", Repository maintenance
        job settings are no longer configured via Velero server flags; the maintenance
        job CPU/memory and keep-latest settings must be moved to the repository maintenance
        job ConfigMap., 'PVC restore behavior change: selected-node annotation is
        now removed during PVC restore when no node mapping exists (previously it
        could be preserved in some cases).']
  chart_version: 11.2.0
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.16.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: ['Upgrade Velero application from v1.15.0 to v1.16.0 (image tag
        `velero/velero:v1.16.0`).', 'Runtime/dependency bumps: Go 1.23.7, Kopia 0.19.0.',
      'Velero image now bundles `velero`, `velero-helper`, and `velero-restore-helper`
        binaries into a single image (if you previously referenced a separate restore-helper
        image, adjust accordingly).']
    features: ['Windows cluster support: Velero can run in hybrid Linux/Windows clusters;
        node-agent, data mover pods, and maintenance jobs can be scheduled onto Windows
        nodes; built-in data mover supports Windows workload backup/restore lifecycle
        (with limitations).', 'Parallel Item Block backups: item blocks (and associated
        pre/post hooks) can be processed concurrently; tune with `--item-block-worker-count`
        (default 1).', 'Data mover restore scalability for WaitForFirstConsumer volumes:
        new node-agent config flag `ignoreDelayBinding` allows spreading restores
        across nodes instead of being constrained to the attached node.', 'Improved
        observability for data mover: richer logging of intermediate-object status
        and cleanup errors is emitted in node-agent logs automatically.', 'CSI snapshot
        usability improvement: retained `VolumeSnapshotContent` objects are no longer
        included in backups, reducing unnecessary syncing/restoring across clusters.',
      'Backup repository maintenance improvements: `RecentMaintenance` history in
        `BackupRepository` CR; maintenance jobs are recaptured after server restarts;
        maintenance/init skipped for read-only BSLs; configurable Kopia `fullMaintenanceInterval`
        (normalGC/fastGC/eagerGC).', 'Volume Policy enhancement: can filter volumes
        by PVC labels.', 'Per-object resource status restore: set annotation `velero.io/restore-status`
        on individual objects to control whether status is restored.']
    breaking_changes: ["Windows support has functional limitations: fs-backup is not\
        \ supported for Windows workloads; security descriptors/NTFS extended attributes\
        \ aren\u2019t backed up/restored, so non-admin workloads may not be supported.",
      "Parallel item block processing changes backup concurrency behavior; if you\
        \ raise `--item-block-worker-count`, expect higher API server load and more\
        \ parallel hook execution\u2014review cluster capacity/quotas and hook safety."]
  chart_version: 10.1.3
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.16.2']
- version: 1.15.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Data mover microservice for CSI snapshot data movement: data transfer
        shifts from node-agent pods to dedicated per-backup/restore pods, improving
        security (no hostPath), resiliency, and per-operation resource control.',
      "Item Block + ItemBlockAction (IBA) plugin framework: introduces grouping of\
        \ correlated resources into \u201Citem blocks\u201D for future multi-threaded\
        \ backups; built-in IBAs for Pods and PVCs and support for custom IBAs (multi-thread\
        \ execution not yet enabled in 1.15).", 'Repository maintenance node selection:
        you can constrain which nodes run repository maintenance jobs via a new repository
        maintenance ConfigMap.', 'Backup PVC configuration enhancements for data mover:
        support read-only mounting (can speed up expose on some storage like Ceph)
        and selecting a dedicated StorageClass for backupPVCs.', 'Backup repository
        cache limit configuration: configurable per-repository client-side cache size
        via a new backup repository ConfigMap to avoid pod eviction from ephemeral
        storage pressure.', 'Performance improvements: fixes a memory leak after plugin
        calls; propagates client QPS/burst settings to plugins; reduces kopia maintenance
        memory usage via upstream improvements.']
    breaking_changes: ['Restic filesystem backup path is deprecated starting in 1.15:
        backups/restores still succeed but will emit warnings when restic is selected
        (e.g., --uploader-type=restic) or used for fs-backup; plan migration off restic
        per deprecation policy.', 'Node-agent configuration ConfigMap name is no longer
        fixed: you must set the name via the node-agent server parameter --node-agent-configmap
        if you use a non-default name.', Repository maintenance job settings are moving
        from Velero server flags to a repository maintenance job ConfigMap; configMap
        values take precedence if both are set (flags remain for backward compatibility).,
      "\u201CChanging PVC selected-node\u201D feature is now deprecated and should\
        \ not be used; it will be removed in a future release."]
  chart_version: 8.7.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.15.2']
- version: 1.14.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: [Repository maintenance for kopia/restic unified repositories now runs
        as separate Kubernetes Jobs to avoid Velero server pod OOMs; resources can
        be specified at install time., 'VolumePolicies now support explicit actions
        (e.g., force fs-backup vs snapshot) for fine-grained per-volume backup behavior
        without changing workloads.', Data movement backups (datamover pods) can be
        scheduled onto a subset of nodes via a ConfigMap-based node selection mechanism.,
      'Restore VolumeInfo metadata is now persisted and surfaced in `velero restore
        describe`, improving visibility into how each volume was restored.', A new
        Restore phase `Finalizing` was added so PV label patching and post-restore
        hooks occur after volume data movement completes., Azure plugin adds certificate-based
        service principal authentication support for more secure/phishing-resistant
        auth.]
    breaking_changes: [CSI plugin is now merged into the main Velero repo and installed
        by default as an internal plugin; do not install it separately via `--plugins`
        during `velero install`., 'Default resource requests/limits for the node-agent
        were removed, changing pods to BestEffort QoS; you may need to set your own
        resources if you relied on defaults.', 'Backup namespace filtering behavior
        changes when include/exclude namespaces are unset but label selectors are
        used: only namespaces containing matching resources are included (previously
        all namespaces were included).', 'PV patching in the new Restore `Finalizing`
        phase can result in a restore ending `PartiallyFailed` if PVs are stuck Pending,
        where earlier versions might report Complete.']
  chart_version: 7.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.14.1']
- version: 1.13.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Resource Modifiers now support JSON Merge Patch and Strategic Merge
        Patch in addition to JSON Patch, allowing more flexible restore-time mutations
        using the same ConfigMap rules.', Node-agent now supports configurable per-node/global
        concurrency for data movement workloads (fs-backups and CSI snapshot data
        movement) to control resource usage., Kopia uploader gains configurable parallel
        file upload options to speed up fs-backups and CSI snapshot data movements.,
      Restores can optionally write sparse files for fs-restore and CSI snapshot data
        movement restores., "`velero backup describe` now includes a \u201CBackup\
        \ Volumes\u201D section summarizing volume coverage across native snapshots,\
        \ fs-backups, CSI snapshots, and CSI snapshot data movement (and no longer\
        \ hides CSI info based on client-side feature gate checks).", 'Backups now
        write a new VolumeInfo metadata file capturing PVC/PV backup method, snapshot
        details, and status to drive PV restore behavior and enable downstream summaries.',
      'Improved resilience of CSI snapshot data movement when Velero server or node-agent
        pods restart, reducing stuck/interrupt scenarios.', 'Backup/Restore CR status
        now includes hook execution details (HooksAttempted, HooksFailed) and `describe`
        output shows this.', 'AWS support moves to AWS SDK for Go v2, improving CPU/memory
        utilization.', Azure Workload Identity support is extended to Kopia operations
        (filesystem backup / data mover) in addition to existing Azure plugin support.,
      'Runtime/dependency bumps: Go 1.21.6 and Kopia 0.15.0 plus other library updates
        to address CVEs and stay current.']
    breaking_changes: ["`velero backup describe` output format changes: some existing\
        \ volume-related information is moved into the new \u201CBackup Volumes\u201D\
        \ section; scripts that parse output may break.", 'API type change: `DataMoverConfig`
        in `DataUploadSpec` changes from `*map[string]string` to `map[string]string`
        (affects clients/plugins compiling against API types).', '`velero install`
        behavior change: informer cache is enabled by default (was disabled previously),
        which can increase Velero pod memory usage and may require tuning or disabling.']
  chart_version: 6.7.0
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.13.2']
- version: 1.12.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: '### Helm chart changes to account for

      - **Chart v4.0.0+: BSL/VSL values structure changed (breaking)**: `configuration.backupStorageLocation`
      and `configuration.volumeSnapshotLocation` moved from **map/object** to **list/slice**
      to support **multiple** BSLs/VSLs. Update your `values.yaml` *before* upgrading.

      - **Uploader default changed**: if your Helm values rely on defaults, note that
      **`uploader-type` default is now `kopia` (was `restic`)**. If you want to stay
      on Restic behavior, set it explicitly.

      - **CSI snapshot timeouts behavior changed**: verify any Helm values (or server
      args) related to CSI snapshot timeouts; the effective behavior now depends on
      `backup.spec.csiSnapshotTimeout` and operation timeouts (default up to 4h).

      '
    chart_updates: []
    features: ['CSI Snapshot Data Movement: move CSI snapshot contents into durable
        backup storage and restore across environments/clouds (data mover).', 'Resource
        Modifiers (JSON substitutions): apply JSONPatch-like modifications during
        restore without writing a custom RestoreItemAction plugin.', 'Multiple VolumeSnapshotClasses:
        choose a specific VolumeSnapshotClass per backup instead of a single class
        inferred by labels/driver.', 'Restore finalizer: `velero restore delete` now
        cleans up associated external data in the backup storage location, not just
        Kubernetes restore resources.']
    breaking_changes: [Default filesystem uploader changed from Restic to Kopia (`uploader-type`
        default). This can change repository format/behavior and may require explicit
        configuration if you depend on Restic., Helm chart v4.0.0 changes BSL/VSL
        from map to list to support multiple locations; this is not backward compatible
        and requires values refactor before upgrade., 'CSI snapshot timeout handling
        changed: sync timeout is now `backup.spec.csiSnapshotTimeout` (instead of
        fixed 10m), and async readiness uses operation timeouts (default 4h).', Finalizers
        added to Velero CRs (restore/dataupload/datadownload) can cause namespace
        deletion to hang; prefer `velero uninstall` or remove finalizers safely before
        deleting the namespace.]
  chart_version: 5.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.12.3']
- version: 1.11.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary: null
  chart_version: 5.0.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.11.1']
- version: 1.10.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.9.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.8.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
