icon: https://velero.io/img/Velero.svg
git_url: https://github.com/vmware-tanzu/velero
release_url: https://github.com/vmware-tanzu/velero/releases/tag/v{vsn}
helm_repository_url: https://vmware-tanzu.github.io/helm-charts
versions:
- version: 1.18.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.18.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "- **Restic uploader removed:** `--uploader-type=restic` is no longer\
      \ valid in v1.17. If your Helm values/extraArgs still set this, remove it. You\
      \ can still **restore** from existing Restic-based backups until v1.19, but\
      \ you can\u2019t create new Restic-path backups.\n- **Repository maintenance\
      \ flags removed from server args:** If your Helm values set any of these via\
      \ `configuration.extraArgs`/`initContainers`/`server.extraArgs`, remove them:\n\
      \  - `--keep-latest-maintenance-jobs`\n  - `--maintenance-job-cpu-request`\n\
      \  - `--maintenance-job-mem-request`\n  - `--maintenance-job-cpu-limit`\n  -\
      \ `--maintenance-job-mem-limit`\n  These settings move to a **repository maintenance\
      \ job ConfigMap** (Velero now supports ConfigMap-backed settings with CLI fallback\
      \ for `keepLatestMaintenanceJobs`).\n- **New optional config knobs you may want\
      \ to set in values:**\n  - **PriorityClass** support across server/node-agent/data\
      \ mover/maintenance jobs (set per component).\n  - **node-agent `PrepareQueueLength`**\
      \ to limit pending data mover pod creation (helps large clusters).\n  - **Kubelet\
      \ mount path parameterization** for node-agent installation (set if your kubelet\
      \ root differs).\n  - Optional: disable pod volume hostPath mount for node-agent\
      \ (if your security posture disallows it).\n"
    chart_updates: [fs-backup (file system backup) is re-architected to a micro-service
        model under node-agent; expect different pod patterns and improved resiliency/steady
        resource usage., Data mover scheduling controls improved (prepare queue length;
        better restart/cancel/resume behavior)., Windows support is expanded to include
        fs-backup (data mover pods can run on Windows nodes for volume backup/restore).,
      Beta support for Kubernetes VolumeGroupSnapshot for CSI snapshot backup and
        CSI snapshot data movement., 'PriorityClassName can now be applied consistently
        to Velero server, node-agent, data movers, and repository maintenance jobs.',
      PVC restore behavior changed regarding `selected-node` annotation handling when
        no node mapping exists., BackupStorageLocation (BSL) availability is now checked
        for backup/restore operations; new gauge metric for BSL availability., 'Security
        hardening: mounted cloud credentials should not be world-readable.', Kopia
        dependency bumped to 0.21.1.]
    features: ['Modernized fs-backup to a micro-service architecture: adds concurrency
        control, cancel, and resume-on-restart with more robust and steadier node-agent
        resource usage.', fs-backup now supports Windows workloads by running data
        mover pods on Windows nodes when needed., 'Beta support for Kubernetes VolumeGroupSnapshot
        enables crash-consistent, write-order-consistent snapshots across multiple
        volumes for CSI backups and data movement.', PriorityClass support across
        Velero components lets you control scheduling preference for server/node-agent/data
        movers/maintenance jobs separately., 'Scalability/resiliency improvements
        for data movers: configurable `PrepareQueueLength`, better handling of node-agent
        restarts, and improved node selection (including per storage class) for CSI
        snapshot data movement restores.', Resource policies now support reusable
        include/exclude filters via `includeExcludePolicy` in addition to `volumePolicy`.,
      'Operational improvements: BSL availability checks/metrics, better hook tracking,
        imagePullSecrets inheritance for data mover/maintenance jobs, and improved
        observability for failures.']
    breaking_changes: ['Restic deprecation enforced: creating new fs-backups using
        the Restic uploader is removed; `--uploader-type=restic` is invalid (restores
        from existing Restic backups still supported until v1.19).', Repository maintenance
        configuration flags were removed from Velero server CLI; you must use the
        repository maintenance job ConfigMap instead., 'PVC restore behavior change:
        Velero now always removes the `selected-node` annotation during PVC restore
        when no node mapping exists (previously it was preserved if the node existed).']
  chart_version: 11.3.2
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.16.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: [Windows cluster support for running Velero components on Windows nodes
        and backing up/restoring Windows workloads (with noted limitations)., Parallel
        ItemBlock backup via a configurable worker pool (`--item-block-worker-count`)
        to improve backup throughput; hooks run as part of item blocks and can execute
        in parallel., 'Data mover restore scalability improvement: optional spreading
        of restores for WaitForFirstConsumer volumes across nodes via node-agent `ignoreDelayBinding`
        configuration.', Improved observability for data mover backup/restore by logging
        intermediate object statuses and cleanup deletion errors in node-agent logs.,
      CSI snapshot backup/restore usability improvement by removing retained VolumeSnapshotContent
        objects from backups (avoids syncing/restoring unnecessary CSI artifacts).,
      'BackupRepository maintenance enhancements: maintenance history (`RecentMaintenance`),
        job recapture after server restart, and better handling of readOnly BSLs/BackupRepositories;
        configurable maintenance interval (`fullMaintenanceInterval` with normal/fast/eager
        GC).', Volume Policy enhancement to filter volumes by PVC labels., Per-object
        control of restoring resource status via `velero.io/restore-status` annotation.,
      Velero restore-helper binary merged into the main Velero image (single image
        contains velero/velero-helper/velero-restore-helper).]
    breaking_changes: []
  chart_version: 10.1.3
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.16.2']
- version: 1.15.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Data mover micro service: CSI snapshot data movement shifts from node-agent
        pods to dedicated per-backup/restore pods, improving security (no hostPath),
        resilience, and allowing per-job resource controls.', "Item Block concepts\
        \ + ItemBlockAction (IBA) plugin: resources can be grouped into \u201Citem\
        \ blocks\u201D for future multi-threaded backups; built-in IBAs for Pods/PVCs\
        \ plus custom IBAs supported (single-threaded processing still in 1.15).",
      'Node selection for repository maintenance jobs via a new repository maintenance
        configMap, to steer heavy maintenance workloads to specific/idle nodes.',
      'Backup PVC configuration via new configMap: support read-only mounts to speed
        exposes on some storage (e.g., Ceph) and choose a dedicated storageClass for
        backup PVCs.', Backup repository cache limit configuration via new configMap
        to cap client-side cache/ephemeral storage usage per repository and reduce
        eviction risk., 'Performance improvements: fixes Velero server memory leak
        after plugin calls; plugin inherits client-qps/client-burst; Kopia upstream
        fixes to reduce memory in large repos.']
    breaking_changes: ['Restic path for fs-backup is deprecated starting 1.15: backups/restores
        still work but warnings appear when using --uploader-type=restic or restic-based
        fs-backup flows; plan migration to kopia/uploader alternatives.', node-agent
        configuration configMap name is no longer fixed; if you use a custom configMap
        you must set the node-agent server parameter node-agent-configmap to match.,
      Repository maintenance job tuning flags are effectively moved to a repository
        maintenance configMap (flags still accepted but configMap takes precedence
        if both set)., "\u2018Changing PVC selected-node\u2019 feature is deprecated\
        \ in 1.15 and should not be relied upon; will be removed in a future release."]
  chart_version: 8.7.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.15.2']
- version: 1.14.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: [Moves kopia/restic backup repository maintenance out of the Velero
        server pod into separate Kubernetes Jobs to reduce OOM risk; resources for
        these jobs can be configured during install., 'Extends VolumePolicies to support
        per-volume backup action selection (e.g., `fs-backup` vs `snapshot`) for finer-grained
        control without changing workloads.', 'Adds node selection for data-mover
        pods via a ConfigMap so long-running, resource-heavy data movement can be
        constrained to eligible nodes.', Persists VolumeInfo metadata for restores
        (similar to backups) and enhances `velero restore describe` output to show
        restored volume handling details., Introduces a new Restore `Finalizing` phase
        to ensure PV label restoration and post-restore hooks happen after volume
        restore/data movement completes., Adds Azure service principal certificate-based
        authentication support (in addition to secret-based) to enable phishing-resistant
        auth and conditional access policies.]
    breaking_changes: [CSI plugin is now merged into the main Velero repo and installed
        by default as an internal plugin; do not install it separately via `velero
        install --plugins`., 'Default resource requests/limits for the node-agent
        are removed, making node-agent pods BestEffort QoS; you may need to set explicit
        resources if you relied on previous defaults.', 'Namespace filtering behavior
        changes: when `includedNamespaces`/`excludedNamespaces` are unset but label
        selectors are set, only namespaces containing matching resources are backed
        up (previously all namespaces were included).', Restore may now end as `PartiallyFailed`
        if PV patching in the new `Finalizing` phase is blocked by a PV stuck in `Pending`
        (previously could report `Complete`).]
  chart_version: 7.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.14.1']
- version: 1.13.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Resource Modifiers gained JSON Merge Patch and Strategic Merge Patch
        support, enabling more flexible restore-time resource edits from the same
        ConfigMap rules.', Node-agent concurrency controls were added so you can cap/shape
        how many filesystem backup and CSI snapshot data-mover operations run per
        node (globally and per-node)., Kopia uploader now supports configurable parallel
        file upload options to speed up filesystem backups and CSI snapshot data movement.,
      Restores can optionally write sparse files for fs-restore and CSI snapshot data
        movement to improve performance/space usage in some cases., "`velero backup\
        \ describe` output was enhanced with a new \u201CBackup Volumes\u201D section\
        \ and now shows CSI snapshot data movement details.", 'Backups now write a
        new VolumeInfo metadata file in the repository to record PV/PVC volume backup
        method, snapshot info, and status; used to drive PV restore decisions.', Improved
        resilience of CSI snapshot data movement across Velero pod/node-agent restarts
        so operations are less likely to get stuck after restarts., Backup/restore
        hook execution details are now tracked in CR status (HooksAttempted/HooksFailed)
        and shown in describe output., AWS SDK for Go was bumped to v2 for better
        CPU/memory performance., Azure AD/Workload Identity support was extended to
        Kopia operations (filesystem backup/data mover/etc.) in addition to native
        snapshots., Runtime bumped to Go 1.21.6 and Kopia bumped to 0.15.0 (plus other
        dependency bumps for CVEs).]
    breaking_changes: ['CLI output change: `velero backup describe` reorganized/changed
        formatting; scripts parsing the old output may break.', 'API type change:
        `DataUploadSpec.DataMoverConfig` changed from `*map[string]string` to `map[string]string`;
        any custom tooling/controllers using this field must be updated.', '`velero
        install` now enables informer cache by default (previously disabled); this
        can increase Velero pod memory usage and may require raising memory limits
        or explicitly disabling via `--disable-informer-cache`.']
  chart_version: 6.7.0
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.13.2']
- version: 1.12.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['CSI Snapshot Data Movement: can move CSI snapshot contents out of
        the source cluster/storage into durable backup storage and restore later (including
        cross-environment/cloud scenarios).', 'Resource Modifiers (JSON Substitutions):
        define match filters and JSON patch operations to mutate resources during
        restore without writing a custom RestoreItemAction plugin.', 'Multiple VolumeSnapshotClasses
        support in the Velero CSI plugin: allows choosing a specific VolumeSnapshotClass
        per backup instead of relying on a single labeled class.', 'Restore finalizer
        cleanup: `velero restore delete` now also cleans up restore-associated data
        in the backup storage location.', 'Runtime/deps refresh: Golang bumped to
        1.20.7 and Kopia bumped to 0.13.x along with other dependency updates.']
    breaking_changes: ['Default `uploader-type` changes from `restic` to `kopia`,
        which can change filesystem-backup behavior and repository expectations if
        you relied on restic defaults.', 'CSI snapshot timing/timeout behavior changed:
        snapshot handle creation uses `backup.spec.csiSnapshotTimeout` (was a fixed
        10m) and ReadyToUse waiting uses operation timeouts (default 4h).', Helm chart
        v4.0.0+ supports multiple BackupStorageLocations (BSL) and VolumeSnapshotLocations
        (VSL) and changes their values schema from map to slice; this is not backward
        compatible and should be migrated before upgrading., Finalizers added to Velero
        CRs (restore/dataupload/datadownload) can cause `kubectl delete namespace
        velero` to hang; use `velero uninstall` or remove/handle finalizers before
        namespace deletion.]
  chart_version: 5.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.12.3']
- version: 1.11.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary: null
  chart_version: 5.0.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.11.1']
- version: 1.10.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.9.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.8.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
