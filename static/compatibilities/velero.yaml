icon: https://velero.io/img/Velero.svg
git_url: https://github.com/vmware-tanzu/velero
release_url: https://github.com/vmware-tanzu/velero/releases/tag/v{vsn}
helm_repository_url: https://vmware-tanzu.github.io/helm-charts
versions:
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "## Helm values / install-time config changes to check\n\n### 1)\
      \ **Restic uploader removed (breaking)**\n* `--uploader-type=restic` is **no\
      \ longer valid** in v1.17.\n  * If your Helm chart values set anything equivalent\
      \ (commonly `configuration.uploaderType`, `uploaderType`, `deployRestic`, `deployNodeAgent`/`restic`\
      \ toggles, etc.), remove/disable Restic and use the current fs-backup path.\n\
      \  * You can **still restore old Restic-based backups until v1.19**, but you\
      \ cannot create new ones.\n\n### 2) **Repository maintenance job flags removed\
      \ from velero server (breaking)**\nThe following server parameters were removed\
      \ and must be configured via the **repository maintenance job ConfigMap** instead:\n\
      * `--keep-latest-maintenance-jobs`\n* `--maintenance-job-cpu-request`\n* `--maintenance-job-mem-request`\n\
      * `--maintenance-job-cpu-limit`\n* `--maintenance-job-mem-limit`\n\nIf you previously\
      \ set these via chart values that map to `server.extraArgs`, move them to the\
      \ chart\u2019s maintenance-job configmap values (name varies by chart).\n\n\
      ### 3) New/updated **node-agent** configuration knobs worth reviewing\nThese\
      \ are additive but may require Helm values if you want to use them:\n* `PrepareQueueLength`\
      \ (node-agent): throttles creation of data mover pods to avoid large numbers\
      \ stuck Pending.\n* `priorityClassName` support across modules (server, node-agent,\
      \ data mover pods, maintenance jobs): you may want to set these explicitly.\n\
      * Parameterized kubelet mount path for node-agent install (only if you run non-standard\
      \ kubelet paths).\n\n### 4) Modernized fs-backup (architecture change)\nfs-backup\
      \ is now micro-service based. In Helm terms this may translate into:\n* more/changed\
      \ pod templates for data mover / fs-backup components,\n* potential new configmaps/args\
      \ for concurrency/cancel/resume behavior.\n\n(Exact value keys depend on your\
      \ chart; validate rendered manifests before applying.)"
    chart_updates: ['fs-backup moved to a micro-service architecture (better concurrency
        control, cancel/resume, and resiliency across node-agent restarts).', 'Windows
        support expands: fs-backup now supports Windows workloads; data mover pods
        can run on Windows nodes with required tolerations.', Volume Group Snapshots
        support added (Kubernetes beta feature) for CSI snapshot backup and CSI snapshot
        data movement., 'PriorityClass support added across Velero components (server,
        node-agent, data mover pods, maintenance jobs).', 'Data mover scalability
        improvements: throttled pod creation via node-agent `PrepareQueueLength`,
        improved restart/orphan handling, expanded node-selection for restore and
        per-storageclass node-selection.', Resource policy enhanced with reusable
        include/exclude filters via `includeExcludePolicy`., 'Operational changes:
        repository maintenance job configuration moved from server flags to a ConfigMap;
        additional config validation added for install CLI and server start.']
    features: [Modernized fs-backup into a micro-service architecture with concurrency
        control plus cancel/resume and improved resiliency across node-agent restarts.,
      'fs-backup now supports Windows workloads, enabling full Windows backup/restore
        scenarios (with CSI data movement support introduced earlier).', Adds support
        for Kubernetes Volume Group Snapshots to take point-in-time consistent snapshots
        across multiple related volumes., 'Adds PriorityClass support so you can control
        scheduling priority for server, node-agent, data movers, and maintenance jobs.',
      'Improves data mover scalability with a node-agent prepare queue to avoid flooding
        the cluster with Pending pods, plus better restart/orphan handling and node-selection
        (including per-storageclass).', Adds reusable resource include/exclude filtering
        via `includeExcludePolicy` in resource policies.]
    breaking_changes: ["Restic uploader path is removed: `--uploader-type=restic`\
        \ is no longer a valid install configuration; you can\u2019t create new Restic-based\
        \ backups (restores remain supported until v1.19).", Repository maintenance
        job settings are no longer configured via Velero server flags; the maintenance
        job CPU/memory and keep-latest settings must be moved to the repository maintenance
        job ConfigMap., 'PVC restore behavior change: selected-node annotation is
        now removed during PVC restore when no node mapping exists (previously it
        could be preserved in some cases).']
  chart_version: 11.2.0
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.17.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Modernized file-system backup (fs-backup) to a micro-service architecture,
        enabling concurrency control, cancel/resume behavior, and better resiliency/resource
        isolation for backups/restores.', 'fs-backup now supports Windows workloads
        by allowing data mover pods to run on Windows nodes, completing end-to-end
        Windows workload coverage alongside CSI data movement introduced in 1.16.',
      'Adds VolumeGroupSnapshot support (Kubernetes beta feature) for both CSI snapshot
        backups and CSI snapshot data movement to take crash-consistent, write-order-consistent
        point-in-time snapshots across multiple volumes.', 'Adds PriorityClass configuration
        support across Velero components (server, node-agent, data mover pods, and
        repository maintenance jobs) to control scheduling priority.', 'Improves data
        mover scalability/resiliency with a node-agent `PrepareQueueLength` throttle
        to avoid creating excessive pending pods, and improved restart handling so
        data movements can resume after node-agent restarts.', Adds node selection
        controls for CSI snapshot data movement restores (and per storage class) so
        data mover pods can be restricted to compatible nodes., 'Extends Resource
        Policy with reusable include/exclude filters (`includeExcludePolicy`) in addition
        to volumePolicy, allowing shared resource filtering across multiple backups.']
    breaking_changes: ['Restic-based fs-backup creation is removed: `--uploader-type=restic`
        is no longer valid for installs; you can still restore from existing Restic
        backups until v1.19.', Repository maintenance job settings are no longer configurable
        via Velero server flags; the related server parameters were removed and must
        be managed via the repository maintenance job ConfigMap instead., 'PVC restore
        behavior change: during PVC restore, Velero now always removes the `selected-node`
        annotation when no node mapping exists (previously it could be preserved if
        the node existed).']
  chart_version: 11.3.1
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
- version: 1.16.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Windows cluster support, including hybrid/multi-arch image builds
        and ability for node-agent, data mover pods, and maintenance jobs to run on
        Windows nodes; data mover can now back up/restore Windows workloads end-to-end
        (with stated limitations).', 'Parallel ItemBlock backup: Velero now backs
        up ItemBlocks concurrently via a configurable thread pool (`--item-block-worker-count`,
        default 1), improving throughput; pre/post hooks are executed within ItemBlocks
        and can run in parallel.', Improved data mover restore scalability for WaitForFirstConsumer
        volumes by optionally distributing restores across nodes via node-agent config
        flag `ignoreDelayBinding`., 'Data mover observability improvements: richer
        status/error logging for intermediate objects and cleanup failures, enabled
        by default in node-agent logs.', 'CSI snapshot usability improvement: avoids
        retaining/restoring unnecessary `VolumeSnapshotContent` objects in backups,
        reducing cross-cluster sync noise.', 'BackupRepository maintenance resiliency/observability:
        adds `RecentMaintenance` history in BackupRepository status, recaptures running
        jobs after server restart, and respects readOnly BackupStorageLocations (no
        init/maintenance).', Configurable Kopia full maintenance intervals (`normalGC`/`fastGC`/`eagerGC`)
        via `fullMaintenanceInterval` in backupRepository configuration., 'Volume
        Policy enhancements: filter volumes by PVC labels (and additional CSI PV VolumeAttributes
        properties).', Per-object resource status restore control via `velero.io/restore-status`
        annotation., 'Velero restore-helper binaries are merged into the main Velero
        image, reducing separate image management.']
    breaking_changes: []
  chart_version: 10.1.3
  images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.16.2']
- version: 1.15.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Data mover micro service: CSI Snapshot Data Movement transfers move
        from node-agent pods to dedicated per-operation backupPods/restorePods, improving
        isolation, resource control, and avoiding privileged hostPath access for volume
        data.', 'Item Block concepts and ItemBlockAction (IBA) plugin type added to
        group related resources (e.g., Pods/PVCs) into blocks; groundwork for future
        multi-threaded backup processing (concurrency not enabled yet).', 'Repository
        maintenance job node selection via a new repository maintenance configuration
        ConfigMap, letting you steer maintenance jobs onto specific/idle nodes.',
      'Backup PVC configuration for data movement: support read-only mounts (to speed
        expose for some storages like Ceph) and selecting a different StorageClass
        for backupPVCs.', Backup repository cache limit configuration via a new backup
        repository configuration ConfigMap to control client-side cache and reduce
        pod eviction from ephemeral storage pressure., 'Performance improvements:
        fixed server memory leak after plugin calls; server client-qps/client-burst
        args now passed to plugins; includes upstream Kopia improvements for high-file-count
        repos.']
    breaking_changes: ['Restic is deprecated for fs-backup starting in 1.15: backups/restores
        still succeed but warnings appear when using --uploader-type=restic or otherwise
        taking the restic path; plan migration to kopia/node-agent workflows before
        restic removal in a future release.', node-agent configuration ConfigMap name
        is no longer fixed; if you use a custom name you must pass it via the node-agent
        server parameter node-agent-configmap., Repository maintenance job settings
        are moving from server flags to a repository maintenance job configuration
        ConfigMap; ConfigMap values take precedence over flags when both are set (flags
        kept for backward compatibility)., Changing PVC selected-node restore feature
        is deprecated and not recommended; expect removal in a future release per
        Velero deprecation policy.]
  chart_version: 8.7.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.15.2']
- version: 1.14.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: [Repository maintenance for kopia/restic backup repositories is moved
        to separate Kubernetes Jobs to avoid Velero server pod OOM during maintenance;
        users can set job resource requests., "VolumePolicies can now choose the backup\
        \ method per volume (e.g., force `fs-backup` or `snapshot`) to enable fine\u2011\
        grained opt-in/out behavior without changing workloads.", Data mover (snapshot
        data movement / FS backup) supports node selection via ConfigMap to constrain
        where datamover pods run., Restore operations now persist VolumeInfo metadata
        and `velero restore describe` surfaces more detailed volume restore information.,
      'A new Restore phase `Finalizing` improves correctness: PV label patching happens
        after volume data restore, and post-restore hooks run after data movement
        completes.', Azure gains service principal certificate-based authentication
        support (phishing-resistant option).]
    breaking_changes: [CSI plugin is now merged into the Velero repo and installed
        by default as an internal plugin; do not install it via `--plugins` during
        install/upgrade., 'Default CPU/memory requests/limits for the node-agent are
        removed; node-agent pods become BestEffort unless you explicitly set resources,
        which can affect scheduling/evictions.', 'Namespace filtering behavior changes
        when `includedNamespaces`/`excludedNamespaces` are unset but label selectors
        are set: only namespaces containing matching resources are included (previously
        all namespaces were included).', 'Restores may report `PartiallyFailed` in
        cases where PV patching in `Finalizing` is blocked (e.g., PV stuck Pending),
        whereas previous versions could end as `Complete`.']
  chart_version: 7.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.14.1']
- version: 1.13.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: ''
    chart_updates: []
    features: ['Resource Modifiers enhanced to support JSON Merge Patch and Strategic
        Merge Patch in addition to JSON Patch, allowing more flexible restore-time
        edits from the same ConfigMap.', Node-agent concurrency controls let you cap/shape
        how many filesystem backup and CSI snapshot data-mover tasks run per node
        (globally or per-node) to manage cluster resource usage., Kopia uploader now
        has configurable parallel file upload options to speed up filesystem backups
        and CSI snapshot data movement backups., 'Restores can optionally write sparse
        files for fs-restore and CSI snapshot data movement restores, improving efficiency
        for sparse data.', "`velero backup describe` gains a dedicated \u201CBackup\
        \ Volumes\u201D section and better visibility into CSI snapshot data movement\
        \ details; hook execution details are now surfaced in CR status and describe\
        \ output.", 'Backups now write a VolumeInfo metadata file (PVC/PV method,
        snapshot/data-mover status) that drives PV restore decisions and provides
        a volume-summary for downstream tooling.', Improved resiliency for CSI snapshot
        data movement and related operations when the Velero server pod or node-agent
        restarts., AWS SDK for Go upgraded to v2 for better CPU/memory efficiency;
        Azure AD/Workload Identity support extended to Kopia operations (fs-backup/data
        mover)., 'Runtime/dependencies updated: Go 1.21.6 and Kopia 0.15.0 (plus other
        library bumps).']
    breaking_changes: ["`velero backup describe` output format changes: several fields\
        \ for native snapshots/CSI/fs-backups moved under the new \u201CBackup Volumes\u201D\
        \ section\u2014any parsing/automation may break.", 'API change in DataUploadSpec:
        `DataMoverConfig` changes from `*map[string]string` to `map[string]string`,
        which can break custom tooling/clients expecting the old type.', 'Installer
        behavior change: informer cache is now enabled by default to match help text;
        may increase memory usage and can cause OOM unless memory limits are raised
        or cache is disabled via `--disable-informer-cache`.']
  chart_version: 6.7.0
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.13.2']
- version: 1.12.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary:
    helm_changes: "## Helm values / chart migration notes (Velero chart v3.x \u2192\
      \ v4.0.0 implied by app v1.12)\n\n- **BackupStorageLocation (BSL) and VolumeSnapshotLocation\
      \ (VSL) values change from *map* to *slice*** starting with **velero Helm chart\
      \ v4.0.0** (referenced in the v1.12 breaking changes). This is **not backward\
      \ compatible**.\n  - Action: update your `values.yaml` to the new list format\
      \ **before** upgrading the chart/app.\n  - Validate any templating/overlays\
      \ (Helmfile/Kustomize) that assumed map keys.\n\n- **Default `uploader-type`\
      \ changes to `kopia`** in v1.12 (was `restic`).\n  - Action: if you want to\
      \ keep Restic behavior, **explicitly set** `uploaderType: restic` (or the equivalent\
      \ chart value/extraArgs) during the upgrade.\n  - Action: if adopting Kopia,\
      \ ensure repo/credentials/IAM assumptions match Kopia requirements.\n\n- **Namespace\
      \ deletion behavior changes due to new finalizers** (`restore`, `dataupload`,\
      \ `datadownload`).\n  - Action: prefer `velero uninstall` for removal, or ensure\
      \ finalizers are cleared before deleting the namespace to avoid a stuck namespace.\n\
      \n- **CSI snapshot timing knobs changed**.\n  - Action: review/set timeouts\
      \ in values/extraArgs to align with your environment (see breaking changes below).\n"
    chart_updates: ["Helm chart v4.0.0 supports configuring **multiple** BackupStorageLocations\
        \ and VolumeSnapshotLocations (drives the map\u2192slice migration).", 'Operational
        behavior change: uninstall/namespace deletion may be impacted by new Velero
        CR finalizers; plan lifecycle operations accordingly.']
    features: ['CSI Snapshot Data Movement: ability to move CSI snapshot data into
        durable backup storage and restore across environments/clouds.', 'Resource
        Modifiers (JSON Substitutions): apply JSON patches to selected resources during
        restore without writing a custom RestoreItemAction plugin.', 'Multiple VolumeSnapshotClasses
        support: choose a specific VolumeSnapshotClass per backup rather than relying
        on driver-name matching and a single label.', 'Restore finalizer cleanup:
        `velero restore delete` now cleans up associated external/backup-storage data,
        not only in-cluster CRs.']
    breaking_changes: [Default file-system backup uploader switches from **Restic**
        to **Kopia** (`uploader-type` default changes). This can change repository
        format/behavior and operational expectations unless you explicitly pin Restic.,
      'CSI snapshot timeouts behavior changes: snapshot handle creation wait is now
        `backup.spec.csiSnapshotTimeout` (instead of fixed 10m), and async wait for
        `ReadyToUse` uses the operation timeout (default 4h). Review these timeouts
        for your clusters.', "Helm chart v4.0.0: BSL/VSL configuration changes from\
        \ **map \u2192 slice**, not backward compatible; update values before upgrading.",
      'Finalizers added to Velero CRs (`restore`, `dataupload`, `datadownload`) can
        cause **namespace deletion to hang** if pods are removed first; use `velero
        uninstall` or manage finalizers explicitly.']
  chart_version: 5.2.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.12.3']
- version: 1.11.0
  kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
    '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
  requirements: []
  incompatibilities: []
  summary: null
  chart_version: 5.0.2
  images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.11.1']
- version: 1.10.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.9.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
- version: 1.8.0
  kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19',
    '1.18']
  requirements: []
  incompatibilities: []
  summary: null
