addons:
- icon: https://avatars.githubusercontent.com/u/30269780?s=200&v=4
  git_url: https://github.com/argoproj/argo-rollouts
  release_url: https://github.com/argoproj/argo-rollouts/releases/tag/v{vsn}
  helm_repository_url: https://argoproj.github.io/argo-helm
  versions:
  - version: 1.8.3
    kube: ['1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["No Helm chart changelog was provided in the notes you pasted\
          \ (only application GitHub release notes). Treat this as an application-only\
          \ summary; verify the Helm chart version you\u2019ll deploy and diff `values.yaml`\
          \ separately."]
      features: ['Prometheus metric provider: adds range query support, enabling analyses
          over a time range instead of single-point queries.', 'Analysis/New Relic:
          can now set a timeout and the provider returns the resolved query as metadata
          (useful for debugging/traceability).', 'Datadog metric provider: supports
          multi-account configurations and adds support for providing credentials
          to download plugins.', 'Controller: adds an (alpha) canary steps plugin
          mechanism for extending canary step behavior.', 'Controller: canary ingress
          support allows specifying full annotations for nginx canary ingresses (more
          flexibility for NGINX users).', 'Controller: enables pprof profiling support
          for debugging performance issues.', 'Analysis: adds ConsecutiveSuccessLimit
          to Analysis (lets you require N consecutive successful measurements).',
        'Metrics/observability: new Prometheus `build_info` metric is emitted.']
      breaking_changes: []
    chart_version: 2.40.5
    images: ['quay.io/argoproj/argo-rollouts:v1.8.3']
  - version: 1.8.0
    kube: ['1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Prometheus metric provider: adds Prometheus range query support
          for Analysis metrics (enables querying over a time window instead of only
          instant queries).', 'Controller: introduces an (alpha) canary steps plugin
          mechanism, allowing canary step behavior/logic to be extended via plugins.',
        'Controller: allows specifying full annotations for NGINX canary ingresses
          (not just limited/filtered subsets).', 'Metrics/Analysis providers: expands
          New Relic provider (adds timeout support and returns resolved queries as
          metadata) and adds multi-account support for Datadog metrics provider; also
          adds support for providing credentials to download metric provider plugins.',
        'Observability: adds pprof profiling support in the controller for performance
          troubleshooting.', 'Monitoring: adds a new Prometheus build_info metric
          to expose version/build metadata.']
      breaking_changes: []
    chart_version: 2.39.1
    images: ['quay.io/argoproj/argo-rollouts:v1.8.0']
  - version: 1.7.0
    kube: ['1.29', '1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Support multiple ALB ingresses for ALB traffic routing (useful when
          a rollout needs to manage traffic across more than one ALB resource)., 'Prometheus
          metric provider enhancements: configurable request timeout, optional TLS
          verification disable (insecure), and support for custom HTTP headers when
          querying Prometheus.', 'AnalysisRun/AnalysisTemplate enhancements: support
          custom metadata on AnalysisRun, allow setting job metadata via metrics.provider.job.metadata,
          include Rollout selector MatchLabels in generated AnalysisRuns, and add
          a merge key to AnalysisTemplate.', 'UI/UX: refreshed Rollouts dashboard.',
        'Events/notifications: controller can emit Kubernetes events on informer add;
          adds self-service notification support.']
      breaking_changes: ['No explicit breaking changes were called out in the provided
          notes for v1.7.0; however, verify any custom traffic router plugins and
          ALB configuration fields against your current manifests because several
          ALB-related behaviors changed in 1.7.0.']
    chart_version: 2.36.0
    images: ['quay.io/argoproj/argo-rollouts:v1.7.0']
  - version: 1.6.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["No Helm chart changelog/values information was provided in\
          \ the notes you pasted (these are Argo Rollouts *application* release notes).\
          \ Treat the Helm upgrade as potentially requiring chart value review (RBAC,\
          \ container args, extraVolumes/extraArgs, dashboard/service) but confirm\
          \ against the chart\u2019s own CHANGELOG/values.yaml for the versions you\u2019\
          re moving between."]
      features: [Dashboard UI refresh in v1.6.0 improves Rollouts dashboard look/UX.,
        'AnalysisRun supports custom metadata, plus additional context/merge behavior
          (e.g., merge key) to help manage metric/analysis configuration.', 'Prometheus
          metric provider enhancements: configurable timeout, optional insecure TLS,
          and support for custom HTTP headers.', 'Traffic routing/ingress improvements:
          support multiple ALB ingresses and retain TLS config for NGINX canary ingresses;
          additional docs/plugins for routers like Contour and guidance for other
          ingress controllers.', 'Operational/observability improvements: controller
          emits additional Kubernetes events and logging improvements (klog/logrus
          bridge).']
      breaking_changes: ['Traffic router plugin naming pattern was standardized/changed;
          if you use trafficrouter plugins (or custom plugins), verify plugin names/identifiers
          and update any references accordingly.']
    chart_version: 2.32.0
    images: ['quay.io/argoproj/argo-rollouts:v1.6.0']
  - version: 1.2.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["No Helm chart changelog was provided in the notes; summary\
          \ below covers application/controller changes only. If you are upgrading\
          \ via Helm, also review the chart\u2019s own CHANGELOG/values for your chart\
          \ version bump (image tag, CRDs install/upgrade behavior, RBAC, ServiceAccount,\
          \ leaderElection settings, ingress apiVersion handling)."]
      features: ['HA (active-passive) leader election support for rollouts-controller,
          enabling higher availability controller deployments.', 'Networking.k8s.io/v1
          Ingress support (Kubernetes v1.22+), improving compatibility with newer
          clusters.', "Analysis \u201Cdry-run\u201D mode (also for experiments), allowing\
          \ you to validate analysis definitions without enforcing failures.", Support
          for weighted experiment steps and richer experiment traffic routing behavior.,
        Ping-pong service management to simplify blue/green-style service swapping
          patterns., 'Customizable metric/measurement retention limits for AnalysisRuns/metrics,
          improving resource usage control.', AWS App Mesh traffic routing support
          as an additional provider., Support for multiple traffic routing providers
          simultaneously via multiple TrafficRoutingReconcilers., 'Web metric providers
          now support POST/PUT requests (not just GET), enabling more flexible integrations.',
        Additional metadata surfaced from analysis providers (useful for debugging)
          and Argo Rollouts version exported on the /metrics endpoint., Scalability/performance
          improvements including higher default Kubernetes client QPS/Burst (and making
          them tunable).]
      breaking_changes: ['Canary rollout calculation/approximation behavior was changed
          to improve accuracy and to honor maxSurge (marked as a breaking fix in the
          release notes). This can change how many pods are created at each step compared
          to v1.1, so watch capacity and rollout pacing during the first upgrades.']
    chart_version: 2.12.0
    images: ['quay.io/argoproj/argo-rollouts:v1.2.0']
  - version: 1.1.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.2.0
    images: ['quay.io/argoproj/argo-rollouts:v1.1.0']
  name: argo-rollouts
- icon: https://kubernetes.io/images/blog-logging/2018-04-10-container-storage-interface-beta/csi-logo.png
  git_url: https://github.com/kubernetes-sigs/aws-ebs-csi-driver
  release_url: https://github.com/kubernetes-sigs/aws-ebs-csi-driver/releases/tag/v{vsn}
  helm_repository_url: https://kubernetes-sigs.github.io/aws-ebs-csi-driver
  versions:
  - version: 1.54.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.54.1
    images: ['public.ecr.aws/csi-components/csi-attacher:v4.10.0-eksbuild.3', 'public.ecr.aws/csi-components/csi-node-driver-registrar:v2.15.0-eksbuild.3',
      'public.ecr.aws/csi-components/csi-provisioner:v6.1.0-eksbuild.2', 'public.ecr.aws/csi-components/csi-resizer:v2.0.0-eksbuild.3',
      'public.ecr.aws/csi-components/livenessprobe:v2.17.0-eksbuild.3', 'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.54.0',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20251209-855adc2699-master']
  - version: 1.53.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.53.0
    images: ['public.ecr.aws/csi-components/csi-attacher:v4.10.0-eksbuild.2', 'public.ecr.aws/csi-components/csi-node-driver-registrar:v2.15.0-eksbuild.2',
      'public.ecr.aws/csi-components/csi-provisioner:v5.3.0-eksbuild.5', 'public.ecr.aws/csi-components/csi-resizer:v1.14.0-eksbuild.5',
      'public.ecr.aws/csi-components/livenessprobe:v2.17.0-eksbuild.2', 'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.53.0',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20251021-e2c2c9806f-master']
  - version: 1.52.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.52.0
    images: ['public.ecr.aws/csi-components/csi-attacher:v4.9.0-eksbuild.4', 'public.ecr.aws/csi-components/csi-node-driver-registrar:v2.14.0-eksbuild.5',
      'public.ecr.aws/csi-components/csi-provisioner:v5.3.0-eksbuild.4', 'public.ecr.aws/csi-components/csi-resizer:v1.14.0-eksbuild.4',
      'public.ecr.aws/csi-components/livenessprobe:v2.16.0-eksbuild.5', 'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.52.0',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250925-95b5a2c7a5-master']
  - version: 1.51.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.51.0
    images: ['public.ecr.aws/csi-components/csi-attacher:v4.9.0-eksbuild.4', 'public.ecr.aws/csi-components/csi-node-driver-registrar:v2.14.0-eksbuild.5',
      'public.ecr.aws/csi-components/csi-provisioner:v5.3.0-eksbuild.4', 'public.ecr.aws/csi-components/csi-resizer:v1.14.0-eksbuild.4',
      'public.ecr.aws/csi-components/livenessprobe:v2.16.0-eksbuild.5', 'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.51.0',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250925-95b5a2c7a5-master']
  - version: 1.50.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.50.0
    images: ['public.ecr.aws/csi-components/csi-attacher:v4.9.0-eksbuild.4', 'public.ecr.aws/csi-components/csi-node-driver-registrar:v2.14.0-eksbuild.5',
      'public.ecr.aws/csi-components/csi-provisioner:v5.3.0-eksbuild.4', 'public.ecr.aws/csi-components/csi-resizer:v1.14.0-eksbuild.4',
      'public.ecr.aws/csi-components/livenessprobe:v2.16.0-eksbuild.5', 'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.50.0',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250925-95b5a2c7a5-master']
  - version: 1.49.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.49.1
    images: ['public.ecr.aws/csi-components/csi-attacher:v4.9.0-eksbuild.4', 'public.ecr.aws/csi-components/csi-node-driver-registrar:v2.14.0-eksbuild.5',
      'public.ecr.aws/csi-components/csi-provisioner:v5.3.0-eksbuild.4', 'public.ecr.aws/csi-components/csi-resizer:v1.14.0-eksbuild.4',
      'public.ecr.aws/csi-components/livenessprobe:v2.16.0-eksbuild.5', 'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.49.0',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250905-c89b045f57-master']
  - version: 1.48.0
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
      '1.25', '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.48.0
    images: ['public.ecr.aws/csi-components/csi-attacher:v4.9.0-eksbuild.4', 'public.ecr.aws/csi-components/csi-node-driver-registrar:v2.14.0-eksbuild.5',
      'public.ecr.aws/csi-components/csi-provisioner:v5.3.0-eksbuild.4', 'public.ecr.aws/csi-components/csi-resizer:v1.14.0-eksbuild.4',
      'public.ecr.aws/csi-components/livenessprobe:v2.16.0-eksbuild.5', 'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.48.0',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250815-171060767f-master']
  - version: 1.47.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.47.0
    images: ['public.ecr.aws/csi-components/csi-attacher:v4.9.0-eksbuild.3', 'public.ecr.aws/csi-components/csi-node-driver-registrar:v2.14.0-eksbuild.4',
      'public.ecr.aws/csi-components/csi-provisioner:v5.3.0-eksbuild.3', 'public.ecr.aws/csi-components/csi-resizer:v1.14.0-eksbuild.3',
      'public.ecr.aws/csi-components/livenessprobe:v2.16.0-eksbuild.4', 'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.47.0',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250722-31ecdfb417-master']
  - version: 1.46.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.46.0
    images: ['public.ecr.aws/csi-components/csi-attacher:v4.9.0-eksbuild.3', 'public.ecr.aws/csi-components/csi-node-driver-registrar:v2.14.0-eksbuild.4',
      'public.ecr.aws/csi-components/csi-provisioner:v5.3.0-eksbuild.3', 'public.ecr.aws/csi-components/csi-resizer:v1.14.0-eksbuild.3',
      'public.ecr.aws/csi-components/livenessprobe:v2.16.0-eksbuild.4', 'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.46.0',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250613-876fb90a97-master']
  - version: 1.45.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.45.1
    images: ['public.ecr.aws/csi-components/csi-attacher:v4.9.0-eksbuild.2', 'public.ecr.aws/csi-components/csi-node-driver-registrar:v2.14.0-eksbuild.3',
      'public.ecr.aws/csi-components/csi-provisioner:v5.3.0-eksbuild.2', 'public.ecr.aws/csi-components/csi-resizer:v1.14.0-eksbuild.2',
      'public.ecr.aws/csi-components/livenessprobe:v2.16.0-eksbuild.3', 'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.45.0',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250613-876fb90a97-master']
  - version: 1.44.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.44.0
    images: ['public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.44.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.8.1-eks-1-33-3',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.2.0-eks-1-33-3',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.13.2-eks-1-33-3',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.15.0-eks-1-33-3',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.13.0-eks-1-33-3',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250513-98d205aae3-master']
  - version: 1.43.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.43.0
    images: ['public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.43.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.8.1-eks-1-33-1',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.2.0-eks-1-33-1',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.13.2-eks-1-33-1',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.15.0-eks-1-33-1',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.13.0-eks-1-33-1',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250411-0688312353-master']
  - version: 1.42.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.42.0
    images: ['public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.42.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.8.1-eks-1-33-1',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.2.0-eks-1-33-1',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.13.2-eks-1-33-1',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.15.0-eks-1-33-1',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.13.0-eks-1-33-1',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250411-0688312353-master']
  - version: 1.41.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.41.0
    images: ['public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.41.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.8.1-eks-1-32-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.2.0-eks-1-32-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.13.2-eks-1-32-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.14.0-eks-1-32-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.13.0-eks-1-32-7',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250311-73aac21714-master']
  - version: 1.40.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.40.0
    images: ['public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.40.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.8.0-eks-1-32-6',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.2.0-eks-1-32-6',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.13.1-eks-1-32-6',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.14.0-eks-1-32-6',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.13.0-eks-1-32-6',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20250212-686cf422c6-master']
  - version: 1.39.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.39.0
    images: ['public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.39.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.8.0-eks-1-31-12',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.1.0-eks-1-31-12',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.12.0-eks-1-31-11',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.14.0-eks-1-31-12',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.13.0-eks-1-31-12',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20241230-3006692a6f-master']
  - version: 1.38.1
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.38.1
    images: ['public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.38.1', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.7.0-eks-1-32-1',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.1.0-eks-1-32-1',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.12.0-eks-1-32-1',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.14.0-eks-1-32-1',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.12.0-eks-1-32-1',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20241128-8df65c072f-master']
  - version: 1.37.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.37.0
    images: ['public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.37.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.7.0-eks-1-31-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.1.0-eks-1-31-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.12.0-eks-1-31-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.14.0-eks-1-31-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.12.0-eks-1-31-7',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20241021-d3a4913879-master']
  - version: 1.36.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.36.0
    images: ['public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.36.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.7.0-eks-1-31-5',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.1.0-eks-1-31-5',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.12.0-eks-1-31-5',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.14.0-eks-1-31-5',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.12.0-eks-1-31-5',
      'us-central1-docker.pkg.dev/k8s-staging-test-infra/images/kubekins-e2e:v20241011-e8871c079d-master']
  - version: 1.35.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.35.0
    images: ['gcr.io/k8s-staging-test-infra/kubekins-e2e:v20240903-6a352c5344-master',
      'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.35.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.7.0-eks-1-31-3',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.1.0-eks-1-31-3',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.12.0-eks-1-31-3',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.14.0-eks-1-31-3',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.12.0-eks-1-31-3']
  - version: 1.34.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.34.0
    images: ['gcr.io/k8s-staging-test-infra/kubekins-e2e:v20240803-cf1183f2db-master',
      'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.34.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.6.1-eks-1-30-10',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.0.1-eks-1-30-10',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.11.1-eks-1-30-10',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.13.0-eks-1-30-10',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.11.0-eks-1-30-10']
  - version: 1.33.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.33.0
    images: ['gcr.io/k8s-staging-test-infra/kubekins-e2e:v20240705-131cd74733-master',
      'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.33.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.6.1-eks-1-30-10',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.0.1-eks-1-30-10',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.11.1-eks-1-30-10',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.13.0-eks-1-30-10',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.11.0-eks-1-30-10']
  - version: 1.32.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.32.0
    images: ['gcr.io/k8s-staging-test-infra/kubekins-e2e:v20240611-597c402033-master',
      'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.32.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.6.1-eks-1-30-8',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.0.1-eks-1-30-8',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.11.1-eks-1-30-8',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.13.0-eks-1-30-8',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.11.0-eks-1-30-8']
  - version: 1.31.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.31.0
    images: ['gcr.io/k8s-staging-test-infra/kubekins-e2e:v20240311-b09cdeb92c-master',
      'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.31.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.5.1-eks-1-30-4',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v4.0.1-eks-1-30-4',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.10.1-eks-1-30-4',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.12.0-eks-1-30-4',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.10.1-eks-1-30-4']
  - version: 1.30.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Retry Manager to reduce EC2 API RateLimitExceeded errors during high
          churn/scale events., Prometheus metrics endpoint can be served over HTTPS
          by providing a certificate., 'Improved node drain behavior: supports Cluster
          Autoscaler taint and prestop hook now handles deleted Node objects to avoid
          ~6 minute attachment delays.', Migrated AWS interactions to AWS SDK for
          Go v2 for continued support and newer SDK features., Batch polling for DescribeVolumesModifications
          across volume modify/expand paths to reduce non-mutating API token limit
          issues at scale., 'Refactored node service to be platform-agnostic, improving
          modularity, testability, and code coverage.', Improved configuration management
          and internal architecture (entrypoint/controller/cloud module relationships).,
        Added explicit AttachVolume call during attachment-state polling to handle
          EC2 eventual consistency mismatches.]
      breaking_changes: ['Migration to AWS SDK for Go v2 may change behavior of AWS
          credential/config resolution and retry semantics; validate IAM/IRSA, endpoints,
          and any custom AWS config assumptions before/after upgrade.']
    chart_version: 2.30.0
    images: ['gcr.io/k8s-staging-test-infra/kubekins-e2e:v20240311-b09cdeb92c-master',
      'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.30.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.5.1-eks-1-30-2',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v4.0.1-eks-1-30-2',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.10.1-eks-1-30-2',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.12.0-eks-1-30-2',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.10.1-eks-1-30-2']
  - version: 1.29.1
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.29.1
    images: ['gcr.io/k8s-staging-test-infra/kubekins-e2e:v20240311-b09cdeb92c-master',
      'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.29.1', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.5.0-eks-1-29-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v4.0.0-eks-1-29-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.10.0-eks-1-29-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.12.0-eks-1-29-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.10.0-eks-1-29-7']
  - version: 1.29.0
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23',
      '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.29.0
    images: ['gcr.io/k8s-staging-test-infra/kubekins-e2e:v20240311-b09cdeb92c-master',
      'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.29.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.5.0-eks-1-29-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v4.0.0-eks-1-29-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.10.0-eks-1-29-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.12.0-eks-1-29-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.10.0-eks-1-29-7']
  - version: 1.28.0
    kube: ['1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21',
      '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.28.0
    images: ['gcr.io/k8s-staging-test-infra/kubekins-e2e:v20231206-f7b83ffbe6-master',
      'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.28.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.5.0-eks-1-29-5',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v4.0.0-eks-1-29-5',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.10.0-eks-1-29-5',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.12.0-eks-1-29-5',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.10.0-eks-1-29-5']
  - version: 1.26.1
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23',
      '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.26.1
    images: ['gcr.io/k8s-staging-test-infra/kubekins-e2e:v20231206-f7b83ffbe6-master',
      'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.26.1', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.4.3-eks-1-29-2',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v3.6.3-eks-1-29-2',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.9.3-eks-1-29-2',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.11.0-eks-1-29-2',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.9.3-eks-1-29-2']
  - version: 1.23.1
    kube: ['1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21',
      '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.23.1
    images: ['gcr.io/k8s-staging-test-infra/kubekins-e2e:v20230727-ea685f8747-master',
      'public.ecr.aws/ebs-csi-driver/aws-ebs-csi-driver:v1.23.1', 'public.ecr.aws/eks-distro/kubernetes-csi/external-attacher:v4.3.0-eks-1-28-4',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v3.5.0-eks-1-28-4',
      'public.ecr.aws/eks-distro/kubernetes-csi/external-resizer:v1.8.0-eks-1-28-4',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.10.0-eks-1-28-4',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.8.0-eks-1-28-4']
  name: aws-ebs-csi-driver
- icon: https://cdn.worldvectorlogo.com/logos/amazon-elastic-file-system.svg
  git_url: https://github.com/kubernetes-sigs/aws-efs-csi-driver
  release_url: https://github.com/kubernetes-sigs/aws-efs-csi-driver/releases/tag/v{vsn}
  helm_repository_url: https://kubernetes-sigs.github.io/aws-efs-csi-driver
  versions:
  - version: 2.2.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.3.0
    images: ['public.ecr.aws/csi-components/csi-node-driver-registrar:v2.15.0-eksbuild.2',
      'public.ecr.aws/csi-components/csi-provisioner:v5.3.0-eksbuild.5', 'public.ecr.aws/csi-components/livenessprobe:v2.17.0-eksbuild.2',
      'public.ecr.aws/efs-csi-driver/amazon/aws-efs-csi-driver:v2.2.0']
  - version: 2.1.2
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.1.3
    images: ['public.ecr.aws/efs-csi-driver/amazon/aws-efs-csi-driver:v2.1.2', 'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.1.0-eks-1-31-5',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.14.0-eks-1-31-5',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.12.0-eks-1-31-5']
  - version: 2.1.1
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
      '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.1.2
    images: ['public.ecr.aws/efs-csi-driver/amazon/aws-efs-csi-driver:v2.1.1', 'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v5.1.0-eks-1-31-5',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.14.0-eks-1-31-5',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.12.0-eks-1-31-5']
  - version: 2.0.2
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.0.3
    images: ['public.ecr.aws/efs-csi-driver/amazon/aws-efs-csi-driver:v2.0.2', 'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v4.0.0-eks-1-29-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.12.0-eks-1-29-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.10.0-eks-1-29-7']
  - version: 2.0.0
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23',
      '1.22', '1.21', '1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.0.0
    images: ['amazon/aws-efs-csi-driver:v2.0.0', 'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v4.0.0-eks-1-29-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.12.0-eks-1-29-7',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.10.0-eks-1-29-7']
  - version: 1.7.4
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23',
      '1.22', '1.21', '1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.5.4
    images: ['amazon/aws-efs-csi-driver:v1.7.4', 'public.ecr.aws/eks-distro/kubernetes-csi/external-provisioner:v3.6.3-eks-1-29-2',
      'public.ecr.aws/eks-distro/kubernetes-csi/livenessprobe:v2.11.0-eks-1-29-2',
      'public.ecr.aws/eks-distro/kubernetes-csi/node-driver-registrar:v2.9.3-eks-1-29-2']
  name: aws-efs-csi-driver
- icon: https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/e5d625f96415fd44e6399e9c75e2bd985f5a2288/docs/assets/images/aws_load_balancer_icon.svg
  git_url: https://github.com/kubernetes-sigs/aws-load-balancer-controller
  release_url: https://github.com/kubernetes-sigs/aws-load-balancer-controller/releases/tag/v{vsn}
  helm_repository_url: https://aws.github.io/eks-charts
  helm_values: clusterName=example
  chart_name: aws-load-balancer-controller
  versions:
  - version: 2.9.9
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 2.9.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm/CRD changes you must account for\n- **CRDs must be updated\
        \ manually as part of the Helm upgrade** (Helm won\u2019t automatically upgrade\
        \ CRDs):\n  ```bash\n  kubectl apply -k \"github.com/aws/eks-charts/stable/aws-load-balancer-controller/crds?ref=master\"\
        \n  ```\n- **New/changed CRD fields (introduced across 2.8.x\u21922.9.0)**\n\
        \  - `IngressClassParams.spec.certificateArn` (new in 2.8.0)\n  - `IngressClassParams.spec.ipAddressType`\
        \ updated to include `dualstack-without-public-ipv4` (2.8.0)\n  - `TargetGroupBinding.spec.vpcID`\
        \ (new in 2.8.0; validation updated in 2.9.0 to allow `vpc-...`)\n  - `IngressClassParams.spec.listenerAttributes`\
        \ (new in 2.9.0; currently unused for ALB but required for forward compatibility)\n\
        \n## Helm chart value changes / knobs mentioned in notes\n- **Ingress validation\
        \ can be disabled via Helm flag** (new in 2.9.0 chart).\n- Chart enhancements\
        \ from 2.8.x line that may affect your values if you use them:\n  - Additional\
        \ ServiceMonitor functionality.\n  - Templated values support for `clusterName`,\
        \ `region`, `vpcId`.\n  - `runtimeClassName` support.\n  - `--load-balancer-class`\
        \ support in chart.\n  - More customization options for the service mutator\
        \ webhook."
      chart_updates: ['Chart: allow disabling ingress validation via Helm flag (2.9.0).',
        'Chart: HPA template uses `.Capabilities.KubeVersion.Version` (compat/templating
          change).', (From 2.8.0 line) Additional ServiceMonitor functionality., '(From
          2.8.0 line) Allow templating for `clusterName`, `region`, `vpcId` values.',
        (From 2.8.0 line) Add `runtimeClassName` support., (From 2.8.0 line) Support
          `--load-balancer-class` in Helm chart., (From 2.8.0 line) More customization
          options for the service mutator webhook.]
      features: ['Controller migrates to **AWS SDK for Go v2**, improving API efficiency
          and retry/backoff behavior (2.9.0).', Adds `listenerAttributes` plumbing
          (via `IngressClassParams`) to support listener attributes on load balancers;
          ALB has none yet (2.9.0)., NLB now supports configurable **TCP idle timeout**
          (2.9.0)., 'Fix/feature: allow resolving/attaching **multiple security groups
          with the same Name tag** (2.9.0).', New runtime option to **identify VPC
          by tags** when metadata is blocked / VPC ID unknown at deploy time (2.9.0).,
        (From 2.8.0 line) IngressClass-level `certificateArn` defaults for ingresses.,
        (From 2.8.0 line) New IP address type `dualstack-without-public-ipv4` to disable
          public IPv4 on dualstack LBs., (From 2.8.0 line) Optional enforcement of
          NLB security groups on PrivateLink traffic via annotation., (From 2.8.0
          line) TargetGroupBinding can target resources outside cluster VPC via `vpcID`.,
        (From 2.8.0 line) Managed Prefix List annotations for SG-based access control.]
      breaking_changes: ['**Do not deploy v2.9.0 if AWS Shield Advanced is enabled**:
          it can crash the controller; use **v2.9.2+** if Shield Advanced is subscribed
          and Shield is enabled on the controller (action-required note).', CRD schema
          changes require **manual CRD apply** during Helm upgrade; skipping can break
          reconciliation or future compatibility (2.8.0 and 2.9.0 action-required
          notes)., 'IAM policy updates may be required depending on features used:
          China mTLS needs `elasticloadbalancing:DescribeTrustStores` (2.8.0); NLB
          TCP idle timeout/listener attribute management needs `DescribeListenerAttributes`/`ModifyListenerAttributes`
          (2.9.0).']
    chart_version: 1.9.0
    images: ['public.ecr.aws/eks/aws-load-balancer-controller:v2.9.0']
  - version: 2.8.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm/CRD upgrade notes (read before `helm upgrade`)\n\n- **Manual\
        \ CRD update required for v2.8.0**: v2.8.0 adds/updates fields in CRDs (IngressClassParams\
        \ and TargetGroupBinding). If you upgrade with Helm, **apply the CRDs yourself\
        \ first**:\n  ```sh\n  kubectl apply -k \"github.com/aws/eks-charts/stable/aws-load-balancer-controller/crds?ref=master\"\
        \n  ```\n- **Controller image**: `public.ecr.aws/eks/aws-load-balancer-controller:v2.8.0`\n\
        - **Kubernetes compatibility**: v2.8.0 requires **Kubernetes 1.22+** (same\
        \ baseline as v2.7.0).\n- **China partition IAM policy** (only if you use\
        \ ALB mTLS in China regions): update the reference IAM policy to include `elasticloadbalancing:DescribeTrustStores`.\n\
        \n## Chart-related enhancements you may want to configure\n\n- **ServiceMonitor\
        \ improvements**: chart adds additional ServiceMonitor functionality (review\
        \ your `serviceMonitor` values if you scrape metrics via Prometheus Operator).\n\
        - **Templated values support**: chart allows passing **templated** values\
        \ for `clusterName`, `region`, and `vpcId`.\n- **RuntimeClassName**: chart\
        \ supports setting `runtimeClassName` for the controller pod.\n- **loadBalancerClass\
        \ support**: chart supports `--load-balancer-class`.\n- **Service mutator\
        \ webhook customization**: more knobs to tune webhook behavior (review webhook-related\
        \ values if you previously customized it).\n"
      chart_updates: ['CRDs changed in v2.8.0: IngressClassParams adds `certificateArn`
          and updates `ipAddressType`; TargetGroupBinding adds `vpcID` (manual CRD
          apply required when upgrading via Helm).', 'Chart enhancements: additional
          ServiceMonitor functionality.', 'Chart enhancements: allow templated values
          for `clusterName`, `region`, `vpcId`.', 'Chart enhancements: add `runtimeClassName`
          support.', 'Chart enhancements: add support for `--load-balancer-class`.',
        'Controller/webhook: more customization options for the service mutator webhook.',
        'Controller behavior: preserve `loadBalancerClass` on Service updates.']
      features: ['IngressClass-level default certificate configuration: `certificateArn`
          can be set in IngressClassParams to apply certificates across ingresses
          in that class.', New ALB `ipAddressType` option `dualstack-without-public-ipv4`
          to create dualstack LBs without public IPv4 addresses (IPv6-only public
          clients). Can be set via ingress annotation or at IngressClassParams., Optional
          enforcement of NLB security groups on AWS PrivateLink traffic via annotation
          `aws-load-balancer-inbound-sg-rules-on-private-link-traffic`., TargetGroupBinding
          can register targets in a different VPC by setting `spec.vpcID` (defaults
          to the cluster VPC if omitted)., Allow access control via AWS Managed Prefix
          Lists using new annotations for ALB ingresses and NLB services; ignored
          if explicit security groups are set.]
      breaking_changes: [CRD schema changes in v2.8.0 mean you must update CRDs before/alongside
          the Helm upgrade; otherwise the controller may fail to reconcile resources
          or validation may reject new fields., '(Regional/IAM) Using ALB mTLS in
          China now requires IAM policy permission `elasticloadbalancing:DescribeTrustStores`;
          without it, mTLS-related reconciliation will fail.']
    chart_version: 1.8.0
    images: ['public.ecr.aws/eks/aws-load-balancer-controller:v2.8.0']
  - version: 2.7.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **IAM policy update required (action required):** add `elasticloadbalancing:DescribeTrustStores`\
        \ to the controller IAM policy to support the new **Ingress mTLS** capability.\n\
        - **New controller flag:** `--service-target-eni-security-group-tags` (Helm\
        \ values/args need to be updated if you want to use it) to control which Security\
        \ Group tags are considered when adding ingress rules for NLB targets.\n-\
        \ **Readiness probe added by default (chart >= 1.7.0):** running an **older\
        \ controller image** with the **newer Helm chart** may fail because the old\
        \ image doesn\u2019t expose the readiness endpoint expected by the chart.\n\
        - **Chart knobs added:**\n  - Webhook readiness check enabled in the chart.\n\
        \  - `revisionHistoryLimit` override.\n  - Field to **enable HPA** for the\
        \ controller (intended to help during load spikes on `aws-load-balancer-webhook-service`)."
      chart_updates: [Introduced chart-level webhook readiness check and default controller
          readiness probe wiring., Added `revisionHistoryLimit` configurability for
          controller Deployment., Added an option to enable HorizontalPodAutoscaler
          (HPA) for the controller., General Helm chart and documentation enhancements.]
      features: [Ingress mTLS support via integration with ELBv2 trust stores; configure
          mTLS mode and trust store name/ARN via new Ingress annotations (requires
          new IAM permission)., EKS Pod Identity support (enables using EKS Pod Identity
          for AWS auth instead of/alongside IRSA depending on cluster setup)., NLB
          target security-group discovery can now consider additional tags via `--service-target-eni-security-group-tags`
          for more flexible environments.]
      breaking_changes: ['If you upgrade the Helm chart (>=1.7.0) but keep an older
          controller image, installation may fail due to the newly added readiness
          probe expecting endpoints not present in older images.', 'IAM permissions
          must be updated to include `elasticloadbalancing:DescribeTrustStores` if
          you want to use (or avoid errors when enabling) the new Ingress mTLS feature.']
    chart_version: 1.7.0
    images: ['public.ecr.aws/eks/aws-load-balancer-controller:v2.7.0']
  - version: 2.6.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['NLB security group support: controller can now create/attach a frontend
          SG to NLBs and manage a backend SG to control NLB->node/ENI traffic, enabling
          tighter instance exposure controls. You can optionally attach existing frontend
          SGs via annotation and optionally enable/disable backend rule management
          via a new annotation.', Improved ACM certificate auto-discovery for Ingress
          to recognize more key algorithms (RSA 1024/2048/3072/4096 and multiple EC
          curves).]
      breaking_changes: []
    chart_version: 1.6.0
    images: ['public.ecr.aws/eks/aws-load-balancer-controller:v2.6.0']
  - version: 2.5.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / manifest changes you must account for\n\n- **Do not\
        \ just bump the controller image tag on the existing Deployment.** v2.5.0\
        \ image is **not compatible with older manifests**; upgrade via **`helm upgrade`**\
        \ or apply the full updated manifests.\n- New helm value: **`enableServiceMutatorWebhook`**\
        \ (renamed in this release). Set to `false` to disable the new Service mutator\
        \ webhook and keep the in-tree CCM/default behavior.\n- New helm value: **`defaultTargetType`**\
        \ to set the default target type for created target groups.\n- **CRDs are\
        \ not fully updated by helm upgrade:** `IngressClassParams` gained new fields\
        \ (`subnets`, `InboundCIDRs`, `SSLPolicy`). You must **manually apply updated\
        \ CRDs**:\n  ```bash\n  kubectl apply -k \"http://github.com/aws/eks-charts/stable/aws-load-balancer-controller//crds?ref=master\"\
        \n  ```\n"
      chart_updates: [Controller is now intended to be upgraded via updated manifests/helm
          because of webhook/mutating webhook additions; old manifests are considered
          incompatible., Adds a mutating webhook so the controller can claim/own Service
          type LoadBalancer by default (sets `spec.loadBalancerClass`)., Helm chart
          supports setting default target type (`defaultTargetType`)., 'IngressClassParams
          CRD schema expanded with `subnets`, `InboundCIDRs`, and `SSLPolicy`.', Leader
          election moved/migrated toward ConfigMap leases., Ingress/service annotation
          validation tightened (notably ssl-ports and ingress condition annotations).]
      features: ['Controller provides a **Service mutator webhook** that sets `spec.loadBalancerClass`
          on newly created Services of type `LoadBalancer`, making AWS LBC the default
          controller for them (can be disabled via `enableServiceMutatorWebhook=false`).',
        You can configure a **default target type** for target groups (via helm `defaultTargetType`
          or controller flag)., '`IngressClassParams` supports new configuration fields:
          **`subnets`**, **`InboundCIDRs`**, and **`SSLPolicy`**.']
      breaking_changes: ['**Kubernetes 1.22+ required** in v2.5.0 due to reliance
          on `spec.loadBalancerClass` support when making LBC the default Service
          controller.', 'Behavior change: controller now **creates an internal NLB
          by default** for Service type `LoadBalancer`; to get internet-facing you
          must set `service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing`.',
        'If you leave the Service mutator webhook enabled, you **cannot provision
          new Classic Load Balancers (CLB)** from Kubernetes Services (existing CLBs
          continue to work).', 'Known issue/action required: v2.5.0 ingress validator
          has a bug handling ingress rules without an HTTP path (issue #3158); **do
          not upgrade** if you have such ingresses.']
    chart_version: 1.5.0
    images: ['public.ecr.aws/eks/aws-load-balancer-controller:v2.5.0']
  - version: 2.4.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '## Helm values / install behavior changes to review

        - **Kubernetes version requirement raised:** v2.4.0 requires **Kubernetes
        1.19+** because it moves Ingress examples/objects to `networking.k8s.io/v1`.

        - **Upgrade method:** if upgrading from a prior version, **re-apply the full
        manifest or use Helm** because of **webhook changes**.

        - **New default resources (Helm):** the chart now **creates an `IngressClass`
        named `alb` by default** and also creates **`IngressClassParams` by default**.

        - **Default name change:** `IngressClassParams` default name is now **`alb`**.

        - **New chart feature:** **ServiceMonitor** support added (for Prometheus
        Operator environments).

        - **Default value change:** `keepTLSSecret` is now **`true` by default** (previously
        you may have relied on it being false to allow rotation/recreation).

        '
      chart_updates: [Chart now creates `IngressClass` and `IngressClassParams` resources
          by default (including default naming of `alb`)., Chart adds optional `ServiceMonitor`
          resource for metrics scraping via Prometheus Operator., Chart defaults `keepTLSSecret=true`
          (TLS secret reuse behavior changes)., Chart removed use of `admissionregistration.k8s.io/v1beta1`
          (aligns with newer Kubernetes APIs).]
      features: [Ingress objects now use/support the stable `networking.k8s.io/v1`
          Ingress API (Kubernetes 1.19+)., Supports `Service.spec.loadBalancerClass`
          to bind Services to a specific load balancer implementation., Adds an option
          to disable security group rule management for NLBs (useful if rules are
          managed externally)., Merges tags defined on Kubernetes Ingress/Service
          with controller-managed AWS resource tags for more consistent tagging.,
        Introduces feature gate `ServiceTypeLoadBalancerOnly` to optionally limit
          reconciliation to `Service` objects of type `LoadBalancer`., Helm chart
          can create `IngressClass`/`IngressClassParams` and a `ServiceMonitor` out
          of the box.]
      breaking_changes: ['**Kubernetes 1.18 and older are no longer supported** starting
          with v2.4.0 due to the move to `networking.k8s.io/v1` Ingress.', '**Webhook
          resources changed**; upgrades require applying the complete updated manifest
          or performing the upgrade via Helm to ensure webhook configuration/CA bundles
          are correct.', 'Helm now creates `IngressClass`/`IngressClassParams` by
          default, which can conflict with pre-existing resources or other controllers
          if you were managing these manually.']
    chart_version: 1.4.0
    images: ['602401143452.dkr.ecr.us-west-2.amazonaws.com/amazon/aws-load-balancer-controller:v2.4.0']
  - version: 2.3.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / install notes (2.2.0 \u2192 2.3.0)\n\n- **Helm\
        \ v3 chart**: v2.3.0 ships as a Helm v3 chart. Ensure your tooling/pipeline\
        \ uses Helm 3.\n- **cert-manager API v1**: chart/manifests move to `cert-manager.io/v1`.\
        \ If you enable cert-manager integration (or install via YAML that uses cert-manager),\
        \ **upgrade cert-manager to v1.5.3+**.\n- **Webhook TLS handling improvements**:\n\
        \  - Chart can **reuse existing TLS secrets**.\n  - Chart supports **supplying\
        \ your own webhook TLS cert/key**.\n- **New/changed Helm values** (as referenced\
        \ in notes):\n  - `enableBackendSecurityGroup` (to revert to previous SG behavior\
        \ by setting `false`).\n  - `backendSecurityGroup` (to provide an explicit\
        \ backend SG instead of controller-managed shared SG).\n  - `serviceAnnotations`\
        \ is **optional** (new value to annotate the controller Service).\n- **PDB\
        \ apiVersion**: chart will use `policy/v1` PodDisruptionBudget if available.\n\
        - **IngressClass creation parameter**: chart adds an option/parameter to create\
        \ the `IngressClass` resource (verify and set if you rely on chart-managed\
        \ IngressClass)."
      chart_updates: [Helm chart moved to **Helm v3** packaging/structure., Manifests/chart
          updated to use `admissionregistration.k8s.io/v1` (webhooks) and cert-manager
          `v1` resources., Chart now prefers `policy/v1` PodDisruptionBudget when
          the cluster supports it., Chart supports reusing existing webhook TLS secrets
          and optionally providing custom TLS cert/key., Chart adds optional `serviceAnnotations`
          and a parameter to create an `IngressClass` resource.]
      features: ['Optimized/improved security group management for ALBs (shared backend
          SG model, with port-range restriction options).', 'Support for **ALB IPv6
          target groups** (notably for IPv6 clusters, plus new IAM perms).', Support
          for **EndpointSlice** as a backend discovery source for IP target groups.,
        'Ability to specify NLB attributes via annotations, including **NLB deletion
          protection**.', 'Improved subnet discovery behavior (only on new LB creation;
          can consider available IP addresses) and additional filtering (e.g., by
          VPC ID).']
      breaking_changes: ["Controller upgrade can **reconfigure existing ALBs' security\
          \ groups** due to the new shared backend SG behavior; there may be a brief\
          \ traffic impact window during reconciliation\u2014plan a maintenance window\
          \ or pin behavior via `enableBackendSecurityGroup=false` / `--enable-backend-security-group=false`\
          \ or set an explicit backend SG.", 'If you use cert-manager integration/manifests,
          you must be on **cert-manager v1.5.3+** because resources now use the `cert-manager.io/v1`
          API.', New IAM permissions are required for **IPv6 clusters**; failing to
          update policy may break reconciliation for IPv6-related features.]
    chart_version: 1.3.2
    images: ['602401143452.dkr.ecr.us-west-2.amazonaws.com/amazon/aws-load-balancer-controller:v2.3.0']
  - version: 2.2.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / manifests changes to plan for\n- **Update IAM policy**\
        \ attached to the controller (IRSA role/instance profile) to the **v2.2.0\
        \ sample policy**. This release explicitly requires **new IAM permissions**.\n\
        - **RBAC changes required**: new permissions are needed; the **latest chart/manifests\
        \ include them**, but ensure your cluster role is updated if you manage RBAC\
        \ separately.\n- **CRD + webhook updates required**: apply the updated CRDs\
        \ and webhook configurations (the latest chart/manifests include them). If\
        \ you install CRDs out-of-band, update them before/with the controller.\n\
        - If you use controller flags, note new/changed behavior around tagging:\n\
        \  - `--default-tags` now has **highest priority** (can override tags coming\
        \ from other sources).\n  - New flags to **opt out** of managing specific\
        \ tags (\"external-managed-tags\").\n  - New flags to customize **webhook\
        \ certificate locations** and **default SSL policy**.\n\n> No specific Helm\
        \ values keys were provided in the notes you pasted; treat the above as **behavioral/manifest\
        \ requirements** rather than guaranteed `values.yaml` key changes."
      chart_updates: ['Controller image moves to `docker.io/amazon/aws-alb-ingress-controller:v2.2.0`
          (and corresponding ECR mirrors).', 'Manifests updated to newer Kubernetes
          APIs: webhook + CRDs upgraded to `v1` APIs; deprecated apiVersions removed.',
        'Admission webhooks improved: pod mutator webhook now uses `objectSelector`;
          webhook cert/key locations are configurable via flags.', 'New CRD introduced:
          **IngressClassParams** (plus validating webhook) and RBAC added to read
          it.']
      features: [Adds **NLB instance mode** support., 'Adds annotation to set **private
          static IPv4 addresses** for internal NLBs: `service.beta.kubernetes.io/aws-load-balancer-private-ipv4-addresses`.',
        Introduces **IngressClassParams** to constrain/standardize LB settings across
          multiple Ingresses., "Adds `alb.ingress.kubernetes.io/ssl-redirect` to simplify\
          \ HTTP\u2192HTTPS redirects.", Supports Ingress **PathType**., Supports
          resource tagging for **ALB listeners and listener rules**., Allows specifying
          a **custom load balancer name** for ALB/NLB., Allows selecting backend nodes
          by **node labels** for Ingress/Service/TargetGroupBinding., Supports provisioning
          ALB on **Local Zones**., Adds ability to opt out management for certain
          tags via controller flags., Adds ability to customize webhook certificate
          locations via controller flags., Adds ability to specify a default **SSL
          policy** via controller flags.]
      breaking_changes: ['**NLB scheme default changed**: new NLBs are **internal
          by default**. To create an internet-facing NLB you must set `service.beta.kubernetes.io/aws-load-balancer-scheme:
          internet-facing` on the Service (existing NLBs are not affected).', Ingress
          rules that reference a **non-existent Service/Action** no longer block reconcile;
          they will be replaced with **fixed 503 responses** (changes failure mode/traffic
          behavior)., 'Tag precedence change: tags specified via the controller flag
          `--default-tags` now take **highest priority**, which can override tags
          set elsewhere.']
    chart_version: 1.2.2
    images: ['602401143452.dkr.ecr.us-west-2.amazonaws.com/amazon/aws-load-balancer-controller:v2.2.0']
  - version: 2.1.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16', '1.15']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **RBAC update required if you use `IngressClass`:** v2.1.0
        needs permission to **read `IngressClass`** resources. The upstream helm chart/manifests
        include this; ensure your rendered RBAC includes `get/list/watch` on `networking.k8s.io/ingressclasses`
        (or equivalent).

        - No other helm values changes were called out in the provided notes. (You
        may still want to diff your chart values between versions to catch defaults
        changes, but nothing is explicitly mentioned here.)'
      chart_updates: [RBAC roles/manifests updated to include permissions for `IngressClass`
          (required when using `IngressClass`).]
      features: [IngressClass support (Kubernetes 1.18+) so the controller can select/manage
          ingresses via `IngressClass` instead of only the legacy `kubernetes.io/ingress.class`
          annotation., 'gRPC end-to-end HTTP/2 support for ALB workloads, improving
          compatibility for gRPC services behind ALB.', Customer Owned IP (COIP) pool
          configuration support for ALB on AWS Outposts., NLB IPv6 support for dual-stack/IPv6-facing
          services., NLB ALPN policy configuration support (useful for TLS negotiation
          behavior)., 'NLB target group attributes can be configured via annotations,
          allowing tuning of target group behavior.', 'Ability to explicitly configure
          subnets for NLB, rather than relying solely on discovery.', Default AWS
          tags support so all AWS resources created/managed by the controller can
          receive a standard tag set.]
      breaking_changes: ['If you use `IngressClass`, the controller will fail to watch/operate
          correctly until RBAC is updated to allow reading `IngressClass` resources.']
    chart_version: 1.1.1
    images: ['602401143452.dkr.ecr.us-west-2.amazonaws.com/amazon/aws-load-balancer-controller:v2.1.0']
  - version: 2.0.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16', '1.15']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.0.6
    images: ['602401143452.dkr.ecr.us-west-2.amazonaws.com/amazon/aws-load-balancer-controller:v2.0.0']
  name: aws-load-balancer-controller
- icon: https://cdn2.iconfinder.com/data/icons/amazon-aws-stencils/100/Non-Service_Specific_copy_Virtual_Private_CLoud_-512.png
  git_url: https://github.com/aws/amazon-vpc-cni-k8s
  release_url: https://github.com/aws/amazon-vpc-cni-k8s/releases/tag/v{vsn}
  helm_repository_url: https://aws.github.io/eks-charts
  versions:
  - version: 1.21.1
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.21.1
  - version: 1.21.0
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.21.0
  - version: 1.20.0
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.20.0
  - version: 1.19.0
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.19.0
  - version: 1.18.0
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.18.0
  - version: 1.17.1
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.17.1
  - version: 1.16.2
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.16.2
  - version: 1.16.0
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.16.0
  - version: 1.15.0
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['`aws-node` DaemonSet continues to include the additional `aws-eks-nodeagent`
          container introduced in 1.14.x for Kubernetes NetworkPolicy support; image
          bump to `amazon/aws-network-policy-agent:v1.0.2` in 1.15.0.', 'RBAC/manifest
          content changed in 1.15.0: the `aws-node` `ClusterRole` is modified (remove
          `update` on `nodes`; add `get, list, patch` on `CNINode`). Upgrade must
          apply the full manifest/chart so the new RBAC is present.', 'Security Groups
          for Pods integration now uses the `CNINode` CRD in 1.15.0, deprecating reliance
          on the `vpc.amazonaws.com/has-trunk-attached` node label.']
      features: ["Support for VPC Resource Controller\u2019s `CNINode` (used by Security\
          \ Groups for Pods) was added/reintroduced.", New `DISABLE_CONTAINER_V6`
          env var allows disabling IPv6 networking inside container network namespaces.,
        New `IP_COOLDOWN_PERIOD` env var allows configuring the IP cooldown period.]
      breaking_changes: [RBAC change in 1.15.0 requires updating the entire manifest/chart
          (including `aws-node` `ClusterRole`) during upgrade/downgrade; partial applies
          can prevent the CNI containers from starting., Security Groups for Pods
          now relies on the `CNINode` CRD and deprecates the `vpc.amazonaws.com/has-trunk-attached`
          label; any tooling/automation depending on that label should be updated.]
    chart_version: 1.15.0
    images: []
  - version: 1.14.0
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['`aws-node` DaemonSet now runs an additional container `aws-eks-nodeagent`
          (AWS Network Policy Agent) alongside the existing CNI containers.', 'Verification
          output/images now include `amazon/aws-network-policy-agent:v1.0.1` in addition
          to `amazon-k8s-cni-init` and `amazon-k8s-cni`.', 'If deploying via raw manifests,
          use the v1.14.0 YAMLs (and region-specific variants for gov/cloud-cn), as
          the DaemonSet spec changed to include the new container.']
      features: [Adds Kubernetes NetworkPolicy enforcement support via an in-pod Network
          Policy Agent (`aws-eks-nodeagent`).]
      breaking_changes: ["`aws-eks-nodeagent` exposes metrics on host-network port\
          \ 8080 by default; this can conflict with other hostNetwork workloads binding\
          \ to 8080. Change the agent\u2019s metrics port via the `metrics-bind-addr`\
          \ container argument if needed."]
    chart_version: 1.14.0
    images: []
  - version: 1.13.0
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / values changes to review\n- **New env var(s) to consider**\
        \ (set via chart values that template env):\n  - `ENABLE_V6_EGRESS` (new in\
        \ v1.13.0): enables IPv6 egress from pods in an **IPv4** cluster.\n  - `DISABLE_LEAKED_ENI_CLEANUP`\
        \ (new): disables the leaked ENI cleanup background task (only set if you\
        \ have a specific reason).\n  - `AWS_EC2_ENDPOINT` (new): override the EC2\
        \ API endpoint (useful for custom/VPC endpoints).\n- **Chart templating change**:\
        \ image template logic was refactored for \u201Cendpoint flexibility\u201D\
        . If you override image registry/repository/tag today, diff your rendered\
        \ manifests (`helm template`) to ensure images still resolve correctly.\n\
        - **Tolerations YAML fix**: v1.13.0 includes a chart fix for tolerations rendering.\
        \ If you had custom tolerations, re-validate output for any formatting differences.\n\
        - **Env var case-insensitivity**: all AWS VPC CNI env vars are now treated\
        \ case-insensitively; standardize to canonical uppercase to avoid confusion.\n"
      chart_updates: ['CNI chart: fix tolerations templating to produce valid YAML.',
        'CNI chart: refactor image template logic to better support flexible endpoints/registries.',
        'Init container behavior: install all core CNI plugins via init container
          (manifest content/containers may change).', 'EKS add-on manifest: add resource
          limits on init container (may affect custom overrides).']
      features: ['`ENABLE_V6_EGRESS`: allows pods in an IPv4 cluster to reach IPv6
          endpoints (IPv6 egress capability).', '`DISABLE_LEAKED_ENI_CLEANUP`: lets
          operators disable the leaked ENI cleanup task if it conflicts with their
          operational model.', '`AWS_EC2_ENDPOINT`: supports using a custom EC2 API
          endpoint (e.g., private endpoints or special partitions).']
      breaking_changes: []
    chart_version: 1.13.0
    images: []
  - version: 1.12.5
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.2.7
    images: []
  - version: 1.11.5
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 1.10.3
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.1.15
    images: []
  name: amazon-vpc-cni-k8s
- icon: https://docs.tigera.io/img/calico-logo.webp
  git_url: https://github.com/projectcalico/calico
  release_url: https://github.com/projectcalico/calico/releases/tag/v{vsn}
  helm_repository_url: https://docs.tigera.io/calico/charts
  chart_name: tigera-operator
  versions:
  - version: 3.31.3
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.31.3
    images: ['quay.io/tigera/operator:v1.40.3']
  - version: 3.31.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.31.0
    images: ['quay.io/tigera/operator:v1.40.0']
  - version: 3.30.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.30.0
    images: ['quay.io/tigera/operator:v1.38.0']
  - version: 3.29.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.29.0
    images: ['quay.io/tigera/operator:v1.36.0']
  - version: 3.28.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.28.0
    images: ['quay.io/tigera/operator:v1.34.0']
  - version: 3.27.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.27.0
    images: ['quay.io/tigera/operator:v1.32.3']
  - version: 3.26.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.26.0
    images: ['quay.io/tigera/operator:v1.30.0']
  - version: 3.25.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.25.0
    images: ['quay.io/tigera/operator:v1.29.0']
  - version: 3.24.1
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.24.1
    images: ['quay.io/tigera/operator:v1.28.1']
  - version: 3.23.4
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.23.4
    images: ['quay.io/tigera/operator:v1.27.14']
  - version: 3.22.5
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.22.5
    images: ['quay.io/tigera/operator:v1.25.13']
  - version: 3.20.6
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.20.6
    images: ['quay.io/tigera/operator:v1.20.9']
  name: calico
- icon: https://raw.githubusercontent.com/cert-manager/cert-manager/d53c0b9270f8cd90d908460d69502694e1838f5f/logo/logo-small.png
  git_url: https://github.com/cert-manager/cert-manager
  release_url: https://github.com/cert-manager/cert-manager/releases/tag/v{vsn}
  helm_repository_url: https://charts.jetstack.io
  versions:
  - version: 1.19.0
    kube: ['1.34', '1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / chart behavior changes (actionable)\n\n- **`global.rbac.disableHTTPChallengesRole`\
        \ was added in 1.18, then *reverted* in 1.19.0**.\n  - If you set this value\
        \ in 1.18.x, **remove it before/when upgrading to 1.19.0** (it will no longer\
        \ exist / have effect in 1.19.0).\n  - Background: the value was meant to\
        \ drop permissions for creating pods when HTTP-01 isn\u2019t used, but it\
        \ was rolled back.\n\n- **New Helm value: `global.nodeSelector` (1.19.0)**\n\
        \  - Lets you set a single nodeSelector applied across cert-manager components.\n\
        \  - If you currently set nodeSelector separately per component, you can optionally\
        \ consolidate to this.\n\n- **Helm template change:** tokenrequest `RoleBinding`\
        \ naming template fixed for consistency (1.19.0).\n  - Typically no action\
        \ required, but expect **resource name changes** which can show up as replace/rename\
        \ in diff.\n\n- **Helm chart quoting change (1.18.0):** nodeSelector values\
        \ are quoted.\n  - Mostly transparent, but can affect strict YAML/value types\
        \ if you relied on non-string types.\n"
      chart_updates: [Default NetworkPolicy now includes IPv6 rules (1.19.0)., Pods
          now support an experimental `hostUsers` field (not enabled by default) (1.19.0).,
        Services/ServiceMonitors switched to using **named ports** instead of numeric
          ports (1.18.0)., 'Ingress-shim: new `--extra-certificate-annotations` option
          to copy selected annotations from Ingress-like resources to resulting Certificates
          (1.18.0).', 'Metrics changes: certificate metrics moved to a collector approach
          (1.19.0); new `certmanager_certificate_challenge_status` metric (1.19.0);
          new notBefore/notAfter timestamp metrics (1.18.0).', 'ACME HTTP-01: added
          feature gate to default solver Ingress `pathType` to `Exact` (1.19.0); also
          earlier change set pathType to `Exact` for reliability/security (1.18.0).']
      features: [Global `nodeSelector` Helm value to pin cert-manager components to
          specific nodes (deployment flexibility)., Configurable resource requests/limits
          for ACME HTTP-01 solver pods via Issuer/ClusterIssuer (overrides global
          `--acme-http01-solver-resource-*`)., CAInjectorMerging promoted to **BETA**
          and enabled by default (more robust CA bundle injection behavior)., 'Improved
          observability: version + git commit logged on startup; new certificate challenge
          status metric; additional certificate issuance/expiry timestamp metrics.',
        'Platform/compatibility improvements: default NetworkPolicy adds IPv6 rules;
          increased ACME authorization timeout to reduce flakiness.']
      breaking_changes: ["**Potential incident risk / known issue:** v1.19.0 has a\
          \ known issue causing **unexpected certificate renewal** after upgrade;\
          \ it\u2019s fixed in **v1.19.1**. Strongly prefer upgrading to 1.19.1+ if\
          \ possible.", "Monitoring breaking change: **removed the `path` label**\
          \ from core ACME client metrics\u2014dashboards/alerts that filter/group\
          \ by `path` must be updated.", "Behavioral breaking changes introduced in\
          \ 1.18 (still relevant if you\u2019re coming from 1.18.0): default `Certificate.spec.privateKey.rotationPolicy`\
          \ changed to **`Always`** (can trigger key rotation on renewals), and default\
          \ `Certificate.spec.revisionHistoryLimit` set to **1** (fewer historical\
          \ CertificateRequest revisions retained).", "Access-control/values breaking\
          \ change: `global.rbac.disableHTTPChallengesRole` was **reverted** in 1.19.0\u2014\
          config relying on it must be removed and you may need an alternative approach\
          \ if you were using it to reduce privileges."]
    chart_version: 1.19.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.19.0', 'quay.io/jetstack/cert-manager-controller:v1.19.0',
      'quay.io/jetstack/cert-manager-startupapicheck:v1.19.0', 'quay.io/jetstack/cert-manager-webhook:v1.19.0']
  - version: 1.18.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart config changes to review\n- **New value:**\
        \ `global.rbac.disableHTTPChallengesRole` \u2014 when set, cert-manager will\
        \ **not create the RBAC needed for HTTP-01** (notably permissions to create\
        \ Pods), reducing privileges if you *only* use DNS-01/TLS-ALPN-01.\n- Existing\
        \ (from 1.17) Helm knobs remain relevant: `webhook.extraEnv`, `cainjector.extraEnv`,\
        \ `startupapicheck.extraEnv` (useful if you previously templated env vars).\n\
        - **Chart templating fix:** nodeSelector values are now quoted; if you relied\
        \ on unquoted numeric/bool-looking values, rendering/behavior may change slightly.\n"
      chart_updates: [RBAC can now be tightened via `global.rbac.disableHTTPChallengesRole`
          (drops Pod-creation permissions when HTTP-01 is disabled)., Service/ServiceMonitor
          ports are now defined using **named ports** instead of numeric ports (may
          affect scraping or any tooling selecting ports by number)., 'Ingress-shim
          related additions: supports copying selected annotations via new flag `--extra-certificate-annotations`.',
        'Helm template fixes: nodeSelector quoting; ServiceAccount annotations handling
          boolean values correctly.']
      features: ['ACME: **Support for ACME Profiles** (draft ACME profiles extension)
          allowing more profile-driven issuance behavior when your ACME CA supports
          it.', 'Observability: new certificate validity metrics for NotBefore/NotAfter
          timestamps (`certmanager_certificate_not_before_timestamp_seconds`, `certmanager_certificate_not_after_timestamp_seconds`).',
        'Security hardening option: ability to disable HTTP-01 RBAC permissions via
          Helm when not using HTTP-01 challenges.', "Vault Issuer: option to specify\
          \ the expected server name when validating Vault\u2019s presented TLS certs.",
        'Ingress-shim: can copy a configured list of annotations from Ingress-like
          resources onto the generated Certificate.', 'Resource UX: new kubectl shortnames
          `iss` (Issuer) and `ciss` (ClusterIssuer).', 'Crypto: ability to customize
          the certificate signature algorithm.', 'Features promoted to GA: `UseDomainQualifiedFinalizer`;
          `AdditionalCertificateOutputFormats` always enabled.']
      breaking_changes: ["Default `Certificate.spec.privateKey.rotationPolicy` changes\
          \ from **`Never` \u2192 `Always`**. This can trigger private key rotation\
          \ on renewals/issuance unless you explicitly set it back.", Default `Certificate.spec.revisionHistoryLimit`
          effectively becomes **1** (CertificateRequest revision history). This may
          surprise users relying on multiple historical CertificateRequests for debugging/auditing.,
        "Ingress HTTP-01 solver Ingress `pathType` changes from **ImplementationSpecific\
          \ \u2192 Exact**, which can change matching behavior on some ingress controllers.",
        "Feature gate **`ValidateCAA` removed** (setting it becomes a no-op with a\
          \ warning); if you depended on it, behavior won\u2019t be enforced by that\
          \ gate anymore.", 'Known issue: ingress-nginx validating webhook may reject
          ACME HTTP-01 challenge paths (see cert-manager #7791); plan mitigations
          if you use ingress-nginx + HTTP-01.']
    chart_version: 1.18.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.18.0', 'quay.io/jetstack/cert-manager-controller:v1.18.0',
      'quay.io/jetstack/cert-manager-startupapicheck:v1.18.0', 'quay.io/jetstack/cert-manager-webhook:v1.18.0']
  - version: 1.17.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / chart behavior changes to account for\n- **New\
        \ env injection values** (v1.17 chart):\n  - `webhook.extraEnv`\n  - `cainjector.extraEnv`\n\
        \  - `startupapicheck.extraEnv`\n  Use these if you previously patched Deployments\
        \ to add env vars.\n\n- **Keystore password config change (API-level, but\
        \ impacts manifests you deploy):**\n  - In `Certificate.spec.keystores.{jks,pkcs12}`\
        \ you can now set `password: \"...\"` directly.\n  - `password` is **mutually\
        \ exclusive** with `passwordSecretRef`; ensure only one is set.\n\n- **PDB\
        \ percentages supported**: `podDisruptionBudget.minAvailable` and `podDisruptionBudget.maxAvailable`\
        \ now accept percentage strings.\n\n- **ServiceAccount annotations templating**:\
        \ Helm now runs `tpl` on ServiceAccount annotation keys/values, which can\
        \ change rendering if you used Helm template syntax there.\n\n- **Image pull\
        \ secrets behavior**: when service accounts aren't created, imagePullSecrets\
        \ can be added to Deployments; verify if you rely on custom SA creation.\n\
        \n- **If you used `ValidateCAA` feature gate via Helm flags/env**: it is deprecated\
        \ in 1.17 and will warn; plan removal before 1.18.\n"
      chart_updates: [Feature gates `NameConstraints` and `UseDomainQualifiedFinalizer`
          are now **enabled by default** (promoted to Beta). Expect behavior changes
          without explicitly setting flags., Optional new feature gate `CAInjectorMerging`
          available for ca-injector; enabling changes CA bundle rotation behavior
          (merge vs replace)., Some log lines are now structured; log formats may
          differ from 1.16.]
      features: ["RSA signing compliance: CA and SelfSigned issuers select hash based\
          \ on RSA key size (3072\u2192SHA-384, 4096\u2192SHA-512).", 'Keystore passwords
          (JKS/PKCS#12) can be set as a literal string in the `Certificate` resource,
          not only via Secret reference.', Feature gates `NameConstraints` and `UseDomainQualifiedFinalizer`
          are now enabled by default (Beta)., New `CAInjectorMerging` feature gate
          to make CA bundle rotation safer by merging new CAs instead of replacing.,
        'Helm improvements: extra env var injection for webhook/cainjector/startupapicheck
          and `tpl` support for ServiceAccount annotations.', 'AzureDNS: new `tenantID`
          option for managed identity with service principals; Venafi username/password
          client ID customization.', 'Larger trust bundles supported: increased PEM
          parsing capacity.']
      breaking_changes: ['Potentially breaking cryptography change: CA/SelfSigned
          issuers now use stronger hashes for larger RSA keys (3072/4096+). Verify
          downstream consumers support SHA-384/SHA-512 with your chosen RSA key sizes.',
        'Potentially breaking operational change: some previously unstructured log
          messages are now structured; any tooling that greps/matches exact log strings
          may break.', '`ValidateCAA` feature gate is deprecated and will be removed
          in 1.18; enabling it now emits warnings (plan to stop using it).']
    chart_version: 1.17.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.17.0', 'quay.io/jetstack/cert-manager-controller:v1.17.0',
      'quay.io/jetstack/cert-manager-startupapicheck:v1.17.0', 'quay.io/jetstack/cert-manager-webhook:v1.17.0']
  - version: 1.16.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart behavior changes to account for\n- **CRD\
        \ lifecycle behavior changed (introduced in 1.15)**: the Helm chart **keeps\
        \ CRDs on uninstall by default** to prevent data loss. If you *do* want CRDs\
        \ removed on uninstall, install/upgrade with:\n  - `crds.keep=false`\n  -\
        \ Prefer the new options **`crds.enabled`** and **`crds.keep`** instead of\
        \ the older `installCRDs` value.\n- **startupapicheck image reference (since\
        \ 1.15)**: ensure any overrides point at **`quay.io/jetstack/cert-manager-startupapicheck`**.\n\
        - **New in 1.16: Helm values JSON schema validation** (`values.schema.json`).\
        \ This can cause upgrades to fail if your values file contains **typos or\
        \ unknown keys**. Run a dry-run/template locally and clean up values.\n- **New\
        \ Helm values in 1.16**:\n  - `webhook.extraEnv`, `cainjector.extraEnv`, `startupapicheck.extraEnv`\
        \ (inject custom env vars)\n- **Helm chart defaults in 1.16**:\n  - `config.apiVersion`\
        \ and `config.kind` now default in the chart (you may be able to remove explicit\
        \ settings unless you intentionally override).\n- **Helm values that appeared\
        \ in 1.15 but matter for upgrades**:\n  - `disableAutoApproval`, `approveSignerNames`\n\
        \  - `extraObjects` (install extra manifests with the release)\n  - optional\
        \ `hostAliases` support for cert-manager pod DNS self-check scenarios"
      chart_updates: ['Helm chart adds a JSON schema for values (1.16), making `helm
          install/upgrade` stricter and more likely to fail on invalid/unknown values.',
        Helm chart now supports adding extra environment variables to webhook/cainjector/startupapicheck
          pods via new `*.extraEnv` values (1.16)., 'Chart behavior around CRDs changed
          (1.15): CRDs are no longer removed on uninstall by default; `crds.enabled`/`crds.keep`
          replace `installCRDs`.', startupapicheck image repository reference changed
          (1.15) to `quay.io/jetstack/cert-manager-startupapicheck`.]
      features: ['More Prometheus metrics: new metrics servers for webhook and cainjector;
          controller now exposes process and Go runtime metrics.', Certificate renewal
          can now be expressed as `renewBeforePercentage` as an alternative to `renewBefore`.,
        'Gateway API HTTP01 solver now supports a user-provided Pod template, similar
          to the Ingress HTTP01 solver.', 'Route53 ACME DNS01 improvements: better
          region handling (ambient/IRSA), regional STS endpoints, and improved debug
          logging/user-agent tagging for AWS requests.', 'Vault and Venafi improvements:
          Vault supports client certificate auth; Venafi adds SecretRef for CA bundle
          and improved duration handling; TPP OAuth with username/password support.']
      breaking_changes: [Helm schema validation in 1.16 may reject existing values
          files that contain unknown keys/typos; you may need to clean up `values.yaml`
          before upgrading., 'Venafi Issuer behavior changes in 1.16 can break renewals
          if requested durations violate Venafi policy min/max, or if using TPP username/password
          auth in certain configurations.', 'Venafi TPP: API Key authentication (deprecated/removed
          in recent TPP versions) is no longer used; environments relying on it must
          migrate to supported auth methods.', Old cert-manager API versions were
          removed from the codebase (v1alpha2/v1alpha3/v1beta1 for acme.cert-manager.io
          and cert-manager.io); ensure no manifests/CRs still use those versions.]
    chart_version: 1.16.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.16.0', 'quay.io/jetstack/cert-manager-controller:v1.16.0',
      'quay.io/jetstack/cert-manager-startupapicheck:v1.16.0', 'quay.io/jetstack/cert-manager-webhook:v1.16.0']
  - version: 1.15.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm chart / values changes to apply or review\n- **CRD uninstall\
        \ behavior changed**: from v1.15 the chart **will not uninstall CRDs by default**\
        \ when the chart is removed. If you *want* CRDs removed on uninstall, set:\n\
        \  - `crds.keep=false`\n  - Note: new CRD knobs exist: `crds.keep` and `crds.enabled`.\n\
        - **`installCRDs` is superseded**: use the new options instead:\n  - `crds.enabled`\
        \ (whether Helm installs CRDs)\n  - `crds.keep` (whether CRDs are retained\
        \ on uninstall)\n- **startupapicheck image reference**: update any pinned/airgapped\
        \ mirrors or image allowlists to use:\n  - `quay.io/jetstack/cert-manager-startupapicheck`\n\
        \  (cmctl is no longer the startupapicheck image.)\n- **New Helm values /\
        \ chart features**:\n  - `extraObjects`: list of arbitrary YAML manifests\
        \ to install/uninstall alongside cert-manager.\n  - Optional `hostAliases`\
        \ for the cert-manager Pod (to help DNS01 self-check in custom DNS scenarios).\n\
        \  - New chart options: `disableAutoApproval` and `approveSignerNames` (controls\
        \ auto-approval behavior for CertificateRequests / signers).\n"
      chart_updates: [CRDs are now retained by default on Helm uninstall to prevent
          accidental data loss; introduced `crds.keep`/`crds.enabled` to manage this
          behavior., Helm chart adds `extraObjects` to let you ship additional manifests
          with the release., Helm chart supports optional `hostAliases` on the cert-manager
          Pod., 'Fixed/adjusted Helm behaviors noted in release notes: logic distinguishing
          `0` vs empty values; restored default Prometheus Service resource behavior;
          corrected cainjector image value; ensured cainjector ConfigMap mounts correctly.',
        Added Helm options `disableAutoApproval` and `approveSignerNames`., 'Operational
          note: `cmctl` and `kubectl cert-manager` moved to the separate `cert-manager/cmctl`
          repo and are versioned independently (affects where you fetch the binary,
          not the Helm chart directly).']
      features: [Gateway API integration is now Beta; enable it with `--enable-gateway-api`
          (was previously experimental)., '`LiteralCertificateSubject` and `AdditionalCertificateOutputFormats`
          feature gates are now Beta; additional output formats are enabled by default.',
        'Helm can now install extra Kubernetes objects via `extraObjects`, and can
          set `hostAliases` to help DNS self-checks in custom environments.', 'Vault
          integration enhancements: mTLS support when Vault requires strict client
          certs, plus ability to configure additional Kubernetes auth audiences.',
        AWS Route53 provider supports AssumeRoleWithWebIdentity for credential retrieval;
          JKS keystore can now set a custom key alias.]
      breaking_changes: ['**CRD lifecycle change on uninstall**: Helm uninstall will
          no longer remove cert-manager CRDs by default; adjust your uninstall/runbook
          (set `crds.keep=false` only if you explicitly want CRDs deleted).', '**ACME
          `preferredChain` behavior fix**: if you relied on the previously unintended
          chain selection when `preferredChain` is set, certificate chain selection
          may change after upgrading (now uses the intended chain).', 'Tooling packaging
          change: `cmctl` moved to a separate repository and is versioned independently;
          update any automation that downloads `cmctl` from the main cert-manager
          release assets.']
    chart_version: 1.15.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.15.0', 'quay.io/jetstack/cert-manager-controller:v1.15.0',
      'quay.io/jetstack/cert-manager-startupapicheck:v1.15.0', 'quay.io/jetstack/cert-manager-webhook:v1.15.0']
  - version: 1.14.0
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Helm values split for feature gates (introduced in 1.13):**\
        \ if you set `.Values.featureGates`, those gates now apply **only to the controller**.\
        \ To enable gates on the webhook, use `.Values.webhook.featureGates`.\n- **ConfigMap\
        \ creation is now conditional (1.14):**\n  - Controller ConfigMap is created\
        \ **only if** `.Values.config` is set.\n  - Webhook ConfigMap is created **only\
        \ if** `.Values.webhook.config` is set.\n  If you previously relied on these\
        \ ConfigMaps existing, ensure the corresponding values are set.\n- **Startup\
        \ API check image change (1.14):** the `startupapicheck` Job now uses a **new\
        \ OCI image** named `startupapicheck` instead of the `ctl` image. If you pre-pull\
        \ / mirror images, add this new image.\n- **Service links / enableServiceLinks:**\
        \ service links were disabled across chart deployments in 1.13, and `enableServiceLinks`\
        \ became configurable; ACME HTTP solver pods specifically have it disabled\
        \ to avoid crashloops in clusters with many Services.\n- **Monitoring:** a\
        \ Helm value was added in 1.13 for ServiceMonitor endpoint extra fields: `prometheus.servicemonitor.endpointAdditionalProperties`\
        \ (e.g., relabelings).\n- **Known issue warning (1.14.0):** 1.14.0\u2019s\
        \ chart was manually corrected during release due to a wrong `cainjector`\
        \ image reference; upstream recommends installing **>= 1.14.2** instead of\
        \ 1.14.0/1.14.1."
      chart_updates: ['Security hardening defaults: pods now run with `readOnlyRootFilesystem:
          true` by default (including the ACME HTTP01 solver pod).', Controller liveness
          probe enabled by default; additional clock-skew detector liveness probe
          added., Webhook timeout default increased to 30s (max) to improve error
          visibility., Webhook can be restricted via custom `spec.namespaceSelector`
          support., Metrics endpoint can now be served over TLS (static cert files
          or dynamically issued certs)., 'ACME HTTP01 solver pods gain a default `cluster-autoscaler.kubernetes.io/safe-to-evict:
          "true"` annotation (overridable in podTemplate).']
      features: ['X.509: Certificate spec can now include certain `otherName` SANs
          (alpha; requires enabling `OtherName` feature gate on controller and webhook).',
        'CA Issuer: support for Name Constraints in CA certs and Authority Information
          Accessors (AIA) URLs for issued certificates.', 'Security: more secure HTTP
          server defaults (DoS mitigations), optional HTTPS metrics, and read-only
          root filesystem by default for pods.', 'Operational: controller liveness
          probe enabled by default plus clock-skew restart detection; configurable
          dynamic serving leaf certificate duration.', 'PKCS#12: new `.spec.keystores.pkcs12.algorithms`
          to control encryption/MAC algorithms.']
      breaking_changes: ['If you set Helm `.Values.featureGates`, those gates no longer
          get passed to the webhook (controller only). Use `.Values.webhook.featureGates`
          for webhook gates.', '`startupapicheck` job now uses a new `startupapicheck`
          image instead of `ctl`; environments that mirror/preload images must include
          it.', 'Potential compatibility change: KeyUsage and BasicConstraints are
          now encoded as **critical** in the CSR blob inside CertificateRequests;
          any downstream tooling expecting non-critical encoding may be affected.',
        'Webhook validation is stricter (from 1.13): CertificateRequest KeyUsages/ExtendedKeyUsages
          must be explicitly declared on the resource and must not be exceeded by
          the CSR contents.']
    chart_version: 1.14.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.14.0', 'quay.io/jetstack/cert-manager-controller:v1.14.0',
      'quay.io/jetstack/cert-manager-startupapicheck:v1.14.0', 'quay.io/jetstack/cert-manager-webhook:v1.14.0']
  - version: 1.13.0
    kube: ['1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart config changes to check\n- **Breaking:**\
        \ Helm `.featureGates` is now **controller-only**. If you previously set:\n\
        \  ```yaml\n  featureGates:\n    SomeGate: true\n  ```\n  those gates will\
        \ **no longer be passed to the webhook** in v1.13.0. To enable gates on the\
        \ webhook, move/add them under:\n  ```yaml\n  webhook:\n    featureGates:\n\
        \      SomeGate: true\n  ```\n  (PR #6093)\n\n- New/updated Helm knobs introduced\
        \ in/around v1.13.0:\n  - `prometheus.servicemonitor.endpointAdditionalProperties`:\
        \ add extra ServiceMonitor endpoint fields (e.g., `relabelings`).\n  - `enableServiceLinks`\
        \ is now configurable for all Deployments and the `startupapicheck` Job; additionally,\
        \ service links were disabled broadly in the chart and ACME HTTP solver pods\
        \ specifically to avoid crash loops in clusters with many Services.\n\n###\
        \ Upgrade sequencing note (operational, but matters for Helm rollouts)\n-\
        \ If coming from **< v1.12**, upgrade to the **latest v1.12 patch** first\
        \ before moving to v1.13, to avoid unexpected certificate re-issuance (release\
        \ note #6494 comment)."
      chart_updates: ['Webhook helm template behavior changed so controller feature
          gates are no longer inadvertently applied to the webhook (fix in #6093).',
        'NetworkPolicy templating fix: corrected indentation for webhook `matchLabels`
          (#6220).', 'Adds configurability / defaults around `enableServiceLinks`
          for deployments and `startupapicheck` job (#6292, plus follow-up changes
          disabling service links more broadly).', Adds ServiceMonitor endpoint extension
          point via `prometheus.servicemonitor.endpointAdditionalProperties` (#6110).,
        Adds Apache 2.0 license annotation in chart metadata (#6225).]
      features: ["DNS-over-HTTPS (DoH) support for ACME DNS-01 self-checks (use `--dns01-recursive-nameservers-only=true`\
          \ with an `https://\u2026/dns-query` endpoint).", Controller options can
          now be provided via a versioned configuration file (useful for managing
          controller settings declaratively)., 'Feature gates **StableCertificateRequestName**
          and **SecretsFilteredCaching** promoted to **Beta** and enabled by default
          (note known issue for StableCertificateRequestName in 1.13.0, fixed in 1.13.1+).',
        CertificateRequest / CSR validation tightened when using pki CertificateTemplate
          functions to ensure signed certs match requested usages and CA-ness., 'Helm:
          can add extra properties to Prometheus ServiceMonitor endpoints; `enableServiceLinks`
          can be configured across deployments; logging options can be set via webhook
          config file.']
      breaking_changes: ["**Helm breaking change:** `.featureGates` no longer applies\
          \ to the webhook; use `webhook.featureGates` instead. If you relied on controller\
          \ gates being passed through to the webhook\u2019s `--feature-gates`, that\
          \ will now fail unless the webhook actually supports those gates.", '**Potentially
          breaking:** webhook validation of CertificateRequest is stricter: all `keyUsages`/`extendedKeyUsages`
          must be explicitly declared on the CertificateRequest, and the CSR must
          not contain additional usages beyond those declared.', '**Known issue in
          1.13.0:** StableCertificateRequestName (now Beta, enabled by default) has
          a name-collision bug; upgrade to **v1.13.1+** to avoid it.', 'Upgrade path
          warning: if upgrading from <1.12, you must first upgrade to latest 1.12
          patch before 1.13 or some certs may be unexpectedly re-issued.']
    chart_version: 1.13.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.13.0', 'quay.io/jetstack/cert-manager-controller:v1.13.0',
      'quay.io/jetstack/cert-manager-ctl:v1.13.0', 'quay.io/jetstack/cert-manager-webhook:v1.13.0']
  - version: 1.12.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / chart behavior changes to review\n- **New PodDisruptionBudgets\
        \ (PDBs)** added for cert-manager components, **disabled by default**. If\
        \ you want disruption protection, enable and size these appropriately.\n-\
        \ **Webhook NetworkPolicy**: chart now also allows **egress to the API server\
        \ on 6443/TCP** (needed for OpenShift/OKD where apiserver listens on 6443).\n\
        - **New volume/volumeMount hooks via values** for **cainjector, webhook, and\
        \ startupapicheck** (useful for custom CA bundles, extra files, etc.).\n-\
        \ **New controller flags exposed via Helm values**: `--dns01-recursive-nameservers`,\
        \ `--dns01-recursive-nameservers-only`, and `--enable-certificate-owner-ref`\
        \ can now be configured through values.\n- **ACME solver image override precedence\
        \ clarified**: `acmesolver.extraArgs` (specifically `--acme-http01-solver-image`)\
        \ takes precedence over `acmesolver.image`.\n- **Controller liveness probe\
        \ support**: controller now has `/livez` endpoint and a **liveness probe is\
        \ available but disabled by default** in the chart/manifest.\n\n## Values/flags\
        \ to double-check if you customize\n- If you rely on cainjector\u2019s old\
        \ `--watch-certs` flag, it was **renamed** to `--enable-certificates-data-source`.\n\
        - ACME HTTP-01 solver can now be configured with `ingressClassName`; if you\
        \ previously relied on the deprecated ingress.class annotation behavior, consider\
        \ moving to the field.\n"
      chart_updates: [Added optional PodDisruptionBudgets for cert-manager components
          (off by default)., Webhook NetworkPolicy updated to permit egress to Kubernetes
          API on 6443/TCP (OpenShift/OKD compatibility)., Helm chart now supports
          adding extra volumes and volumeMounts to cainjector/webhook/startupapicheck
          pods via values., Helm chart exposes additional controller flags for DNS01
          recursion and certificate owner refs., Chart behavior updated so `--acme-http01-solver-image`
          in `acmesolver.extraArgs` overrides `acmesolver.image`., 'Chart documentation:
          fixed dead links in values.yaml.']
      features: [JSON logging is now supported via `--logging-format=json` (handy
          for log aggregation/parsing)., New `--concurrent-workers` flag lets you
          tune controller concurrency per controller., 'HTTP-01 solver can now set
          `ingressClassName` on created Ingresses, improving compatibility with clusters
          that require it.', Vault issuer supports ephemeral Kubernetes service account
          tokens via `serviceAccountRef` (short-lived auth to Vault)., Significant
          memory footprint reductions (controller and cainjector) through filtered/metadata-only
          caching and other optimizations., cainjector now has flags to disable unneeded
          injectable kinds to reduce memory usage.]
      breaking_changes: ['Gateway API integration (introduced in 1.11) moved to a
          more stable API; if you use the experimental Gateway API support, ensure
          the required Gateway API version is installed (1.11 notes).', 'cainjector
          behavior change: if the `certificates.cert-manager.io` CRD is not installed
          and you relied on cainjector running anyway, you now must pass `--watch-certificates=false`
          or cainjector will not start.', 'ACME Challenge naming calculation changed;
          to avoid duplicate issuances, ensure there is **no in-progress ACME issuance**
          during the upgrade.', 'POTENTIALLY BREAKING for Go consumers only: cert-manager
          binaries/tests were split into separate Go modules; code changes may be
          required if you import these modules.']
    chart_version: 1.12.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.12.0', 'quay.io/jetstack/cert-manager-controller:v1.12.0',
      'quay.io/jetstack/cert-manager-ctl:v1.12.0', 'quay.io/jetstack/cert-manager-webhook:v1.12.0']
  - version: 1.11.0
    kube: ['1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '## Helm chart / values changes to check

        - **ACME HTTP-01 solver image is now configurable** via Helm values (new options
        added). If you previously relied on default `acmesolver` image settings, review
        the new value keys and ensure they match your registry/mirroring policy.

        - **New controller flag exposed in the chart:** `--max-concurrent-challenges`
        (added as a Helm value). Consider setting this if you need to rate-limit ACME
        challenge processing.

        - **Feature gates via Helm now apply to the webhook too** (bug fix). If you
        used `extraArgs`/feature gate values, verify webhook args align with controller
        after upgrade.

        - **`extraArgs` precedence fix:** if you set `extraArgs`, it now correctly
        overrides the new ACME solver image options.

        - **Cainjector namespace scoping bug fixed:** the `--namespace` flag now works.
        If you want lower memory usage / fewer RBAC reads, consider setting cainjector
        to watch only the cert-manager namespace.

        '
      chart_updates: ['Reduced runtime memory usage (notably: controller secret caching
          fixed; cainjector namespace scoping works).', Gateway API integration moved
          to **v1beta1** for the experimental feature; requires Gateway API v1beta1
          CRDs installed if you use it., Security and dependency updates (Go minor
          bumps; `golang/x/net` and `x/text` vulns fixed)., Improved AzureDNS integration
          (Workload Identity support + a fix for misconfigured WI setups)., 'Venafi
          issuer improvements: vcert bumped; renewal and Ed25519 issues fixed; TLS
          renegotiation support for certain TPP setups.', Certificate secrets will
          refresh when keystore format changes; secrets get an additional label for
          troubleshooting/ownership.]
      features: [Significant reduction in runtime memory usage (fixing duplicate Secret
          caching and enabling cainjector namespace scoping)., Helm chart can now
          configure the ACME HTTP-01 solver image and expose `--max-concurrent-challenges`
          for tuning challenge throughput., 'AzureDNS solver gains Workload Identity
          support, improving AKS/Azure integrations.', Issuers can specify a custom
          CA bundle when connecting to an ACME server., Experimental Gateway API integration
          now targets the more stable v1beta1 API.]
      breaking_changes: ["**Gateway API breaking change (experimental):** cert-manager\u2019\
          s `ExperimentalGatewayAPISupport` now uses **Gateway API v1beta1**. Clusters\
          \ must have v1beta1 Gateway API CRDs installed; v1alpha2-only installs will\
          \ break."]
    chart_version: 1.11.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.11.0', 'quay.io/jetstack/cert-manager-controller:v1.11.0',
      'quay.io/jetstack/cert-manager-ctl:v1.11.0', 'quay.io/jetstack/cert-manager-webhook:v1.11.0']
  - version: 1.10.0
    kube: ['1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / chart behavior changes to review\n- **Container\
        \ name changes (breaking for automation):** cert-manager 1.10 changes the\
        \ *container names* in the controller and webhook (and other) Pods (e.g.,\
        \ `cert-manager` \u2192 `cert-manager-controller`, `cert-manager` \u2192 `cert-manager-webhook`).\
        \ If you have scripts/alerts that target container names, update them before\
        \ upgrading.\n- **Pod securityContext change (can affect OpenShift):** 1.10\
        \ sets `securityContext.seccompProfile.type: RuntimeDefault` on Pods. On some\
        \ OpenShift setups this can be rejected by SCC; you may need SCC updates/allowances\
        \ before the upgrade.\n- **New Helm values:**\n  - `commonLabels`: add labels\
        \ to all chart resources.\n  - NetworkPolicy support is added (new values\
        \ will exist to enable/configure it).\n  - ServiceMonitor annotations support\
        \ added (new values/fields related to ServiceMonitor metadata).\n- **Release\
        \ namespace handling:** chart avoids hard-coding the release namespace; if\
        \ you previously relied on older behavior, validate resources render into\
        \ the intended namespace.\n\n*(From 1.9: note that `securityContext.enabled`\
        \ was removed earlier; ensure you are not still setting it in values.)*"
      chart_updates: [Add NetworkPolicy support in the Helm chart., Add `commonLabels`
          to apply consistent labels across chart resources., Add support for ServiceMonitor
          annotations in the chart., Avoid hard-coding release namespace in chart
          templates., 'Rename containers in Pods to unique, role-reflecting names
          (breaking for scripts/CI).', Set Pod seccomp profile to `RuntimeDefault`
          to improve PSS/restricted compliance (may require OpenShift SCC changes).]
      features: ['Certificate metrics now include `issuer_name`, `issuer_kind`, and
          `issuer_group` labels for better attribution in monitoring.', Vault Issuer
          supports `caBundleSecretRef` (mutually exclusive with inline `caBundle`)
          to source CA bundle from a Secret., Gateway API dependency bumped to v0.5.0
          (relevant if you use Gateway-related integrations)., New (disabled-by-default)
          feature gate `StableCertificateRequestName` to generate deterministic CertificateRequest
          names and reduce "multiple CertificateRequests found" errors., 'Improved
          SelfSigned issuance behavior: CertificateRequests/CSRs will re-reconcile
          when referenced private key Secrets appear or become valid.', 'Chart-level
          quality-of-life: ability to set global `commonLabels`, plus optional NetworkPolicy
          resources.']
      breaking_changes: ['**Container name changes in cert-manager Pods** (Helm/static
          manifests): update any automation/monitoring that references container names
          (e.g., `kubectl logs -c cert-manager ...`, Prometheus scrape relabeling,
          log collection configs).', '**OpenShift SCC compatibility risk**: new `seccompProfile:
          RuntimeDefault` may cause Pods to be rejected until SCCs are adjusted/approved
          for the service accounts.']
    chart_version: 1.10.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.10.0', 'quay.io/jetstack/cert-manager-controller:v1.10.0',
      'quay.io/jetstack/cert-manager-ctl:v1.10.0', 'quay.io/jetstack/cert-manager-webhook:v1.10.0']
  - version: 1.9.0
    kube: ['1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / chart behavior changes to review\n- **New value:**\
        \ `namespace` \u2014 allows overriding the namespace where chart resources\
        \ are created (useful when cert-manager is a subchart). If you previously\
        \ relied on `.Release.Namespace` implicitly, verify behavior with this override.\n\
        - **New capability:** disable automounting of service account tokens (value\
        \ name not included in the pasted notes; check current chart values for the\
        \ relevant `automountServiceAccountToken`/`serviceAccount.automountServiceAccountToken`\
        \ knobs).\n- **Removed value:** `securityContext.enabled` was removed from\
        \ the chart; if you still set it in `values.yaml`, Helm will warn/fail depending\
        \ on your tooling. Remove it and set security context fields directly.\n-\
        \ **Chart scheduling fix:** `startupapicheck` is now scheduled only on **Linux**\
        \ nodes by default; ensure this matches your cluster node OS mix and any custom\
        \ node selectors/tolerations.\n"
      chart_updates: [Adds `namespace` override for resource creation (supports subchart
          use)., Option to disable auto-mounting service account tokens., Removes
          deprecated `securityContext.enabled` chart value., startupapicheck job scheduling
          constrained to Linux nodes.]
      features: ['Alpha: `Certificate.spec.literalSubject` to preserve ordered X.509
          subject RDN sequence (requires `--feature-gates=LiteralCertificateSubject=true`
          on controller and webhook; mutually exclusive with `spec.subject`/`spec.commonName`).',
        'ingress-shim: configure `Certificate.spec.privateKey` and `Certificate.spec.revisionHistoryLimit`
          via Ingress annotations (enables rotationPolicy best practices like `Always`).',
        'AWS credentials: can load both access key ID and secret access key from Kubernetes
          Secrets for AWS-based integrations/solvers.', 'Observability: new (alpha)
          Prometheus summary metric for Venafi API request latency.']
      breaking_changes: ['ingress-shim: **drops support for `networking.k8s.io/v1beta1`
          Ingress**. Clusters/manifests must use `networking.k8s.io/v1` (Kubernetes
          1.22+).', "Helm chart: `securityContext.enabled` value removed\u2014must\
          \ be deleted from your values and replaced with explicit securityContext\
          \ fields if needed.", 'Feature-gated field: using `spec.literalSubject`
          requires enabling the feature gate on both controller and webhook; otherwise
          applies/updates will fail validation.']
    chart_version: 1.9.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.9.0', 'quay.io/jetstack/cert-manager-controller:v1.9.0',
      'quay.io/jetstack/cert-manager-ctl:v1.9.0', 'quay.io/jetstack/cert-manager-webhook:v1.9.0']
  - version: 1.8.0
    kube: ['1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / chart behavior changes to review\n- **Default\
        \ `nodeSelector` now `kubernetes.io/os: linux`**. If your nodes don\u2019\
        t have this label (or you run Windows nodes), override `nodeSelector` in values\
        \ or add the label. (v1.8)\n- **ServiceAccount labels are now configurable**\
        \ via:\n  - `serviceAccount.labels`\n  - `cainjector.serviceAccount.labels`\n\
        \  - `webhook.serviceAccount.labels`\n  - `startupapicheck.serviceAccount.labels`\
        \ (v1.8)\n- **Security hardening defaults**: chart sets `securityContext.allowPrivilegeEscalation=false`\
        \ by default for controller/cainjector/webhook and the `startupapicheck` Job;\
        \ ACME solver pods also default to `allowPrivilegeEscalation=false`. If you\
        \ had custom securityContext overrides, re-check them. (v1.8)\n- If you use\
        \ **alpha `additionalOutputFormats`**, you must enable the feature gate on\
        \ **both** controller and webhook in v1.8 (`--feature-gates=AdditionalCertificateOutputFormats=true`),\
        \ not only controller. (v1.8)\n"
      chart_updates: ['Default nodeSelector changed to linux (`kubernetes.io/os: linux`).',
        New values to add labels to ServiceAccounts across components., 'Chart sets
          `allowPrivilegeEscalation: false` by default for core pods and startupapicheck
          job.']
      features: ['Alpha server-side-apply support behind `ServerSideApply=true` feature
          gate on Kubernetes 1.22+, reducing optimistic-locking conflicts and log
          noise.', "Exponential backoff for failed certificate issuances (1h \u2192\
          \ 2h \u2192 4h \u2026 up to 32h) plus a new `failedIssuanceAttempts` field\
          \ on Certificates.", 'Support for Kubernetes CSR `spec.expirationSeconds`
          (Kubernetes 1.22+), retaining the existing duration annotation with a minimum
          of 600s.', 'Ingress/Gateway shim enhancements: override whitelist-source-range
          via Issuer `ingressTemplate`, and ability to use an external issuer resource
          as default for ingress-shim.', 'Operational tooling improvements: `cmctl
          experimental uninstall` and build system transition from Bazel to Make (primarily
          developer-facing).']
      breaking_changes: ['Cert-manager API removals already landed in v1.7: v1alpha2/v1alpha3/v1beta1
          CRDs removed; all resources must be stored as v1 prior to upgrade (run `cmctl
          upgrade migrate-api-version`).', "v1.8 validates `spec.privateKey.rotationPolicy`\
          \ on Certificates; only `Never` and `Always` are allowed\u2014invalid manifests\
          \ will be rejected by the API/webhook and can break GitOps syncs.", 'If
          enabling `ServerSideApply=true` when upgrading to v1.8, pre-1.8 Challenge
          resources may not be cleaned up; ensure no Challenges exist or delete them
          once `valid`.', "Container internal binary paths changed due to Bazel\u2192\
          Make container layout; scripts or init containers that referenced old deep\
          \ Bazel paths will break.", Leader election now uses only Lease objects;
          old ConfigMap-based leader election objects may remain and require manual
          cleanup (upgrade-from-very-old versions not supported).]
    chart_version: 1.8.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.8.0', 'quay.io/jetstack/cert-manager-controller:v1.8.0',
      'quay.io/jetstack/cert-manager-ctl:v1.8.0', 'quay.io/jetstack/cert-manager-webhook:v1.8.0']
  - version: 1.7.0
    kube: ['1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '### Helm values / chart behavior changes

        - **New value:** `prometheus.servicemonitor.honorLabels` to set `honor_labels`
        on the ServiceMonitor scrape config.

        - **Bugfix:** Helm chart service annotations handling for the controller and
        webhook Services was fixed; if you had workarounds/patches, re-check your
        rendered manifests.

        - **Operational note (CRDs):** If you manage cert-manager CRDs with `kubectl
        apply --server-side`, upgrading to 1.7 can fail due to managedFields/conversionWebhook
        changes. Prefer Helm/client-side apply for CRDs, or patch CRD `managedFields`
        as described in the release notes before retrying.

        '
      chart_updates: ['CRDs shipped/installed by the chart no longer include deprecated
          API versions (`v1alpha2`, `v1alpha3`, `v1beta1`); CRD manifests are smaller
          and no longer require a conversion webhook.', Chart includes the service-annotation
          handling fix for controller/webhook Services.]
      features: [New `Certificate.spec.additionalOutputFormats` supports `CombinedPEM`
          (key+chain bundle) and `DER` outputs in addition to existing secret data
          formats., Webhook can now be configured via a mounted configuration file
          (ConfigMap) instead of only CLI flags., 'Server-Side Apply is now used to
          manage Secret labels/annotations and reconcile `secretTemplate`, improving
          drift correction.', New flag `--acme-http01-solver-nameservers` allows custom
          nameservers for ACME HTTP-01 propagation checks., 'New `cmctl upgrade migrate-api-version`
          command helps migrate stored CRs to `apiVersion: v1` before upgrading.']
      breaking_changes: ['**Deprecated APIs removed:** cert-manager no longer serves
          `v1alpha2`, `v1alpha3`, or `v1beta1`. All cert-manager CRs must be stored
          in etcd as `v1` and CRDs must have only `v1` as the stored version before
          upgrading (use `cmctl upgrade migrate-api-version`).', '**Ingress class
          semantics changed (reverted):** HTTP-01 solver Ingresses go back to using
          the `kubernetes.io/ingress.class` annotation (instead of `spec.ingressClassName`).
          If you relied on the newer behavior or use non-default classes/controllers,
          validate HTTP-01 behavior after upgrade.', '**Upgrading with Server-Side
          Apply:** SSA upgrades can produce invalid CRD configs due to CRD spec changes
          (conversion webhook removal). Use client-side apply/Helm for CRDs or patch
          CRD managedFields.', '**Flags:** `--dns01-self-check-nameservers` removed;
          use `--dns01-recursive-nameservers` instead.', '**Kubernetes compatibility:**
          cert-manager 1.7 requires Kubernetes >= 1.18 (due to reliance on Server-Side
          Apply).']
    chart_version: 1.7.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.7.0', 'quay.io/jetstack/cert-manager-controller:v1.7.0',
      'quay.io/jetstack/cert-manager-ctl:v1.7.0', 'quay.io/jetstack/cert-manager-webhook:v1.7.0']
  - version: 1.6.0
    kube: ['1.22', '1.21', '1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **(Helm chart)** `startupapicheck` post-install hook now **cleans
        up leftover hook resources** from prior failed installs, so `helm install`
        can be re-run without manual deletion.

        - **(Helm chart)** Added support to **set annotations on chart Services**
        (useful for cloud-provider/LB integrations).

        - **(Helm chart)** Added a **PodSecurityPolicy** for the `startupapicheck`
        Job (only relevant on clusters where PSP is enabled).


        _No explicit values key renames/removals were called out in the provided notes;
        validate against your current `values.yaml` and run `helm diff` before applying._'
      chart_updates: ["Startup API check hook behavior improved: deletes leftover\
          \ hook resources after failed installs (reduces \u201Calready exists\u201D\
          /hook collision issues on retry).", PodSecurityPolicy added for the startup
          API check job (legacy PSP environments)., Service templates updated to allow
          custom annotations via chart values.]
      features: ['API no longer serves deprecated cert-manager resource versions `v1alpha2`,
          `v1alpha3`, `v1beta1` (upgrade enforces using `cert-manager.io/v1`).', New
          Prometheus metric exposing Certificate `renewBefore` behavior for monitoring
          and alerting., Azure DNS solver can specify a managed identity ID (improves
          support for multiple identities)., 'CLI improvements in `cmctl`: shell completion
          + better Kubernetes flag exposure, plus build-time configurable command
          name.']
      breaking_changes: ["Deprecated cert-manager API versions `v1alpha2`, `v1alpha3`,\
          \ and `v1beta1` are **not served** in 1.6; manifests using them will fail\
          \ after upgrade\u2014convert resources/manifests to `cert-manager.io/v1`\
          \ before upgrading.", 'JKS keystores enforce a minimum password length of
          6 characters in 1.6.0 due to a dependency upgrade; this is fixed in 1.6.1,
          so avoid 1.6.0 if you rely on shorter JKS passwords.']
    chart_version: 1.6.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.6.0', 'quay.io/jetstack/cert-manager-controller:v1.6.0',
      'quay.io/jetstack/cert-manager-ctl:v1.6.0', 'quay.io/jetstack/cert-manager-webhook:v1.6.0']
  - version: 1.5.0
    kube: ['1.22', '1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [cert-manager 1.5 is the first release to support Kubernetes
          1.22 (ensure your cluster version/PSPs/security policies are compatible).,
        cert-manager now only accepts AdmissionReviewVersion v1 and ConversionReviewVersion
          v1 (requires Kubernetes >=1.16; webhook/API server must support v1)., 'Added
          a startup API check Job that waits for the cert-manager API to become ready,
          plus a `kubectl cert-manager check api` command (may create an extra Job
          during startup/upgrade).', New optional controller `gateway-shim` for Gateway
          API (can be enabled/disabled; adds additional reconciler behavior if enabled).,
        'Helm-chart level improvements: ability to configure labels on the cert-manager
          webhook Service via a Helm value; service port for Prometheus scraping now
          has a name (may affect ServiceMonitor scraping selectors); and support for
          configuring which annotations are copied from Certificate to CertificateRequest
          (with some keys excluded by default).']
      features: [Kubernetes 1.22 support., 'Gateway API support: optional gateway-shim
          to auto-create ACME certs for annotated Gateways and Gateway API HTTP01
          solver support.', 'TLS Secret customization: add custom annotations/labels
          to the Secret containing the issued key pair.', 'Crypto: Ed25519 private
          keys/signatures supported for Certificates.', 'Experimental CSR signing
          support for ACME, SelfSigned, Vault, and Venafi issuers behind `--feature-gates=ExperimentalCertificateSigningRequestControllers=true`,
          plus a CLI command to create Kubernetes CSRs from Certificate manifests.',
        'Observability/ops: named Prometheus scrape port, new `clock_time_seconds`
          metric, improved shutdown/leader election behavior, and new kubectl plugin
          commands (`version`, `check api`, `x install`).']
      breaking_changes: [cert-manager webhooks now only support AdmissionReview and
          ConversionReview API version v1 (v1beta1 removed); clusters must be Kubernetes
          >=1.16 and any integrations expecting v1beta1 will break., "Pre-v1 cert-manager\
          \ resource requests must be convertible to v1 to be validated/mutated by\
          \ admission webhooks; if conversion isn\u2019t in place, older manifests\
          \ may be rejected (relevant if you still apply deprecated API versions).",
        'Forward-looking: APIs deprecated in 1.4 (v1alpha2/v1alpha3/v1beta1) will
          stop being served in 1.6; you should complete CRD/resource migration to
          v1 during/after this upgrade to avoid being blocked later.']
    chart_version: 1.5.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.5.0', 'quay.io/jetstack/cert-manager-controller:v1.5.0',
      'quay.io/jetstack/cert-manager-ctl:v1.5.0', 'quay.io/jetstack/cert-manager-webhook:v1.5.0']
  - version: 1.4.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Security context default change:** `runAsNonRoot` is now\
        \ **enabled by default** via Helm values. If you inject **custom containers**\
        \ (e.g., extra sidecars) that must run as root, explicitly set it back to\
        \ `false` (or set an appropriate `runAsUser`/`fsGroup` etc. for non-root operation).\n\
        - **New chart value:** `serviceLabels` (controller Service) lets you add custom\
        \ labels to the cert-manager controller Service.\n- (From prior 1.3.0 urgent\
        \ note, still relevant if you\u2019re on 1.3.0) **Helm upgrade path:** upgrade\
        \ to **v1.3.1 first** to avoid a CRD type conversion issue, then proceed to\
        \ v1.4.0."
      chart_updates: [Controller leader election lock type changed to `ConfigMapsLeasesResourceLock`
          (internal behavior; may affect required RBAC in locked-down clusters).,
        Base image updated (distroless/static) and Kubernetes libraries updated to
          v1.21.0 (generally transparent but can surface compatibility issues in very
          old clusters/tools)., Webhook can be configured to be reachable from outside
          the cluster (new capability; requires conscious networking configuration
          if enabled).]
      features: ['Helm: add `serviceLabels` to apply custom labels to the controller
          Service.', 'Security: `runAsNonRoot` enabled by default (hardening); requires
          adjustments if any container needs root.', 'Issuers: CA/Vault/Venafi now
          build and expose a proper certificate chain and set `CertificateRequest.Status.CA`
          to the root-most certificate when available.', New option to implement the
          CA Issuer via the Kubernetes `CertificateSigningRequest` controller., Webhook
          can be exposed outside the cluster (useful for external API server/webhook
          reachability scenarios)., Akamai issuer updated to EdgeDNS v2 API; kubectl
          plugin built for darwin/arm64.]
      breaking_changes: ['CA Issuer behavior change: `ca.crt` on issued Secrets now
          stores the **root CA** (when available) rather than the issuing/intermediate
          CA; the intermediate should now appear in `tls.crt` chain. Consumers that
          assumed `ca.crt` contained the intermediate may need updates.', 'Helm default
          security context change: `runAsNonRoot=true` can break deployments that
          add custom root-running containers unless values are overridden.']
    chart_version: 1.4.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.4.0', 'quay.io/jetstack/cert-manager-controller:v1.4.0',
      'quay.io/jetstack/cert-manager-webhook:v1.4.0']
  - version: 1.3.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **Helm users:** avoid upgrading to **v1.3.0** due to a **CRD
        type conversion issue**; upgrade directly to **v1.3.1** instead (ref. #3880).

        - If you previously set `--renew-before-expiration-duration` via Helm values/extraArgs
        for the controller, **remove it**: the flag was deprecated in v1.2 and **removed
        in v1.3**. Use `Certificate.spec.renewBefore` (or ingress-shim annotations
        `cert-manager.io/renew-before`) instead.

        - New chart option: `automountServiceAccountToken` on cert-manager service
        accounts (consider setting to `false` for least-privilege).

        - Service `targetPort` behavior now uses the port from Helm values (verify
        if you override webhook/service ports).

        '
      chart_updates: ['Helm chart: add `automountServiceAccountToken` field to service
          accounts.', 'Helm chart: fix/adjust Helm upgrade behaviors (v1.2 had a type
          conversion bug fix; v1.3 notes include additional Helm upgrade fix).', 'Helm
          chart/service: ensure `targetPort` uses the value-defined port (may affect
          custom port overrides).']
      features: [CertificateRequests now support an `Approved` condition and include
          requester `UserInfo` fields (username/groups/uid/extra) for auditing., 'New
          kubectl plugin commands: `kubectl cert-manager approve|deny` and improved
          default output for `kubectl get certificaterequest`.', Issuers and Certificates
          now publish `observedGeneration` in conditions to make status vs. spec drift
          easier to detect., Certificates gain `revisionHistoryLimit` to garbage-collect
          old CertificateRequests and reduce clutter., 'Controller can selectively
          disable specific controllers via `--controllers=\*,-foo`.', Venafi issuer
          updated for Venafi Cloud OutagePREDICT compatibility.]
      breaking_changes: [Controller flag `--renew-before-expiration-duration` was
          **removed** in v1.3; move to `Certificate.spec.renewBefore` / ingress-shim
          annotations or manifests will fail to start if still set., "CertificateRequests\
          \ are now **immutable**: `spec` and `metadata.annotations` can\u2019t be\
          \ changed after creation; workflows that patch CertificateRequests must\
          \ be adjusted.", 'Venafi Cloud zone syntax changed due to OutagePREDICT
          migration: zone is now `<<Application Name>>\\<<Issuing Template Alias>>`
          (e.g., `My Application\\My CIT`).', "Helm upgrade pitfall: v1.3.0 has a\
          \ CRD type conversion issue\u2014**upgrade to v1.3.1** instead of v1.3.0."]
    chart_version: 1.3.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.3.0', 'quay.io/jetstack/cert-manager-controller:v1.3.0',
      'quay.io/jetstack/cert-manager-webhook:v1.3.0']
  - version: 1.2.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **New chart values / knobs:**\n  - `webhook.podLabels` and\
        \ `cainjector.podLabels` can now be set (added in v1.1.0).\n  - Webhook call\
        \ timeout is configurable (added in v1.1.0).\n- **Chart bugfix:**\n  - v1.2.0\
        \ fixes a Helm chart type conversion issue; if you had workarounds (e.g.,\
        \ quoting numeric/bool values unusually), re-test and simplify.\n\n> Note:\
        \ the provided notes don\u2019t include a full chart values diff; review your\
        \ existing values file for any custom flags/args that may now be deprecated\
        \ (e.g., `--renew-before-expiration-duration`)."
      chart_updates: [Minimum supported Kubernetes version is now **v1.16.0** (v1.2.0).,
        Admissionregistration resources now use `admissionregistration.k8s.io/v1`
          (v1.2.0)., Ingress-related work moved to newer API group (`networking.k8s.io/v1beta1`)
          in code paths (v1.2.0)., User-Agent changed to reflect CNCF ownership transfer
          (v1.2.0)., 'Vault issuer secret contents changed: `ca.crt` now stores the
          **root CA** instead of the issuing CA (v1.2.0).']
      features: [Ingress-shim can now set key usages via `cert-manager.io/usages`
          and includes Server Auth by default., 'New plugin: `kubectl cert-manager
          inspect secret` to print certificate info from a Secret.', CRDs now include
          category names so you can list them with `kubectl get cert-manager` / `kubectl
          get cert-manager-acme`., Controller can generate a PKCS12 truststore (`truststore.p12`)
          from a CA., Controller can expose pprof profiling when enabled via `--enable-profiling`.,
        CA issuer can set a custom OCSP server for issued certificates., Cainjector
          leader election timing can be tuned via new flags (lease duration / renew
          deadline / retry period)., Ingress-shim now honors `cert-manager.io/duration`
          and `cert-manager.io/renew-before` annotations.]
      breaking_changes: [Kubernetes **v1.16.0** is now the minimum supported version;
          clusters on v1.15 or below must upgrade Kubernetes first or stay on cert-manager
          v1.1.x., The controller flag `--renew-before-expiration-duration` is **deprecated**
          in favor of `Certificate.spec.renewBefore` and will be removed in the next
          release (plan to migrate now)., 'Vault issuer output changed: `ca.crt` now
          contains the **root CA** (not the issuing CA), which may break consumers
          that expect the previous CA chain behavior.']
    chart_version: 1.2.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.2.0', 'quay.io/jetstack/cert-manager-controller:v1.2.0',
      'quay.io/jetstack/cert-manager-webhook:v1.2.0']
  - version: 1.1.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16', '1.15', '1.14', '1.13',
      '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart behavior changes (v1.0.0 \u2192 v1.1.0)\n\
        - **New:** `webhook.podLabels` and `cainjector.podLabels` to add custom pod\
        \ labels to those Deployments.\n- **New:** Configurable **webhook call timeout**\
        \ (Helm option added; check your values for a new `webhook.timeoutSeconds`-style\
        \ key depending on your chart version).\n\n**Action:** If you rely on labels\
        \ for monitoring/PSP/policy selection or you need longer webhook admission\
        \ timeouts, consider setting these new values. Otherwise no required values\
        \ changes are called out in the provided notes."
      chart_updates: ['Helm chart: allow setting custom `podLabels` on `webhook` and
          `cainjector` Deployments.', 'Helm chart: allow configuring the webhook timeout
          for admission calls.']
      features: ['Certificate spec: `encodeUsagesInRequest` allows disabling encoding
          key usages in the CSR.', "ACME: can pass Certificate `duration` to the ACME\
          \ server (not supported by Let\u2019s Encrypt at the time).", 'ACME: support
          issuing certificates with IP Subject Alternative Names.', 'ACME DNS-01:
          propagation check period is now configurable.', 'Controller tuning: Kubernetes
          client QPS throttling is now configurable.', 'Venafi TPP issuer: now supports
          access-token credentials.']
      breaking_changes: []
    chart_version: 1.1.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.1.0', 'quay.io/jetstack/cert-manager-controller:v1.1.0',
      'quay.io/jetstack/cert-manager-webhook:v1.1.0']
  - version: 1.0.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16', '1.15', '1.14', '1.13',
      '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '## Helm chart / values changes to plan for

        - **Webhook host networking (new option):** `webhook.hostNetwork` can be enabled
        to run the webhook Pod with `hostNetwork: true`.

        - **Webhook probes configurable (new options):** Chart now allows configuring
        the webhook health probes (liveness/readiness/startup as exposed by the chart).

        - **Webhook annotations (new values):** Extra custom annotations can be set
        on the **mutating** and **validating** webhook configurations.

        - **Image pinning via digest (new values):** Chart supports specifying an
        **image digest** in addition to tags (useful for supply-chain pinning).

        - (From 0.16.0 era chart) **Per-deployment securityContext:** Ability to set
        container `securityContext` for each deployment in the chart.


        ## Upgrade tooling prerequisites

        - **Use modern `kubectl` and `helm`:** Older versions may fail to update cert-manager
        CRDs correctly (called out as urgent in both v0.16.0 and v1.0.0 notes).'
      chart_updates: [Introduces the stable **v1 API** and makes it the **storage
          version** for cert-manager resources; CRDs now include `apiextensions.k8s.io/v1`
          variants and controllers are updated accordingly., 'Moves to newer/stable
          Kubernetes APIs across the board: admissionregistration.k8s.io/v1 for webhooks
          and rbac.authorization.k8s.io/v1 for RBAC.', Improved logging via klog v2
          and log-level usage; internal refactors like cainjector leader election
          simplification., 'Enhances kubectl/ctl UX, especially `kubectl cert-manager
          status certificate`, adding more related resource and event output for debugging.',
        ACME improvements including preferred chain support and better handling of
          Retry-After backoff; better error surfacing for Orders/Challenges.]
      features: ['Stable `v1` API is introduced and becomes the default/storage version,
          improving long-term compatibility expectations.', '`kubectl cert-manager
          status certificate` gains richer output (related Secret, Issuer, Orders/Challenges,
          and Events) for faster troubleshooting.', 'Helm chart gains options for
          webhook host networking, configurable probes, extra webhook annotations,
          and image digests for pinning.', 'ACME enhancements: support for `preferredChain`
          and improved rate-limit backoff handling via Retry-After.', 'Issuer/provider
          improvements: async Venafi issuance (0.16), Vault issuer namespace support
          (1.0), and additional HTTP01 podTemplate fields (serviceAccountName/priorityClassName).']
      breaking_changes: ['**Kubernetes version compatibility:** Kubernetes < **v1.16**
          requires special upgrade instructions for 0.16 -> 1.0 (per urgent notes).',
        '**API removals:** Support for `AuditSink` resources in `auditregistration.k8s.io/v1alpha1`
          was removed (v0.16.0).', '**CRD upgrade sensitivity:** Upgrading CRDs can
          fail with old `kubectl`/`helm`; treat CRD updates as a critical step and
          follow the documented upgrade guides.']
    chart_version: 1.0.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v1.0.0', 'quay.io/jetstack/cert-manager-controller:v1.0.0',
      'quay.io/jetstack/cert-manager-webhook:v1.0.0']
  - version: 0.16.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16', '1.15', '1.14', '1.13',
      '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Helm chart**: v0.15 introduced `installCRDs` (disabled by\
        \ default). If you want Helm to manage CRDs, set `installCRDs=true`.\n- **Helm\
        \ chart**: v0.16 added the ability to set **per-deployment container `securityContext`**\
        \ via values (for cert-manager, webhook, and cainjector).\n- **Tooling caution**:\
        \ v0.16 notes that **older `kubectl`/`helm` struggle to update CRDs**; follow\
        \ the 0.15\u21920.16 upgrade doc and ensure your client tooling is new enough.\n"
      chart_updates: ['v0.15: Helm chart can optionally install/manage CRDs via `installCRDs`
          (was previously external/static-manifest managed).', 'v0.15: ServiceAccount
          customization added for webhook and cainjector (chart options).', 'v0.16:
          Helm chart exposes container-level `securityContext` configuration per deployment.']
      features: ['Optional Helm-managed CRDs via `installCRDs`, reducing manual CRD
          lifecycle steps when installing/upgrading with Helm.', 'Webhook startup
          is more reliable because it can bootstrap/manage its own CA/certs (dynamic
          authority), reducing dependency on the controller being ready.', JKS and
          PKCS#12 keystore support is GA and configurable per-Certificate via `spec.keystores`.,
        'New `kubectl cert-manager` (ctl) plugin features: status output improvements,
          manual renewal support (0.15 feature-gated; more commands in 0.16), and
          creation of CertificateRequests from Certificate YAML.', 'New `v1beta1`
          API version is introduced in 0.16, preparing for API stabilization/migrations.',
        'Experimental certificate controller implementations become enabled for all
          users in 0.16, bringing features like private key rotation closer to default
          behavior.']
      breaking_changes: ["v0.15: Default KeyUsage no longer includes `serverAuth`;\
          \ if you rely on it and your issuer doesn\u2019t set it, you must explicitly\
          \ add `serverAuth` to Certificate/CertificateRequest `usages` to avoid behavior\
          \ changes.", 'v0.16: Support for `AuditSink` (`auditregistration.k8s.io/v1alpha1`)
          as a cainjector target is removed; any setups relying on injecting CA bundles
          into AuditSink will stop working.', 'v0.16: CRD upgrade can fail with older
          Helm/kubectl clients; using outdated tooling may break the upgrade until
          clients are updated and CRDs are applied per the documented procedure.']
    chart_version: 0.16.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v0.16.0', 'quay.io/jetstack/cert-manager-controller:v0.16.0',
      'quay.io/jetstack/cert-manager-webhook:v0.16.0']
  - version: 0.15.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16', '1.15', '1.14', '1.13',
      '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart behavior changes\n- **New chart value:**\
        \ `installCRDs` (default **false**). When set to `true`, Helm will install/manage\
        \ cert-manager CRDs as part of the release.\n  - Use via `values.yaml` or\
        \ `--set installCRDs=true`.\n  - Decide explicitly whether you want Helm to\
        \ own CRDs; if you already manage CRDs separately, leave this off.\n- **Feature\
        \ gates via values:** experimental certificate controllers can be enabled\
        \ with:\n  - `featureGates: \"ExperimentalCertificateControllers=true\"`\n\
        \n### Important carryover from v0.14.0 (if you haven\u2019t already done it)\n\
        - v0.14.0 required updating Deployment selectors to Helm best practices; upgrading\
        \ required **deleting the three cert-manager Deployments before upgrading**\
        \ (controller/cainjector/webhook). If your 0.14 install came from Helm and\
        \ you didn\u2019t perform this, validate your current resources/selectors\
        \ before the 0.15 upgrade."
      chart_updates: [Helm chart gained the `installCRDs` switch to optionally manage
          CRDs with Helm (disabled by default)., 'Webhook deployment/process was improved
          in 0.15 (DynamicAuthority / self-managed CA for serving certs), reducing
          dependency on the controller for webhook startup reliability.', 'Chart supports
          additional customization around service accounts (webhook and cainjector),
          and a narrower-scoped RBAC role for leader-election configmaps (operational
          hardening).']
      features: ['Optional Helm-managed CRDs via `installCRDs`, simplifying installations
          that want CRDs lifecycle tied to the Helm release.', Experimental new Certificate
          controller architecture (feature-gated) to enable capabilities like private
          key rotation and manual renewal triggering., Webhook startup is more reliable
          and faster because the webhook now bootstraps/maintains its own CA and serving
          certs without waiting on the controller., General availability of per-Certificate
          JKS and PKCS#12 keystore output via `certificate.spec.keystores` (no global
          experimental flags needed)., New `kubectl cert-manager` (cert-manager-ctl)
          plugin adds `convert` (API version conversion) and `renew` (manual renewal;
          requires experimental certificate controllers).]
      breaking_changes: ['**Urgent:** `serverAuth` key usage was removed from the
          default usages set. If your Issuer does not automatically include it and
          you require it, you must explicitly add `serverAuth` to `Certificate` and
          `CertificateRequest` `usages` to avoid unexpected behavior after upgrade.',
        "If you previously relied on v0.14\u2019s global experimental JKS/PKCS12 flags,\
          \ v0.15\u2019s recommended approach is per-Certificate `spec.keystores`;\
          \ plan a migration of configuration/expectations accordingly."]
    chart_version: 0.15.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v0.15.0', 'quay.io/jetstack/cert-manager-controller:v0.15.0',
      'quay.io/jetstack/cert-manager-webhook:v0.15.0']
  - version: 0.14.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16', '1.15', '1.14', '1.13',
      '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / chart behavior changes to account for\n\n- **Webhook\
        \ is now mandatory**: the Helm value `webhook.enabled` was **removed**; you\
        \ can no longer disable the webhook. Plan networking/RBAC so the API server\
        \ can reach the webhook.\n- **`isOpenShift` value removed** from the Helm\
        \ chart; use the appropriate manifest/variant for OpenShift/Kubernetes version\
        \ instead of toggling this flag.\n- **Deployment selector change (breaking\
        \ for Helm upgrades)**: the Deployments\u2019 `spec.selector` was updated\
        \ to follow Helm best practices. **You must delete the existing Deployments\
        \ (`cert-manager`, `cert-manager-webhook`, `cert-manager-cainjector`) before\
        \ upgrading** or the upgrade will fail because selectors are immutable.\n\
        - If you previously disabled cainjector: a bug fix indicates `cainjector.enabled=false`\
        \ now works correctly; re-check your values to ensure your intended state\
        \ is applied post-upgrade.\n"
      chart_updates: [Webhook component is required starting v0.14 (no-webhook variant
          removed; webhook enable toggle removed in chart)., "Installation manifests\
          \ reworked into two variants: `cert-manager.yaml` (standard) and `cert-manager-legacy.yaml`\
          \ (for Kubernetes 1.11\u20131.14 / OpenShift 3.11).", 'CRD distribution
          changed: `00-crds.yaml` replaced by a release-published CRD manifest; CRD
          conversion webhook enabled to serve v1alpha3 alongside v1alpha2.', Deployment
          selectors updated (requires deleting existing Deployments prior to Helm
          upgrade)., Webhook leader-election RoleBinding now uses leader election
          namespace rather than hard-coded `kube-system`., Flags/params added around
          webhook TLS cipher suites and improved webhook startup time.]
      features: ['CRD conversion webhook enabled and new `v1alpha3` API served alongside
          `v1alpha2`, easing future API transitions.', Experimental certificate bundle
          output support for **JKS** and **PKCS#12** via controller flags (global
          enable)., 'Venafi issuer enhancements: custom fields via `venafi.cert-manager.io/custom-fields`
          annotation (TPP 19.2+ required for TPP).', New `emailSANs` field on Certificate
          resources., 'Improved install compatibility: support extended to Kubernetes
          1.11 and OpenShift 3.11 (via legacy manifests).']
      breaking_changes: ['**Helm upgrade requires manual intervention**: delete the
          three cert-manager Deployments before upgrading due to immutable selector
          changes.', '**Webhook cannot be disabled anymore**; environments that relied
          on `webhook.enabled=false` or no-webhook installs must now run the webhook
          and ensure API server-to-webhook connectivity.', 'API evolution begins (`v1alpha3`
          + conversion webhook): while intended to be seamless, any hardcoded assumptions
          about field locations/serialization in clients may need validation.']
    chart_version: 0.14.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v0.14.0', 'quay.io/jetstack/cert-manager-controller:v0.14.0',
      'quay.io/jetstack/cert-manager-webhook:v0.14.0']
  - version: 0.13.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16', '1.15', '1.14', '1.13',
      '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **New chart values available (optional):**\n  - `volumes` /\
        \ `volumeMounts` for cert-manager pods.\n  - `deploymentAnnotations`, `webhook.deploymentAnnotations`,\
        \ `cainjector.deploymentAnnotations`.\n  - Arbitrary `securityContext` support;\
        \ plus optional `webhook.securityContext` and `cainjector.securityContext`.\n\
        \  - PodSecurityPolicy-related toggle to **disable AppArmor** when PSPs are\
        \ enabled.\n- **Chart rendering fix:** handles \u201Cfalse-y\u201D values\
        \ better to mitigate kubernetes/kubernetes#66450.\n- **Chart manifest detail:**\
        \ explicitly sets `containerPort` protocol.\n\n_No mandatory Helm values changes\
        \ are called out for 0.12\u21920.13; v0.13 is described as not requiring special\
        \ upgrade steps._"
      chart_updates: [Helm chart now supports configuring additional pod `volumes`
          and `volumeMounts`., Helm chart supports configurable deployment annotations
          for controller/webhook/cainjector., Helm chart supports setting pod securityContext
          for controller and separately for webhook/cainjector., Helm chart can disable
          AppArmor when using PodSecurityPolicies., Helm chart fixes templating of
          false-y values (kubernetes/kubernetes#66450)., Helm chart explicitly defines
          `containerPort` protocol.]
      features: ['ACME External Account Binding (EAB) support via `spec.acme.externalAccountBinding`
          on ACME Issuer/ClusterIssuer, enabling use with ACME providers that require
          EAB.', 'Certificate subject supports the full set of standard X.509 subject
          fields (e.g., OU, province, serialNumber, country, etc.).', New `InvalidRequest`
          status condition on `CertificateRequest` lets external issuers signal a
          non-retriable invalid CSR/request to avoid endless retries/quota burn.]
      breaking_changes: ["No breaking changes or special upgrade steps are indicated\
          \ for v0.13.0 relative to v0.12.0 in the provided notes (it\u2019s described\
          \ as a minor, incremental update)."]
    chart_version: 0.13.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v0.13.0', 'quay.io/jetstack/cert-manager-controller:v0.13.0',
      'quay.io/jetstack/cert-manager-webhook:v0.13.0']
  - version: 0.12.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16', '1.15', '1.14', '1.13',
      '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **cainjector subchart removed/flattened:** v0.12.0 removes
        the nested `cainjector` subchart and includes it in the main chart. If you
        had values under a subchart key, re-check and migrate any `cainjector`-scoped
        values to the new location as required by your chart version.

        - **Service ports now specify protocol explicitly:** the Helm chart explicitly
        defines `ContainerPort` protocol; usually no action required unless you patched
        templates or depended on implicit defaults.

        - **Chart metadata fix:** `apiVersion` missing in `Chart.yaml` was fixed;
        no user action.

        '
      chart_updates: ['Webhook component deployment was redesigned to no longer rely
          on an `APIService`, reducing risk of cluster-wide issues if the webhook
          is unavailable.', Multi-architecture image support is now automatic via
          Docker manifest lists (no need for arch-specific images/manifests)., Improved
          ACME Challenge diagnostics; more information surfaced on Challenge resources
          (`kubectl describe challenge ...`)., 'Various bug fixes: PSP compatibility,
          OwnerReferencesPermissionEnforcement admission controller compatibility,
          leader election signal handling, and solver/docs fixes.', 'Defaults/behavioral
          tweaks: webhook listen address default changed to **10250** for better GKE
          private cluster compatibility.', 'Schema/validation tightened: `CertificateRequest.spec.csr`
          marked required; additional API resource validation for `status` subresource;
          immutability enforced on multiple Order fields.']
      features: [Automatic multi-architecture image selection using Docker manifest
          lists (arm/arm64 etc.) without changing manifests., Much better debugging
          for ACME authorization failures via richer status/details on Challenge resources.,
        Webhook simplified (no `APIService`) and now includes support for CRD API
          conversion groundwork for future v1beta1., Cloudflare issuer supports API
          token authentication., Certificates now include `serverAuth` extended key
          usage by default.]
      breaking_changes: ['**Vault Kubernetes auth path change:** if you set a custom
          Kubernetes Auth Mount Path, you must now specify the full mount path; cert-manager
          appends `/login` automatically. Default changed from `kubernetes` to `/v1/auth/kubernetes`.',
        'Order resource fields made immutable; if you have automation that mutates
          these fields after creation, it will now fail and must be updated.', '`CertificateRequest.spec.csr`
          is now required by schema; any manifests missing it (for CRs you create
          directly) will be rejected.']
    chart_version: 0.12.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v0.12.0', 'quay.io/jetstack/cert-manager-controller:v0.12.0',
      'quay.io/jetstack/cert-manager-webhook:v0.12.0']
  - version: 0.11.0
    kube: ['1.9']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.11.0
    images: ['quay.io/jetstack/cert-manager-cainjector:v0.11.0', 'quay.io/jetstack/cert-manager-controller:v0.11.0',
      'quay.io/jetstack/cert-manager-webhook:v0.11.0']
  name: cert-manager
- icon: https://avatars.githubusercontent.com/u/21054566?s=48&v=4
  release_url: https://github.com/cilium/cilium/releases/tag/v{vsn}
  helm_repository_url: https://helm.cilium.io/
  helm_values: debug.verbose=flow
  versions:
  - version: 1.18.5
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Envoy proxy was bumped within the 1.18 line (to 1.34.11/1.34.12),
          bringing in upstream proxy fixes and behavior updates.', 'Hybrid-DSR support
          was added via the existing annotation infrastructure, enabling a new service
          load-balancing mode where applicable.', Kubernetes endpoints that are terminating
          are now retained in BPF backend state (regardless of the "serving" condition)
          to reduce connection disruption during pod termination., Secret-sync controller
          gained a periodic resync to improve eventual consistency.]
      breaking_changes: []
    chart_version: 1.18.5
    images: ['quay.io/cilium/cilium-envoy:v1.34.12-1765374555-6a93b0bbba8d6dc75b651cbafeedb062b2997716@sha256:3108521821c6922695ff1f6ef24b09026c94b195283f8bfbfc0fa49356a156e1',
      'quay.io/cilium/cilium:v1.18.5@sha256:2c92fb05962a346eaf0ce11b912ba434dc10bd54b9989e970416681f4a069628',
      'quay.io/cilium/operator-generic:v1.18.5@sha256:36c3f6f14c8ced7f45b40b0a927639894b44269dd653f9528e7a0dc363a4eb99']
  - version: 1.18.2
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **ServiceMonitor labels:** Helm now enforces consistent default
        labels on all `ServiceMonitor` resources. If you have custom label selectors
        in Prometheus/Prometheus Operator, verify they still match after the upgrade.

        - **cilium-ingress-service NodePort behavior:** Helm will **only set `nodePort`**
        for `cilium-ingress-service` **when explicitly specified**. If you relied
        on an implicitly assigned/templated NodePort, you must set it in values.

        - **dnsPolicy extensibility:** Adds support for downstream packagers to extend
        `cilium-agent` `dnsPolicy` (usually no action unless you maintain a derivative
        chart/packaging).

        '
      chart_updates: [Cilium Operator includes an additional toleration for `node.cloudprovider.kubernetes.io/uninitialized`
          (improves scheduling during cloud-provider init)., 'API-server load reduction:
          unnecessary headless Service watching is disabled when not using Gateway
          API/Ingress features (behavioral change aimed at reducing apiserver load).',
        'LB IPAM stability improvements: operator restart or pool selector/CIDR widening
          no longer triggers LoadBalancer IP reallocations.', 'Envoy behavior: listeners
          are served only after clusters have been ACKed (helps avoid transient traffic
          failures during xDS convergence).']
      features: ['BGP Control Plane v2: configurable BGP **origin attribute** for
          LoadBalancer IPs to ease migration from MetalLB integration.', 'Operational
          efficiency: reduced kube-apiserver watch load in clusters not using Gateway
          API/Ingress by avoiding unnecessary headless service watching.']
      breaking_changes: ['Policy validation is stricter: namespaced `CiliumNetworkPolicy`
          objects with `nodeSelector` inside a `specs[]` entry are now **rejected**
          (previously accepted but ignored). This can break installs that unknowingly
          relied on the old behavior; fix policies before/with the upgrade.']
    chart_version: 1.18.2
    images: ['quay.io/cilium/cilium-envoy:v1.34.7-1757592137-1a52bb680a956879722f48c591a2ca90f7791324@sha256:7932d656b63f6f866b6732099d33355184322123cfe1182e6f05175a3bc2e0e0',
      'quay.io/cilium/cilium:v1.18.2@sha256:858f807ea4e20e85e3ea3240a762e1f4b29f1cb5bbd0463b8aa77e7b097c0667',
      'quay.io/cilium/operator-generic:v1.18.2@sha256:cb4e4ffc5789fd5ff6a534e3b1460623df61cba00f5ea1c7b40153b5efb81805']
  - version: 1.18.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Service load-balancing control-plane redesigned to reduce agent memory
          usage and provide a better foundation for future load-balancing features.,
        "Support added for new virtual network device configurations (e.g., VXLAN-in-IPsec\
          \ \u201CVinE\u201D and IPIP tunnels).", 'Egress Gateway policies can now
          select multiple gateway nodes for a single policy, enabling HA/scale-out
          egress.', Bandwidth manager adds ingress rate limiting support., L2 pod
          announcement can announce from multiple network devices., Neighbor subsystem
          reworked with reconciliation between desired neighbor entries and kernel
          state to improve resilience., 'IPv6 tunneling datapath supports IPv6 underlay,
          including with IPsec transparent encryption; kube-proxy replacement also
          supports IPv6 underlay service translation.', Delegated IPAM can configure
          IPv6 routes when the delegated plugin supports IPv6; ordered IPv6 fragments
          are now processed for policy/routing; egress gateway CIDR matching supports
          IPv6 ranges., 'Hubble/hubble-cli improvements: policy names shown in flows,
          a new free-text policy log field is exposed in flows, and encapsulated traffic
          decoding improves observability.', ClusterMesh adds an option to restrict
          the "cluster" entity to the local cluster only; Grafana policy dashboards
          improved., Operational improvements include better kube-apiserver connection
          handling at scale and optional ConfigMap sync into the agent with drift
          metrics., 'Several CRDs promoted to stable: CiliumCIDRGroup, CiliumLoadBalancerIPPool,
          and all BGP CRDs; Gateway API support bumped to v1.3.0 with new CiliumGatewayClassConfig
          and improved reconciliation.', IPAM enhancements include AWS ENI prefix
          delegation on bare metal and multi-pool IPAM support in external KVStore
          mode and with IPsec/tunnel routing., 'BGP enhancements include route aggregation,
          overlapping selector matches in CiliumBGPAdvertisement, and new router-id
          generation modes.', 'Performance improvements include faster policy/service
          processing at scale, smaller arm64 images, optimized egress gateway matching,
          and batched CT map GC.']
      breaking_changes: ['Minimum supported Linux kernel for the 1.18 release series
          is now 5.10 (or equivalent, e.g., RHEL 8.6); clusters with older kernels
          must upgrade nodes before upgrading Cilium.', The local unix-socket Policy
          REST API is deprecated; prefer Kubernetes CRDs or filesystem-based policy
          mechanisms going forward., 'Some underused features are deprecated (Custom
          Calls, Recorder API, External Workloads); if you rely on them, plan migration
          before they are removed in a future release.', 'Cilium dependencies were
          updated (Kubernetes v1.33, Envoy v1.34, LLVM 19.1, CNI v1.1), which can
          surface compatibility constraints with older clusters or custom integrations.']
    chart_version: 1.18.0
    images: ['quay.io/cilium/cilium-envoy:v1.34.4-1753677767-266d5a01d1d55bd1d60148f991b98dac0390d363@sha256:231b5bd9682dfc648ae97f33dcdc5225c5a526194dda08124f5eded833bf02bf',
      'quay.io/cilium/cilium:v1.18.0@sha256:dfea023972d06ec183cfa3c9e7809716f85daaff042e573ef366e9ec6a0c0ab2',
      'quay.io/cilium/operator-generic:v1.18.0@sha256:398378b4507b6e9db22be2f4455d8f8e509b189470061b0f813f0fabaf944f51']
  - version: 1.17.8
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Helm value default change:** `kafka.apiKey` is now set to\
        \ `true` by default (noted in v1.17.4 release notes). If you previously relied\
        \ on the old default/explicitly set this to `false`, review Kafka/L7 policy\
        \ behavior and set it explicitly in your `values.yaml` to preserve intent.\n\
        - **Helm bugfix:** Fix for a **Hubble dynamic metrics config conflict** (v1.17.4\
        \ notes). If you have custom `hubble.metrics.dynamic` (or equivalent) configuration,\
        \ re-test after upgrade; the chart behavior is intended to be more consistent.\n\
        - **Packaging/templating:** v1.17.8 includes support for downstream packagers\
        \ to **extend `cilium-agent` `dnsPolicy`**. This is primarily relevant if\
        \ you vendor/patch the chart; most users won\u2019t change values for this."
      chart_updates: ['Cilium Agent liveness probe behavior changed: it no longer
          fails solely due to Kubernetes API server unreachability (helps avoid agent
          restarts during apiserver downtime).', 'Gateway API robustness: reconciler
          handles missing TLSRoute CRD more gracefully and fixes parentRef matching
          logic.', 'Envoy/xDS reliability: fixes cases where updated resources were
          not sent to Envoy; in v1.17.8, Envoy starts serving listeners only after
          clusters are ACKed (reduces race conditions on rollout).', 'Kernel compatibility:
          fix for pre-v5.7 kernels where LocalRedirectPolicy could trigger BPF verifier
          rejection.', 'NAT/masquerade robustness: improvements to NAT LRU fallback
          paths; addresses flakes and should reduce edge-case failures under pressure.',
        'Various datapath fixes: NodePort NAT46x64 clash avoidance, ipip MTU fix,
          device controller netfilter dependency fix, WireGuard overlay cleanup, IPSec
          key derivation hardening, and deadlock/panic fixes around missing IPv4 and
          ipset reconciliation.', 'Policy correctness: fixes for invalid CNP/CCNP
          status reporting and an important fix where L7 rules could override `enableDefaultDeny:
          false` and incorrectly drop traffic.']
      features: ['Adds new WireGuard observability points (`TRACE_FROM/TO_CRYPTO`)
          and BPF metrics for packets to/from WireGuard, improving troubleshooting/monitoring.',
        'GAMMA (Gateway API for Mesh Management and Administration) reconciler can
          now attach multiple HTTPRoutes to the same Service, expanding Gateway API
          routing flexibility.']
      breaking_changes: []
    chart_version: 1.17.8
    images: ['quay.io/cilium/cilium-envoy:v1.33.9-1757932127-3c04e8f2f1027d106b96f8ef4a0215e81dbaaece@sha256:06fbc4e55d926dd82ff2a0049919248dcc6be5354609b09012b01bc9c5b0ee28',
      'quay.io/cilium/cilium:v1.17.8@sha256:6d7ea72ed311eeca4c75a1f17617a3d596fb6038d30d00799090679f82a01636',
      'quay.io/cilium/operator-generic:v1.17.8@sha256:5468807b9c31997f3a1a14558ec7c20c5b962a2df6db633b7afbe2f45a15da1c']
  - version: 1.17.4
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **Helm values change:** `kafka.apiKey` is now set/updated to
        `true` in the chart (called out in v1.17.4 notes). Review any overrides you
        currently set for Kafka L7 policy/visibility to avoid unexpected behavior
        changes.

        - **Helm bugfix:** fix for **Hubble dynamic metrics** config conflict; if
        you use the `hubble-metrics-config` ConfigMap introduced in 1.17.0, upgrading
        to 1.17.4 should reduce config collisions.

        '
      chart_updates: [Hubble dynamic metrics Helm templating/config conflict fix landed
          (v1.17.4)., 'Kafka-related Helm default/value updated: `kafka.apiKey=true`
          (v1.17.4).']
      features: [(1.17.0) Pod egress QoS via annotations for traffic priority (Guaranteed/Burstable/BestEffort).,
        (1.17.0) Kubernetes Multi-Cluster Services (MCS) API support for global services
          in ClusterMesh., (1.17.0) L4 protocol-based service load balancing (differentiate
          TCP vs UDP on same port) plus per-service LB algorithm selection (maglev/random).,
        (1.17.0) IPAM enhancements (AWS tag-based static allocation; multi-pool improvements)
          and dynamic MTU detection without agent restart., '(1.17.0) Observability
          upgrades: new Hubble metrics ConfigMap workflow and new Prometheus metrics
          exposing enabled features.']
      breaking_changes: []
    chart_version: 1.17.4
    images: ['quay.io/cilium/cilium-envoy:v1.32.6-1746661844-0f602c28cb2aa57b29078195049fb257d5b5246c@sha256:a04218c6879007d60d96339a441c448565b6f86650358652da27582e0efbf182',
      'quay.io/cilium/cilium:v1.17.4@sha256:24a73fe795351cf3279ac8e84918633000b52a9654ff73a6b0d7223bcff4a67a',
      'quay.io/cilium/operator-generic:v1.17.4@sha256:a3906412f477b09904f46aac1bed28eb522bef7899ed7dd81c15f78b7aa1b9b5']
  - version: 1.17.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Quality of Service for egress: pod annotations can set egress priority
          (Guaranteed/Burstable/BestEffort) to influence traffic handling.', Multi-Cluster
          Service (MCS) API support for Cluster Mesh to manage global services across
          clusters., 'L4 protocol-aware load balancing: can distinguish TCP vs UDP
          (and similar) on the same port to route to different backends.', 'Per-Service
          load-balancing algorithm selection (e.g., Maglev vs random) on a per-service
          basis.', LoadBalancer source ranges can be treated as deny lists instead
          of only allow lists., 'Improved IPAM controls: support static allocation
          via AWS tags and improved multi-pool handling of single IP ranges.', 'Dynamic
          MTU detection: agent adapts to runtime MTU changes without restart.', 'Network
          policy performance improvements for complex policy combinations, reducing
          CPU cost.', CiliumEndpointSlices can prioritize critical namespaces using
          Kubernetes priorityNamespaces to speed endpoint propagation., Better NetworkPolicy
          validation feedback via Kubernetes (more/better validation)., CIDRGroups
          can be labeled and selected by label in network policies., 'ToServices policy
          enhancements: services with selectors can be targeted by ToServices rules.',
        FQDN/L7 filtering for hostNetwork via CiliumClusterwideNetworkPolicy for node-originated
          DNS traffic., HTTP L7 policies can apply to port ranges (multiple ports
          redirected to Envoy)., Gateway API support updated to v1.2.1 including HTTP
          retries and mirror fractions., 'Static gateway addressing: allow statically
          specifying gateway addresses.', 'Improved Envoy TLS handling via SDS, speeding
          policy calculation and improving secrets access for TLS visibility.', Dynamic
          Hubble metrics configuration via a hubble-metrics-config ConfigMap., 'New
          Prometheus metrics exposing which features are enabled in cilium-agent and
          cilium-operator; plus many new metrics across BGP, connections, policy,
          and component health.', cilium-health tuned for more reliable high-scale
          connectivity checks., Rate-limited monitor events to balance eBPF event
          volume vs CPU usage., Double-Write Identity mode to ease migration between
          CRD and KVStore identity backends.]
      breaking_changes: [No explicit breaking changes were included in the provided
          release-note excerpts; review the full v1.17.0 CHANGELOG.md for any required
          config/behavior changes before upgrading.]
    chart_version: 1.17.0
    images: ['quay.io/cilium/cilium-envoy:v1.31.5-1737535524-fe8efeb16a7d233bffd05af9ea53599340d3f18e@sha256:57a3aa6355a3223da360395e3a109802867ff635cb852aa0afe03ec7bf04e545',
      'quay.io/cilium/cilium:v1.17.0@sha256:51f21bdd003c3975b5aaaf41bd21aee23cc08f44efaa27effc91c621bc9d8b1d',
      'quay.io/cilium/operator-generic:v1.17.0@sha256:1ce5a5a287166fc70b6a5ced3990aaa442496242d1d4930b5a3125e44cccdca8']
  - version: 1.16.15
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- No explicit Helm chart value changes are called out in the\
        \ provided notes for **v1.16.15**.\n- From **v1.16.10**, there is one Helm-related\
        \ change to be aware of if you carry values forward:\n  - `kafka.apiKey` Helm\
        \ value was updated to default to `true` (or the chart/value expects `true`).\
        \ If you set this explicitly today, verify it still matches your intended\
        \ Kafka L7 policy behavior after the upgrade.\n\n> Note: This summary only\
        \ reflects what was included in the text you provided; it does not include\
        \ any additional Helm chart changelog entries."
      chart_updates: [v1.16.15 is mostly CI/build/release tooling and dependency churn;
          no chart-facing feature changes were highlighted in the provided notes.,
        'v1.16.15 includes an Envoy behavior fix: listeners are served only after
          clusters have been ACKed, which can affect L7/LB readiness timing in practice.',
        v1.16.15 fixes a kernel verifier rejection on pre-5.7 kernels when LocalRedirectPolicy
          is enabled (stability fix for older kernels).]
      features: ['Envoy now delays serving listeners until clusters have been ACKed,
          improving correctness during (re)configuration and potentially reducing
          transient L7 failures during rollout.']
      breaking_changes: []
    chart_version: 1.16.15
    images: ['quay.io/cilium/cilium-envoy:v1.33.9-1757932127-3c04e8f2f1027d106b96f8ef4a0215e81dbaaece@sha256:06fbc4e55d926dd82ff2a0049919248dcc6be5354609b09012b01bc9c5b0ee28',
      'quay.io/cilium/cilium:v1.16.15@sha256:c0fa87d70a7ba624fbe581d40a7b7e9e8773a6efd4bb17d0bd14ff854039ec75',
      'quay.io/cilium/operator-generic:v1.16.15@sha256:fea37022f858272c27cefe6b4959d45e2ca03d957decbfa210ce35931f346ecd']
  - version: 1.16.10
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **Kafka policy Helm value change:** `kafka.apiKey` is updated
        to default to `true` in the chart. If you explicitly set this value today,
        re-check your `values.yaml` to avoid unexpected Kafka L7 policy behavior changes
        after upgrade.

        '
      chart_updates: ['Daemon status reporting changed: `cilium status` is now independent
          of Kubernetes status (agent/daemon-side behavior change).', "Hubble/Helm\
          \ related robustness: Hubble peer-service endpoint uses an absolute FQDN\
          \ (already present by 1.16.5, but relevant if you\u2019re comparing older\
          \ installs)."]
      features: ['Operational improvement: `cilium status` no longer depends on Kubernetes
          status, which can make troubleshooting clearer when the apiserver is degraded.',
        'Improved policy feedback: invalid CiliumNetworkPolicy / CiliumClusterwideNetworkPolicy
          rules are now correctly reported as invalid.']
      breaking_changes: []
    chart_version: 1.16.10
    images: ['quay.io/cilium/cilium-envoy:v1.32.6-1746661844-0f602c28cb2aa57b29078195049fb257d5b5246c@sha256:a04218c6879007d60d96339a441c448565b6f86650358652da27582e0efbf182',
      'quay.io/cilium/cilium:v1.16.10@sha256:fc4ccc494c4a381439162fd3684c07ba9c26d3c2670a2b2e1623acee99097461',
      'quay.io/cilium/operator-generic:v1.16.10@sha256:05e5f5e676aa51ae5e3bf6be3594ecf52958f46f07f9f55368a7a952012a13c1']
  - version: 1.16.5
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '### Helm values / chart configuration changes to watch

        - **Hubble TLS secrets via Helm values are deprecated (1.16.1).** If you currently
        provide Hubble TLS cert/key/CA material directly in `values.yaml`, plan to
        migrate to managing TLS secrets separately (e.g., pre-created Kubernetes Secrets)
        and reference them instead. Review your current `hubble.tls.*`-related values
        and update to the recommended approach.

        - **New Helm knobs for NAT map stats (1.16.1).** Chart adds configuration
        for `nat-map-stats-interval` and `nat-map-stats-entries`. No action unless
        you want to tune/enable these.

        - **SPIRE imagePullSecrets support (1.16.1).** If you deploy SPIRE components
        via the chart and pull from private registries, you can now set imagePullSecrets
        for spire agent/server pods.

        - **Hubble peer-service endpoint now uses an absolute FQDN (1.16.5).** This
        is a chart behavior change to prevent wrong DNS resolution when resolving
        outside cluster domains. Typically no values change needed, but if you override
        peer-service names/domains, validate the rendered endpoint.

        - **CronJob appArmorProfile template condition fix (1.16.1).** No values change
        required, but if you use that CronJob + AppArmor, confirm manifests render
        as expected.'
      chart_updates: ['Deprecation: Providing Hubble TLS secrets directly in Helm
          values is deprecated; update your installation approach accordingly.', 'Chart/templating:
          Added Gateway API required labels/annotations and fixed internal listener
          reference qualification (namespace + CEC name).', 'Chart options: Added
          NAT map stats interval/entries configuration fields.', 'Chart options: Added
          imagePullSecrets support for SPIRE agent/server pods.', 'Chart behavior:
          Hubble peer-service endpoint is rendered as an absolute FQDN to avoid incorrect
          DNS resolution.', 'Templating: Fixed CronJob AppArmor profile condition
          rendering.']
      features: ['Gateway API support gets additional required labels/annotations
          and better handling of internal listener references, improving correctness
          in multi-namespace/CEC scenarios.', 'Optional new tuning knobs were added
          for NAT map statistics reporting (interval/entries), useful for observability/performance
          tuning.', 'SPIRE components can now be configured with imagePullSecrets,
          simplifying private registry use cases.']
      breaking_changes: ['Hubble TLS secrets provided directly via Helm values are
          now deprecated; while not an immediate hard break, you should migrate before
          it becomes unsupported in a future release.', 'Hubble no longer builds 32-bit
          binaries (1.16.5). If you run Hubble components on 32-bit architectures,
          this is effectively breaking.']
    chart_version: 1.16.5
    images: ['quay.io/cilium/cilium-envoy:v1.30.8-1733837904-eaae5aca0fb988583e5617170a65ac5aa51c0aa8@sha256:709c08ade3d17d52da4ca2af33f431360ec26268d288d9a6cd1d98acc9a1dced',
      'quay.io/cilium/cilium:v1.16.5@sha256:758ca0793f5995bb938a2fa219dcce63dc0b3fa7fc4ce5cc851125281fb7361d',
      'quay.io/cilium/operator-generic:v1.16.5@sha256:f7884848483bbcd7b1e0ccfd34ba4546f258b460cb4b7e2f06a1bcc96ef88039']
  - version: 1.16.1
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart behavior changes to account for\n- **Hubble\
        \ TLS secrets via Helm values are deprecated** (1.16.1).\n  - If you currently\
        \ pass TLS material for Hubble via chart values (for example inline certs/keys/CA\
        \ or value-driven Secret generation), plan to migrate to **pre-created Kubernetes\
        \ Secrets** and reference them, or use the chart\u2019s recommended TLS management\
        \ approach.\n  - Action: review your `values.yaml` for any Hubble TLS secret/cert/key\
        \ fields and update before/with the upgrade to avoid relying on deprecated\
        \ configuration.\n\n- **New Helm config knobs for NAT map stats** (1.16.1).\n\
        \  - Adds values to configure `nat-map-stats-interval` and `nat-map-stats-entries`\
        \ (names as per PR description). If you need NAT map pressure/stats tuning,\
        \ you can now set these via Helm.\n\n- **Gateway API chart templates updated\
        \ to add required labels/annotations** (1.16.1).\n  - If you deploy Gateway\
        \ API components, expect metadata changes (labels/annotations). Usually safe,\
        \ but review if you have policies/automation that match on labels/annotations.\n\
        \n- **CronJob template fix for appArmorProfile condition** (1.16.1).\n  -\
        \ If you enable the CronJob in the chart and use AppArmor profiles, this corrects\
        \ rendering behavior; no action unless you had workarounds.\n\n- **SPIRE imagePullSecrets\
        \ configurable for agent/server pods** (1.16.1).\n  - If you run SPIRE integration\
        \ and pull from private registries, you can now set imagePullSecrets for those\
        \ pods via Helm values.\n"
      chart_updates: ['Gateway API manifests: add required labels and annotations
          (metadata changes).', 'Helm templates: fix appArmorProfile conditional in
          CronJob template.', 'Helm: expose NAT map stats interval/entries as configurable
          values.', 'Helm: add support to configure imagePullSecrets for SPIRE agent/server
          pods.', 'Helm/docs: improve Hubble TLS configuration guidance; deprecate
          value-driven TLS secret provisioning.']
      features: ['Security fixes: 1.16.1 addresses two published advisories (GHSA-vwf8-q6fw-4wcm,
          GHSA-qcm3-7879-xcww).', 'Operational tuning: Helm can now configure NAT
          map stats interval/entries for better observability/tuning of NAT map behavior.',
        'SPIRE integration: chart now supports setting imagePullSecrets for SPIRE
          agent/server pods (useful for private registries).', 'Gateway API: required
          labels/annotations added and route sorting now considers HTTP method conditions
          for more correct routing behavior.']
      breaking_changes: ['Deprecation: Providing Hubble TLS secrets via Helm values
          is deprecated in 1.16.1; future chart versions may remove this path, so
          migrate to Kubernetes Secrets/references now.']
    chart_version: 1.16.1
    images: ['quay.io/cilium/cilium-envoy:v1.29.7-39a2a56bbd5b3a591f69dbca51d3e30ef97e0e51@sha256:bd5ff8c66716080028f414ec1cb4f7dc66f40d2fb5a009fff187f4a9b90b566b',
      'quay.io/cilium/cilium:v1.16.1@sha256:0b4a3ab41a4760d86b7fc945b8783747ba27f29dac30dd434d94f2c9e3679f39',
      'quay.io/cilium/operator-generic:v1.16.1@sha256:3bc7e7a43bc4a4d8989cb7936c5d96675dd2d02c306adf925ce0a7c35aa27dc4']
  - version: 1.16.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **(From 1.15.17)** Helm value change noted: `kafka.apiKey`\
        \ was updated/expected to be `true` (the release note says \u201CUpdate kafka\
        \ apiKey helm chart value to true\u201D). Verify your `values.yaml` doesn\u2019\
        t override this back to `false`.\n\n- **(For 1.16.0)** The provided application\
        \ release notes don\u2019t include Helm-chart-specific value changes. Before\
        \ upgrading, review the **Cilium Helm chart changelog** for 1.16.0 and compare\
        \ your rendered manifests (`helm template`) against current to catch any renamed/removed\
        \ values (especially around Envoy, Gateway API, and ClusterMesh/KVStoreMesh\
        \ defaults)."
      chart_updates: ['Cilium 1.16.0 introduces/expands features across networking,
          BGP, Gateway API/Ingress, policy, operations, and Hubble observability.',
        'No chart-structure changes are explicitly called out in the supplied notes,
          but behavior may change due to new defaults (notably Envoy deployment model
          for new installs, and ClusterMesh KVStoreMesh default).']
      features: [Cilium NetKit to improve container-network throughput/latency closer
          to host networking performance., 'BGPv2 with a new API, plus BGP advertisement
          support for ExternalIP and ClusterIP services.', Kubernetes 1.30 Service
          Traffic Distribution can be configured via Service spec (not annotations).,
        'Local Redirect Policy is promoted to Stable for redirecting service traffic
          to local backends (e.g., node-local DNS).', Multicast datapath support for
          defining multicast groups in Cilium., Per-pod fixed MAC address support.,
        'Gateway API enhancements: GAMMA support (east-west), Gateway API 1.1 support,
          and ExternalTrafficPolicy support for Ingress/Gateway API.', Envoy proxy
          can run as a dedicated DaemonSet (separate lifecycle); enabled by default
          for new installs., CiliumEnvoyConfig now supports nodeSelector to target
          specific nodes., 'Network policy improvements: port ranges, validation status
          in `kubectl describe`, per-policy control of default-deny behavior, CIDRGroups
          in egress/deny, loading default policies from filesystem, and node-based
          selectors (ToNodes/FromNodes).', 'Operational improvements: new ELF loader
          logic reduces median memory usage; improved DNS-based policy performance;
          KVStoreMesh becomes the default ClusterMesh deployment option.', 'Hubble/observability
          improvements: CEL flow filters, improved HTTP metrics, improved BPF map
          pressure metrics, more egress-path observability metrics, k8s event generation
          on packet drops, and filtering flows by node labels.']
      breaking_changes: ['The supplied 1.16.0 release-notes excerpt does not explicitly
          list breaking changes. Treat the following as **potential behavior changes
          to validate** during upgrade testing: KVStoreMesh becoming the default for
          ClusterMesh deployments, and the move to a dedicated Envoy DaemonSet being
          default for new installs (may affect how you manage/upgrade Envoy if you
          adopt it). Review the full v1.16.0 CHANGELOG.md for any explicit breaking
          changes that apply to your deployment.']
    chart_version: 1.16.0
    images: ['quay.io/cilium/cilium-envoy:v1.29.7-39a2a56bbd5b3a591f69dbca51d3e30ef97e0e51@sha256:bd5ff8c66716080028f414ec1cb4f7dc66f40d2fb5a009fff187f4a9b90b566b',
      'quay.io/cilium/cilium:v1.16.0@sha256:46ffa4ef3cf6d8885dcc4af5963b0683f7d59daa90d49ed9fb68d3b1627fe058',
      'quay.io/cilium/operator-generic:v1.16.0@sha256:d6621c11c4e4943bf2998af7febe05be5ed6fdcf812b27ad4388f47022190316']
  - version: 1.15.17
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Kafka L7 / API key handling default change (1.15.17):** the\
        \ Helm chart value for Kafka `apiKey` is updated to `true`.\n  - If you explicitly\
        \ set this value today, keep your current behavior by pinning it in `values.yaml`.\n\
        \  - If you did **not** set it, expect behavior to follow the new default\
        \ in 1.15.17; validate Kafka L7 policies/traffic in staging."
      chart_updates: ['Helm chart defaults updated for Kafka (`apiKey: true`) in 1.15.17
          (may affect Kafka L7 policy behavior).']
      features: [No major new user-facing features called out in the provided notes;
          this patch set is primarily bugfixes and dependency/image updates.]
      breaking_changes: [Potential behavior change for Kafka L7 policy users due to
          Helm default `apiKey` being set to `true` in 1.15.17 if you relied on the
          previous default.]
    chart_version: 1.15.17
    images: ['quay.io/cilium/cilium:v1.15.17@sha256:8824313a6f17d934b4e63902fee71e6ca36be6f69d68ae174df28f1b0705e587',
      'quay.io/cilium/operator-generic:v1.15.17@sha256:a0f5b5dc8cecd4e5ead7d3bddb3756e4b34beba8e7aa089e7e2fb761725defe1']
  - version: 1.15.12
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- No explicit Helm values changes are called out in the provided
        notes for **1.15.12**.

        - From the **1.15.8** notes (already on your starting version): the chart
        added **Helm validation to prevent using removed/deprecated values** and cleaned
        up deprecated attributes/Kubernetes version checks. Practically, when you
        run `helm upgrade`, expect the chart to **fail fast** if your values file
        still contains removed/deprecated keys.


        **Action for upgrade:** run a dry-run with validation and review failures:


        ```bash

        helm upgrade --install cilium cilium/cilium -n kube-system -f values.yaml
        --version 1.15.12 --dry-run

        ```


        If it errors, remove/rename the flagged deprecated values.'
      chart_updates: [No chart-template changes were explicitly listed for 1.15.12
          in the provided excerpt (mostly CI/docs/dependency bumps)., '1.15.12 updates
          image digests and bumps bundled dependencies (notably CNI plugins to v1.6.0,
          Envoy image tags, Go patch version), which can affect runtime behavior only
          insofar as bugfixes/security patches apply.']
      features: [cilium-health-ep controller made more robust against successive failures
          (improves health endpoint/controller resilience)., Gateway API checks fixed
          for namespace handling (improves correctness for Gateway API users).]
      breaking_changes: ['No breaking changes were mentioned in the provided release
          notes for the target patch release (1.15.12). Patch upgrades in the same
          minor series are expected to be non-breaking, but Helm schema validation
          may block upgrades if you still use removed/deprecated values.']
    chart_version: 1.15.12
    images: ['quay.io/cilium/cilium:v1.15.12@sha256:d1793b67d976e1bc0a4ab01b34c94adfcd35a8be7612d04c6d618bf25f50f0d1',
      'quay.io/cilium/operator-generic:v1.15.12@sha256:e48d863367bfd39843917400aa7454ca6a4af74f995cf29a2edb81d7d13c7277']
  - version: 1.15.8
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Helm chart now validates removed/deprecated values**: v1.15.8\
        \ adds helm-side validation to prevent using deprecated values that have been\
        \ removed. Expect `helm upgrade` to fail fast if your `values.yaml` still\
        \ contains removed keys; clean up old values before upgrading. (PR #34213)\n\
        - **Helm chart cleanup of deprecated attributes / old Kubernetes version checks**:\
        \ v1.15.8 removes legacy k8s version checks and deprecated chart attributes.\
        \ If you relied on older/deprecated chart knobs, re-check your values against\
        \ the current chart schema/docs. (PR #34157)\n- **Chart/templating robustness**\
        \ (seen in the notes you pasted from 1.15.5): a fix for \u201Chelm chart incompatible\
        \ types for comparison\u201D indicates the chart became stricter about value\
        \ types; keep booleans/ints/strings consistent with chart expectations to\
        \ avoid template errors.\n"
      chart_updates: ['Helm: add validation to block removed/deprecated values (upgrade
          may now hard-fail on stale values).', 'Helm: cleanup deprecated attributes
          and old Kubernetes version checks.', 'Helm: remove duplicate Envoy pod metrics
          output.', 'Docs/values: allow setting DNS proxy socket linger timeout to
          zero via Helm (enables explicitly disabling linger).']
      features: ['Hubble Relay is more resilient to transient errors, improving stability
          in flaky network/control-plane conditions.', 'Gateway API routing improvements:
          routes can be sorted with HTTP method conditions and react to ReferenceGrant
          changes more reliably.']
      breaking_changes: [Helm upgrades may now fail if you still use values that were
          previously deprecated and are now removed; you must remove/replace them
          before upgrading.]
    chart_version: 1.15.8
    images: ['quay.io/cilium/cilium:v1.15.8@sha256:3b5b0477f696502c449eaddff30019a7d399f077b7814bcafabc636829d194c7',
      'quay.io/cilium/operator-generic:v1.15.8@sha256:e77ae6fc8a978f98363cf74d3c883dfaa6454c6e23ec417a60952f29408e2f18']
  - version: 1.15.5
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm/values changes to account for (1.15.0 \u2192 1.15.5)\n\
        \nFrom the provided notes, the following items may require Helm values updates\
        \ or at least verification:\n\n- **Removed Helm options (breaking for existing\
        \ values files):**\n  - `enableK8sEventHandover` and `enableCnpStatusUpdates`\
        \ were removed (and their underlying flags were removed too). If you still\
        \ set either value, Helm rendering/upgrade will fail; delete them.\n\n- **kubeProxyReplacement\
        \ value semantics:**\n  - Helm chart changed to **use `kubeProxyReplacement:\
        \ true` instead of `kubeProxyReplacement: strict`**. If your values file still\
        \ uses `strict`, update it.\n\n- **Deprecated tunnel option removed:**\n \
        \ - A deprecated tunneling option and its Helm value were removed. If your\
        \ values still set a legacy `tunnel`-related flag/value (older style), remove/replace\
        \ per current chart docs.\n\n- **API rate limiting via Helm:**\n  - There\
        \ is now a Helm value to pass `api-rate-limit` (if you used extraArgs before,\
        \ consider migrating).\n\n- **SPIRE Helm values layout changed:**\n  - SPIRE\
        \ image/value configuration was changed to match other images in the chart.\
        \ If you customize SPIRE image/registry/tag, compare your values against new\
        \ schema.\n  - SPIRE: support for using an **existing namespace** was added.\n\
        \n- **Observability / ServiceMonitor knobs:**\n  - Optional configurable `jobLabel`\
        \ was added to cilium-agent/operator/hubble ServiceMonitors.\n  - Envoy running\
        \ inside cilium-agent can be scraped via ServiceMonitor (if enabled).\n\n\
        - **Preflight resources:**\n  - Chart now allows adding annotations to preflight\
        \ resources.\n\n- **Prometheus metrics enablement default changes:**\n  -\
        \ Cilium-operator and clustermesh/kvstore metrics are enabled by default in\
        \ Helm; check whether this changes your scrape volume/cost.\n\n- **1.15.5\
        \ specific Helm-related fix:**\n  - `Agent: add kubeconfigPath to initContainers`\
        \ \u2014 if you use custom initContainers or nonstandard kubeconfig mounting,\
        \ verify it continues to work.\n  - `Fix helm chart incompatible types for\
        \ comparison` \u2014 indicates some previously tolerated value type mismatches\
        \ may have caused issues; ensure your values types match the chart expectations\
        \ (strings vs bools vs ints).\n"
      chart_updates: ['Chart now removes deprecated clustermesh CA configuration from
          the Helm chart (if you relied on the old CA options, migrate to the supported
          clustermesh CA/config approach).', "clustermesh-apiserver and kvstoremesh\
          \ images were merged into a single image in 1.15.0; verify your deployments/overrides\
          \ don\u2019t assume separate images.", 'Default metrics enablement changed:
          operator and clustermesh/kvstore metrics are enabled by default in Helm
          (may affect Prometheus scraping and RBAC).', Chart includes extraVolumeMounts
          support for the cilium-config init container and a securityContext for SPIRE
          pods (verify if you override these templates)., 'Ingress/Gateway features
          and related Helm wiring expanded (e.g., trusted LB hops, proxy protocol
          support, SSL passthrough annotation support).']
      features: [Dynamic flowlog exporters can now be configured via a YAML file (ConfigMap)
          without restarting the agent., 'Gateway API support was extended up to v1.0,
          including GRPCRoute support and additional Gateway API capabilities.', ClusterMesh
          can be extended up to 511 clusters via `--max-connected-clusters=511` (with
          identity-space tradeoffs)., 'BGP control plane enhancements: new routes
          API/CLI commands and support for BGP MD5/passwords and advertised path attributes.',
        'Improved Hubble functionality (filters, redaction options, new dashboards/metrics)
          and additional observability metrics across components.']
      breaking_changes: [Deprecated Helm values `enableK8sEventHandover` and `enableCnpStatusUpdates`
          were removed; upgrades will fail if they remain in your values., '`kubeProxyReplacement`
          Helm value usage changed (no longer `strict`); adjust values to the current
          expected type/value.', A deprecated tunnel option (and its Helm value) was
          removed; remove/replace any legacy tunnel-related values before upgrading.]
    chart_version: 1.15.5
    images: ['quay.io/cilium/cilium:v1.15.5@sha256:4ce1666a73815101ec9a4d360af6c5b7f1193ab00d89b7124f8505dee147ca40',
      'quay.io/cilium/operator-generic:v1.15.5@sha256:f5d3d19754074ca052be6aac5d1ffb1de1eb5f2d947222b5f10f6d97ad4383e8']
  - version: 1.15.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm chart / values changes to account for (1.14 \u2192 1.15)\n\
        \n> Notes below are based on the release notes you provided; they\u2019re\
        \ not a complete Helm chart changelog.\n\n### Removed / incompatible values\
        \ (breaking)\n- **Removed deprecated Helm values**: `enableK8sEventHandover`\
        \ and `enableCnpStatusUpdates` were removed. If you still set them, Helm upgrade\
        \ will fail. Their corresponding flags were also removed:\n  - Agent flag\
        \ `enable-k8s-event-handover`\n  - Operator flag `cnp-status-update-interval`\n\
        - **Deprecated `--tunnel` option removed** (and corresponding Helm value).\
        \ Use `routingMode` / `tunnelProtocol` style configuration instead.\n\n###\
        \ Renames / behavioral changes in values\n- **`kubeProxyReplacement` value\
        \ semantics**: Helm chart now uses `strict=true` style (string/boolean) consistently;\
        \ ensure you\u2019re not using old `partial|strict|disabled` forms.\n- **SPIRE\
        \ Helm values schema adjusted**: values structure for SPIRE images/config\
        \ was changed \u201Cto match other images\u201D (expect possible key/path\
        \ changes if you customized SPIRE images).\n- **ClusterMesh CA config cleanup**:\
        \ deprecated clustermesh CA config removed from the Helm chart; use the global\
        \ CA configuration.\n\n### New / notable Helm options\n- **API rate limiting\
        \ via Helm**: option to pass `api-rate-limit` via Helm values.\n- **Hubble\
        \ exporter enhancements**: new values to configure filters / field masks.\n\
        - **ServiceMonitors**: optional configurable `jobLabel` for cilium-agent,\
        \ cilium-operator, and Hubble ServiceMonitors.\n- **Extra volume mounts for\
        \ config init container**: `extraVolumeMounts` support for the cilium-config\
        \ init container.\n- **Preflight resources**: ability to set annotations.\n\
        - **Metrics defaults**:\n  - Cilium-operator and clustermesh kvstore metrics\
        \ enabled by default in Helm.\n\n### Image/component packaging changes that\
        \ affect Helm\n- **clustermesh-apiserver + kvstoremesh image merge**: the\
        \ components were merged into a single image; verify your Helm values for\
        \ image overrides, deployments, and metrics toggles if you run clustermesh/kvstoremesh.\n"
      chart_updates: [Deprecated Helm values `enableK8sEventHandover` and `enableCnpStatusUpdates`
          removed (upgrade will fail if still set)., Deprecated tunnel Helm value
          removed; must use routing-mode/tunnel-protocol style config., Helm chart
          updated to use `strict=true` semantics for kubeProxyReplacement-related
          configuration (avoid old enum-like settings)., SPIRE Helm values schema
          changed to align with other image configuration patterns (verify any custom
          SPIRE image overrides/securityContext)., Deprecated clustermesh CA configuration
          removed from chart; use global CA config., Operator + clustermesh kvstore
          metrics enabled by default via Helm; confirm your Prometheus scraping expectations.,
        clustermesh-apiserver and kvstoremesh consolidated into one image; validate
          your clustermesh-related Helm values and upgrades.]
      features: [Dynamic FlowLog exporters can be updated via a ConfigMap-backed YAML
          file without restarting cilium-agent., 'Gateway API v1.0 support, including
          GRPCRoute, plus multiple Gateway API controller improvements and startup
          CRD checks.', ClusterMesh scalability increased up to 511 clusters via `--max-connected-clusters=511`
          (with identity tradeoff)., 'BGP improvements including new `bgp/routes`
          API endpoint, `cilium bgp routes` CLI, passwords/MD5 secret handling improvements,
          and route policy tooling.', 'Observability enhancements: new Hubble dashboards,
          more Hubble filtering (HTTP URLs/headers), and improved relay health/readiness
          behavior.', Egress Gateway changed to BPF-based interface selection; `--install-egress-gateway-routes`
          is no longer needed., 'Modularization and module health reporting improvements
          in `cilium status`, plus more Prometheus metrics across components.']
      breaking_changes: ['If you set Helm values `enableK8sEventHandover` or `enableCnpStatusUpdates`,
          the upgrade will break because these options and their corresponding agent/operator
          flags were removed.', 'If you relied on the deprecated `tunnel` Helm/flag
          configuration, it is removed; you must migrate to routing-mode/tunnel-protocol
          configuration.', Egress Gateway no longer needs (and effectively deprecates)
          the `--install-egress-gateway-routes` behavior; operational expectations
          for route setup change., 'ClusterMesh 511-cluster mode is only for new clusters
          and must be consistent across all clusters; enabling it reduces available
          cluster-local identities to 32,768.', clustermesh-apiserver/kvstoremesh
          packaging changed (single image); custom image overrides and deployment
          assumptions may need adjustment.]
    chart_version: 1.15.0
    images: ['quay.io/cilium/cilium:v1.15.0@sha256:9cfd6a0a3a964780e73a11159f93cc363e616f7d9783608f62af6cfdf3759619',
      'quay.io/cilium/operator-generic:v1.15.0@sha256:e26ecd316e742e4c8aa1e302ba8b577c2d37d114583d6c4cdd2b638493546a79']
  - version: 1.14.18
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **New/adjusted Helm value:** `dnsProxy.socketLingerTimeout`\
        \ (or similarly named DNS proxy socket linger setting) can now be set to **`0`**\
        \ (previously disallowed). This aligns with the 1.14.14 note: \u201CAllow\
        \ socket linger timeout to be set to zero\u201D. If you had to use a workaround\
        \ (e.g., omit the value or use a small positive number), you can now explicitly\
        \ set `0`.\n\nNo other Helm-values changes are called out in the notes you\
        \ provided for 1.14.14 \u2192 1.14.18."
      chart_updates: [No functional Helm chart template changes were called out in
          the excerpts provided (most Helm-related items were CI/linting oriented).,
        Image digests/tags advance to `v1.14.18` for all Cilium components; ensure
          any private registry mirroring or allowlists are updated accordingly.]
      features: ['No notable new user-facing features are highlighted in the provided
          patch release notes; the focus is on bugfixes, dependency bumps, and minor
          operational robustness improvements.', 'XDP: `cilium_calls_xdp` map is now
          per-endpoint (internal change that may improve correctness/isolation for
          some XDP datapath scenarios).']
      breaking_changes: ["None called out in the provided release note excerpts for\
          \ these patch versions (1.14.14 \u2192 1.14.18)."]
    chart_version: 1.14.18
    images: ['quay.io/cilium/cilium:v1.14.18@sha256:a09bd4ee7345ccdb42679985bf3e5a696ad8416e31a70a3609129bc745804123',
      'quay.io/cilium/operator-generic:v1.14.18@sha256:f41a9f3d899e14ba34a9696e7327147cd9811fc563c255668d59658ad90aa69e']
  - version: 1.14.14
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **New Helm value:** `dnsproxy.socketLingerTimeout` (name from
        PR context) can now be set to `0` to disable/clear the linger timeout for
        upstream DNS proxy sockets. This is relevant if you previously tried to set
        it to zero and Helm/schema/defaults prevented it.


        _No other Helm values changes were mentioned in the provided notes for 1.14.14._'
      chart_updates: ['Helm chart: allow configuring DNS proxy upstream socket linger
          timeout to `0` (enables fully disabling the linger behavior via values).']
      features: ["Security fix included for advisory GHSA-q7w8-72mr-vpgw (upgrade\
          \ recommended even if you don\u2019t change config).", 'Improved resilience
          in high node-churn clusters: agent can recover from stale nodeID mappings
          that could lead to dropped IPsec traffic.', 'More accurate observability:
          report correct drop reason when packets are dropped by `bpf_lxc`.']
      breaking_changes: []
    chart_version: 1.14.14
    images: ['quay.io/cilium/cilium:v1.14.14@sha256:43d664501afbf35496e494dae0c5a7f8680a51ed9084997bea9c64bf4451a637',
      'quay.io/cilium/operator-generic:v1.14.14@sha256:0f2c8178bd20189fc9aeaa71224e6becdf71b42642209610b57390f7b798aae2']
  - version: 1.14.11
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Reduces BPF conntrack/NAT map pressure by skipping overlay traffic
          in BPF SNAT processing, which can help stability under high connection churn
          and in overlay/tunnel-heavy clusters.', 'Improves DNS proxy behavior, including
          reserving ports that conflict with the transparent DNS proxy and fixing
          timeouts/memory leak scenarios.', 'Envoy/L7 improvements: upstream connections
          can be made unique per downstream when preserving original pod source IP,
          plus additional Envoy configuration knobs (idle timeout, trusted XFF hops).',
        Operational robustness fixes for cloud IPAM modes (ENI/Azure/Alibaba) including
          correct route MTU selection and netlink retries during ENI device setup.,
        'Operator/metrics and general reliability improvements (e.g., operator error/warn
          metrics, reduced noisy logs, safer taint handling in chained CNI mode).']
      breaking_changes: []
    chart_version: 1.14.11
    images: ['quay.io/cilium/cilium:v1.14.11@sha256:2b2118042dc6efe88dbc40c78909b6afd72b369896782ce38d132435724ee269',
      'quay.io/cilium/operator-generic:v1.14.11@sha256:df76f71a06f1c681848bfa86fdd99243af593d33034c9e2057c6af969bc25109']
  - version: 1.14.6
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Helm chart bugfix:** Fixes `cilium-envoy` `ServiceMonitor`\
        \ template issues/annotations (relevant if you scrape Envoy metrics via Prometheus\
        \ Operator).\n- **Helm behavior change (guardrail):** Chart now **enforces\
        \ routing mode** when `gke.enabled=true` or `aksbyocni.enabled=true`. If you\
        \ set either of these, double-check your `routingMode`/kube-proxy replacement\
        \ related settings to ensure they\u2019re valid/expected.\n- **Values parsing\
        \ robustness:** Improved parsing of string-slice flags (comma preferred, space\
        \ allowed). This notably fixes parsing for `prometheus.metrics` lists; review\
        \ any custom `prometheus.metrics` formatting.\n- **SPIRE agent scheduling:**\
        \ Adds a **default toleration** for SPIRE agent on control-plane nodes (only\
        \ relevant if you deploy SPIRE/SPIFFE integration)."
      chart_updates: [Envoy `ServiceMonitor` template typo + annotation fix (Prometheus
          Operator users)., Chart validation/logic tightened for managed Kubernetes
          toggles (GKE / AKS BYOCNI) to prevent invalid routing-mode combos., 'Improved
          Helm/flag parsing for list-like metrics settings (e.g., `prometheus.metrics`).',
        Default toleration added for SPIRE agent to run on control-plane nodes.]
      features: ['Adds a `proxy_type` label to L7 proxy metrics, improving visibility
          and filtering of L7 metrics.', Cilium DNS proxy can operate in a transparent
          mode (`--dnsproxy-enable-transparent-mode`) so queries can use the original
          pod IP as the source toward upstream DNS servers., 'Adds BGPv1 routes API
          endpoint plus `cilium bgp routes` CLI command, and integrates it into `bugtool`
          for easier troubleshooting.']
      breaking_changes: []
    chart_version: 1.14.6
    images: ['quay.io/cilium/cilium:v1.14.6@sha256:37a49f1abb333279a9b802ee8a21c61cde9dd9138b5ac55f77bdfca733ba852a',
      'quay.io/cilium/operator-generic:v1.14.6@sha256:2f0bf8fb8362c7379f3bf95036b90ad5b67378ed05cd8eb0410c1afc13423848']
  - version: 1.14.2
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '## Helm / values changes to review

        The app release notes include a few Helm-relevant behavior and value changes
        (some are from 1.14.0; 1.14.2 itself has only a small Helm fix):


        ### Values/behavior changes introduced in 1.14.0 (affecting upgrades from
        1.14.0)

        - **`authentication.mutual.spire.install.enabled` default changed to `true`.**
        If you were not using SPIRE/mTLS, explicitly set this to `false` to avoid
        installing extra components.

        - **CNI config file management changed.** Cilium now manages the CNI config
        file; setting **`cni.exclusive=false` disables overwriting** (useful for chaining
        other CNIs such as Istio).

        - **CNI chaining supported via `cni.chainingTarget`.** If you previously used
        custom chaining approaches, confirm your intended chaining target.

        - **Helm chart can configure `kvstoremesh`.** If you use clustermesh at scale,
        review/enable the new `kvstoremesh` settings.

        - **Helm chart changes around clustermesh CA/TLS configuration.** Notes mention
        deprecating clustermesh CA config in favor of global CA config and simplifying
        TLS configuration; review your `clustermesh.*` / global CA values.

        - **`enableEndpointCRD` Helm option type changed from string to boolean.**
        If you had `'
      chart_updates: ['1.14.2 is a patch release focused on stability: multiple IPsec
          fixes, Gateway API fixes, NodePort datapath fixes, and smaller operational
          improvements.', 'Minor Helm chart change in 1.14.2: fixes Envoy DaemonSet
          log level handling when multiple verbose debug groups are configured.']
      features: ['Gateway API: support for additional/extended Gateway API features
          (more complete feature coverage) compared to earlier 1.14.x.', 'Operational
          visibility: `cilium status` now shows SPIRE connection information (helps
          validate mutual-auth/SPIRE deployments).']
      breaking_changes: ["1.14.0 had a strong warning: do not upgrade to 1.14.0 if\
          \ you are using IPsec. For a 1.14.0 \u2192 1.14.2 target, treat IPsec as\
          \ a key risk area and ensure you land on 1.14.2 quickly (or upgrade directly\
          \ to 1.14.2).", 'Helm value type change: `enableEndpointCRD` changed from
          string to boolean in 1.14.0; existing values files may fail template rendering
          or silently misconfigure if not updated.']
    chart_version: 1.14.2
    images: ['quay.io/cilium/cilium:v1.14.2@sha256:6263f3a3d5d63b267b538298dbeb5ae87da3efacf09a2c620446c873ba807d35',
      'quay.io/cilium/operator-generic:v1.14.2@sha256:52f70250dea22e506959439a7c4ea31b10fe8375db62f5c27ab746e3a2af866d']
  - version: 1.14.0
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / values changes to review\n\n- **IPsec users: do not\
        \ upgrade to 1.14.0.** The 1.14.0 release notes explicitly warn: *\u201CDo\
        \ NOT upgrade to this release if you are using IPsec.\u201D* If you rely on\
        \ IPsec, hold on 1.13.x and/or move to a later 1.14.x patch where the issue\
        \ is resolved.\n\n- **SPIRE install default changed**\n  - `authentication.mutual.spire.install.enabled`\
        \ **default changes to `true`**.\n  - Impact: upgrading to 1.14 may start\
        \ installing SPIRE components unless you explicitly disable it.\n  - Action:\
        \ if you are not using Cilium mutual auth/mTLS via SPIRE, set:\n    - `authentication.mutual.spire.install.enabled:\
        \ false`\n\n- **CNI config file ownership / chaining behavior changed**\n\
        \  - New behavior: Cilium manages/overwrites the CNI config file by default.\n\
        \  - Setting `cni.exclusive: false` **disables** Cilium\u2019s \u201Coverwrite\
        \ CNI conf\u201D behavior.\n  - New capability: chaining with arbitrary plugins\
        \ via `cni.chainingTarget`.\n  - Action:\n    - If you chain CNIs (e.g., Istio\
        \ CNI or other plugins), review and set `cni.exclusive` and/or `cni.chainingTarget`\
        \ appropriately.\n\n- **kube-proxy replacement value semantics**\n  - The\
        \ release notes mention deprecating `--kpr=partial|strict|disabled` in favor\
        \ of `--kpr=true|false`, and then a revert of that deprecation is listed.\
        \ Practical takeaway: **double-check what your chart version expects** for\
        \ `kubeProxyReplacement` / `--kube-proxy-replacement` to avoid a mismatch\
        \ during upgrade.\n\n- **New component / chart support: kvstoremesh**\n  -\
        \ Helm chart now supports configuring **kvstoremesh** (a companion to clustermesh-apiserver).\n\
        \  - Action: if you run ClusterMesh at scale or want improved scalability,\
        \ review new kvstoremesh values and whether you should enable it.\n\n- **Ingress/Gateway\
        \ API and L7 proxy validation**\n  - There is explicit validation that enabling\
        \ Ingress or Gateway API while L7 proxy is disabled is invalid.\n  - Action:\
        \ if you use Ingress/Gateway API, ensure `l7Proxy` (Envoy) is enabled.\n\n\
        - **Independent Envoy DaemonSet (optional new deployment model)**\n  - Cilium\
        \ can deploy L7 proxy (Envoy) **as a separate DaemonSet**.\n  - Action: consider\
        \ whether to adopt this for availability/performance; if not, keep default\
        \ co-located model.\n\n- **Endpoint CRD Helm option type change (watch for\
        \ values file drift)**\n  - `enableEndpointCRD` type changed from **string\
        \ to boolean**.\n  - Action: ensure your values use `true|false`, not quoted\
        \ strings.\n\n- **Image digests made optional/configurable**\n  - \u201Cmake\
        \ image digests optional & configurable\u201D is listed; if you previously\
        \ relied on pinned digests, confirm your chart values around `useDigest` /\
        \ digests align with your supply-chain policy.\n\n- **CA bundle / webhook\
        \ CA handling improvements**\n  - Chart adds support for specifying a CA bundle\
        \ and allowing `caBundle` to come from a Secret.\n  - Action: if you have\
        \ custom PKI for webhooks/API services, review these new options.\n"
      chart_updates: [Adds optional new component **kvstoremesh** and corresponding
          Helm configuration to improve clustermesh scalability., 'Adds support for
          deploying **Envoy (L7 proxy) as an independent DaemonSet**, decoupling it
          from the agent for availability/performance/security benefits.', Helm chart
          includes additional dashboards / dashboard integrations (Hubble dashboards
          and sample dashboards integration)., 'Chart validation tightened: enabling
          Ingress/Gateway API while L7 proxy disabled now fails fast (prevents broken
          installs).', 'Various Helm cleanups: deprecated values removed/cleaned up;
          clustermesh CA configuration deprecated in favor of global CA configuration;
          TLS configuration simplified for clustermesh peers.', 'Adds service account
          for nodeinit daemonset and other minor chart template fixes (e.g., indentation
          fixes).']
      features: ['**Gateway API improvements**: adds TLSRoute support and supports
          newer Gateway API versions (v0.6.x/v0.7.0 called out in notes).', '**L2
          announcements**: introduces L2 announcement functionality including gratuitous
          ARP (gARP) pod announcements for on-LAN advertisement use cases.', '**WireGuard
          enhancements**: adds host-to-host and load balancer traffic encryption capabilities.',
        '**High-scale IPCache mode**: new mode designed for very large clustermeshes
          (millions of pods), plus compatibility with encapsulation/DSR scenarios.',
        '**mTLS policy authentication options**: adds `mtls-spiffe` as a CiliumNetworkPolicy
          auth mode and related SPIRE integrations for cert rotation/identity delivery.',
        '**CNI chaining improvements**: supports chaining with arbitrary CNI plugins
          and changes how/when the CNI config file is managed for more reliable upgrades.',
        '**IPv6 datapath enhancements**: BPF-based IPv6 masquerading and IPv4 BIG
          TCP support (plus continued BIG TCP work).', "**Operational safety**: operator\
          \ can taint nodes when Cilium isn\u2019t running to prevent scheduling onto\
          \ unnetworked nodes; CNI conf no longer removed on agent shutdown to avoid\
          \ stuck pod deletions during upgrades."]
      breaking_changes: ['**Hard stop for IPsec**: 1.14.0 release notes explicitly
          warn not to upgrade when using IPsec; treat this as a blocking upgrade constraint.',
        '**CLI/flags removals**: the deprecated `policy_trace` command is removed;
          if you rely on it in runbooks/scripts, update them.', '**Hubble metrics
          change**: the deprecated `pod-short` context option in Hubble metrics is
          removed; dashboards/alerts depending on it need updating.', '**CNI config
          management behavioral change**: Cilium now manages/overwrites the CNI config
          by default; if you used to manually modify the CNI config file or rely on
          other chained plugins, you must adjust (`cni.exclusive=false` and/or `cni.chainingTarget`)
          to avoid unexpected overwrites.', '**Value type change**: `enableEndpointCRD`
          Helm value changed from string to boolean; incorrect type may break templating
          or behavior.']
    chart_version: 1.14.0
    images: ['quay.io/cilium/cilium:v1.14.0@sha256:5a94b561f4651fcfd85970a50bc78b201cfbd6e2ab1a03848eab25a82832653a',
      'quay.io/cilium/operator-generic:v1.14.0@sha256:3014d4bcb8352f0ddef90fa3b5eb1bbf179b91024813a90a0066eb4517ba93c9']
  - version: 1.13.16
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Improved observability tooling: bugtool can now collect Hubble metrics,
          making it easier to capture flow/metrics context during incident triage.',
        'Security and dependency refresh: includes fixes for published vulnerabilities
          (Envoy-related) and bumps core dependencies (Envoy version, Go toolchain
          used in components).', "Reliability/performance improvements across datapath\
          \ and control-plane edges: better handling of BPF service map retries, fewer\
          \ noisy \u201Cstale identity observed\u201D messages, and multiple fixes\
          \ in DNS proxying, IPAM, and Envoy/xDS behavior."]
      breaking_changes: []
    chart_version: 1.13.16
    images: ['quay.io/cilium/cilium:v1.13.16@sha256:f1f26a973419ba449a47a08e8c4c8e280d8941bb4fd77d1e992e2721425c0629',
      'quay.io/cilium/operator-generic:v1.13.16@sha256:a2711d5b891da9fd66c2116b77782b58a1a428eb4abdab2dd3ac1221937d846b']
  - version: 1.13.11
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ["Improved observability signal-to-noise: reduces \u201Cstale identity\
          \ observed\u201D warnings (and further reduces related Hubble debug noise),\
          \ making logs/alerts less chatty.", 'DNS proxy enhancement: optional transparent
          mode (--dnsproxy-enable-transparent-mode) allows the DNS proxy to preserve
          the original pod source IP when talking to upstream DNS servers.', 'Performance
          improvement/fix for heavy-load datapath: further fixes to prevent pod-to-pod
          throughput drops when tunneling and IPsec are both enabled, including reducing
          trace/monitor event volume when aggregation is enabled.']
      breaking_changes: []
    chart_version: 1.13.11
    images: ['quay.io/cilium/cilium:v1.13.11@sha256:3b117c7a6be212e2723813b44b909c757b76943cb0e9fdd0ec2aa4475bfcadb5',
      'quay.io/cilium/operator-generic:v1.13.11@sha256:730e2209b8777f1525186c602f77d5f22259ec4f1f6a2e923f4c03809ab7b0b1']
  - version: 1.13.7
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **1.13.2 note:** the release explicitly warns: *\u201CWhen\
        \ updating to this release, make sure that you are using new helm chart version.\u201D\
        * Ensure you also bump the **Cilium Helm chart** along with the app version.\n\
        - **cert-manager users:** Helm now **mandates issuer configuration** when\
        \ using cert-manager to generate certificates (1.13.2 bugfix note). Verify\
        \ your values include the required issuer settings if you rely on cert-manager.\n"
      chart_updates: [No explicit Helm chart template/structure changes were included
          in the provided notes beyond the cert-manager issuer requirement and the
          general reminder to use the matching chart version.]
      features: ['Better observability for NAT map allocation drops: Cilium now reports
          the kernel error code when drops occur due to failures creating NAT map
          entries (1.13.7).', 'BGP operations visibility: `cilium bgp peers` now shows
          operational state of BGP peers (1.13.2).', 'Host routing/fast-forward support
          expanded: fast-forward (BPF host routing) can work on L2-less devices (1.13.2).']
      breaking_changes: []
    chart_version: 1.13.7
    images: ['quay.io/cilium/cilium:v1.13.7@sha256:3b084617febd708aa9d88de2472c6faf9aee71884112725e8511bca628ce5cf1',
      'quay.io/cilium/operator-generic:v1.13.7@sha256:0ec1bc5d9ecc444a890aaa2e0f397e77d15f1832910f1c20be3adc535688baba']
  - version: 1.13.2
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Use a newer Helm chart when upgrading to Cilium v1.13.2.**\
        \ The 1.13.2 release notes explicitly warn: *\u201CWhen updating to this release,\
        \ make sure that you are using new helm chart version.\u201D*\n- **If using\
        \ cert-manager for certificate generation, you now must configure an issuer.**\
        \ Change introduced via Helm: *\u201Cmandate issuer configuration when using\
        \ cert-manager to generate certificates.\u201D* Ensure your values set the\
        \ cert-manager issuer (and kind) for any Cilium components that request cert-manager-managed\
        \ certs (commonly the clustermesh-apiserver, Hubble, and/or ingress/gateway\
        \ TLS depending on your setup).\n- **ENI postStart hook location/behavior\
        \ changed (AWS ENI IPAM users).** The postStart ENI script was moved from\
        \ the nodeinit pod to the agent pod; there was also a Helm fix related to\
        \ executing `poststart-eni.bash` in the agent DaemonSet. If you rely on AWS\
        \ ENI IPAM / nodeinit behavior, validate your current values around `nodeinit`/ENI\
        \ settings and confirm postStart runs on the agent after the upgrade.\n"
      chart_updates: ['Helm: require explicit cert-manager issuer configuration for
          generated certificates.', 'Helm: fix `poststart-eni.bash` execution in the
          Cilium agent DaemonSet.', 'Operational packaging note: move the postStart
          ENI script from `nodeinit` to the agent pod (impacts how/where initialization
          runs).']
      features: ["Security: v1.13.2 includes a fix for advisory GHSA-pg5p-wwp8-97g8;\
          \ upgrading is recommended if you\u2019re impacted.", 'BGP: adds a `cilium
          bgp peers` CLI command to show the operational state of BGP peers.', 'Datapath/host-routing:
          adds support for L2-less devices when using fast-forward (BPF-based host
          routing).']
      breaking_changes: ['Helm/cert-manager: upgrades may fail or certificates may
          not be issued if you use cert-manager without specifying an issuer; the
          chart now enforces issuer configuration.', 'Operational change (AWS ENI
          IPAM context): the ENI postStart workflow moved from nodeinit to the agent
          pod, which can change troubleshooting and ordering expectations around node
          initialization.']
    chart_version: 1.13.2
    images: ['quay.io/cilium/cilium:v1.13.2@sha256:85708b11d45647c35b9288e0de0706d24a5ce8a378166cadc700f756cc1a38d6',
      'quay.io/cilium/operator-generic:v1.13.2@sha256:a1982c0a22297aaac3563e428c330e17668305a41865a842dec53d241c5490ab']
  - version: 1.13.0
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart behavior to review\n- **New:** `ipMasqAgent.nonMasqueradeCIDRs`\
        \ (1.13) \u2014 lets you configure additional CIDRs that should not be masqueraded\
        \ by the ip-masq-agent.\n- **New/updated:** `configuredMTU` (chart option)\
        \ \u2014 overrides auto-detected MTU; useful if you currently rely on autodetection\
        \ but have non-standard MTU/tunnel settings.\n- **Ingress (Cilium Ingress/Gateway\
        \ API):**\n  - Shared LoadBalancer mode added; chart also gained options to\
        \ configure the **shared Ingress Service type and nodePorts**.\n  - Added\
        \ Helm validation for Ingress controller options (may cause install/upgrade\
        \ failures if values are inconsistent).\n- **Security context / permissions:**\n\
        \  - Chart supports **less-permissive Linux capabilities** (optional). If\
        \ you have custom PSP/OPA/Gatekeeper policies, validate they still allow required\
        \ caps.\n  - SELinux options for pods\u2019 securityContext made configurable.\n\
        - **DaemonSet customization:** ability to add **extra containers** to the\
        \ cilium-agent DaemonSet via Helm values.\n- **Node selectors / control-plane\
        \ labels:** chart adds `node-role.kubernetes.io/control-plane` handling; review\
        \ if you customize operator scheduling.\n- **Hubble UI:** chart updates defaults\
        \ to **hubble-ui v0.10.0** images; if you pin images/tags, reconcile with\
        \ new defaults.\n\n### Values or features that may require action\n- **Egress\
        \ Gateway CRD migration is now mandatory:**\n  - In 1.12, `CiliumEgressNATPolicy`\
        \ was deprecated in favor of `CiliumEgressGatewayPolicy`.\n  - In 1.13, **support\
        \ for `CiliumEgressNATPolicy` is dropped**. You must migrate manifests before\
        \ upgrading.\n"
      chart_updates: [Ingress/Gateway API improvements including shared LoadBalancer
          mode and expanded Service configuration for Ingress., Helm validations added
          for ingress controller values (bad combinations may block the upgrade).,
        Optional reduction of Linux capabilities and more securityContext configurability
          (including SELinux)., Support for adding extra containers to cilium-agent
          DaemonSet via values., Defaults updated for Hubble UI images (v0.10.0).]
      features: [LB-IPAM (LoadBalancer IP address management) to allocate/assign LoadBalancer
          IPs without an external controller., BGP Control Plane can announce Kubernetes
          LoadBalancer services (useful for on-prem/BGP-based LBs)., Gateway API support
          updated (v0.5.1) and Ingress shared LoadBalancer mode added., CiliumNetworkPolicy
          adds TLS SNI enforcement and expands TLS origination/termination capabilities.,
        Per-node configuration overrides via new `CiliumNodeConfig` CRD for label-selected
          node-specific tuning., 'Improved observability: socket-LB tracing, TraceID
          support in Hubble flows/metrics, and additional Hubble metrics contexts.']
      breaking_changes: [Linux minimum version bumped to **4.19.57** (or equivalent);
          older kernels are unsupported and must be upgraded before Cilium 1.13.,
        'Egress Gateway: `CiliumEgressNATPolicy` support removed; clusters using it
          must migrate to `CiliumEgressGatewayPolicy` prior to upgrade.', IPVLAN support
          removed (it was deprecated earlier); environments relying on IPVLAN datapath
          must switch to a supported mode., SockOps deprecated (plan to avoid depending
          on it long-term); expect future removal and validate if any workload depends
          on sockops-based features.]
    chart_version: 1.13.0
    images: ['quay.io/cilium/cilium:v1.13.0@sha256:6544a3441b086a2e09005d3e21d1a4afb216fae19c5a60b35793c8a9438f8f68',
      'quay.io/cilium/operator-generic:v1.13.0@sha256:4b58d5b33e53378355f6e8ceb525ccf938b7b6f5384b35373f1f46787467ebf5']
  - version: 1.12.18
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- No Helm chart changelog was provided in the notes you pasted,
        so there are **no confirmed Helm values changes** to make for this upgrade
        based on this input.

        - One potentially relevant new tunable mentioned in the 1.12.18 app notes
        is the ability to set **resources for the `cgroups` automount initContainer**
        in the agent DaemonSet; if your chart exposes this, consider setting requests/limits
        to match your cluster policy.

        '
      chart_updates: []
      features: ['DNS proxy: new transparent mode (`--dnsproxy-enable-transparent-mode`)
          allows the DNS proxy to use the original pod IP as the source when talking
          to upstream DNS servers.', 'Operability: you can now configure resource
          requests/limits for the cgroups automount initContainer in the Cilium agent
          DaemonSet (helps with strict PodSecurity/ResourceQuota environments).']
      breaking_changes: []
    chart_version: 1.12.18
    images: ['quay.io/cilium/cilium:v1.12.18@sha256:71218d52b2b9a63525e31e9be716810605696cbc02008e658953212f638d6b6b',
      'quay.io/cilium/operator-generic:v1.12.18@sha256:ac9b8a95d6faddacc1bca4145562c5143543dfbbc41b244383b52b8be83238ab']
  - version: 1.12.14
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["No Helm chart changelog was provided in the notes you pasted,\
          \ so I can\u2019t list exact chart/values changes for 1.12.9\u21921.12.14\
          \ from source material here.", 'From the v1.12.9 release notes: when updating
          to 1.12.9 you must also use the corresponding new Helm chart version (implies
          chart/version coupling; verify chart version for 1.12.14 in the Cilium Helm
          chart release notes).']
      features: []
      breaking_changes: []
    chart_version: 1.12.14
    images: ['quay.io/cilium/cilium:v1.12.14@sha256:a54b28a5c15e14f3491c772ca7cfa86266a2b1efb85326bc1ab6c95b91aeaa77',
      'quay.io/cilium/operator-generic:v1.12.14@sha256:b9ce66384c74f79a2982ef3a4602f649d49e9b8b79b58db5faa344c7451cb7c9']
  - version: 1.12.9
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **Use the matching newer Cilium Helm chart when upgrading to
        v1.12.9.** The release explicitly notes to upgrade the chart alongside the
        app.

        - **cert-manager users:** chart now **mandates an issuer configuration** when
        using cert-manager to generate certificates. Ensure `certManagerIssuerRef`/issuer
        settings are provided (chart validation got stricter again compared to earlier
        relaxations).

        '
      chart_updates: ['Helm chart validation/behavior updated around cert-manager:
          issuer configuration is now required when cert-manager is enabled for certificate
          generation.']
      features: [Security fix included (GHSA-pg5p-wwp8-97g8) in v1.12.9; primary reason
          to take this patch., 'Envoy sidecar/proxy components are bumped (to Envoy
          v1.23.8, also mentions v1.23.7 during backports), which can indirectly change
          L7 behavior/performance and compatibility.']
      breaking_changes: ['If you rely on cert-manager auto-generated certs without
          explicitly configuring an issuer, the v1.12.9 Helm chart upgrade can fail
          or block deployment until issuer settings are supplied.']
    chart_version: 1.12.9
    images: ['quay.io/cilium/cilium:v1.12.9@sha256:677e7a906506b8a13fecb6f0f783ed647b36036786c8c640ff98e25ec2f2ab1f',
      'quay.io/cilium/operator-generic:v1.12.9@sha256:cc8d7b222f63812c691a685b32fedab8a805d243da720653cdc2ff0c4a562673']
  - version: 1.12.6
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm chart / values changes to watch (1.12.0 \u2192 1.12.6)\n\
        \nFrom the notes you provided, the only explicit Helm-related change called\
        \ out in **v1.12.6** is:\n\n- **Removed Helm validation for `certManagerIssuerRef`**\
        \ (`helm: Delete validations for certManagerIssuerRef`).\n  - Practical impact:\
        \ installs/upgrades that previously failed due to chart-side validation may\
        \ now proceed. No action required unless you relied on the validation as a\
        \ guardrail.\n\nFrom **v1.12.0** (initial 1.12 series) you should ensure your\
        \ values align with renamed/new options that appear in the release notes:\n\
        \n- **Config rename:** `bpf.hostRouting` \u2192 `bpf.hostLegacyRouting` (ConfigMap\
        \ option). If you set the old key, move to the new one.\n- **Prometheus ports\
        \ default changed** to new reserved Cilium ports. If you scrape by port number\
        \ or have NetworkPolicies/firewalls, verify and update.\n- **Ingress controller\
        \ support** added (including Helm support to create a `cilium` `IngressClass`).\
        \ Only relevant if you enable Cilium Ingress.\n- **Egress Gateway CRD change:**\
        \ new `CiliumEgressGatewayPolicy` introduced; `CiliumEgressNATPolicy` deprecated.\
        \ If you use egress gateway, plan CRD/policy migration.\n- **DaemonSet privileged\
        \ mode removed** in 1.12.0; ensure your cluster/runtime doesn\u2019t depend\
        \ on privileged security context for Cilium.\n\nIf you have your current Helm\
        \ values file, do a `helm diff upgrade` and specifically search for the items\
        \ above.\n"
      chart_updates: [v1.12.6 contains a Helm chart tweak to remove validations for
          `certManagerIssuerRef` (less strict chart-side validation during install/upgrade).,
        No other chart-template structural changes were explicitly listed in the snippets
          you provided for v1.12.6; most changes in 1.12.6 are runtime/agent fixes.,
        'The 1.12.0 notes mention multiple Helm chart enhancements (IngressClass creation,
          more exposed values, certgen update, service type/nodePort options for Hubble
          Relay/UI) which may be present throughout the 1.12.x chart series depending
          on your starting chart version.']
      features: ['v1.12.0 introduces the integrated Cilium Ingress Controller, enabling
          Kubernetes Ingress to be served by Cilium/Envoy.', v1.12.0 adds major Service
          Mesh capabilities (sidecar and sidecar-free options) and support for `CiliumEnvoyConfig`
          CRDs., v1.12.0 promotes Egress Gateway to stable and introduces new capabilities
          like NAT46/64 for Services and service backend quarantine/maintenance states.,
        'v1.12.6 adds a bugtool flag to exclude endpoint objects, improving supportability
          when collecting diagnostics.', 'v1.12.6 includes a CES queue delay metric
          fix and other observability-related improvements (e.g., preventing a crash
          when the tracker is nil).']
      breaking_changes: ['Egress Gateway policy CRD changed in 1.12.0: `CiliumEgressGatewayPolicy`
          is introduced and the previous `CiliumEgressNATPolicy` is deprecated; clusters
          using the old CRD should plan migration and confirm CRDs are installed/updated
          before applying new policies.', 'Config option rename in 1.12.0: `bpf.hostRouting`
          was renamed to `bpf.hostLegacyRouting`; using the old key may result in
          the setting being ignored depending on your config management.', 'Default
          Prometheus ports changed in 1.12.0; monitoring configs, NetworkPolicies,
          and firewalls that assume the old ports may break scraping until updated.']
    chart_version: 1.12.6
    images: ['quay.io/cilium/cilium:v1.12.6@sha256:454134506b0448c756398d3e8df68d474acde2a622ab58d0c7e8b272b5867d0d',
      'quay.io/cilium/operator-generic:v1.12.6@sha256:eec4430d222cb2967d42d3b404d2606e66468de47ae85e0a3ca3f58f00a5e017']
  - version: 1.12.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / values changes to plan for (1.11.2 \u279C 1.12.0)\n\
        \n### New or expanded values you may want to set\n- **ServiceMonitor annotations\
        \ (from 1.11.2):** the chart added values to set *custom annotations* on the\
        \ ServiceMonitor objects. If you rely on Prometheus Operator scraping via\
        \ ServiceMonitors and need custom labels/annotations, review and wire these\
        \ values in.\n- **Ingress controller (new in 1.12):** the Helm chart can now:\n\
        \  - create a **`cilium` IngressClass** (`helm: Create cilium IngressClass`).\n\
        \  - configure the **integrated Cilium Ingress Controller** (several ingress-related\
        \ chart options were added; you\u2019ll likely need to enable it and set class/ports/TLS\
        \ behavior depending on your cluster).\n- **Hubble Relay/UI service exposure:**\
        \ new chart values allow setting **Service type and nodePort** for Hubble\
        \ Relay and Hubble UI.\n- **bpf root:** new `bpf-root` configuration value\
        \ exposed via Helm.\n- **Hubble UI & Relay security contexts:** new values\
        \ such as `hubble.ui.securityContext` and `hubble.relay.securityContext`.\n\
        - **Helm-managed PDBs:** chart fixed PDB creation; if you expected none before,\
        \ you may now see PDBs created once enabled/configured.\n- **DNS proxy parameters\
        \ exposed via Helm:** additional DNS proxy tuning is now configurable through\
        \ values.\n\n### Behavior/compat changes in the chart you should validate\n\
        - **Linux-only nodeSelector applied** to nodeinit and preflight jobs (chart\
        \ now sets a Linux nodeSelector). On mixed-OS clusters, confirm nodeinit/preflight\
        \ still schedule as expected.\n- **Default Prometheus ports changed** to \u201C\
        reserved Cilium ports\u201D. If you scrape metrics by fixed port numbers (Prometheus,\
        \ ServiceMonitors, NetworkPolicies, firewalls), you must update those configs.\n\
        - **`hostAliases` duplicate key removed** (values.yaml cleanup). If you had\
        \ custom values relying on old duplication behavior, recheck.\n\n### Upgrade\
        \ tooling note\n- 1.12 introduces **automatic Helm values** generation and\
        \ wider **cilium-cli Helm-based install/upgrade** support. Decide whether\
        \ you stick with your existing Helm pipeline or standardize on cilium-cli\
        \ for validation/preflight.\n"
      chart_updates: [Integrated Ingress Controller shipped and corresponding Helm
          templates/IngressClass support added., Chart now applies Linux nodeSelectors
          to nodeinit and preflight components (important for mixed OS clusters).,
        Prometheus metrics ports default changed to reserved Cilium ports (update
          scrape configs)., 'Helm chart gained additional values for bpf root, Hubble
          Relay/UI service exposure (type/nodePort), and Hubble securityContexts.',
        'Chart fixes around resource generation (e.g., PodDisruptionBudgets) and several
          template/value alignment cleanups.']
      features: [Integrated Cilium Ingress Controller (no separate ingress controller
          needed) with optional Helm-created IngressClass., Cilium Service Mesh support
          including CiliumEnvoyConfig CRD to manage Envoy behavior via Kubernetes
          resources., Egress Gateway promoted to stable and new Egress Gateway CRD
          introduced for configuration., BGP control plane backed by GoBGP plus IPv6-related
          routing/BGP enhancements., NAT46/64 support for Services and bandwidth manager
          improvements including optional BBR congestion control.]
      breaking_changes: ['Egress Gateway CRD migration: new `CiliumEgressGatewayPolicy`
          CRD added and the older `CiliumEgressNATPolicy` is deprecated; plan to migrate
          manifests.', "DaemonSet no longer runs in privileged mode; verify your cluster\u2019\
          s security policies/PSPs/OPA/Gatekeeper rules allow required capabilities\
          \ and mounts.", 'Default Prometheus metrics ports changed; any hardcoded
          scrapes, firewall rules, or NetworkPolicies must be updated.', 'Config rename:
          `bpf.hostRouting` renamed to `bpf.hostLegacyRouting`; update any custom
          CiliumConfig/values referencing the old name.', 'Deprecated options removed
          (e.g., deprecated `native-routing-cidr` option and prefilter-* options);
          if you still use old flags, the agent may fail to start after upgrade.']
    chart_version: 1.12.0
    images: ['quay.io/cilium/cilium:v1.12.0@sha256:079baa4fa1b9fe638f96084f4e0297c84dd4fb215d29d2321dcbe54273f63ade',
      'quay.io/cilium/operator-generic:v1.12.0@sha256:bb2a42eda766e5d4a87ee8a5433f089db81b72dd04acf6b59fcbb445a95f9410']
  - version: 1.11.16
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Use a newer Helm chart when moving to Cilium v1.11.16.**\
        \ The v1.11.16 release notes explicitly call out that upgrading to this patch\
        \ requires updating the Helm chart version as well (don\u2019t just bump images).\n\
        - No specific `values.yaml` key renames/additions are mentioned in the provided\
        \ notes; expect this to be a **chart packaging/security fix update** rather\
        \ than a config change. Still, run a `helm diff upgrade` against your current\
        \ values to confirm no new required values appear.\n"
      chart_updates: [v1.11.16 release note explicitly requires using a newer Helm
          chart version (likely to address the security advisory GHSA-pg5p-wwp8-97g8
          and/or chart templating changes)., 'Image digests updated for v1.11.15/1.11.16;
          ensure your chart pulls the matching images/digests for all subcomponents
          you deploy (agent, operator, hubble-relay, clustermesh-apiserver, etc.).']
      features: [Bugtool gains a flag to exclude endpoint objects (useful for slimmer/supportable
          diagnostics)., Hubble UI supports being served behind an ingress on non-root
          paths (URLs not starting at `/`).]
      breaking_changes: []
    chart_version: 1.11.16
    images: ['quay.io/cilium/cilium:v1.11.16@sha256:d2f2632c997a027ee4e540432edb4d8594e78e33315427e7ec3c06b473ec1e4e',
      'quay.io/cilium/operator-generic:v1.11.16@sha256:ea3fbe5ab65efc41228d716a64804b6fca9e2299835c3d39ae1cb248c1594c55']
  - version: 1.11.13
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['1.11.13 adds a bugtool flag to exclude endpoint objects from the
          collected bundle, which can reduce output size and avoid sharing endpoint
          details when needed.', '1.11.13 improves operational robustness via an agent
          init check that cleans up unmanaged/stale CiliumEndpoint objects on restart,
          helping avoid endpoint drift and related issues.']
      breaking_changes: ['If you are still using the legacy taint `node.cilium.io/agent-not-ready=true:NoSchedule`
          (noted as important in v1.11.2 release notes), update to `node.cilium.io/agent-not-ready=true:NoExecute`
          to ensure correct scheduling/eviction behavior on affected environments
          such as GKE; this can change how pods are handled while the agent is not
          ready.']
    chart_version: 1.11.13
    images: ['quay.io/cilium/cilium:v1.11.13@sha256:cc5212dd709d1fadf19ffeae602d2af54d03634791f0f1a7e3bab0bd263918a1',
      'quay.io/cilium/operator-generic:v1.11.13@sha256:a34fc3d5007201bdfe7fc3a469351dc6b9f190720ea54622f94cdfb0b28c6726']
  - version: 1.11.2
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart configuration changes\n- **New value:**\
        \ Support for **custom annotations on the ServiceMonitor** created by the\
        \ Cilium chart (Prometheus Operator). If you need extra annotations (e.g.,\
        \ for scraping, relabeling, or tenant routing), set the new ServiceMonitor\
        \ annotation values rather than patching manifests post-install.\n\n### Upgrade\
        \ note (Helm practice)\n- The upstream notes previously warned against Helm\
        \ `--reuse-values` during upgrades (from 1.11.1 notes). For this patch upgrade,\
        \ prefer an explicit `values.yaml` (or `helm get values` \u2192 review \u2192\
        \ apply) to avoid carrying forward deprecated/incorrect defaults."
      chart_updates: ['Helm: add values to allow custom ServiceMonitor annotations.',
        'Helm: minor updates/maintenance (e.g., values.yaml link updates, release
          tooling improvements) carried into this patch release.']
      features: ['Envoy in the Cilium host proxy is updated to **v1.21.1**, addressing
          multiple CVEs (low/moderate/high severity).', 'Prometheus metrics: expose
          additional **XFRM (IPsec) statistics**.', 'Daemon: allow enabling the **Hubble
          PCAP recorder** even when not running in load-balancer mode.', 'Config flexibility:
          `install-no-conntrack-iptables-rules` can be used when **all masquerading
          is disabled**.']
      breaking_changes: ['**Operational change for GKE users:** update node taint
          from `node.cilium.io/agent-not-ready=true:NoSchedule` to `node.cilium.io/agent-not-ready=true:NoExecute`
          to avoid scheduling/cleanup issues when the agent is not ready. This is
          the most important action item in 1.11.2.', '**Behavioral gotcha after first
          reboot (GKE/containerd flavors):** after applying the fix, the *first* node
          reboot may still see pods get IPs from the default CNI because `cilium-node-init`
          runs later; subsequent reboots should behave correctly.']
    chart_version: 1.11.2
    images: ['quay.io/cilium/cilium:v1.11.2@sha256:4332428fbb528bda32fffe124454458c9b716c86211266d1a03c4ddf695d7f60',
      'quay.io/cilium/operator-generic:v1.11.2@sha256:4c8bea6818ee3e4932f99e9c1d7efa88b8c0f3cd516160caec878406531e45e7']
  - version: 1.11.1
    kube: ['1.26', '1.25', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Helm chart change included:** the 1.11.1 release includes\
        \ a Helm template fix for `externalWorkloads` (so if you use external workloads,\
        \ validate your rendered manifests after upgrade).\n- **New operator flag\
        \ (not a Helm value by itself unless your chart exposes it):** `excess-ip-release-delay`\
        \ was introduced to control the delay before marking an IP for release when\
        \ using the \u201Cexcess IP release\u201D features.\n- **Upgrade process note\
        \ (doc change but operationally important):** Cilium explicitly warns **against\
        \ using Helm `--reuse-values` during upgrades**; prefer a clean values file\
        \ and/or `helm get values` + review.\n"
      chart_updates: [Fix Helm template for externalWorkloads., Fix Helm chart annotations
          for CRDs installed by Cilium.]
      features: [No new user-facing features in 1.11.1; this is primarily a patch
          release focused on stability and bugfixes., Underlying container images
          include upstream OS updates (security/bugfix refresh).]
      breaking_changes: ['No explicit breaking changes called out for 1.11.1 (patch
          release). However, behavior may change if you rely on buggy prior behavior
          in areas fixed here (FQDN policy, egress gateway, IPAM/IP release handshake,
          kube-proxy replacement init/finalization).']
    chart_version: 1.11.1
    images: ['quay.io/cilium/cilium:v1.11.1@sha256:251ff274acf22fd2067b29a31e9fda94253d2961c061577203621583d7e85bd2',
      'quay.io/cilium/operator-generic:v1.11.1@sha256:977240a4783c7be821e215ead515da3093a10f4a7baea9f803511a2c2b44a235']
  - version: 1.11.0
    kube: ['1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / values changes to review\n\nFrom the provided release\
        \ notes, these are the Helm-facing changes most likely to affect your `values.yaml`\
        \ when moving from **Cilium 1.10.8 \u2192 1.11.0**:\n\n- **New/changed default\
        \ behaviors (double-check your current config):**\n  - **kube-proxy replacement\
        \ is disabled by default** in 1.11 (`install: Disable kube-proxy-replacement\
        \ by default`). If you rely on kube-proxy replacement, you must explicitly\
        \ set it.\n  - **Bandwidth Manager is disabled by default** (`helm: Disable\
        \ the bandwidth manager by default`). If you previously relied on it being\
        \ enabled, set it explicitly.\n  - **BPF masquerading disabled in v1.10+**\
        \ is reiterated (`helm: Disable BPF masquerading in v1.10+`). Ensure your\
        \ masquerading configuration matches expectations.\n\n- **New Helm options\
        \ / knobs:**\n  - **Disable CRD registration by the operator**: New Helm option\
        \ to prevent the operator from registering CRDs (`Add Helm option to disable\
        \ registering CRD from Cilium Operator`). This matters if you manage CRDs\
        \ separately (GitOps, locked-down clusters).\n  - **`disable-endpoint-crd`\
        \ option support**: Helm support added (`helm: Add support for disable-endpoint-crd\
        \ option`). Relevant if you want to avoid the legacy CiliumEndpoint CRD in\
        \ favor of newer constructs.\n  - **Probe timers configurable via Helm** (`Allow\
        \ configuration of probe timers in Helm chart`).\n  - **Expose L2 neighbor\
        \ discovery related agent flags via Helm** (`helm: Expose l2 neigh discovery\
        \ related agent flags`).\n  - **ServiceMonitor custom labels and annotations**:\n\
        \    - 1.10.8: add values for **custom ServiceMonitor annotations**.\n   \
        \ - 1.11: allow **custom labels** on ServiceMonitors for cilium-agent/operator/hubble.\n\
        \n- **Chart behavior / compatibility adjustments:**\n  - **CronJob apiVersion\
        \ switched to `batch/v1` for Kubernetes >= 1.21** (`helm: Use batch/v1 apiVersion\
        \ for CronJob in K8s 1.21+`). Important if you have older clusters or strict\
        \ API policy checks.\n  - **Hubble UI / cert generation:** multiple Helm-related\
        \ fixes and enhancements (standalone UI install, TLS cert generation, cert-manager\
        \ integration). If you enable Hubble UI, re-validate the generated resources\
        \ and RBAC.\n\n- **Config / flag renames you may have surfaced through Helm\
        \ values:**\n  - **Egress gateway flag rename**: `--egress-gateway` renamed\
        \ to **`enable-ipv4-egress-gateway`** (called out as `option: Rename egress\
        \ gateway flag to enable-ipv4-egress-gateway`). If you set the old flag via\
        \ Helm `extraConfig`/`extraArgs`, update it.\n  - **nativeRoutingCIDR deprecation\
        \ / rename**: docs indicate moving to **`ipv4NativeRoutingCIDR`** (`doc: use\
        \ ipv4NativeRoutingCIDR instead of nativeRoutingCIDR`). If you set `nativeRoutingCIDR`\
        \ in Helm, plan to migrate.\n\n> Note: the provided content is *application*\
        \ release notes; Helm chart version/changelog specifics aren\u2019t included.\
        \ Treat the above as \u201Cthings to verify in values.yaml\u201D rather than\
        \ an exhaustive Helm diff."
      chart_updates: ["Envoy/Proxy components updated across the stack; note that\
          \ 1.10.8 updated the host proxy to Envoy 1.21.1 for CVEs, while 1.11.0\u2019\
          s listed Envoy integration version is 1.18.4 (verify which applies to your\
          \ deployed components and images).", 'Helm chart cleanup and restructuring
          work is referenced (`cleanup helm chart`, `Restructure helm chart into components`),
          which can change rendered object names/labels and the shape of values.',
        Improved device auto-detection (route-based) and expanded multi-device support
          (notably for XDP acceleration) can change which interfaces Cilium programs
          by default; re-check `devices` / `directRoutingDevice` overrides if you
          set them previously., CiliumEndpointSlice feature introduced for scalability
          in CRD-only clusters; may introduce additional CRDs/resources and changes
          in control-plane behavior when enabled., 'Host firewall promoted to stable;
          if you enable host firewall, ensure your policies and expectations match
          the now-stable feature status.']
      features: ["OpenTelemetry export for Hubble L3\u2013L7 observability data (traces\
          \ and metrics).", New `kube-apiserver` policy entity to simplify modeling
          policy to/from the Kubernetes API server., "Topology-aware load balancing\
          \ using Kubernetes service topology hints to prefer \u201Cclosest\u201D\
          \ backends.", BGP PodCIDR route advertisement support., Graceful service
          backend termination to drain connections when endpoints are removed/terminated.,
        Host firewall promoted to stable for production use., Load balancer scalability
          improvements (supporting >64K backends) and improved XDP fast-path support
          for bonded/multi-device setups., CiliumEndpointSlice for improved scalability
          in CRD-only clusters (1000+ nodes without requiring an etcd kvstore).]
      breaking_changes: ['Default install behavior changes: kube-proxy replacement
          is **disabled by default** in 1.11; clusters relying on it must explicitly
          enable it during/after upgrade.', 'Some flags/configuration names changed
          or deprecated (notably egress gateway flag rename to `enable-ipv4-egress-gateway`,
          and `nativeRoutingCIDR` deprecation in favor of `ipv4NativeRoutingCIDR`),
          which can break upgrades if you pass old flags via Helm.', 'Known issue:
          ToFQDN rules can become ineffective after modifying a policy selecting a
          pod; mitigation is to apply all policies then restart the agent or affected
          pods.']
    chart_version: 1.11.0
    images: ['quay.io/cilium/cilium:v1.11.0@sha256:ea677508010800214b0b5497055f38ed3bff57963fa2399bcb1c69cf9476453a',
      'quay.io/cilium/operator-generic:v1.11.0@sha256:b522279577d0d5f1ad7cadaacb7321d1b172d8ae8c8bc816e503c897b420cfe3']
  - version: 1.10.19
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **New Helm values (1.10.8):** `serviceMonitor.annotations`\
        \ / custom ServiceMonitor annotations were added so you can attach extra labels/annotations\
        \ to the Prometheus ServiceMonitor (useful for Prometheus Operator discovery/tenancy).\n\
        \  - Action: if you previously patched the ServiceMonitor post-install, you\
        \ can now move that into values.yaml.\n\n- **Hubble Relay deployment manifest\
        \ fix (1.10.19):** The chart/manifests were adjusted to set the correct `terminationMessagePolicy`\
        \ for the Hubble Relay Deployment.\n  - Action: no value changes expected,\
        \ but after upgrade verify the rendered Deployment spec matches your policy/standards\
        \ if you enforce them via admission policies.\n"
      chart_updates: [Host proxy (Envoy) version was updated in the 1.10.8 release
          line (Envoy 1.21.1) to address multiple CVEs; expect new images/digests
          for cilium components., Hubble Relay Deployment spec was fixed in 1.10.19
          (termination message policy)., CNI plugins were updated to v1.2.0 by 1.10.19;
          this changes the bundled CNI binary version shipped with the images.]
      features: ['Prometheus metrics: xfrm (IPsec/XFRM) statistics are now exposed,
          improving observability for encrypted traffic paths.', 'Helm chart now supports
          adding custom annotations to the ServiceMonitor directly via values, reducing
          the need for post-render patches.']
      breaking_changes: []
    chart_version: 1.10.19
    images: ['quay.io/cilium/cilium:v1.10.19@sha256:63c76e5c2317b22f9e11c5d30f1b799cd19eb88649c03941f66dbd9b8f487f15',
      'quay.io/cilium/operator-generic:v1.10.19@sha256:d09f5ca4738bb9190c977f4ffed77e2aec2eae50db2a75368cbcc3f8f7ab6708']
  - version: 1.10.8
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **New Helm values:** Add support for **custom annotations on\
        \ ServiceMonitor objects**.\n  - Expect a new values key similar to `prometheus.serviceMonitor.annotations`\
        \ / `hubble.metrics.serviceMonitor.annotations` (exact path depends on chart\
        \ section) to attach annotations to the ServiceMonitor.\n- **Upgrade hygiene:**\
        \ Release notes reiterate **avoid `helm upgrade --reuse-values`** for Cilium.\
        \ Prefer supplying an explicit values file (or diffing defaults between chart\
        \ versions) to avoid silently carrying forward deprecated/changed defaults."
      chart_updates: [Helm chart exposes new knobs for ServiceMonitor annotations
          (Prometheus Operator integration)., 'Installation manifests/images updated:
          Envoy (host proxy) bumped to v1.21.1; base images and image digests refreshed
          for v1.10.8.']
      features: ['Prometheus metrics now include **XFRM (IPsec) statistics**, improving
          visibility into IPsec/XFRM behavior and troubleshooting.', 'Helm chart can
          now **apply custom annotations to ServiceMonitors**, useful for Prometheus
          Operator setups (scrape configs, relabeling, tenant metadata, etc.).']
      breaking_changes: []
    chart_version: 1.10.8
    images: ['quay.io/cilium/cilium:v1.10.8@sha256:e6147e39a03c685e5f1225c5642e1358dcd4899bbd94e8a043bb4be52cd2f008',
      'quay.io/cilium/operator-generic:v1.10.8@sha256:a77dff6103d047d8810ea5e80067b2fade6d099771c8dda197bdba5e4e2f0255']
  - version: 1.10.7
    kube: ['1.26', '1.25', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm chart / values changes to watch\nFrom the provided 1.10.0\
        \ notes (and still relevant when you land on 1.10.7), there are several Helm-value\
        \ structure changes and new knobs that commonly trip upgrades:\n\n- **Do not\
        \ use `helm --reuse-values` for upgrades.** The 1.10.7 notes explicitly warn\
        \ against it; use an explicit values file (or `helm get values ...` into a\
        \ file and edit) so you don\u2019t accidentally keep deprecated/renamed fields.\n\
        - **`extraArgs` format changed**: Helm **replaced object-based `extraArgs`\
        \ with an array-based format**. If you previously had `extraArgs: { foo: \"\
        bar\" }`, you must convert to the new list style.\n- **Encryption values restructured**:\n\
        \  - Helm **consolidated IPSec and WireGuard options** under a common encryption\
        \ hierarchy.\n  - **IPSec options moved under `encryption.ipsec`** (older\
        \ top-level ipsec keys need mapping).\n- **New top-level `eni` block for AWS\
        \ ENI IPAM** with more options; also includes `eni.iamRole` to support IAM\
        \ roles for service accounts on the operator.\n- **`kubeProxyReplacement`\
        \ behavior changed for new installs**: quick-install default became **disabled\
        \ by default**, so make sure your existing setting is explicitly set to what\
        \ you expect.\n- **New/changed optional toggles you may want to set explicitly**\
        \ (depending on your deployment):\n  - `enableEgressGateway` (enables egress\
        \ gateway feature)\n  - `enable-ipv6-masquerade` agent option when using iptables\
        \ masquerade mode\n  - `proxy.prometheus.enabled` (can disable the proxy metrics\
        \ service)\n  - Support for **external serviceAccounts** (if you manage RBAC\
        \ externally)\n\nIf you share your current `values.yaml`, we can map old keys\
        \ to new ones precisely."
      chart_updates: ['Cilium 1.10 introduced multiple Helm chart refactors that still
          apply when upgrading within the 1.10 patch line, including moving/renaming
          values blocks (notably encryption and ENI).', 1.10.7 includes a manifest
          change adding `mountPropagation` to the `bpf-maps` volume in the Cilium
          DaemonSet (important if you rely on BPF map mounts/persistence)., "1.10.7\
          \ refreshes underlying container image digests (agent, operator variants,\
          \ hubble-relay, etc.), so expect new image SHAs even if your values don\u2019\
          t change."]
      features: [Standalone load-balancer datapath mode (`--datapath-mode=lb`) for
          running Cilium as an L4 LB without full CNI duties., WireGuard pod-to-pod
          encryption integration and Helm consolidation of encryption configuration
          options., 'BGP-based LoadBalancer external IP allocation/announcement, plus
          the egress gateway feature toggle in Helm for controlled rollout.', ARM64
          support (multi-arch images) enabling Cilium to run on arm64 nodes., Kubernetes
          1.21 support and raised minimum supported Kubernetes version to 1.16.]
      breaking_changes: [Kubernetes minimum supported version increased to **1.16**
          (from older 1.9.x support); clusters below 1.16 cannot upgrade to 1.10.x.,
        "Helm values breaking changes: `extraArgs` changed structure (object \u2192\
          \ array) and encryption/IPSec settings were moved under `encryption.*`;\
          \ upgrades that blindly reuse old values can fail or silently misconfigure\
          \ encryption."]
    chart_version: 1.10.7
    images: ['quay.io/cilium/cilium:v1.10.7@sha256:e23f55e80e1988db083397987a89967aa204ad6fc32da243b9160fbcea29b0ca',
      'quay.io/cilium/operator-generic:v1.10.7@sha256:d0b491d8d8cb45862ed7f0410f65e7c141832f0f95262643fa5ff1edfcddcafe']
  - version: 1.10.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / values changes to review (1.9.13 \u279C 1.10.0)\n\n\
        These are the Helm-facing changes explicitly mentioned in the 1.10.0 release\
        \ notes and are the ones most likely to require changes to your `values.yaml`.\n\
        \n- **`extraArgs` format changed**: Helm **replaced object-based `extraArgs`\
        \ with array-based**.\n  - If you had something like:\n    ```yaml\n    extraArgs:\n\
        \      debug: \"true\"\n      devices: \"eth0\"\n    ```\n    you\u2019ll\
        \ need to convert to the chart\u2019s new list/array form (exact syntax depends\
        \ on the chart schema you use).\n\n- **Encryption values reorganized**:\n\
        \  - Helm **consolidated IPsec and WireGuard encryption options**.\n  - Helm\
        \ **moved IPsec options under `encryption.ipsec`**.\n  - If you previously\
        \ set top-level IPsec-related values, you must relocate them under the new\
        \ `encryption` tree.\n\n- **New Helm toggles / options**:\n  - `enableEgressGateway`\
        \ was added.\n  - `enable-k8s-event-handover` can now be configured via Helm.\n\
        \  - `proxy.prometheus.enabled` flag added to disable the proxy Prometheus\
        \ service.\n  - `EndpointStatus` enablement added to Helm chart.\n  - `serviceAccounts.*.create`\
        \ is respected (ensure your values align with the intended SA creation behavior).\n\
        \  - External ServiceAccounts are now supported (you can point to pre-created\
        \ SAs).\n\n- **Image digest controls**:\n  - Helm added **digest flags** to\
        \ pin images by digest (useful for reproducible upgrades / restricted registries).\n\
        \n- **ENI values schema change**:\n  - Helm created a **top-level `eni` block**\
        \ and added more ENI options.\n  - `eni.iamRole` option was added to allow\
        \ using IAM roles for service accounts on `cilium-operator`.\n\n- **TLS secret\
        \ content**:\n  - Helm adds `ca.crt` to TLS secrets (relevant if you manage/override\
        \ those secrets).\n"
      chart_updates: ['Helm chart refactors for 1.10: encryption values consolidation
          and IPsec values moved under `encryption.ipsec`.', Helm `extraArgs` values
          schema changed from map/object to array/list form., Helm added support for
          pinning images via digest flags., 'Helm added options for egress gateway,
          k8s event handover, proxy Prometheus service toggle, EndpointStatus, and
          expanded ServiceAccount controls (including external SAs).', Helm reorganized/expanded
          ENI configuration into a top-level `eni` block and added `eni.iamRole` for
          IRSA-style setups., Helm TLS secrets now include `ca.crt`.]
      features: [Standalone load balancer datapath mode via `--datapath-mode=lb` (run
          cilium-agent as an LB without full CNI)., 'WireGuard integration for pod-to-pod
          encryption, including support for managed Kubernetes environments.', Service
          LoadBalancer external IP allocation and announcement via BGP., 'Egress Gateway
          support (control plane + datapath), exposed via a Helm option.', 'NodePort
          BPF support on L2-less devices (e.g., WireGuard/tun).', ARM64 support for
          building and installing Cilium., 'Kubernetes support updated: adds support
          for K8s 1.21 and raises minimum supported K8s to 1.16.']
      breaking_changes: [Minimum supported Kubernetes version is now **1.16** (clusters
          older than 1.16 are unsupported)., '`kube-proxy-replacement` is **disabled
          by default** for new installs (if you relied on kube-proxy replacement previously,
          you must explicitly enable/configure it).', "Helm values breaking change:\
          \ `extraArgs` schema changed (map/object \u279C array/list), requiring `values.yaml`\
          \ updates.", 'Helm values breaking change: IPsec/WireGuard encryption options
          were reorganized (IPsec options moved under `encryption.ipsec`).', Managed
          etcd mode is deprecated (plan migration away if you are using Cilium-managed
          etcd)., Legacy flannel integration was removed (clusters depending on it
          must use supported CNI/chaining modes).]
    chart_version: 1.10.0
    images: ['quay.io/cilium/cilium:v1.10.0@sha256:587627d909ffe0418c0bd907516496844867a21812946af82096d367760e4c1e',
      'quay.io/cilium/operator-generic:v1.10.0@sha256:65143311a62a95dbe23c69ff2f624e0fdf030eb225e6375d889da66a955dd828']
  - version: 1.9.13
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [No Helm chart changelog was provided in the notes; only application
          (Cilium) release notes were included., 'Expect container image tags/digests
          to change to v1.9.13 for cilium, operator, hubble-relay, clustermesh-apiserver,
          etc. If you pin digests, update them accordingly.', 'Envoy (Cilium host
          proxy) is updated; if you run L7 policies/ingress with the host proxy, plan
          for a rolling restart and validate Envoy config compatibility.']
      features: ['Security update: Cilium host proxy (Envoy) updated to v1.21.1 to
          address multiple CVEs.', Operational reliability improvements via several
          bug fixes affecting networking and node lifecycle edge-cases.]
      breaking_changes: []
    chart_version: 1.9.13
    images: ['quay.io/cilium/cilium:v1.9.13', 'quay.io/cilium/operator-generic:v1.9.13']
  - version: 1.9.12
    kube: ['1.26', '1.25', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / values changes to watch\n\nFrom the notes you provided,\
        \ there are **no explicit Helm value changes required specifically between\
        \ 1.9.0 \u2192 1.9.12** (most 1.9.12 items are bugfixes and image updates).\n\
        \nHowever, **1.9.0 itself introduced major Helm chart changes** that matter\
        \ if you are *actually coming from an older chart layout*:\n\n- **Single consolidated\
        \ `cilium` chart (no subcharts)** and lots of values were re-scoped. If your\
        \ current install was created with the pre-1.9 chart structure, you must follow\
        \ the 1.9 upgrade guide and review your values for renamed/moved keys.\n-\
        \ **Helm 2 support removed; Helm 3 required**.\n- **PodSecurityPolicy removed\
        \ from the chart** (Kubernetes PSP deprecation).\n\nOther Helm-related items\
        \ mentioned in the 1.9.0 notes (verify if you use them):\n\n- **Hubble ingress\
        \ template updated** for newer Kubernetes Ingress APIs.\n- **Load balancer\
        \ related Helm parameters were renamed** (the note references a rename; validate\
        \ your `values.yaml` if you configure kube-proxy replacement / NodePort /\
        \ LB settings).\n- The installation docs mention **hubble-ui image reference\
        \ fixes** and repository changes (ensure your Helm values don\u2019t pin old\
        \ hubble-ui image repos/tags).\n"
      chart_updates: ['1.9.12: Updates underlying container base images and image
          digests; includes a fix for hubble-ui-backend image deployment and hubble-ui
          image reference corrections.', '1.9.0: Helm charts were fully restructured
          into a single `cilium` chart (no subcharts) with many values re-scoped;
          Helm 3 minimum enforced and Helm 2 dropped.', '1.9.0: Chart removed PodSecurityPolicy
          templates.', '1.9.0: Operator/Agent behavior around CRDs changed: operator
          handles CRD operations and agent waits for CRDs to be available.']
      features: ['(1.9.0) Deny policies added (policy can explicitly deny traffic,
          not just allow).', (1.9.0) Maglev consistent hashing support for kube-proxy
          replacement Services (NodePort/LoadBalancer/externalIPs)., (1.9.0) Cilium
          operator HA mode., '(1.9.0) Beta support for external workloads (e.g., VMs)
          and Services for those workloads.', (1.9.0) Various observability/Hubble
          improvements including (m)TLS support and additional flow filtering/metrics.]
      breaking_changes: ['(1.9.0) Helm chart restructuring (single chart, values re-scoped)
          can break upgrades if you reuse old `values.yaml` without mapping renamed/moved
          keys.', (1.9.0) Helm 2 support removed; requires Helm 3., (1.9.0) PodSecurityPolicy
          manifests removed; clusters relying on PSP-based admission need an alternative
          (or accept changed security enforcement)., (1.9.0) Removal/deprecation of
          several agent/operator options and DNS poller removal may break automation/scripts
          that referenced those flags or behavior., (1.9.0) `blacklist-conflicting-routes`
          agent option removed; routing conflicts with PodCIDR must now be handled
          by the user/operator outside Cilium.]
    chart_version: 1.9.12
    images: ['quay.io/cilium/cilium:v1.9.12', 'quay.io/cilium/operator-generic:v1.9.12']
  - version: 1.9.0
    kube: ['1.19', '1.18', '1.17', '1.16', '1.15', '1.14', '1.13', '1.12']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.9.0
    images: ['quay.io/cilium/cilium:v1.9.0', 'quay.io/cilium/operator-generic:v1.9.0']
  name: cilium
- icon: https://avatars.githubusercontent.com/u/54918165?s=48&v=4
  git_url: https://github.com/projectcontour/contour
  release_url: https://github.com/projectcontour/contour/releases/tag/v{vsn}
  helm_repository_url: https://charts.bitnami.com/bitnami
  versions:
  - version: 1.32.1
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Envoy dependency bumped from v1.34.1 to v1.34.4, bringing in upstream
          fixes and changes from Envoy 1.34.4.', Go toolchain/runtime bumped from
          v1.24.3 to v1.24.6.]
      breaking_changes: []
    chart_version: 21.1.4
    images: ['docker.io/bitnami/contour:1.32.1-debian-12-r0', 'docker.io/bitnami/envoy:1.34.5-debian-12-r0']
  - version: 1.32.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Improved performance in clusters with many endpoints by switching
          EDS caching to go-control-plane LinearCache., "Bumped supported/tested Kubernetes\
          \ versions to 1.31\u20131.33 and updated CI/e2e kind node image accordingly.",
        'Updated bundled dependencies: Envoy to v1.34.1 and Go to 1.24.3.', 'Fixed
          the `contour` CLI xDS discovery behavior so subsequent DiscoveryRequests
          include the requested resource names, not only the first request.']
      breaking_changes: []
    chart_version: 21.1.2
    images: ['docker.io/bitnami/contour:1.32.0-debian-12-r8', 'docker.io/bitnami/envoy:1.34.4-debian-12-r0']
  - version: 1.31.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ["External authorization enhancements: you can now disable Global\
          \ ExtAuth by default and selectively re-enable it at vhost/route level;\
          \ additionally, ExtAuth is no longer enforced on HTTP\u2192HTTPS redirect\
          \ responses (avoids 401s on redirect).", "Envoy overload protections: new\
          \ bootstrap flag `overload-downstream-max-conn` enables Envoy\u2019s global\
          \ downstream connection limit; admin listeners ignore the global limit so\
          \ stats/admin remain reachable, and there\u2019s a new health-check config\
          \ option to make readiness/liveness respect overload rejection behavior.",
        Gateway API compatibility bumped to v1.2.1., 'Operational/config additions:
          configurable HTTP compression algorithm (gzip/brotli/zstd/disabled), new
          `strip-trailing-host-dot` request handling option, support for Service `appProtocol`
          http/https, expanded retryOn conditions, and more redirect status codes
          (303/307/308) for requestRedirectPolicy.', "Dependency/platform updates:\
          \ Envoy updated to v1.34.0; Go updated to 1.24.2; tested Kubernetes versions\
          \ now 1.30\u20131.32; plus bugfixes for follower readiness and memory leak."]
      breaking_changes: ["Removal: legacy `contour` xDS server implementation removed;\
          \ go-control-plane xDS server is now the only supported option. Corresponding\
          \ config fields that selected xDS server type have been removed\u2014configs\
          \ referencing them must be cleaned up before/while upgrading.", 'Removal:
          `useEndpointSlices` feature flag and remaining Endpoints-path code removed.
          Any setups that explicitly forced Endpoints API (or relied on disabling
          EndpointSlice mirroring) must be updated; Contour now always uses EndpointSlices.']
    chart_version: 20.0.1
    images: ['docker.io/bitnami/contour:1.31.0-debian-12-r2', 'docker.io/bitnami/envoy:1.34.1-debian-12-r0']
  - version: 1.30.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Gateway API: Implement Listener/Route hostname isolation so requests
          are routed to the most specific matching Listener and its attached routes.',
        Monitoring examples updated to expose Envoy metrics on port 8002 and to use
          Prometheus Operator `PodMonitor` resources (instead of `prometheus.io/*`
          annotations)., Gateway API compatibility updated to v1.1.0 (includes GRPCRoute
          now GA/v1)., 'Circuit breaker configuration added for Extension Services,
          with PerHostMaxConnections also configurable globally.', Fallback certificate
          handling now applies global external auth (Global ExtAuth) filters., 'Gateway
          API: GRPCRoute match conflict handling now mirrors HTTPRoute behavior (oldest
          wins, then alphabetical; sets Accepted/PartiallyInvalid conditions).']
      breaking_changes: ['Gateway API v1.1.0 includes breaking changes to `BackendTLSPolicy`,
          moving it to `v1alpha3`; users must uninstall v1alpha2 CRD before installing
          the new one.', 'Deprecated: sample manifests and Gateway provisioner no
          longer add `prometheus.io/*` scrape annotations; monitoring should move
          to `PodMonitor`/Prometheus Operator flow.', 'Deprecated: xDS server type
          fields in the config file and ContourConfiguration CRD are now deprecated
          and planned for removal in 1.31 (along with the legacy `contour` xDS implementation).']
    chart_version: 19.2.1
    images: ['docker.io/bitnami/contour:1.30.0-debian-12-r6', 'docker.io/bitnami/envoy:1.31.2-debian-12-r0']
  - version: 1.29.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 18.2.3
    images: ['docker.io/bitnami/contour:1.29.0-debian-12-r1', 'docker.io/bitnami/envoy:1.29.5-debian-12-r0']
  - version: 1.28.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 1.27.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Fixes path match sorting for Prefix/Regex routes so longer patterns
          are ordered first (then lexicographic for ties), improving match specificity
          consistency across HTTPProxy inclusion, Ingress, and Gateway API.', 'Routes
          can disable an inherited virtualhost global rate limit policy via `rateLimitPolicy.global.disabled:
          true` at the route level.', 'Contour waits for informer cache sync *and*
          handler processing before starting DAG rebuild and serving XDS, improving
          startup correctness.', HTTPProxy supports dynamic Host header rewrites using
          request header variables (route-level only)., Optional EndpointSlice support
          added behind `useEndpointSlices` feature flag (off by default)., 'Adds listener
          config knobs for HTTP/2 DoS mitigation/tuning: `listener.max-requests-per-io-cycle`
          and `listener.http2-max-concurrent-streams`.', Gateway provisioner can run
          in/out of cluster via `--incluster`/`--kubeconfig` flags and supports `overloadMaxHeapSize`
          for Envoy overload manager bootstrap config., Gateway API listener `ResolvedRefs`
          condition now defaults to true; webhook removed from example manifests since
          Gateway API validation uses CEL., 'Build/runtime dependency bumps: Go 1.21.3
          and Envoy 1.28.0.']
      breaking_changes: [Route ordering may change for some combinations of Prefix/Regex
          path matches due to the new sorting algorithm; this can alter which route
          matches first in large/complex routing tables. Validate route order and
          behavior before/after upgrade.]
    chart_version: 15.4.0
    images: ['docker.io/bitnami/contour:1.27.0-debian-11-r9', 'docker.io/bitnami/envoy:1.27.2-debian-11-r8']
  - version: 1.26.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Gateway API: Gateway listeners can now be configured on more than
          two ports (multiple HTTP and multiple HTTPS/TLS listeners). If using the
          Contour Gateway Provisioner, the Envoy Service will automatically expose
          ports for all valid listeners.', 'Gateway API: TCPRoute is now supported
          for simple TCP forwarding on a listener port, and TLS termination is supported
          with TLSRoute (SNI-based routing) or TCPRoute (single backend).', 'Gateway
          API: Updated support to Gateway API v0.8.0, including status/conformance
          refinements and CRD validation changes.', 'HTTPProxy: New regex-based path
          matching and regex header matching conditions are supported in routes/includes.',
        'Rate limiting: You can define a default global rate limit policy in Contour
          config that applies to all HTTPProxies unless they opt out.', "Observability/ops:\
          \ New xDS metrics about status update count/duration and additional controller-runtime\
          \ metrics are exposed; access logs can now include route source (kind/namespace/name)\
          \ and have a new \u201Ccritical\u201D level (>=500 only)."]
      breaking_changes: ['Routing behavior change: Contour no longer strips the port
          from the downstream Host header before proxying to backends; backends will
          now see the Host header including the port if one was present.', 'Gateway/HTTP
          route precedence change: routes that match HTTP method now take precedence
          over routes with header/query matches (aligns with Gateway API v0.7.1+),
          which can change which backend receives requests in overlapping-rule scenarios.',
        'If you use static provisioning for Gateway (manually managed Envoy Service),
          you must now keep the Service ports in sync with all Gateway listeners because
          Contour supports many listener ports; previously some configurations may
          have assumed only one HTTP and one HTTPS port.']
    chart_version: 13.1.4
    images: ['docker.io/bitnami/contour:1.26.0-debian-11-r17', 'docker.io/bitnami/envoy:1.26.5-debian-11-r0']
  - version: 1.25.0
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 12.2.2
    images: ['docker.io/bitnami/contour:1.25.0-debian-11-r73', 'docker.io/bitnami/envoy:1.26.3-debian-11-r10']
  - version: 1.24.0
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 1.23.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ["Overload Manager can be enabled to protect Envoy from OOM-related\
          \ disruptions by shedding load when heap usage is too high; it\u2019s off\
          \ by default and must be explicitly configured.", "HTTPProxy now supports\
          \ JWT verification via Envoy\u2019s jwt_authn filter, with JWTProviders\
          \ defined on the root HTTPProxy and applied per-route (with optional defaults\
          \ and opt-outs).", 'Slow start mode is available to gradually ramp traffic
          to newly added/upscaled endpoints, reducing cold-start overload (useful
          for JVM apps).', 'HTTPProxy CORS policy can now use regex matching for Allowed
          Origins, enabling more flexible Origin header handling.', "Gateway API updates:\
          \ conformance/behavior improvements (e.g., rule precedence is list order),\
          \ more efficient status handling (status-only changes don\u2019t trigger\
          \ xDS), and version bump to Gateway API v0.5.1.", 'Operational configurability
          via ContourDeployment: configurable Contour and Kubernetes client log levels,
          pod annotations/labels, resource requirements, and extra volumes/volumeMounts
          for Envoy pods.']
      breaking_changes: ["Supported Kubernetes versions shift: v1.23.x is tested against\
          \ Kubernetes 1.23\u20131.25 (drops 1.22). Ensure your cluster version is\
          \ within this range before upgrading.", Envoy version moves forward (v1.22
          used Envoy 1.23; v1.23 uses Envoy 1.24). Validate any Envoy-specific config/custom
          filters and observe for behavior/log-format changes tied to the new Envoy
          release., 'Gateway API behavior is more strictly conformant (e.g., HTTPRoute
          rule precedence by list order); if you relied on previous non-conformant
          matching/attachment quirks, re-test routing outcomes after upgrade.']
    chart_version: 10.1.1
    images: ['docker.io/bitnami/contour:1.23.0-debian-11-r10', 'docker.io/bitnami/envoy:1.24.0-debian-11-r11']
  - version: 1.22.0
    kube: ['1.24', '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Upgrade Contour from v1.21.x to v1.22.0 (includes Envoy bump
          to 1.23.0 and Gateway API bump to v0.5.0)., 'Gateway API resources/conformance
          behavior changes: stricter TLS mode enforcement for HTTPS vs TLS listeners,
          updated route/backend error handling and status conditions to match upstream
          spec, and new support for ReferenceGrant alongside deprecated ReferencePolicy.',
        "ContourConfiguration schema change: field rename `spec.envoy.logging.jsonFields`\
          \ \u2192 `spec.envoy.logging.accessLogJSONFields`; removes unused `DebugLogLevel`/`KubernetesDebugLogLevel`\
          \ fields (must be configured via CLI flags).", 'Behavioral defaults/operational
          tweaks: `contour envoy shutdown --check-delay` default is now 0s (faster
          termination when idle).', "Compatibility window changes: supported/tested\
          \ Kubernetes versions now 1.22\u20131.24 (1.21 dropped)."]
      features: [Gateway API updated to v0.5.0 (v1alpha2 and v1beta1) with full v0.5.0
          conformance test pass., 'HTTPProxy routes can now return direct responses
          via `directResponsePolicy` (requires `statusCode`, optional `body`) as an
          alternative to service/redirect.', Client certificate validation can optionally
          check revocation via CRL provided in an Opaque Secret referenced by `httpproxy.spec.virtualhost.tls.clientValidation.crlSecret`.,
        'Gateway API now supports exact HTTP query parameter matching, plus rule-level
          RequestMirror filter support (Gateway API mode).', 'Envoy upgraded to 1.23.0,
          enabling newer access log operators and related logging template keywords.']
      breaking_changes: ['If you use the ContourConfiguration CRD field `spec.envoy.logging.jsonFields`,
          it has been renamed to `spec.envoy.logging.accessLogJSONFields` and must
          be updated before/with the upgrade.', "Gateway API: ReferencePolicy is deprecated\
          \ (ReferenceGrant preferred) and will be removed in the next Contour release\u2014\
          plan migration now to avoid a future breaking upgrade.", 'Gateway API: stricter
          enforcement of TLS modes for listener protocols (HTTPS must be Terminate;
          TLS must be Passthrough) may cause previously-accepted configs to become
          invalid/unready.', "Kubernetes version support shifted to 1.22\u20131.24;\
          \ clusters on 1.21 are no longer in the tested/supported window for v1.22.0."]
    chart_version: 9.1.1
    images: ['docker.io/bitnami/contour:1.22.0-debian-11-r4', 'docker.io/bitnami/envoy:1.23.0-debian-11-r8']
  - version: 1.21.0
    kube: ['1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Leader election RBAC in the example manifests was refactored:
          rules for leader-election resources moved from a ClusterRole to a namespace-scoped
          Role plus RoleBinding (and now also needs access to Events and Leases).
          If your Helm chart templates or values override RBAC, review and align them
          with v1.21.0 expectations (especially if Contour runs outside the default
          namespace or you set a custom leader-election namespace).', Contour leader
          election now uses only Lease objects; any chart flags/args or RBAC must
          include coordination.k8s.io Lease permissions and related Events access
          as per updated manifests., Container images are now published exclusively
          on GHCR; Helm values that reference image repositories must switch from
          Docker Hub to ghcr.io/projectcontour/contour (and ghcr.io/projectcontour/envoy
          for Envoy where applicable)., Leader-election configuration via configuration
          file was removed; charts that mount a config file and previously set leader
          election there must move those settings to command-line flags/args., 'Gateway
          API ecosystem updates: Gateway API bumped to v0.4.3 and example YAML includes
          the validating webhook; if your chart installs Gateway API resources/webhook,
          reconcile versions and webhook deployment expectations.', 'If you use/ship
          certgen jobs/manifests, note the new optional --name-prefix flag for contour
          certgen and that gateway-provisioner no longer relies on a certgen job (generates
          xDS certs directly).']
      features: [Configurable HTTP/HTTPS access log verbosity via accesslog-level
          / spec.envoy.logging.accessLogLevel (info/error/disabled)., New optional
          Contour Gateway provisioner (contour gateway-provisioner) to dynamically
          provision Contour+Envoy per Gateway for Gateway API conformance., 'Gateway
          API enhancements: can target a specific Gateway via gatewayRef; better listener/route
          condition handling; support requested addresses via spec.addresses.', 'New
          load-balancing option: hash based on a query parameter for HTTPProxy backends.',
        'Operational/config additions: upstream TCP connection timeout configurable;
          option to disable Envoy merge_slashes; JSON log format via --log-format=json;
          new HTTPProxy idleConnection timeout field.']
      breaking_changes: [Leader election config in the configuration file has been
          removed; must be configured via CLI flags now., Leader election coordination
          now uses only Lease objects and upgrading to v1.21.0 explicitly requires
          having upgraded to v1.20.0 first for migration., Default deployment RBAC
          for leader election resources changed from ClusterRole to namespace-scoped
          Role/RoleBinding; installs that relied on cluster-wide ConfigMap permissions
          must be updated accordingly., Contour images are no longer pushed to Docker
          Hub; image pulls must be updated to GHCR.]
    chart_version: 8.0.0
    images: ['docker.io/bitnami/contour:1.21.0-debian-11-r0', 'docker.io/bitnami/envoy:1.22.1-debian-11-r0']
  - version: 1.20.1
    kube: ['1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 7.10.2
    images: ['docker.io/bitnami/contour:1.20.1-debian-11-r0', 'docker.io/bitnami/envoy:1.21.2-debian-11-r0']
  name: contour
- icon: https://avatars.githubusercontent.com/u/21110084?s=200&v=4
  release_url: https://github.com/coredns/coredns/releases/tag/{vsn}
  helm_repository_url: https://coredns.github.io/helm
  versions:
  - version: 1.11.3
    kube: ['1.31']
    requirements: []
    incompatibilities: []
    chart_version: 1.32.0
  - version: 1.11.1
    kube: ['1.29']
    requirements: []
    incompatibilities: []
    chart_version: 1.26.0
  - version: 1.10.1
    kube: ['1.27']
    requirements: []
    incompatibilities: []
    chart_version: 1.21.0
  - version: 1.9.3
    kube: ['1.25']
    requirements: []
    incompatibilities: []
    chart_version: 1.19.4
  - version: 1.8.6
    kube: ['1.23']
    requirements: []
    incompatibilities: []
    chart_version: 1.16.5
  - version: 1.8.4
    kube: ['1.22']
    requirements: []
    incompatibilities: []
    chart_version: 1.16.0
  - version: 1.8.0
    kube: ['1.21']
    requirements: []
    incompatibilities: []
    chart_version: 1.14.0
  - version: 1.7.0
    kube: ['1.19']
    requirements: []
    incompatibilities: []
  - version: 1.6.7
    kube: ['1.18']
    requirements: []
    incompatibilities: []
  - version: 1.6.5
    kube: ['1.17']
    requirements: []
    incompatibilities: []
  - version: 1.6.2
    kube: ['1.16']
    requirements: []
    incompatibilities: []
  - version: 1.3.1
    kube: ['1.15', '1.14']
    requirements: []
    incompatibilities: []
  - version: 1.2.6
    kube: ['1.13']
    requirements: []
    incompatibilities: []
  - version: 1.2.2
    kube: ['1.12']
    requirements: []
    incompatibilities: []
  - version: 1.1.3
    kube: ['1.11']
    requirements: []
    incompatibilities: []
  - version: 1.0.6
    kube: ['1.10']
    requirements: []
    incompatibilities: []
  - version: 1.0.1
    kube: ['1.09']
    requirements: []
    incompatibilities: []
  name: coredns
- icon: https://avatars.githubusercontent.com/u/112438027?s=200&v=4
  git_url: https://github.com/cloudnative-pg/cloudnative-pg
  release_url: https://github.com/cloudnative-pg/cloudnative-pg/releases/tag/v{vsn}
  helm_repository_url: https://cloudnative-pg.github.io/charts
  chart_name: cloudnative-pg
  versions:
  - version: 1.28.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Quorum-based failover is now a stable API (`spec.postgresql.synchronous.failoverQuorum`),
          replacing the previous alpha annotation approach.', New declarative Foreign
          Data Wrapper management via the `Database` CRD (`.spec.fdws` and `.spec.servers`)
          to manage FDW extensions and foreign servers., 'Security and ops improvements:
          pod-level `securityContext`/`containerSecurityContext`, optional TLS for
          operator metrics, fine-grained custom TLS for PgBouncer, and a caching layer
          for user-defined monitoring queries.', 'Operational resilience improvements:
          better probe behavior during transient API-server issues and faster replica
          network drop detection via a reduced default `tcp_user_timeout`.']
      breaking_changes: [Default PostgreSQL image version changes (to PostgreSQL 18.1
          system-trixie by default); upgrading may change the default major version
          if you were relying on defaults rather than pinning images., "Kubernetes/PostgreSQL\
          \ support matrix changes: Kubernetes 1.31 and PostgreSQL 13 are no longer\
          \ listed as supported in 1.28 (ensure you\u2019re on K8s 1.32+ and PG 14+).",
        Quorum-based failover configuration moved from `alpha.cnpg.io/failoverQuorum`
          annotation to the stable `spec.postgresql.synchronous.failoverQuorum` field
          (update manifests accordingly if you used the alpha feature).]
    chart_version: 0.27.0
    images: ['ghcr.io/cloudnative-pg/cloudnative-pg:1.28.0']
  - version: 1.27.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Dynamic loading of PostgreSQL extensions via `.spec.postgresql.extensions`,
          mounting extension images as read-only volumes in instance pods.', HA logical
          decoding slot sync via `spec.replicationSlots.highAvailability.synchronizeLogicalDecoding`
          so logical subscribers keep working after failover., Primary Isolation Check
          promoted to stable; adds `.spec.probes.liveness.isolationCheck` and updates
          liveness behavior to shut down an isolated primary within `livenessProbeTimeout`.,
        Experimental failover quorum (quorum-based failover) available via `alpha.cnpg.io/failoverQuorum`
          annotation., New `fqdn-uri` and `fqdn-jdbc-uri` entries in user secrets
          for FQDN-based connection strings., 'CNPG-I: adds Postgres interface support
          and instance webserver metrics capabilities.']
      breaking_changes: ['Liveness probe default behavior changed: an isolated primary
          is now forcibly shut down within `livenessProbeTimeout` (default 30s). This
          can change failure modes and may cause quicker primary pod termination in
          certain network-partition scenarios.', "`Backup.spec` is now immutable after\
          \ creation; any workflows that \u201Cedit\u201D existing Backup objects\
          \ must switch to creating new Backup resources instead."]
    chart_version: 0.26.0
    images: ['ghcr.io/cloudnative-pg/cloudnative-pg:1.27.0']
  - version: 1.26.0
    kube: ['1.33', '1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Offline, declarative in-place major PostgreSQL upgrades using pg_upgrade
          (cluster pods shut down; precheck job; declarative rollback).', Improved
          replica startup/readiness probe behavior with better control tied to streaming
          lag., Database CRD expanded with declarative management of extensions and
          schemas.]
      breaking_changes: ['Native Barman Cloud support is deprecated (still works in
          1.26, removed in 1.28); start migrating clusters to the Barman Cloud Plugin,
          and expect webhook warnings when using in-tree barmanObjectStore/retentionPolicy
          fields.', 'Operator drops support for Barman <=3.4 capability detection;
          if your operand image is very old (pre-Apr 2023), upgrade the operand before
          upgrading the operator.', "kubectl cnpg hibernate commands switched from\
          \ imperative to declarative shortcuts; hibernate status removed\u2014do\
          \ not upgrade plugin/operator unless you\u2019re ready to adopt declarative\
          \ hibernation."]
    chart_version: 0.24.0
    images: ['ghcr.io/cloudnative-pg/cloudnative-pg:1.26.0']
  - version: 1.25.0
    kube: ['1.32', '1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Declarative database management via new `Database` CRD to create/manage
          PostgreSQL databases within a Cluster., 'Declarative logical replication
          via new `Publication` and `Subscription` CRDs, easing replication setup
          and online migrations.', 'Experimental CNPG-I plugin interface to extend
          CloudNativePG via third-party plugins (e.g., Barman Cloud plugin) without
          modifying the operator.']
      breaking_changes: ['Support matrix changes: PostgreSQL 12 is dropped; PostgreSQL
          17 is now supported and the default image is PostgreSQL 17.2. Plan upgrades
          accordingly (major PG upgrade procedures apply).', "Kubernetes support window\
          \ shifts (now 1.32\u20131.29); Kubernetes 1.28 is no longer listed as supported."]
    chart_version: 0.23.1
    images: ['ghcr.io/cloudnative-pg/cloudnative-pg:1.25.0']
  - version: 1.24.0
    kube: ['1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Operator release 1.24.0 includes important resource/labeling
          behavior changes (Service/PDB selector label deprecation) and scheduling/anti-affinity
          default fix that can trigger a full instance rollout on operator upgrade.,
        'Security hardening and connectivity changes: TLS added between operator and
          instance manager; optional TLS for metrics exporter; operator service account
          permissions reduced.', 'Behavioral changes around readiness checks, pod
          spec reconciliation control, and pooler rollout behavior on operator image
          upgrades.']
      features: [Distributed PostgreSQL topologies (enhanced replica clusters) enabling
          multi-cluster/hybrid deployments with declarative primary control and seamless
          switchover without rebuilding the former primary., Managed services configuration
          (`managed.services`) to disable default read/read-only services and to template
          custom Services (including LoadBalancers) for external access/DBaaS use
          cases., New synchronous replication API supporting quorum-based and priority-list
          strategies with full customization of `synchronous_standby_names`., Safety
          mechanism to stop the cluster on WAL disk space exhaustion to simplify recovery
          by resizing storage., Delayed replicas via `.spec.replica.minApplyDelay`
          using PostgreSQL `recovery_min_apply_delay`., Post-init SQL can now be provided
          via multiple ConfigMaps/Secrets using `postInitSQLRefs` and `postInitTemplateSQLRefs`.,
        PostgreSQL 17 support for `allow_alter_system` via `.spec.postgresql.enableAlterSystem`.,
        'Metrics/query improvements: customizable metric/column names and predicate
          queries; PgBouncer 1.23 metrics support in Pooler collector.', New annotation
          `reconcilePodSpec` on Cluster/Pooler to control pod restarts after pod spec
          changes., '`cnpg` plugin improvements including control-plane node install
          option and enhanced status output for distributed topology tokens.']
      breaking_changes: ['`role` label in Service and PodDisruptionBudget selectors
          is deprecated in favor of `cnpg.io/instanceRole`; any tooling or custom
          resources depending on the old selector/label should be updated.', Default
          PodAntiAffinity fix for PostgreSQL pods will trigger a rollout of all instances
          when upgrading the operator (even with online upgrades enabled); plan for
          controlled disruption/capacity during the upgrade., 'Readiness behavior
          tightened: streaming replicas that never connected to primary now fail readiness,
          which may change rollout/alerting behavior in misconfigured or partitioned
          environments.']
    chart_version: 0.22.0
    images: ['ghcr.io/cloudnative-pg/cloudnative-pg:1.24.0']
  - version: 1.23.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Introduced PostgreSQL Image Catalogs via new `ClusterImageCatalog`
          and `ImageCatalog` CRDs; clusters can reference them with `.spec.imageCatalogRef`
          as an alternative to `imageName` and a future default., Added synchronization
          of user-defined physical replication slots from primary to replicas using
          `replicationSlots.synchronizeReplicas`., Added `.spec.enablePDB` to control/disable
          PodDisruptionBudgets (notably helpful for single-instance clusters and maintenance
          evictions)., Allows transitioning an existing cluster into replica mode
          to simplify cross-datacenter switchover operations., Connection pooler Service
          is now customizable (type/labels/annotations)., Supports configuring PostgreSQL
          `wal_log_hints` parameter., Automatically generated connection URI secrets
          can use FQDNs., Improved restore behavior by cleaning up instance Pods not
          owned by the Cluster and adding better error detection for `barman-cloud-wal-restore`.,
        '`kubectl cnpg` plugin improvements: better argument handling, status output
          includes PDBs, backup progress handling, and `sync-sequences` robustness.']
      breaking_changes: ['Support policy change: CloudNativePG now focuses on one
          supported minor release at a time (instead of two), with 3 months supplementary
          support for the previous minor. Plan upgrades accordingly.']
    chart_version: 0.21.1
    images: ['ghcr.io/cloudnative-pg/cloudnative-pg:1.23.0']
  - version: 1.22.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['**Declarative tablespaces**: new `.spec.tablespaces` stanza in the
          `Cluster` CRD to create/manage tablespaces through the operator lifecycle.',
        '**Temporary tablespaces**: `.spec.tablespaces[*].temporary` lets you designate
          a tablespace for temp operations by wiring it into Postgres `temp_tablespaces`.',
        '**Prometheus relabeling support**: you can now set `podMonitorRelabelings`
          and `podMonitorMetricRelabelings` under `.spec.monitoring` for both `Cluster`
          and `Pooler`.', '**Connection pooler scaling to zero**: `Pooler` resources
          can now be scaled down to 0 instances, useful for pausing traffic without
          deleting the resource.', '**Red Hat UBI 8 operator images**: new UBI-based
          images are available, mainly for OLM-style deployments.']
      breaking_changes: ['**`ALTER SYSTEM` is now disabled by default**: if you relied
          on the operator using `ALTER SYSTEM` to apply configuration, you must explicitly
          re-enable it following the upgrade documentation.', '**PostgreSQL default
          image bumped to 16.1**: new clusters (and any clusters that track the default
          operand image) will move from 16.0 to 16.1; validate extension/compatibility
          expectations before rollout.', '**TLS defaults tightened for Postgres 12+**:
          TLSv1.3 is enforced by default, which can break older clients or environments
          that require lower protocol versions unless you override the relevant `ssl_*`
          GUCs.']
    chart_version: 0.20.0
    images: ['ghcr.io/cloudnative-pg/cloudnative-pg:1.22.0']
  - version: 1.21.0
    kube: ['1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Kubernetes VolumeSnapshot support for backup and recovery (initially
          cold backups from a standby), enabling incremental/differential snapshot-based
          workflows.', OLM/OperatorHub installation support via a stable channel for
          the latest patch of the latest minor release., Managed role lifecycle improvements
          (from 1.20) and new cnpg kubectl plugin enhancements (status includes primary
          timestamp/uptime; logs include previous logs)., 'Recovery/replica bootstrap
          enhancements using consistent sets of volume snapshots, including full and
          PITR recovery.']
      breaking_changes: ['Default operational timeouts changed significantly: stopDelay
          now 1800s (was 30s), startDelay now 3600s (was 30s), switchoverDelay now
          3600s; plus new smartShutdownTimeout affecting shutdown behavior.', 'Liveness
          probe behavior changed: initial delay replaced with a Kubernetes startupProbe,
          which can affect readiness/liveness timing assumptions.', 'Superuser access
          is disabled by default (security hardening), which may break workflows expecting
          direct superuser access.', 'Replication slots for HA are enabled by default,
          which can change WAL retention behavior and storage requirements.', The
          legacy `postgresql` label is no longer supported; use `cnpg.io/cluster`
          instead., 'kubectl plugin command change: `cnpg snapshot` replaced by `cnpg
          backup -m volumeSnapshot`; label `role` is being deprecated in favor of
          `cnpg.io/instanceRole` (and new `cnpg.io/instanceRole` added).']
    chart_version: 0.19.0
    images: ['ghcr.io/cloudnative-pg/cloudnative-pg:1.21.0']
  - version: 1.20.0
    kube: ['1.27', '1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Declarative role management via `managed.roles` in the Cluster spec
          to manage PostgreSQL roles lifecycle (create/alter) from Kubernetes., 'Declarative
          cluster hibernation via the `cnpg.io/hibernation` annotation to scale a
          cluster down to zero pods while retaining PVCs, with an inverse restore
          procedure.']
      breaking_changes: ['Default behavior changes for newly created Clusters with
          replicas: backup-from-standby is enabled by default unless `.spec.backup.target`
          is explicitly set to `primary`.', 'Default behavior changes for newly created
          Clusters: `primaryUpdateMethod` now defaults to `restart` (unsupervised
          rolling update completes by restarting the primary) unless explicitly set
          to `switchover`.', 'The `-any` Service is now disabled by default, which
          may affect clients relying on that Service name/type.']
    chart_version: 0.18.0
    images: ['ghcr.io/cloudnative-pg/cloudnative-pg:1.20.0']
  - version: 1.19.0
    kube: ['1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Cluster-managed physical replication slots for HA, automatically
          creating and managing slots for each hot-standby replica.', 'Cluster hibernation
          via `kubectl cnpg hibernate on/off/status`, which removes cluster-generated
          resources except the primary PVCs.', Backup from a standby using `.spec.backup.target=prefer-standby`
          to take a base backup from the most aligned replica., Delayed failover via
          `failoverDelay` to postpone failover after the primary is detected unhealthy.,
        Support for Kubernetes projected volumes in pod specs., Support for custom
          environment variables to control the PostgreSQL server process., New `kubectl
          cnpg backup` plugin command to trigger a base backup., 'Improved separate
          WAL volume support, including moving WAL to a dedicated volume on existing
          clusters and added WAL-related Prometheus metrics.']
      breaking_changes: ['PostgreSQL 10 is no longer supported; CloudNativePG now
          supports PostgreSQL 11+ (plan migrations accordingly, ideally toward PostgreSQL
          15).']
    chart_version: 0.17.0
    images: ['busybox:latest', 'ghcr.io/cloudnative-pg/cloudnative-pg:1.19.0']
  - version: 1.18.0
    kube: ['1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Cluster-managed physical replication slots for HA: the operator
          can automatically create/manage physical replication slots for each hot-standby
          replica on both primary and standby clusters.', 'Postgres cluster hibernation
          (via cnpg kubectl plugin): you can hibernate a cluster (destroy operator-managed
          resources but keep the primary PVCs) and resume it later.', 'New cnpg plugin
          subcommands: `hibernate`, `pgbench` (generate a benchmarking Job), and `install`
          (generate operator install manifests).', PostgreSQL 15.0 becomes the default
          PostgreSQL major/minor version for new clusters., 'Security hardening: add
          `SeccompProfile` to pods and containers.']
      breaking_changes: ['Default PostgreSQL version changes to 15.0 for newly created
          clusters; if you rely on implicit defaults, you may get a different major
          version than before (explicitly set `.spec.imageName`/`.spec.postgresql`
          version to avoid surprises).', Cluster-managed replication slots may change
          replication/slot behavior and resource usage compared to manual slot management;
          review settings/monitoring if you previously managed physical slots yourself.]
    chart_version: 0.16.0
    images: ['busybox:latest', 'ghcr.io/cloudnative-pg/cloudnative-pg:1.18.0']
  - version: 1.17.0
    kube: ['1.24', '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['**v1.16.0:** Adds `bootstrap.initdb.import` to import schemas/data
          over the network from an existing PostgreSQL (including outside Kubernetes)
          using logical backup/restore; can also be used for major PostgreSQL upgrades
          on a new cluster (supports `microservice` and `monolith` import modes).',
        '**v1.16.0:** Adds label-based anti-affinity rules for synchronous replicas
          so they can be scheduled on nodes with different characteristics (e.g.,
          different AZ than the primary).', '**v1.17.0:** Adds optional `walStorage`
          to place `pg_wal` on a dedicated volume separate from the main `storage`/`PGDATA`
          volume to improve write-heavy performance (must be decided at cluster creation).',
        '**v1.17.0:** Improves PgBouncer by allowing configuration of low-level TCP
          network settings.', '**v1.17.0:** Improves UX/ops with `kubectl cnpg destroy`
          to delete an instance and its associated PVCs.']
      breaking_changes: ['**v1.17.0:** `walStorage` cannot be added/removed on an
          existing running cluster; enabling it requires creating a new cluster (or
          recreating) with the setting present from day 1.', '**v1.16.0:** Backup
          tooling requirement bump: Barman >= 3.0.0 is required for future PostgreSQL
          15 support; verify your backup image/tooling versions are compatible before
          upgrading.']
    chart_version: 0.15.0
    images: ['ghcr.io/cloudnative-pg/cloudnative-pg:1.17.0']
  - version: 1.16.0
    kube: ['1.24', '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["Operator now defaults operand/PostgreSQL image to 14.4 (was\
          \ earlier in 1.15.x); verify your clusters\u2019 `.spec.imageName`/operand\
          \ image pinning if you rely on a specific minor version.", 'Backup/WAL archiving
          conditions now use Kubernetes built-in Condition types; if you have tooling
          that parses old custom condition fields, validate it against the new status
          output.', Kubernetes 1.24 is supported (and Barman >= 3.0.0 is required
          for future PostgreSQL 15 support).]
      features: ["Offline logical import/major upgrade workflow via `bootstrap.initdb.import`,\
          \ supporting \u201Cmicroservice\u201D (single DB) and \u201Cmonolith\u201D\
          \ (multiple DBs + roles) import from an external or in-cluster PostgreSQL\
          \ using pg_dump/pg_restore.", 'Label-based anti-affinity for synchronous
          replicas to ensure sync standbys land on nodes with different characteristics
          (e.g., different AZ) than the primary.', Azure AD Workload Identity support
          for Barman Cloud backups via `inheritFromAzureAD`., New `barmanObjectStore.s3Credentials.region`
          value to set AWS region for backup and recovery object stores., Recovery/cloning
          can now redefine app DB name/owner/secret when restoring from object store
          or cloning via pg_basebackup (previously only initdb bootstrap).]
      breaking_changes: []
    chart_version: 0.14.0
    images: ['ghcr.io/cloudnative-pg/cloudnative-pg:1.16.0']
  - version: 1.15.0
    kube: ['1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.13.0
    images: ['ghcr.io/cloudnative-pg/cloudnative-pg:1.15.0']
  name: cloudnative-pg
- icon: https://github.com/kubernetes-sigs/external-dns/blob/master/docs/img/external-dns.png?raw=true
  git_url: https://github.com/kubernetes-sigs/external-dns
  release_url: https://github.com/kubernetes-sigs/external-dns/releases/tag/v{vsn}
  helm_repository_url: https://kubernetes-sigs.github.io/external-dns
  versions:
  - version: 0.20.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['CLI parsing/flag handling was migrated from kingpin to cobra
          (dual-parity), which can subtly affect how flags are parsed/aliased in manifests
          and Helm values -> args; review your configured args carefully.', 'Chart
          release aligns with app v0.20.0 image tag; no explicit Helm values deprecations
          were called out in the provided notes, but validate against your current
          values.yaml due to the CLI migration.', 'If you rely on the `--min-ttl`
          flag, be aware it was unintentionally removed in v0.20.0 and is expected
          to be restored in the next release.']
      features: ['New flags to support OwnerID migration, making it easier to move
          between ownership identifiers without recreating all records.', 'Custom
          annotation prefix support for split-horizon DNS, enabling multiple DNS views
          using different annotation namespaces.', 'Cloudflare provider now supports
          tags for records (where supported), improving record organization and filtering.',
        CoreDNS provider gained new annotations for groups and improved etcd client
          usage with context support., 'Additional provider/source enhancements: AWS
          adds ap-southeast-6 region; F5 Virtual Server source adds host aliases support.']
      breaking_changes: ['`--min-ttl` was unintentionally removed in v0.20.0; any
          deployment depending on it will fail to start or will ignore the setting
          until the flag is restored in a later version.']
    chart_version: 1.20.0
    images: ['registry.k8s.io/external-dns/external-dns:v0.20.0']
  - version: 0.19.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / chart configuration changes to review\n- **New\
        \ Helm value for annotation filtering**: chart adds a **dedicated value to\
        \ configure `annotationFilter`** (instead of only via `extraArgs`). If you\
        \ already set annotation filtering via `extraArgs`, you can keep it, but consider\
        \ migrating to the new value for clarity/validation.\n- **`extraContainers`\
        \ type change**: `.extraContainers` changed to be an **array/list**. If you\
        \ previously provided it as an object/map, update your `values.yaml` accordingly.\n\
        - **Gateway / EndpointSlice RBAC adjustments in chart**:\n  - Ensure the chart\
        \ version you deploy includes the RBAC updates for **EndpointSlices** access\
        \ (introduced with the move from Endpoints\u2192EndpointSlices).\n  - Chart\
        \ also fixes/adjusts **RBAC for namespaced Gateway sources** and makes EndpointSlice\
        \ permissions more conditional. If you use Gateway API sources, double-check\
        \ RBAC after upgrade.\n- **Schema update**: Helm values schema updated to\
        \ accept **`policy: create-only`** as a valid type (useful if you want to\
        \ prevent deletions).\n"
      chart_updates: ['Adds a dedicated Helm value to configure `annotationFilter`
          (PR #5737).', 'Fixes `.extraContainers` values schema/type to be an array
          (PR #5564).', 'RBAC fixes for namespaced Gateway sources (PR #5578).', 'Makes
          EndpointSlice RBAC permissions conditional (PR #5746).', 'Helm values schema
          updated to allow `policy: create-only` (PR #5627).']
      features: ['~10x lower average memory usage for pod/node sources by using informer
          transformers (PR #5596).', 'Adds `build_info` Prometheus metric for easier
          version/build visibility (PR #5643).', 'Adds AWS Route53 support for ap-east-2
          and geoproximity routing policies (PRs #5638, #5347).', 'Adds pod source
          support for annotation and label filters (PR #5583).', 'Chart: easier configuration
          of `annotationFilter` via a dedicated Helm value (PR #5737).']
      breaking_changes: ['Nodes source now exposes external IPv6 by default, which
          can change which AAAA records are published unless you override with flags
          (PR #5575).', 'Traefik legacy listeners on the `traefik.containo.us` API
          group are disabled, so older Traefik CRDs/listeners may stop being watched
          unless you switch to the supported API group/config (PR #5565).']
    chart_version: 1.19.0
    images: ['registry.k8s.io/external-dns/external-dns:v0.19.0']
  - version: 0.18.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm/values changes to plan for\n\n- **RBAC must be updated\
        \ to allow `endpointslices` access** (new default Service discovery path uses\
        \ EndpointSlices). If you use the Helm chart, ensure your chart version includes\
        \ this RBAC rule; the v0.18.0 app notes say it lands in the *next* chart release.\
        \ If you manage RBAC yourself, add permissions for EndpointSlices (typically\
        \ `discovery.k8s.io` API group).\n\n- **`--txt-new-format-only` flag removed**.\
        \ If your Helm values/extraArgs still set it, remove it; the \u201Cnew\u201D\
        \ TXT registry format is now the only supported format.\n\n- **Metrics changed\
        \ significantly**. Expect to adjust Helm chart settings and downstream monitoring\
        \ (ServiceMonitor/Prometheus rules/dashboards/alerts). Even if no values changed,\
        \ your observability config likely will.\n\n- **`default-targets` behavior\
        \ changed with an optional mitigation flag `--force-default-targets`**. If\
        \ you rely on previous default-target logic, review and (if needed) set this\
        \ flag via chart `extraArgs`.\n\n- **Provider removals**: if you were using\
        \ in-tree `ibmcloud`, `tencentcloud`, or `ultradns`, you must pin older versions\
        \ or migrate to a webhook provider. This may require chart values updates\
        \ to the `provider` setting and any provider-specific config.\n"
      chart_updates: [RBAC updates are required for EndpointSlices; note that the
          v0.18.0 app release says this is included in the *next* Helm chart release
          (so upgrading the app image without upgrading the chart/RBAC can break Service
          source)., 'Helm chart release workflow/process fixes mentioned upstream
          (not functional changes, but suggests chart version selection matters).']
      features: ['Cloudflare: support for MX records and DNS record comments; improved
          regional hostnames behavior.', Service source now uses EndpointSlices (more
          scalable than Endpoints)., FQDN templating improvements (ExecTemplate functions;
          pod/node/service-related enhancements)., New/updated metrics including `consecutiveSoftErrors`
          and metrics for all supported endpoint types., Optional `--force-default-targets`
          mitigation flag to control default-target behavior.]
      breaking_changes: ['RBAC: Service source now uses EndpointSlices; without EndpointSlice
          permissions, ExternalDNS may fail to read service endpoints.', Metrics output
          was significantly reworked; existing dashboards/alerts scraping specific
          series/labels will likely break., Removed `--txt-new-format-only` flag and
          deprecated legacy TXT registry format; only the new TXT format is supported
          now., 'Removed in-tree providers: ibmcloud, tencentcloud, and ultradns;
          must migrate (webhook) or stay on an older version.', Default-targets behavior
          changed; may affect record targets unless you opt into the mitigation flag
          (`--force-default-targets`).]
    chart_version: 1.18.0
    images: ['registry.k8s.io/external-dns/external-dns:v0.18.0']
  - version: 0.17.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **`extraArgs` value type change/expansion**: the Helm chart
        now allows `extraArgs` to be **either a list or a map** (PR #5293). If you
        currently set `extraArgs` as a list, it should still work, but you can migrate
        to a map if you need to override individual args cleanly.

        - **Helm schema/validation updates**: the chart schema was updated and missing
        schema values were added (PRs #5228, #5297). This may cause `helm install/upgrade`
        to start failing on previously "accepted" but invalid values; run `helm lint`
        and validate your values.

        - No other explicit required values changes were called out in these notes;
        the main operator-facing changes are provider/flag related (see breaking/risks).'
      chart_updates: [Helm chart schema and validation improvements (added missing
          schema values; updated schema)., 'Chart supports `extraArgs` as a map in
          addition to a list, enabling per-arg overrides.', 'Minor chart typing fix:
          add missing types for empty values.']
      features: ['Helm chart: `extraArgs` can now be a map as well as a list to make
          overriding individual arguments easier.', 'Cloudflare: support multiple
          custom hostnames (plus fixes for duplicates/regional hostnames edge cases).',
        'Pi-hole: added optional v6 support and IPv6 dual format support.', 'Node
          source: can optionally exclude unschedulable nodes.', 'Node source: optional
          exposure/handling of internal IPv6 addresses (`expose-internal-ipv6`) per
          IPv6 proposal 002.', Zone finder is IDNA-aware; also improved handling of
          underscores in DNS records., OVH provider was heavily rewritten (functional
          and behavioral improvements).]
      breaking_changes: ['OpenStack Designate **in-tree provider removed** (`chore(openstack
          designate)!` #5126). If you used `--provider=designate`, you must move to
          the OpenStack webhook provider before upgrading.', 'OVH provider rewrite
          may require **new/updated ACLs/credentials/permissions**; treat as a potentially
          breaking behavioral change and follow the provider docs/PR #5143.', 'Known
          issue: Active Directory provider has a **severe regression since v0.16.0**
          (#5240) and is not fixed in v0.17.0 per notes; avoid upgrading or plan mitigation
          if you rely on AD.', 'Deprecation heads-up: Pi-hole v5 is deprecated (v6
          support added) and will be removed in a future release.', 'Deprecation heads-up:
          legacy TXT registry format is planned to be removed in the next minor version;
          no migration script is provided, so plan record cleanup/migration now.']
    chart_version: 1.17.0
    images: ['registry.k8s.io/external-dns/external-dns:v0.17.0']
  - version: 0.16.1
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Webhook provider improvements (webhook-* annotations forwarded to
          webhooks) and additional webhook provider options documented (e.g., Infoblox,
          Unifi).', CoreDNS provider gains etcd authentication support (and related
          HTTPS doc updates)., AWS provider can use local AWS credential profiles
          from a .credentials file., RFC2136 provider adds optional PTR record support.,
        'Gateway API support evolves: GRPCRoute client updated to stable v1 and Gateway
          API gains dual-stack support, plus a follow-up revert to v1beta1 objects
          in v0.15.0 notes.']
      breaking_changes: [v0.15.0 drops several unmaintained in-tree providers; users
          must stay on older versions or migrate to webhook providers for those DNS
          providers., Infoblox in-tree provider is removed (use the Infoblox webhook
          provider instead)., Cloudflare had a breaking change in v0.16.0 that is
          fixed in v0.16.1; still treat Cloudflare upgrades cautiously., 'TXT registry
          now has an option to use only the new TXT format; the old format is planned
          for removal in the next release, so plan a migration if you rely on legacy
          TXT ownership records.', OpenStack Designate in-tree provider is slated
          for removal next version; migrate to the external webhook provider.]
    chart_version: 1.16.1
    images: ['registry.k8s.io/external-dns/external-dns:v0.16.1']
  - version: 0.15.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **No explicit Helm values breaking changes called out in the\
        \ provided notes.**\n- If you use the Helm chart\u2019s **webhook provider**\
        \ subchart/config, note it received fixes:\n  - Webhook resources now correctly\
        \ honor configured `resources` values.\n  - General \u201Cwebhook provider\
        \ helm chart fixes\u201D landed (review your rendered manifests after upgrade).\n\
        \n> Practical action: run `helm diff upgrade` and pay extra attention to the\
        \ webhook Deployment/Service/SA resources and any values under webhook-related\
        \ keys you use.\n"
      chart_updates: ['Helm chart webhook integration fixes: webhook workload now
          uses the configured resource values; additional chart fixes for webhook
          provider support (verify rendered manifests).']
      features: [Provider cache added to reduce repeated provider lookups and improve
          performance/efficiency., 'CoreDNS provider: added etcd authentication support
          (and accompanying docs for etcd HTTPS).', 'AWS provider: can use AWS profiles
          via a `.credentials` file (useful when not relying on IRSA/ambient credentials).',
        'RFC2136 provider: optional PTR record support.', 'Webhook provider improvements:
          passes `webhook-*` annotations through to webhook providers; webhook flags
          are no longer marked experimental.', 'Gateway API: dual-stack support added.',
        'Ambassador Host source: supports annotation/label filters.']
      breaking_changes: ['Unmaintained providers were removed in v0.15.0; if you rely
          on one of the dropped in-tree providers, you must stay on an older ExternalDNS
          version or migrate to a webhook provider implementation.', Infoblox **in-tree**
          provider was removed; use the new **Infoblox webhook provider** instead.,
        'GRPCRoute client updated from `v1alpha2` to stable `v1`; if you use GRPCRoute-related
          features, validate your Gateway API CRDs/versions and manifests accordingly.']
    chart_version: 1.15.0
    images: ['registry.k8s.io/external-dns/external-dns:v0.15.0']
  - version: 0.14.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["Helm chart release referenced as \u201CReleased chart for v0.13.6\u201D\
          \ (PR #3917). No explicit values schema changes were included in the provided\
          \ notes, so assume chart defaults may have shifted with image/tag bump;\
          \ verify with `helm diff` and the chart\u2019s `values.yaml` between your\
          \ chart versions.", 'Container image continues to be published as `registry.k8s.io/external-dns/external-dns:<tag>`;
          v0.13.1 and v0.14.0 both use registry.k8s.io (align your image repository
          overrides if you still use k8s.gcr.io).', "(From the v0.13.1 notes you included)\
          \ the Helm chart added support for configuring `dnsPolicy` for the Deployment\
          \ and changed Deployment update strategy to `Recreate` to avoid multiple\
          \ external-dns pods conflicting\u2014ensure this matches your availability\
          \ expectations during upgrades."]
      features: ['Webhook provider is officially supported in v0.14.0, enabling out-of-tree
          provider implementations and a mode to run external-dns as a webhook server
          (`--webhook-server`).', 'New CLI flags: `--exclude-record-types` to prevent
          managing specific DNS record types, and `--label-filter` support for the
          node source.', 'Provider/source enhancements: Azure AAAA (IPv6) record support;
          Linode NS record support; target-annotation support expanded across more
          sources; Gateway/Gateway API improvements including annotation target override
          on Gateway.', 'Operational/observability: new metric `external_dns_controller_last_reconcile_timestamp_seconds`
          for tracking last reconcile time.']
      breaking_changes: ['`--run-aws-provider-as-webhook` flag was removed in v0.14.0;
          if you used it, migrate to the new webhook provider model and/or `--webhook-server`
          as appropriate.', 'Build/runtime environment change: external-dns is now
          built with Go 1.21; if you depend on custom builds/plugins or strict base-image
          compliance scanning, re-validate.', 'Behavioral changes worth validating:
          AWS Alias records are represented as record type A; ClusterIP services with
          `internal-hostname` annotation now use ServiceIP; these may affect record
          outputs in some setups.']
    chart_version: 1.14.3
    images: ['registry.k8s.io/external-dns/external-dns:v0.14.0']
  - version: 0.13.1
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart behavior changes to check\n- **Deployment\
        \ strategy changed to `Recreate`** (chart change). If you previously relied\
        \ on rolling updates, note that upgrades will now terminate the old pod before\
        \ starting the new one to avoid multiple external-dns instances conflicting.\n\
        - **New chart value to set `dnsPolicy`** on the Deployment (added in the Helm\
        \ chart). Review whether you need a non-default policy (e.g., `ClusterFirstWithHostNet`\
        \ when using `hostNetwork: true`).\n- **Image registry moved toward `registry.k8s.io`**\
        \ (manifests mention this). Ensure any private registry mirroring / image\
        \ policies allow `registry.k8s.io/external-dns/external-dns:v0.13.1`.\n\n\
        ### Upgrade notes (operational)\n- If upgrading from **v0.12.0\u2013v0.12.2**,\
        \ be aware of the known bug where deletions could incorrectly trigger TXT\
        \ record deletions; ensure you are not running an affected build before/while\
        \ upgrading or validate TXT ownership records after the upgrade."
      chart_updates: [Helm chart supports configuring `dnsPolicy` on the Deployment.,
        Deployment update strategy set to `Recreate` to prevent multiple pods conflicting
          during upgrades., Chart/manifests updated to newer ExternalDNS image versions
          and to use `registry.k8s.io` image registry in deployment YAML.]
      features: ['Target filtering can be based on network, improving control over
          which endpoints are considered.', 'AWS provider supports ExternalID when
          assuming a role, improving compatibility with stricter IAM setups.', 'New
          DNS providers added: Tencent Cloud and Plural DNS.', 'Gateway API dependency
          upgraded (v0.5.0), improving Gateway API route source support compatibility.']
      breaking_changes: [Deployment strategy change to `Recreate` alters rollout behavior;
          expect brief downtime during upgrades and ensure only one replica is used
          to avoid provider conflicts., Image registry change to `registry.k8s.io`
          may break clusters with strict image allowlists or mirroring configurations
          unless updated.]
    chart_version: 1.12.0
    images: ['k8s.gcr.io/external-dns/external-dns:v0.13.1']
  - version: 0.12.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Helm chart release:** the ExternalDNS chart was published\
        \ as **v1.8.0** during this app release cycle.\n- **New chart value/field:**\
        \ `shareProcessNamespace` was added to the Deployment spec (allows setting\
        \ `spec.template.spec.shareProcessNamespace`). If you don\u2019t need it,\
        \ you can ignore it; if you do, set it explicitly.\n- No other Helm values\
        \ changes are clearly called out in the provided notes (the rest are docs/CI\
        \ fixes or app/provider changes)."
      chart_updates: [Helm chart published/released as **v1.8.0**., Deployment template
          now supports setting `shareProcessNamespace`., 'Minor chart/documentation
          fixes (e.g., installation command line correction).']
      features: [New **Gateway API route sources** support (can generate DNS records
          from Gateway API routes)., New **IBM Cloud DNS provider**., New **registry
          record type** support (enhances record ownership/registry behavior)., 'Headless
          Service enhancements: can set target to `NodeExternalIP` or via annotation.',
        'RFC2136 security improvement: Kerberos password is no longer exposed in logs.',
        OpenShift Route source improved by using Route status more effectively., 'Istio
          improvements: reuse existing VirtualService informer and add debug logging
          when endpoints are missing.']
      breaking_changes: ['**Known critical bug in v0.12.0:** deletions of Kubernetes
          resources may incorrectly trigger deletion of TXT records (affects deletions,
          not additions) when upgrading from earlier versions. Mitigate by postponing
          upgrade, being ready to manually recreate records, or downgrading; fix tracked
          in PR #2811.', "Potential behavior changes for specific providers due to\
          \ dependency/client migrations (e.g., Infoblox client v2) \u2014 validate\
          \ in staging if you use these providers."]
    chart_version: 1.10.1
    images: ['k8s.gcr.io/external-dns/external-dns:v0.12.0']
  - version: 0.11.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart behavior changes to consider\n- **New\
        \ value: `txtSuffix`** (PR #2488). If you need a non-default TXT ownership\
        \ record name (e.g., to avoid collisions across clusters), set this explicitly;\
        \ otherwise defaults apply.\n- **New scheduling option: `topologySpreadConstraints`\
        \ support** (PR #2484). No action required unless you want to enforce zone/host\
        \ spreading.\n- **Deployment annotations supported** (PR #2477). If you need\
        \ to add custom annotations (e.g., for Prometheus scraping, Vault injection,\
        \ etc.), use the new values fields.\n- **RBAC expands for additional sources**\
        \ (PR #2468) and restores service read perms when Istio sources are enabled\
        \ (PR #2415) plus **Istio gateway permissions** (PR #2564). If you previously\
        \ had to add custom RBAC to make certain sources work, you may be able to\
        \ remove those overrides.\n- **Chart documentation fix for `logLevel` valid\
        \ options** (PR #2626). Double-check your configured `logLevel` matches the\
        \ documented/accepted values.\n\n> Note: The app release notes include a \u201C\
        feat(chart): Update chart to use v0.10.2\u201D entry; ensure your helm chart\
        \ version actually targets external-dns **v0.11.0** when doing the upgrade."
      chart_updates: ['RBAC updates: added cluster role permissions for other sources;
          restored/added permissions needed for Istio-related sources (services +
          istio-gateway).', Helm chart gained `txtSuffix` value for TXT registry ownership
          records., Helm chart gained support for `topologySpreadConstraints` on the
          Deployment., Helm chart allows adding annotations to the Deployment., Helm
          chart docs corrected the list of valid `logLevel` options.]
      features: [RFC2136 provider now supports creating/updating NS records (useful
          for delegations managed via RFC2136)., 'OpenShift Route source now has an
          event handler, improving responsiveness/updates when Routes change.', New
          SafeDNS provider added., 'BlueCat provider enhancements: supports proxy
          env vars and adds new CLI options including full deploy functionality.',
        'AWS improvements: CloudFront canonical hosted zone added and additional tests/behavior
          around routing policies; AWS SD provider cleanup improvements.']
      breaking_changes: ['No explicit breaking changes are called out in the provided
          v0.11.0 notes; most changes are additive (RBAC, providers, chart values)
          plus dependency bumps.', 'Potential operational change: image base updated
          (Alpine 3.15) and Go version bumped to 1.17; if you have strict runtime/compliance
          constraints, re-validate the image and behavior in your environment.']
    chart_version: 1.9.0
    images: ['k8s.gcr.io/external-dns/external-dns:v0.11.0']
  - version: 0.10.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['External-DNS upstream added an official Helm chart in v0.10.0
          (PR #2208). If you were previously deploying via raw manifests/kustomize
          or a third-party chart, decide whether to migrate to the new chart and reconcile
          values/RBAC/serviceAccount naming accordingly.', "Kustomize tooling in the\
          \ repo was bumped (kustomize v0.9.0) and the repo includes various CI/security\
          \ tooling additions (CodeQL, Trivy, Dependabot). These don\u2019t affect\
          \ runtime directly but may change how you consume/build manifests if you\
          \ vendor them."]
      features: [Official Helm chart added upstream (new supported install path).,
        Controller updated for Kubernetes v1.22 to use networking.k8s.io/v1 Ingress
          API (improves compatibility on newer clusters)., Security posture improvements
          via dependency bumps and base image fixes (alpine vulnerabilities) which
          may reduce CVE findings.]
      breaking_changes: ['Ingress handling updated toward networking.k8s.io/v1; if
          your cluster is <1.19 or you still rely on extensions/v1beta1 or networking.k8s.io/v1beta1
          Ingress, validate API availability and your Ingress manifests before upgrading.',
        'If switching to the newly introduced official Helm chart, treat it as a deployment/migration
          change: flags/args mapping, resource names, and RBAC may differ from your
          current installation method.']
    chart_version: 1.3.2
    images: ['k8s.gcr.io/external-dns/external-dns:v0.10.0']
  - version: 0.9.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16', '1.15', '1.14', '1.13',
      '1.12', '1.11', '1.10']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.2.0
    images: ['k8s.gcr.io/external-dns/external-dns:v0.9.0']
  name: external-dns
- icon: https://avatars.githubusercontent.com/u/52158677?s=200&v=4
  git_url: https://github.com/fluxcd/flux2
  release_url: https://github.com/fluxcd/flux2/releases/tag/v{vsn}
  helm_repository_url: https://fluxcd-community.github.io/helm-charts
  chart_name: flux2
  versions:
  - version: 2.7.0
    kube: ['1.35', '1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 2.6.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 2.5.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary: null
  name: flux
- icon: https://github.com/pluralsh/plural-artifacts/blob/main/ingress-nginx/plural/icons/nginx.png?raw=true
  git_url: https://github.com/kubernetes/ingress-nginx
  release_url: https://github.com/kubernetes/ingress-nginx/releases/tag/controller-v{vsn}
  helm_repository_url: https://kubernetes.github.io/ingress-nginx
  versions:
  - version: 1.14.1
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart behavior changes (1.14.0 \u2192 1.14.1)\n\
        No Helm values changes are called out in the provided notes for **controller-v1.14.1**.\n\
        \n> Reminder: **v1.14.0** introduced a chart change: `controller.extraInitContainers`\
        \ became **templatable**. If you set `controller.extraInitContainers`, verify\
        \ your values still render correctly (they may now support templating functions/`tpl`).\n"
      chart_updates: [No chart-specific updates are mentioned for controller-v1.14.1
          in the provided release notes; changes are primarily image/dependency/CI
          updates., (Context from v1.14.0) Chart added `controller.metrics.serviceMonitor.scrapeTimeout`
          and made `controller.extraInitContainers` templatable; ensure your values
          file accounts for these if you use ServiceMonitor or extra init containers.]
      features: ['Custom error pages: fix to avoid writing the status code too early
          (improves correctness of custom error responses).', 'Controller: improved
          host/path overlap detection when multiple rules are present (reduces incorrect
          overlap warnings/behavior in complex Ingresses).']
      breaking_changes: [No explicit breaking changes are documented for controller-v1.14.1
          in the provided notes. (Most changes are image and dependency bumps.)]
    chart_version: 4.14.1
    images: ['registry.k8s.io/ingress-nginx/controller:v1.14.1@sha256:f95a79b85fb93ac3de752c71a5c27d5ceae10a18b61904dec224c1c6a4581e47',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.6.5@sha256:03a00eb0e255e8a25fa49926c24cde0f7e12e8d072c445cdf5136ec78b546285']
  - version: 1.14.0
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm chart values / behavior changes to review\nFrom the\
        \ notes you provided, these are the chart-facing additions/changes between\
        \ the controller versions you\u2019re upgrading across (1.13.0 \u2192 1.14.0):\n\
        \n- **`controller.metrics.serviceMonitor.scrapeTimeout` (new)**\n  - If you\
        \ use Prometheus Operator `ServiceMonitor`, you can now explicitly set `scrapeTimeout`.\n\
        \  - Action: decide whether to set this (leave unset to keep default behavior).\n\
        \n- **`controller.service.trafficDistribution` (new earlier in 1.13.x line)**\n\
        \  - Adds chart support to configure Kubernetes Service traffic distribution.\n\
        \  - Action: only relevant if you want zone-aware/alternative traffic distribution;\
        \ otherwise leave default.\n\n- **`controller.service.external.labels` and\
        \ `controller.service.internal.labels` (new earlier in 1.13.x line)**\n  -\
        \ Lets you add labels directly onto the created Services.\n  - Action: if\
        \ you previously patched labels post-install, consider moving them into values.\n\
        \n- **`controller.admissionWebhooks.certManager.*.revisionHistoryLimit` (new\
        \ earlier in 1.13.x line)**\n  - Action: review if you run cert-manager-based\
        \ webhook cert management and want to control rollout history.\n\n- **`runtimeClassName`\
        \ support (new earlier in 1.13.x line)**\n  - Action: if you use gVisor/Kata\
        \ or custom runtime classes, you can now set it via values.\n\n- **`activeDeadlineSeconds`\
        \ (new earlier in 1.13.x line)**\n  - Applies to Jobs (notably webhook patch/certgen\
        \ jobs).\n  - Action: set if you have strict job execution time policies.\n\
        \n- **Extra init containers templatable (1.14.0)**\n  - Chart now templates\
        \ extra init containers rather than treating them as static snippets.\n  -\
        \ Action: if you use `extraInitContainers`, re-render manifests (`helm template`)\
        \ and ensure output matches expectations.\n\n- **Resize policy added (1.14.0)**\n\
        \  - Chart includes container resize policy support.\n  - Action: verify this\
        \ does not conflict with cluster policy/PSA/OPA rules.\n\n- **Webhook patch\
        \ job volumes added (1.14.0)**\n  - Chart adds volumes for the admission webhook\
        \ patch job.\n  - Action: ensure your cluster policies allow these volumes;\
        \ check restricted environments.\n\n- **Chart pushes to OCI registry (1.14.0)**\n\
        \  - Distribution change: charts are available via OCI.\n  - Action: if you\
        \ pin chart sources, update your retrieval method (e.g., `helm pull oci://...`).\n\
        \n> Note: Your pasted notes are *controller* release notes, which include\
        \ some \u201CChart:\u201D entries. They do **not** include the full Helm chart\
        \ changelog for the chart version you\u2019ll actually upgrade to (e.g., v4.13.x\
        \ \u2192 v4.14.x). Before executing the upgrade, also review the **chart release\
        \ notes** for the exact chart versions in use."
      chart_updates: ['Controller image updated to v1.14.0 (and chroot variant), including
          NGINX base bumps to v2.2.x and Alpine base bumps (3.22.x).', 'Status handling
          improved: supports multiple Node IP addresses when publishing ingress status.',
        'Admission/webhook and chart plumbing updated: extra init containers are templatable;
          webhook patch job gains volumes; new ServiceMonitor scrapeTimeout knob;
          resize policy support; chart distribution via OCI.', 'Security and robustness
          improvements: panic handling in service deletion handler; hardened socket
          creation; path validation nil-pointer fix; stronger cipher preference ordering.']
      features: ['SSL Proxy now supports **PROXY protocol v2**, enabling richer client
          connection metadata when running behind compatible load balancers/proxies.',
        'Ingress status reporting can now handle **multiple node IPs**, improving
          correctness on multi-NIC / multi-address nodes.', 'Ingress path validation
          now allows a `.` character in `Exact` and `Prefix` paths, expanding valid
          routing patterns.', Chart adds optional `ServiceMonitor` `scrapeTimeout`
          configuration for Prometheus Operator users.]
      breaking_changes: ['Removal of a default value: `proxy-busy-buffers-size` default
          was removed (and related fixes followed). If you relied on the old implicit
          default, set it explicitly in the ConfigMap/values to preserve behavior.',
        "\u201CBye bye, v1.11.\u201D indicates end-of-support for older Kubernetes/legacy\
          \ compatibility paths (exact minimum supported Kubernetes not stated in\
          \ your paste). Validate your cluster version meets the supported matrix\
          \ for controller v1.14.0 before upgrading."]
    chart_version: 4.14.0
    images: ['registry.k8s.io/ingress-nginx/controller:v1.14.0@sha256:e4127065d0317bd11dc64c4dd38dcf7fb1c3d72e468110b4086e636dbaac943d',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.6.4@sha256:bcfc926ed57831edf102d62c5c0e259572591df4796ef1420b87f9cf6092497f']
  - version: 1.13.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm/chart values you likely need to review\n\n### 1) Metrics\
        \ are **disabled by default** (important)\nFrom the 1.12 line, the controller\
        \ changed its default CLI flags:\n- `--enable-metrics` is now **disabled by\
        \ default**.\n\n**Impact:** If you rely on Prometheus scraping, ServiceMonitor,\
        \ dashboards, or alerts, you must explicitly re-enable metrics.\n\n**What\
        \ to do (Helm):** set the chart values that enable metrics for your deployment\
        \ (commonly under `controller.metrics.*`). In 1.12, the chart also introduced\
        \ `controller.metrics.service.enabled` \u2014 confirm it is `true` if you\
        \ want the metrics Service.\n\n### 2) ServiceMonitor / Prometheus integration\
        \ changed in chart\nThe 1.12 line includes chart work:\n- \u201CChart: Rework\
        \ ServiceMonitor\u201D\n- New `controller.metrics.prometheusRule.annotations`\n\
        \n**Impact:** If you use Prometheus Operator, re-check your existing `ServiceMonitor`/`PrometheusRule`\
        \ values and labels/selectors after upgrade.\n\n### 3) New/changed chart knobs\
        \ introduced between 1.12 and 1.13\nFrom the 1.13 line, notable chart values\
        \ include:\n- `controller.service.trafficDistribution` (ties to the new traffic\
        \ distribution feature)\n- `controller.service.external.labels` and `controller.service.internal.labels`\n\
        - `controller.admissionWebhooks.certManager.*.revisionHistoryLimit`\n- `runtimeClassName`\n\
        - `activeDeadlineSeconds`\n\n**Impact:** Mostly additive (not required), but\
        \ if you need these behaviors you can now configure them via values. Also,\
        \ \u201CRemove validation for removed API\u201D suggests older API checks\
        \ were dropped; if you had custom validation expectations, re-test.\n\n###\
        \ 4) PodSecurityPolicy removed from the chart (already in 1.12)\n- \u201C\u26A0\
        \uFE0F Chart: Remove Pod Security Policy\u201D\n\n**Impact:** If you were\
        \ relying on PSP objects from the chart (older clusters), they won\u2019t\
        \ be installed anymore. Ensure you have PSA (Pod Security Admission) or alternative\
        \ policies in place.\n\n### 5) OpenTelemetry init container removed (chart/app\
        \ packaging)\n- \u201C\u26A0\uFE0F Images: Remove OpenTelemetry\u201D (init\
        \ container/image removed; module is built into controller image since v1.10)\n\
        \n**Impact:** If you previously enabled the chart\u2019s OTel init container/image,\
        \ that path is gone; validate your OTel configuration still works with the\
        \ built-in module approach.\n\n## Recommended upgrade checks (values-focused)\n\
        - Confirm `controller.metrics.enabled` (or equivalent in your values) is explicitly\
        \ set the way you want.\n- If using Prometheus Operator, validate `ServiceMonitor`/`PrometheusRule`\
        \ values after the ServiceMonitor rework.\n- If you used PSP, remove PSP-related\
        \ values/resources and ensure PSA policies allow the controller to run.\n\
        - If you used OTel via init container/image, migrate to built-in module configuration.\n"
      chart_updates: [Controller image updated from v1.12.0 to v1.13.0 (new controller
          and chroot images)., NGINX/OpenResty base updated (OpenResty bumped to v1.27.1.x;
          NGINX base and related images bumped through 2.x series)., 'Chart additions:
          `controller.service.trafficDistribution`, service labels for external/internal
          services, `runtimeClassName`, `activeDeadlineSeconds`, and cert-manager
          admission webhook revisionHistoryLimit settings.', 'Chart maintenance: removed
          validation for an already-removed API; multiple bumps of kube-webhook-certgen
          and test runner images.', Ongoing security and dependency updates (Go toolchain
          bumped to 1.24.x in v1.13.0 line; controller includes several security fixes
          in 1.12.x).]
      features: [Traffic distribution support added to the controller (and exposed
          via chart value `controller.service.trafficDistribution`)., NGINX now adds
          an `X-Original-Forwarded-Host` header to preserve the original forwarded
          host., Improved client IP determination in NGINX for more accurate real
          client address handling., NJS (NGINX JavaScript) support added to the NGINX
          build used by ingress-nginx., 'Annotations/security hardening: deny newlines
          in annotations; reload on custom header changes (improves correctness when
          headers are updated).']
      breaking_changes: ['Metrics are disabled by default (`--enable-metrics` now
          defaults to false). If you scrape controller metrics, you must explicitly
          re-enable them via Helm values/args.', 'Security defaults were tightened
          in the 1.12 line: annotation validation enabled by default, cross-namespace
          resources disallowed by default, stricter path type validation enabled.
          This can break previously-working but unsafe configurations.', Global rate
          limit feature was removed (config keys and related annotations no longer
          exist). Any Ingress using those annotations will stop working as intended.,
        'Third-party Lua plugin support was removed (`plugins` config and `/etc/nginx/lua/plugins`
          loading). If you relied on custom Lua plugins, they will no longer be executed.',
        PodSecurityPolicy resources were removed from the Helm chart; clusters depending
          on PSP must migrate to PSA/other policy mechanisms., OpenTelemetry init
          container/image was removed from the deployment packaging; OTel must be
          configured using the built-in module approach.]
    chart_version: 4.13.0
    images: ['registry.k8s.io/ingress-nginx/controller:v1.13.0@sha256:dc75a7baec7a3b827a5d7ab0acd10ab507904c7dad692365b3e3b596eca1afd2',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.6.0@sha256:c9f76a75fd00e975416ea1b73300efd413116de0de8570346ed90766c5b5cefb']
  - version: 1.12.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm chart / values changes to review (1.11.0 \u279C 1.12.0)\n\
        \n### 1) Metrics are **disabled by default** (breaking)\nThe controller CLI\
        \ flag default changed:\n- `--enable-metrics` is now **disabled by default**.\n\
        \n**Action:** if you scrape Prometheus metrics today, explicitly enable them\
        \ in Helm values.\n- Look for a value such as `controller.metrics.enabled:\
        \ true` (or `controller.extraArgs.enable-metrics: \"true\"` depending on your\
        \ current values/chart).\n\n### 2) New chart knob for metrics Service\n- New\
        \ value: `controller.metrics.service.enabled`\n\n**Action:** if you rely on\
        \ a Service for scraping, ensure it\u2019s enabled and matches your scrape\
        \ method (ServiceMonitor vs annotations).\n\n### 3) ServiceMonitor changes\
        \ (may require values updates)\n- Chart: **Rework ServiceMonitor**.\n\n**Action:**\
        \ if you use Prometheus Operator, re-check your `controller.metrics.serviceMonitor.*`\
        \ values (labels/namespace/selector) and run a `helm template` diff to confirm\
        \ the generated ServiceMonitor still matches your Prometheus selectors.\n\n\
        ### 4) Pod Security Policy resources removed (breaking for PSP users)\n- Chart:\
        \ **Remove Pod Security Policy**.\n\n**Action:** if your cluster still uses\
        \ PSP admission (older clusters), you must replace PSP with Pod Security Admission\
        \ (PSA) / alternative controls before upgrade.\n\n### 5) OpenTelemetry init\
        \ container removed (chart behavior change)\n- Chart/Images: **Remove OpenTelemetry\
        \ (init container/image)**; OTel module is already built into the controller\
        \ image since v1.10.\n\n**Action:** if you previously enabled an OTel initContainer\
        \ via chart values, remove/disable that configuration and validate your OTel\
        \ config still works without the init step.\n\n### 6) Global image registry\
        \ option added\n- New value: `global.image.registry`\n\n**Action:** if you\
        \ mirror images to a private registry, you can now set this once globally\
        \ instead of overriding per-image fields.\n\n### 7) New/changed miscellaneous\
        \ chart knobs\n- `controller.progressDeadlineSeconds`\n- `controller.admissionWebhooks.service.servicePort`\n\
        - `controller.admissionWebhooks.service.servicePort`\n- `unhealthyPodEvictionPolicy`\
        \ support\n- Default backend PDB alignment and knobs:\n  - `defaultBackend.maxUnavailable`\n\
        \n**Action:** optional; only set if you need custom rollout/deadline or disruption\
        \ behavior.\n\n### 8) Chart cleanup\n- Chart: Remove `isControllerTagValid`\
        \ (internal chart validation).\n\n**Action:** if you had automation relying\
        \ on that value, remove it from your values file.\n"
      chart_updates: [Metrics now disabled by default (controller flag default change).,
        Controller image updated to v1.12.0; underlying base images bumped (notably
          Alpine 3.21) and Go toolchain updates., 'Chart includes several operational
          enhancements: ServiceMonitor rework, more unit tests, topology spread guidance,
          PDB alignment, and rollout deadline option.', 'Security posture changes
          ship with 1.12.0 (annotation validation on by default, stricter defaults).']
      features: [Native histogram support for histogram metrics (improves Prometheus
          histogram handling when enabled)., New `--metrics-per-undefined-host` option
          to control metrics cardinality for undefined hosts., CORS origins now allow
          any protocol (more flexible CORS configuration)., 'New docs/guides added
          (e.g., maintenance page, Pod Security Admission, AWS health check annotations).']
      breaking_changes: [Metrics are disabled by default (`--enable-metrics` now defaults
          to false); you must explicitly enable if you scrape metrics., "Security\
          \ defaults tightened: annotation validation enabled by default; `allow-cross-namespace-resources`\
          \ disabled by default; `strict-validate-path-type` enabled by default; default\
          \ `annotations-risk-level` lowered to High\u2014this can cause previously-accepted\
          \ Ingresses/annotations to be rejected.", Global rate limit feature removed
          (config keys and related annotations removed); remove any usage before upgrading.,
        3rd-party Lua plugin support removed (the `plugins` config option and `/etc/nginx/lua/plugins`
          user plugin mechanism no longer works)., PodSecurityPolicy resources removed
          from the Helm chart; clusters depending on PSP must migrate to PSA/other
          controls., s390x image support dropped; cannot run controller on s390x nodes.,
        Metric `ingress_upstream_latency_seconds` removed; dashboards/alerts must
          be updated if they reference it., 'OpenTelemetry init container/image removed
          from the chart; if you relied on it, update your values and validate OTel
          configuration.']
    chart_version: 4.12.0
    images: ['registry.k8s.io/ingress-nginx/controller:v1.12.0@sha256:e6b8de175acda6ca913891f0f727bca4527e797d52688cbe9fec9040d6f6b6fa',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.5.0@sha256:aaafd456bda110628b2d4ca6296f38731a3aaf0bf7581efae824a41c770a8fc4']
  - version: 1.11.0
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / values changes to review\n- **Removed value:** `controller.enableWorkerSerialReloads`\
        \ was removed in the chart (`Chart: Remove controller.enableWorkerSerialReloads`).\
        \ If you set it previously, **delete it** from your values; decide if there\
        \ is a replacement value in newer chart docs for worker reload behavior.\n\
        - **Templating changes (may affect custom values):**\n  - `controller.config`\
        \ is now templatable. If you were using literal strings that look like templates\
        \ (`{{ }}`), they may now render; validate rendered ConfigMap output.\n  -\
        \ `controller.podAffinity` (pod affinity) is now templatable. Same caveat\
        \ as above; check rendered pod spec.\n- **Admission webhook patch job RBAC\
        \ is configurable.** If you have restricted clusters, review the new RBAC-related\
        \ values and ensure your security posture matches expectations.\n- **IngressClass\
        \ related chart changes:**\n  - Fixed `IngressClass` annotations.\n  - Accept\
        \ user-defined annotations in `IngressClass`.\n  - Added **IngressClass aliases**.\n\
        \  - `controller.ingressClassResource.parameters` is rendered natively (may\
        \ change YAML output vs string templating). Re-render and compare manifests\
        \ if you set this.\n- **KEDA/HPA behavior:**\n  - Align HPA & KEDA conditions\
        \ and deploy `PodDisruptionBudget` with KEDA. If you use KEDA, verify PDB\
        \ and scaling objects after upgrade.\n- **Default backend:** topologySpreadConstraints\
        \ support and related unit tests. If you run the default backend, confirm\
        \ scheduling behavior matches expectations."
      chart_updates: ['Chart: Remove `controller.enableWorkerSerialReloads`.', 'Chart:
          Make `controller.config` templatable.', 'Chart: Make pod affinity templatable.',
        'Chart: Fix `IngressClass` annotations.', 'Chart: Make admission webhook patch
          job RBAC configurable.', 'Chart: Accept user-defined annotations in IngressClass;
          add IngressClass aliases.', 'Chart: Render `controller.ingressClassResource.parameters`
          natively.', 'Chart: Align HPA & KEDA conditions; deploy PDB with KEDA.',
        'Default backend: add topologySpreadConstraints support and sort HPA metrics.']
      features: [NGINX bumped to 1.25.5 and HTTP/3 module added (new capability; requires
          QUIC/UDP 443 exposure and client support)., 'New annotations for gRPC timeouts,
          plus ConfigMap support for gRPC buffer size.', New annotation allowing custom
          response headers to be added., GeoIP2 auto_reload configuration support.,
        'Leader election improvements: TTL configurable and option/flag to disable
          leader election.']
      breaking_changes: ['Do **not** use controller v1.11.0 with **OCSP stapling enabled**
          due to a known serious issue; use a patched 1.11.x release containing the
          fix (referenced PR #11594) instead.', Chart value `controller.enableWorkerSerialReloads`
          was removed; upgrades will fail lint/templating if your values still reference
          it., 'TLS hardening change: TLSv1 and TLSv1.1 were removed; clients requiring
          those protocols will no longer connect.', Minimum Kubernetes version requirement
          is stated as 1.21; clusters older than that are unsupported.]
    chart_version: 4.11.0
    images: ['registry.k8s.io/ingress-nginx/controller:v1.11.0@sha256:a886e56d532d1388c77c8340261149d974370edca1093af4c97a96fb1467cb39',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366']
  - version: 1.10.1
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm / values changes to watch\n- **IngressClass parameters\
        \ rendering changed:** `controller.ingressClassResource.parameters` is now\
        \ rendered *natively* by the chart. If you were templating/quoting this field\
        \ in values to work around earlier behavior, re-check the resulting `IngressClass`\
        \ manifest after upgrade.\n- **Metrics flag behavior:** chart sets `--enable-metrics`\
        \ based on `controller.metrics.enabled`. Ensure your values align with your\
        \ expectations (especially if you previously set args manually).\n- **Autoscaling\
        \ objects alignment:** HPA and KEDA conditions were aligned; if you use KEDA\
        \ autoscaling, validate generated resources and conditions.\n- **PDB with\
        \ KEDA:** chart now deploys a `PodDisruptionBudget` when KEDA is enabled;\
        \ confirm this doesn\u2019t conflict with any existing PDBs you manage.\n\
        - No explicit required values changes were called out for 1.10.1 specifically;\
        \ most 1.10.1 chart items are tests/docs/CI."
      chart_updates: ['Chart: Render `controller.ingressClassResource.parameters`
          natively.', 'Chart: Align HPA & KEDA conditions.', 'Chart: Deploy `PodDisruptionBudget`
          with KEDA enabled.', 'Chart: Improve IngressClass documentation.', 'Chart:
          Add unit tests for default backend & topology spread constraints; sort default
          backend HPA metrics (no functional change expected).']
      features: ['Reintroduced/available **chroot controller image** in v1.10.1 (`controller-chroot:v1.10.1`),
          addressing the 1.10.0 note that chroot was not supported.', Improved admission
          controller logging to include `admissionTime` and `testedConfigurationSize`
          for better troubleshooting.]
      breaking_changes: ['From **v1.10.0** (still relevant when upgrading to 1.10.1):
          chroot image was not supported in 1.10.0 (fixed in 1.10.1).', 'From **v1.10.0**:
          Opentracing and Zipkin modules were removed; only OpenTelemetry is supported.',
        'From **v1.10.0**: PodSecurityPolicy support was dropped.', 'From **v1.10.0**:
          Legacy GeoIP was dropped; only GeoIP2 is supported.']
    chart_version: 4.10.1
    images: ['registry.k8s.io/ingress-nginx/controller:v1.10.1@sha256:e24f39d3eed6bcc239a56f20098878845f62baa34b9f2be2fd2c38ce9fb0f29e',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.1@sha256:36d05b4077fb8e3d13663702fa337f124675ba8667cbd949c03a8e8ea6fa4366']
  - version: 1.10.0
    kube: ['1.29', '1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['**Chart behavior change (metrics flag):** The Helm chart now
          sets the controller argument `--enable-metrics` based on `controller.metrics.enabled`
          (instead of always/never or requiring manual extraArgs). This came in via
          PR #10959.', '**kube-webhook image tag fix:** Chart/release fixes the `kube-webhook-certgen`
          image tag handling (PR #11033/#11034).', '**PrometheusRule manifest updated:**
          `controller-prometheusrules.yaml` updated (PR #8902), which can change the
          resulting PrometheusRule resources if you enable them.']
      features: ['**NGINX upgraded to 1.25:** Controller now ships with NGINX 1.25,
          bringing the upstream NGINX changes/perf/security updates with it.', '**OCSP
          responder improvements:** Proper support for a TLS-wrapped OCSP responder,
          improving TLS/OCSP stapling edge cases.', '**Annotation completeness:**
          Adds a missing `backend-protocol` annotation option, improving compatibility
          with certain backend protocols/configs.', '**Dashboard/monitoring fixes:**
          Grafana dashboard datasource/exported namespace variable fixes and updated
          Prometheus rules improve observability out of the box.']
      breaking_changes: ['**No chroot image in 1.10.0:** The `controller-chroot` image
          is not supported in this release (promised to return in a later minor patch).',
        '**Tracing modules removed:** OpenTracing and Zipkin NGINX modules were dropped;
          only OpenTelemetry is supported moving forward.', '**PodSecurityPolicy removed:**
          PSP support is dropped; clusters relying on PSP manifests/values must migrate
          to alternatives (e.g., PSA + RBAC).', '**Legacy GeoIP removed:** GeoIP (legacy)
          support is dropped; only GeoIP2 is supported.']
    chart_version: 4.10.0
    images: ['registry.k8s.io/ingress-nginx/controller:v1.10.0@sha256:42b3f0e5d0846876b1791cd3afeb5f1cbbe4259d6f35651dcc1b5c980925379c',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.4.0@sha256:44d1d0e9f19c63f58b380c5fddaca7cf22c7cee564adeff365225a5df5ef3334']
  - version: 1.9.6
    kube: ['1.29', '1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Controller image changed from v1.9.0 to v1.9.6 (and corresponding
          chroot image digest)., Admission webhook cert generator updated to a newer
          release (v20231226-1a7112e06)., 'Annotation validation tightened: regex
          validation added for the common-name annotation; SSL cipher list validation
          expanded to include SECLEVEL and STRENGTH.', ModSecurity library version
          updated to 3.0.11., "Dependency bump: runc 1.1.10 \u2192 1.1.11.", 'From
          1.9.0 baseline: user snippets are disabled by default; controller base image
          no longer includes curl; annotation validation framework introduced. These
          are the main behavior-impacting changes to be aware of when moving off 1.9.0.']
      features: ['Stricter and more complete validation for annotations (including
          regex checks and SSL cipher list fields), reducing risk of invalid config
          reaching NGINX.', 'Updated admission webhook cert generation tooling, improving
          compatibility and maintenance.', Updated ModSecurity library version (3.0.11)
          for security/stability fixes.]
      breaking_changes: [User-provided NGINX snippets are disabled by default starting
          in 1.9.0; any Ingress relying on snippet annotations will stop working unless
          you explicitly re-enable snippets via controller configuration/values.,
        'The controller image no longer includes curl (since 1.9.0); any custom scripts,
          sidecars, or debug workflows that exec into the controller pod expecting
          curl will fail.']
    chart_version: 4.9.1
    images: ['registry.k8s.io/ingress-nginx/controller:v1.9.6@sha256:1405cc613bd95b2c6edd8b2a152510ae91c7e62aea4698500d23b2145960ab9c',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20231226-1a7112e06@sha256:25d6a5f11211cc5c3f9f2bf552b585374af287b4debf693cacbe2da47daa5084']
  - version: 1.9.0
    kube: ['1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **ServiceMonitor namespace default**: Helm chart now defaults\
        \ `ServiceMonitor.metadata.namespace` to `.Release.Namespace` (previously\
        \ it may have defaulted elsewhere). If you rely on scraping from a different\
        \ namespace, set the chart value explicitly.\n- **DaemonSet/Deployment templating\
        \ fixes**: There were chart template fixes around Deployment/DaemonSet values\
        \ and rendering; re-check any overridden values you pass for these objects.\n\
        - **New Helm capabilities**:\n  - `controller.hostAliases` can now be configured\
        \ via values.\n  - Service annotations are now passed through the Helm `tpl`\
        \ engine (templated strings).\n  - `topologySpreadConstraints` is templated\
        \ for Deployment/DaemonSet; if you set this, validate it renders as expected.\n\
        - **KEDA interaction**: If you enable KEDA, the chart will ignore the Deployment\
        \ template `replicas` field (replicas controlled by KEDA)."
      chart_updates: ['Controller image updated from `registry.k8s.io/ingress-nginx/controller:v1.8.4`
          to `v1.9.0` (and chroot variant accordingly).', Base container image changed
          to remove `curl` (impacts any custom scripts/exec probes relying on curl
          inside the controller container)., AJP support was deprecated/removed in
          the 1.9.0 line (do not rely on AJP module)., 'OpenTelemetry libs updated
          (OTel 1.11.0, gRPC updates) and Go bumped to 1.21.1 (mostly build/runtime
          dependency changes).']
      features: ['User snippets are now **disabled by default**, improving security;
          they must be explicitly enabled if you use snippet annotations.', Ingress
          annotation validation was implemented; invalid annotations may now be rejected
          or warned about instead of being silently accepted., "Optional auth access\
          \ logs support (can reduce log volume if you don\u2019t need auth subrequest\
          \ logs).", New controller flag to enable/disable `aio_write` (advanced NGINX
          performance tuning)., 'Helm chart improvements: configurable `hostAliases`,
          templated service annotations via `tpl`, and support for `topologySpreadConstraints`
          in Deployment/DaemonSet.']
      breaking_changes: ['**User snippets disabled by default**: if you use `nginx.ingress.kubernetes.io/*-snippet`
          annotations, behavior will change until you explicitly re-enable snippets
          in config.', '**`curl` removed from the controller image**: any in-container
          debugging, init scripts, or exec probes that call `curl` will fail unless
          you add your own tooling.', '**AJP support removed**: if you relied on AJP,
          you must migrate to HTTP/HTTPS (or another supported protocol) before upgrading.',
        Annotation validation may cause previously-working but non-conformant annotations
          to be rejected or ignored; test your Ingress manifests against the new validation
          behavior.]
    chart_version: 4.8.0
    images: ['registry.k8s.io/ingress-nginx/controller:v1.9.0@sha256:c15d1a617858d90fb8f8a2dd60b0676f2bb85c54e3ed11511794b86ec30c8c60',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20230407@sha256:543c40fd093964bc9ab509d3e791f9989963021f1e9e4c9c7b6700b02bfb227b']
  - version: 1.8.4
    kube: ['1.27', '1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Controller image updated from v1.7.1 to v1.8.4 (and chroot
          variant), including intermediary 1.8.x patch releases.', Go toolchain updated
          in the 1.8.x line (notably to Go 1.21.1)., Auth access logging made optional
          (newer controller behavior/config surface)., ModSecurity internal processing
          disabled in a way intended to improve handling of large Ingress objects.,
        OpenTelemetry init image promoted to distroless; image tagging/metadata process
          updated., AJP module re-added as a dynamic module (affects those using AJP).,
        'Dependency bumps (e.g., golang.org/x/net) and assorted image bumps.']
      features: ["Optional auth access logs, allowing you to reduce log volume/cost\
          \ if you don\u2019t need per-request auth logging.", Improved behavior for
          large Ingress resources by changing how ModSecurity is handled internally.,
        'Distroless OpenTelemetry init image promotion, which can improve security
          posture and reduce image surface area.', AJP support available again via
          a dynamic module for environments that still rely on AJP upstreams.]
      breaking_changes: ['No explicit breaking changes are called out in the provided
          notes; however, expect behavioral differences due to ModSecurity handling
          changes and auth log defaults if you relied on previous implicit behavior.']
    chart_version: 4.7.3
    images: ['registry.k8s.io/ingress-nginx/controller:v1.8.4@sha256:8d8ddf32b83ca3e74bd5f66369fa60d85353e18ff55fa7691b321aa4716f5ba9',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20231011-8b53cabe0@sha256:a7943503b45d552785aa3b5e457f169a5661fb94d82b8a3373bcd9ebaf9aac80']
  - version: 1.7.1
    kube: ['1.27', '1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm/values changes to check\n- **HPA values fix (Terraform\
        \ compatibility):** Default HPA template now includes an explicit `resource`\
        \ type in the metric spec (PR #9803). If you override `controller.autoscaling.*`,\
        \ re-run `helm template` and validate the rendered `HorizontalPodAutoscaler`\
        \ matches your cluster\u2019s supported API/version.\n- **Custom ports for\
        \ internal service:** Chart adds support to configure **custom port(s)** for\
        \ the controller **internal service** (PR #9846). If you rely on the internal\
        \ service for webhook/health/metrics traffic, review the new values and ensure\
        \ they don\u2019t conflict with your existing `controller.service.*` or NetworkPolicies.\n\
        \n_No other explicit values renames/removals were called out in the provided\
        \ notes, but you should diff your current `values.yaml` against the target\
        \ chart\u2019s `values.yaml` for new defaults around metrics, admission, and\
        \ service configuration._"
      chart_updates: ['Add support for custom port configuration for the controller
          internal service (PR #9846).', 'Adjust default HPA configuration to include
          explicit resource type to avoid issues with Terraform Helm usage (PR #9803).',
        'FastCGI ConfigMap is expected to be in the same namespace as the ingress
          controller (PR #9863).', Docs/README updates and formatting fixes (multiple
          PRs).]
      features: ['Support a new `--container` flag for the controller, improving flexibility
          in container/runtime-related scenarios.', "Helm chart can now customize\
          \ ports on the controller\u2019s internal Service, enabling non-default\
          \ port mappings when needed.", HPA defaults were made more explicit to improve
          compatibility with Terraform-managed Helm deployments.]
      breaking_changes: ["InfluxDB support was deprecated and removed; if you were\
          \ exporting metrics to InfluxDB via built-in support, you\u2019ll need an\
          \ alternative integration.", The deprecated `secure-upstream` annotation
          was removed; any Ingresses using it must be updated to supported annotations/configuration.]
    chart_version: 4.6.1
    images: ['registry.k8s.io/ingress-nginx/controller:v1.7.1@sha256:7244b95ea47bddcb8267c1e625fb163fc183ef55448855e3ac52a7b260a60407',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20230312-helm-chart-4.5.2-28-g66a760794@sha256:01d181618f270f2a96c04006f33b2699ad3ccb02da48d0f89b22abce084b292f']
  - version: 1.6.4
    kube: ['1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- No full Helm chart changelog was provided in the notes you\
        \ pasted, so treat Helm-side changes below as **\u201Cverify in chart changelog\
        \ for v4.5.x\u201D**.\n- From the provided notes, the following **values/schema\
        \ additions** are likely relevant when upgrading the Helm release (review\
        \ your `values.yaml` for collisions with defaults):\n  - `controller.metrics.service.labels`\
        \ was added (you may want to set it if you rely on service discovery labels).\n\
        \  - `controller.autoscaling.annotations` was added (if you use HPA and need\
        \ annotations).\n  - PDB gained `maxUnavailable` support.\n  - defaultBackend\
        \ got `updateStrategy` and `minReadySeconds` knobs.\n  - `controller.ingressClass`\
        \ value was added/fixed (ensure you set this if you rely on a non-default\
        \ class).\n  - Helm can **optionally use cert-manager** instead of the admission\
        \ patch job for webhook certs (new option; choose one approach).\n  - Admission\
        \ webhook job got `NetworkPolicy` support; admission webhook job securityContext\
        \ became configurable.\n  - There was work around pathType validation toggles;\
        \ check whether the chart exposes a value to disable/enable strict validation\
        \ in your version.\n"
      chart_updates: ['Controller image update to `registry.k8s.io/ingress-nginx/controller:v1.6.4`
          (and chroot variant) from `v1.5.1`.', CI/release pipeline and chart linting
          were added/adjusted (no runtime impact but indicates chart packaging changes).,
        Grafana dashboard templates were adjusted to remove hardcoded namespaces/datasources
          (may affect how you import/use dashboards)., HPA API version was bumped
          to `autoscaling/v2` (cluster must support it; Kubernetes 1.23+ generally
          OK)., RBAC was tightened by removing some ConfigMap-related permissions
          (may matter if you had custom workflows expecting those permissions).]
      features: [Support for Kubernetes topology-aware hints (can improve client-side
          load distribution when using services that honor hints)., New Prometheus
          metric for orphaned Ingress objects (`orphan_ingress`) to help detect stale/unused
          Ingress resources., ConfigMap option exposed to disable gzip (`gzip-disable`)
          for easier response compression control., New `ipdenylist` annotation to
          deny traffic from specified IP ranges at the Ingress level., Ability to
          disable creation of sync events (reduces event noise in large clusters).,
        Stream module gained `buildResolvers` (helps with DNS resolution behavior
          for TCP/UDP stream configs)., Profiler address became configurable (helps
          with debugging/performance profiling when needed).]
      breaking_changes: ['If you are on an older Kubernetes version, HPA switching
          to `autoscaling/v2` can break installs/updates (verify your cluster supports
          it).', 'Stricter/changed behavior around Ingress `pathType` validation was
          introduced and then partially reverted/toggled; if you relied on invalid/missing
          `pathType` or regex path edge-cases, re-test your Ingress rules after upgrade.',
        RBAC reduction (removal of some ConfigMap permissions) can break custom automation
          that expected the controller service account to have broader access.]
    chart_version: 4.5.2
    images: ['registry.k8s.io/ingress-nginx/controller:v1.6.4@sha256:15be4666c53052484dd2992efacf2f50ea77a78ae8aa21ccd91af6baaa7ea22f',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f']
  - version: 1.5.1
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Kubernetes version support**: v1.21.x is noted as no longer\
        \ supported (the release notes already mention 1.20\u20131.21 deprecated in\
        \ v1.4.0; v1.5.1 includes an explicit chart changelog note removing 1.21.x\
        \ support). Ensure your clusters are **>= 1.22** (practically: v1.23+ is explicitly\
        \ supported in these notes).\n- **Probes can be disabled (new Helm values)**:\
        \ Helm chart gained the ability to disable controller liveness/readiness probes\
        \ (PR #9238). If you have environments where probes are managed externally\
        \ or cause issues, you can now set the corresponding Helm values to disable\
        \ them (review the chart values for the exact keys in your chart version).\n\
        - **Admission webhooks securityContext configurable (new Helm values)**: You\
        \ can now set a `securityContext` for admission-webhook components via Helm\
        \ values (PR #9186). This matters for hardened clusters/PSA where you need\
        \ explicit settings.\n"
      chart_updates: [Controller switched to using **EndpointSlices** (introduced
          in v1.4.0); verify your cluster has the EndpointSlice API enabled (default
          in modern Kubernetes) and that any RBAC/network policies accommodate it.,
        '**Prometheus metric names changed** (v1.4.0): new/updated histogram & counter
          names, some deprecated/removed metrics. Update dashboards/alerts/scrape
          queries accordingly.', 'Controller image registry is **registry.k8s.io**
          (noted around v1.4.0 timeframe); ensure image allowlists, proxies, and mirroring
          are updated.', 'Upgrades in dependencies/runtime: **NGINX 1.21.6** and **Go
          1.19.2** by v1.5.1.', 'Bugfix: **Service name length** issue fixed (v1.5.1,
          PR #9245).', 'Security: includes fixes for **CVE-2022-32149**, **CVE-2022-27664**,
          **CVE-2022-1996** (v1.5.1).']
      features: [EndpointSlice support (instead of Endpoints) to align with modern
          Kubernetes service discovery and scalability (v1.4.0)., New controller timing
          metrics split into request/connect/header/response duration histograms to
          improve latency visibility (v1.4.0)., Helm chart can now disable liveness/readiness
          probes for the controller (v1.5.1)., Helm chart can now set a securityContext
          for admission-webhook resources to support restricted/hardened clusters
          (v1.5.1).]
      breaking_changes: [Prometheus metrics rename/removal in v1.4.0 can break existing
          Grafana dashboards and alert rules; you must update metric names and types
          (some summaries removed/deprecated)., "Kubernetes version support drops\
          \ older clusters: 1.20\u20131.21 deprecated in v1.4.0 and explicitly marked\
          \ as no longer supported by the chart by v1.5.1; upgrading on 1.21 may fail\
          \ or be unsupported."]
    chart_version: 4.4.2
    images: ['registry.k8s.io/ingress-nginx/controller:v1.5.1@sha256:4ba73c697770664c1e00e9f968de14e08f606ff961c76e5d7033a4a9c593c629',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f']
  - version: 1.4.0
    kube: ['1.25', '1.24', '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Controller now uses EndpointSlices instead of Endpoints to discover
          backends., Leader election in 1.3.1 is Lease-only (no ConfigMaps); 1.3.0
          was the transition release., 'Prometheus metrics have been renamed/reshaped;
          several histograms added/updated, some summaries/histograms deprecated/removed.',
        "Kubernetes version support updated: 1.20\u20131.21 deprecated; 1.25 supported;\
          \ supported set called out as 1.23\u20131.25.", Images moved/standardized
          to registry.k8s.io (note broader k8s.gcr.io -> registry.k8s.io migration
          notice)., Go toolchain bumped (1.19 in 1.3.1; 1.19.1 in 1.4.0); base image
          updates (Alpine 3.16.2 in 1.3.1)., New annotation added for sticky cookie
          domain., PSP-related job patch logic avoided on Kubernetes 1.25+., Metrics
          port name can be parameterized (relevant if you scrape by port name).]
      features: ['Backend discovery uses EndpointSlices, improving scalability on
          clusters with many endpoints.', New/updated Prometheus histograms for request/connect/header/response
          timings and request/response sizes., New annotation to set the sticky session
          cookie domain.]
      breaking_changes: ['Prometheus metric names changed; some metrics were deprecated/removed
          (e.g., ingress_upstream_header_seconds summary removed), so dashboards/alerts
          and scrape rules may break until updated.', "Clusters on Kubernetes 1.20\u2013\
          1.21 are now deprecated for this controller line; plan to run on 1.23+ (and\
          \ 1.25 supported) before/with the upgrade.", 'Leader election behavior changed
          in 1.3.1 to Lease-only; if you ever skipped 1.3.0 during the earlier migration
          window, validate no legacy ConfigMap lock assumptions remain.']
    chart_version: 4.3.0
    images: ['registry.k8s.io/ingress-nginx/controller:v1.4.0@sha256:34ee929b111ffc7aa426ffd409af44da48e5a0eea1eb2207994d9e0c0882d143',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20220916-gd32f8c343@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f']
  - version: 1.3.1
    kube: ['1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 4.2.5
    images: ['registry.k8s.io/ingress-nginx/controller:v1.3.1@sha256:54f7fe2c6c5a9db9a0ebf1131797109bb7a4d91f56b9b362bde2abd237dd1974',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.3.0@sha256:549e71a6ca248c5abd51cdb73dbc3083df62cf92ed5e6147c780e30f7e007a47']
  name: ingress-nginx
- icon: https://raw.githubusercontent.com/pluralsh/plural-artifacts/main/istio/plural/icons/istio.png?raw=true
  git_url: https://github.com/istio/istio
  release_url: https://github.com/istio/istio/releases/tag/{vsn}
  helm_repository_url: https://istio-release.storage.googleapis.com/charts
  chart_name: istiod
  versions:
  - version: 1.28.0
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.28.0
    images: ['docker.io/istio/pilot:1.28.0']
  - version: 1.27.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.27.0
    images: ['docker.io/istio/pilot:1.27.0']
  - version: 1.26.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.26.0
    images: ['docker.io/istio/pilot:1.26.0']
  - version: 1.25.0
    kube: ['1.32', '1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.25.0
    images: ['docker.io/istio/pilot:1.25.0']
  - version: 1.24.0
    kube: ['1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.24.0
    images: ['docker.io/istio/pilot:1.24.0']
  - version: 1.23.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.23.0
    images: ['docker.io/istio/pilot:1.23.0']
  - version: 1.22.0
    kube: ['1.30', '1.29', 1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.22.0
    images: ['docker.io/istio/pilot:1.22.0']
  - version: 1.21.0
    kube: ['1.29', 1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.21.0
    images: ['docker.io/istio/pilot:1.21.0']
  - version: 1.20.0
    kube: ['1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.20.0
    images: ['docker.io/istio/pilot:1.20.0']
  - version: 1.18.0
    kube: ['1.27', '1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.18.0
    images: ['docker.io/istio/pilot:1.18.0']
  - version: 1.17.0
    kube: ['1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.17.0
    images: ['docker.io/istio/pilot:1.17.0']
  - version: 1.16.0
    kube: ['1.25', '1.24', '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.16.0
    images: ['docker.io/istio/pilot:1.16.0']
  - version: 1.14.0
    kube: ['1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.14.0
    images: ['docker.io/istio/pilot:1.14.0']
  - version: 1.13.0
    kube: ['1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.13.0
    images: ['docker.io/istio/pilot:1.13.0']
  - version: 1.12.0
    kube: ['1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.12.0
    images: ['docker.io/istio/pilot:1.12.0']
  - version: 1.11.0
    kube: ['1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 1.9.0
    kube: ['1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 1.8.0
    kube: ['1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 1.7.0
    kube: ['1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 1.1.0
    kube: ['1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary: null
  name: istio
- icon: https://avatars.githubusercontent.com/u/28545596?s=200&v=4
  git_url: https://github.com/jaegertracing/jaeger
  release_url: https://github.com/jaegertracing/jaeger/releases/tag/v{vsn}
  helm_repository_url: https://jaegertracing.github.io/helm-charts
  versions:
  - version: 1.62.0
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22',
      '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.61.0
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22',
      '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.60.0
    kube: ['1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22',
      '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.59.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.57.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.56.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.55.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.54.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.53.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19']
    requirements: []
    incompatibilities: []
    chart_version: 0.74.1
  - version: 1.52.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.51.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19']
    requirements: []
    incompatibilities: []
    chart_version: 0.72.0
  - version: 1.50.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.49.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.48.0
    kube: ['1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.47.0
    kube: ['1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.46.0
    kube: ['1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.45.0
    kube: ['1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    chart_version: 0.71.0
  - version: 1.44.0
    kube: ['1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.43.0
    kube: ['1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.42.0
    kube: ['1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    chart_version: 0.69.0
  - version: 1.41.0
    kube: ['1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.40.0
    kube: ['1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.39.0
    kube: ['1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    chart_version: 0.65.2
  - version: 1.38.0
    kube: ['1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.37.0
    kube: ['1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    chart_version: 0.58.0
  - version: 1.36.0
    kube: ['1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    chart_version: 0.57.0
  - version: 1.35.0
    kube: ['1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.34.0
    kube: ['1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  - version: 1.33.0
    kube: ['1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
  name: jaeger
- icon: https://d3g9o9u8re44ak.cloudfront.net/logo/55cad6f2-84cb-49a7-9d60-265f7e4ea91e/8a67fa7b-85bd-44e4-823c-d7d5690777b1.png
  git_url: https://github.com/aws/karpenter-provider-aws
  release_url: https://github.com/aws/karpenter-provider-aws/releases/tag/v{vsn}
  helm_repository_url: oci://public.ecr.aws/karpenter/karpenter
  helm_values: settings.clusterName=example
  versions:
  - version: 1.8.0
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.8.0
    images: ['public.ecr.aws/karpenter/controller:1.8.0@sha256:f913075cdd31cfcdfaa9726ca7a0b264832fc42e8a48eb573a2a0f454b38b112']
  - version: 1.6.0
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm/values changes to check before upgrading\n- **`settings.clusterName`\
        \ is now required**: the chart will **fail to install/upgrade** if this value\
        \ is not set. Ensure your `values.yaml` (or `--set`) includes it.\n- **ServiceMonitor\
        \ enhancements**: if you use the chart\u2019s `ServiceMonitor`, you can now\
        \ configure **`relabelings`** and **`metricRelabelings`**. No change required\
        \ unless you want to use these new fields.\n- **Default security context updated**:\
        \ the chart improved the **default pod/container security context**. If you\
        \ have strict Pod Security Admission / PSP-style policies, verify the rendered\
        \ manifests still comply with your cluster\u2019s requirements.\n- **runAsNonRoot\
        \ removed in chart**: the chart **removed `runAsNonRoot`** to support more\
        \ restricted pod security profiles. If you relied on `runAsNonRoot: true`,\
        \ you may need to explicitly set your own security context via values.\n"
      chart_updates: [Improved default security context in the Helm chart., Chart
          now validates configuration and fails installation if `settings.clusterName`
          is missing., ServiceMonitor template extended to support `relabelings` and
          `metricRelabelings`., Chart securityContext defaults adjusted (including
          removal of `runAsNonRoot`).]
      features: ['Support for AWS KWOK, including delayed registration support for
          simulated nodes.', Capacity Block support (useful for reserving/using pre-purchased
          EC2 capacity blocks)., "Automatically \u201CICE\u201D (temporarily exclude)\
          \ AZs when subnets in that AZ run out of available IPs, improving resilience\
          \ during IP exhaustion events.", 'Additional Bottlerocket configuration
          options, including more log settings and soft eviction support.', '`volumeInitializationRate`
          support for EBS `blockDeviceMappings`, allowing control of EBS initialization
          performance.', "Support for automatically relaxing minimum values in certain\
          \ scheduling/validation paths (reduces unnecessary failures when strict\
          \ mins can\u2019t be met)."]
      breaking_changes: [Kubernetes **1.25 support is dropped**. Clusters on 1.25
          must upgrade Kubernetes before upgrading Karpenter provider to v1.6.0.,
        Helm chart now **requires `settings.clusterName`**; upgrades/installs will
          fail if it is not provided.]
    chart_version: 1.6.0
    images: ['public.ecr.aws/karpenter/controller:1.6.0@sha256:37c761a3a0b485fd34db1390317ef6149141f532c5a699c528b98fb8f9cc722a']
  - version: 1.5.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **Helm install now requires `settings.clusterName`:** the chart
        will fail to install/upgrade if `settings.clusterName` is not set. Ensure
        your `values.yaml` (or `--set`) includes it.

        - **ServiceMonitor enhancements (if you use Prometheus Operator):** the chart
        added support for `relabeling` and `metricRelabeling` on the ServiceMonitor.
        No action required unless you want to use these fields.

        - **Default security context changed:** chart defaults were tightened/improved.
        If you previously relied on running as root or looser permissions, verify
        pod security settings/PSA/PSP compatibility and override `securityContext`/`podSecurityContext`
        only if needed.'
      chart_updates: [Improved/tightened default controller pod security context.,
        Chart validates presence of `settings.clusterName` and fails installation
          if missing., ServiceMonitor template updated to support `relabelings` and
          `metricRelabelings` fields (Prometheus Operator users).]
      features: [Stricter/safer Helm chart defaults (security context) and better
          chart validation (requires `settings.clusterName`)., 'Bottlerocket support
          improvements: soft eviction support and a new `single-process-oom-kill`
          setting, plus additional kubelet configuration test coverage.', 'New NodeClass
          storage option: `volumeInitializationRate` on EBS `blockDeviceMappings`,
          enabling more control over EBS volume initialization performance.']
      breaking_changes: [Kubernetes 1.25 support was dropped; clusters running 1.25
          must be upgraded before moving to these versions., Helm chart installation/upgrade
          can fail if `settings.clusterName` is not set; this is an intentional enforcement
          change.]
    chart_version: 1.5.0
    images: ['public.ecr.aws/karpenter/controller:1.5.0@sha256:339aef3f5ecdf6f94d1c7cc9d0e1d359c281b4f9b842877bdbf2acd3fa360521']
  - version: 1.2.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Supports IAM role paths (useful if your org creates roles like /team/role-name
          instead of flat names)., CRDs can now be installed with optional custom
          annotations., Adds support for a Node Monitoring Agent feature area (node
          health/repair related integrations).]
      breaking_changes: []
    chart_version: 1.2.0
    images: ['public.ecr.aws/karpenter/controller:1.2.0@sha256:24b8fe57f02b70fc4ab3cd6d5aa0d73a6f3d0c62ca5d23d7ffc8853eac01e324']
  - version: 1.0.5
    kube: ['1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.0.5
    images: ['public.ecr.aws/karpenter/controller:1.0.5@sha256:f2df98735b232b143d37f0c6819a6cae2be4740e3c8b38297bceb365cf3f668b']
  - version: 0.37.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / chart-related notes (what to watch during the upgrade)\n\
        \n- **CRD upgrade required (v0.37.0)**: v0.37.0 explicitly notes it **adds\
        \ a readiness condition to `EC2NodeClass`**, which means the **`EC2NodeClass`\
        \ CRD changes** and you must ensure CRDs are upgraded before/with the controller.\n\
        \  - In practice: apply the new CRDs first (or use the chart\u2019s CRD mechanism\
        \ if you manage them that way), then upgrade the Helm release.\n- **ServiceMonitor\
        \ template fix (v0.37.0)**: a chart bug fix corrects **ServiceMonitor indentation**.\
        \ If you use Prometheus Operator/ServiceMonitors, re-check that the rendered\
        \ YAML is valid and that metrics scraping works post-upgrade.\n- **Avoid duplicated\
        \ \u201CAH\u201D config (v0.37.0)**: chart bug fix notes an update to avoid\
        \ duplicating **AH config** (exact setting name not shown in your snippet).\
        \ If you\u2019ve set related values, compare rendered manifests before/after.\n\
        - **Helm generation bugs existed earlier (v0.34.0)**: v0.34.0 includes fixes\
        \ where Helm chart generation didn\u2019t run correctly for v0.33.0. This\
        \ is mainly historical, but it\u2019s a reminder to rely on the **version-matched\
        \ chart** for your target controller.\n\n> You didn\u2019t include the intermediate\
        \ v0.35.x/v0.36.x Helm changelog text, so double-check Helm values diffs for\
        \ those versions as well when you run the upgrade."
      chart_updates: ['v0.37.0: Adds a readiness condition to `EC2NodeClass` (CRD
          update required).', 'v0.37.0: Chart bug fix for ServiceMonitor indentation
          (Prometheus Operator users should validate rendered manifests).', 'v0.37.0:
          Chart change to avoid duplicating AH config in the rendered release (verify
          related values/templating in your environment).', 'v0.34.0: Release includes
          fixes related to Helm chart generation issues present in v0.33.0 (mostly
          historical but emphasizes using the correct chart/version).']
      features: ['`build_info` Prometheus metric added (version/sha/golang_version
          labels) to help with observability and troubleshooting.', Support for mounted
          instance-store ephemeral storage (useful for workloads needing local ephemeral
          disks)., Ability to select instance types by **EBS maximum bandwidth** (more
          precise performance-based scheduling)., Interruption action metric now includes
          a **nodepool label** (better attribution of interruption handling)., Additional
          Bottlerocket Kubernetes configuration fields supported (more flexibility
          for Bottlerocket nodes).]
      breaking_changes: [v0.37.0 requires a **CRD upgrade** because `EC2NodeClass`
          gains a **readiness condition**; upgrading the controller without updating
          CRDs can break reconciliation or leave resources in an unexpected state.,
        'Release notes mention a **BREAKING CHANGE: Refactor NodeClass controller**
          (internal behavior around NodeClass reconciliation may change; validate
          NodeClass/NodePool lifecycle in a staging cluster and watch logs/events
          after upgrade).']
    chart_version: 0.37.0
    images: ['public.ecr.aws/karpenter/controller:0.37.0@sha256:157f478f5db1fe999f5e2d27badcc742bf51cc470508b3cebe78224d0947674f']
  - version: 0.34.0
    kube: ['1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.34.0
    images: []
  - version: 0.31.0
    kube: ['1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.31.0
    images: []
  - version: 0.28.0
    kube: ['1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.25.0
    kube: ['1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
  name: karpenter
- icon: https://avatars.githubusercontent.com/u/49917779?s=48&v=4
  git_url: https://github.com/kedacore/keda
  release_url: https://github.com/kedacore/keda/releases/tag/v{vsn}
  helm_repository_url: https://kedacore.github.io/charts
  versions:
  - version: 2.18.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.18.0
  - version: 2.17.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.17.0
  - version: 2.16.0
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.16.0
  - version: 2.15.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.15.0
  - version: 2.14.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.14.2
  - version: 2.13.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.13.1
  - version: 2.12.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.12.0
  - version: 2.11.0
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.11.0
  - version: 2.10.0
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.10.1
  - version: 2.9.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.9.0
  - version: 2.8.0
    kube: ['1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.8.1
  - version: 2.7.0
    kube: ['1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.7.0
  name: keda
- icon: https://github.com/pluralsh/plural-artifacts/blob/main/monitoring/plural/icons/monitoring.png?raw=true
  git_url: https://github.com/prometheus-community/helm-charts
  release_url: https://github.com/prometheus-community/helm-charts/releases/tag/kube-prometheus-stack-{vsn}
  readme_url: https://raw.githubusercontent.com/prometheus-community/helm-charts/main/charts/kube-prometheus-stack/README.md
  helm_repository_url: https://prometheus-community.github.io/helm-charts
  chart_changelog_url: https://raw.githubusercontent.com/prometheus-community/helm-charts/refs/heads/main/charts/kube-prometheus-stack/UPGRADE.md
  versions:
  - version: 80.10.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Updated etcd image digest to `65b1be4` (chart maintenance/renovate-driven
          change)., Updated kube-prometheus-stack chart dependencies (non-major updates)
          via Renovate.]
      features: []
      breaking_changes: []
    chart_version: 80.10.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.3.1', 'ghcr.io/jkroepke/kube-webhook-certgen:1.7.4',
      'quay.io/kiwigrid/k8s-sidecar:2.1.2', 'quay.io/prometheus-operator/prometheus-operator:v0.87.1',
      'quay.io/prometheus/alertmanager:v0.30.0', 'quay.io/prometheus/node-exporter:v1.10.2',
      'quay.io/prometheus/prometheus:v3.8.1', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 80.9.2
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Grafana Operator YAML dashboards: add `folderRef` and `folderUID`
          fields (80.8.0).', Dependency bumps / non-major dependency updates via Renovate
          (80.9.2).]
      features: ['Grafana Operator dashboard manifests now support `folderRef`/`folderUID`,
          enabling dashboards to be organized into specific Grafana folders when using
          the Grafana Operator.']
      breaking_changes: []
    chart_version: 80.9.2
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.3.1', 'ghcr.io/jkroepke/kube-webhook-certgen:1.7.4',
      'quay.io/kiwigrid/k8s-sidecar:2.1.2', 'quay.io/prometheus-operator/prometheus-operator:v0.87.1',
      'quay.io/prometheus/alertmanager:v0.30.0', 'quay.io/prometheus/node-exporter:v1.10.2',
      'quay.io/prometheus/prometheus:v3.8.1', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 80.8.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Grafana Operator YAML dashboards now include `folderRef` and
          `folderUID` fields (PR #6428).', "No other chart template/value changes\
          \ are mentioned in the 80.7.0\u219280.8.0 release notes; 80.7.0 was primarily\
          \ CI/dependency non-major updates."]
      features: ['Grafana Operator dashboard resources can now set/retain the target
          folder via `folderRef`/`folderUID`, improving organization and reducing
          reliance on default folder placement.']
      breaking_changes: []
    chart_version: 80.8.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.3.0', 'ghcr.io/jkroepke/kube-webhook-certgen:1.7.3',
      'quay.io/kiwigrid/k8s-sidecar:2.1.2', 'quay.io/prometheus-operator/prometheus-operator:v0.87.1',
      'quay.io/prometheus/alertmanager:v0.30.0', 'quay.io/prometheus/node-exporter:v1.10.2',
      'quay.io/prometheus/prometheus:v3.8.1', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 80.7.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Dependency updates only (non-major) for kube-prometheus-stack
          in 80.7.0 (PR #6437).', 'CI-only change: super-linter action bumped to v8.3.2
          (PR #6436); no runtime impact.']
      features: []
      breaking_changes: []
    chart_version: 80.7.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.3.0', 'ghcr.io/jkroepke/kube-webhook-certgen:1.7.3',
      'quay.io/kiwigrid/k8s-sidecar:2.1.2', 'quay.io/prometheus-operator/prometheus-operator:v0.87.1',
      'quay.io/prometheus/alertmanager:v0.30.0', 'quay.io/prometheus/node-exporter:v1.10.2',
      'quay.io/prometheus/prometheus:v3.8.1', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 80.6.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Chart release 80.6.0 only includes non-major dependency updates
          via Renovate (PR #6426).']
      features: [No user-facing features called out in the release notes; this is
          a dependency refresh.]
      breaking_changes: [No breaking changes mentioned in the provided release notes.]
    chart_version: 80.6.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.3.0', 'ghcr.io/jkroepke/kube-webhook-certgen:1.7.3',
      'quay.io/kiwigrid/k8s-sidecar:2.1.2', 'quay.io/prometheus-operator/prometheus-operator:v0.87.1',
      'quay.io/prometheus/alertmanager:v0.30.0', 'quay.io/prometheus/node-exporter:v1.10.2',
      'quay.io/prometheus/prometheus:v3.8.1', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 80.5.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["Bumps the kube-prometheus-stack chart\u2019s dependencies with\
          \ non-major updates (Renovate PR #6425). No chart template/logic changes\
          \ called out in the release notes beyond dependency updates."]
      features: [No new end-user features are mentioned in the 80.5.0 chart release
          notes; this appears to be a dependency refresh.]
      breaking_changes: [No breaking changes are mentioned in the 80.5.0 chart release
          notes.]
    chart_version: 80.5.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.3.0', 'ghcr.io/jkroepke/kube-webhook-certgen:1.7.3',
      'quay.io/kiwigrid/k8s-sidecar:2.1.2', 'quay.io/prometheus-operator/prometheus-operator:v0.87.1',
      'quay.io/prometheus/alertmanager:v0.30.0', 'quay.io/prometheus/node-exporter:v1.10.2',
      'quay.io/prometheus/prometheus:v3.8.1', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 80.4.2
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- No Helm values changes are called out for the **80.4.1 \u2192\
        \ 80.4.2** patch upgrade.\n- (Context only) If you are upgrading from much\
        \ older versions into the 80.x line, ensure you followed the 79\u219280 notes:\
        \ Prometheus Operator is **v0.87.0** in 80.x and CRDs must be upgraded (either\
        \ via `crds.upgradeJob.enabled` or manual `kubectl apply --server-side` of\
        \ the CRDs)."
      chart_updates: ['**80.4.1**: Allow unsetting the Prometheus service reloader
          port (chart template change).', '**80.4.2**: Dependency non-major updates
          for kube-prometheus-stack (renovate-driven).', "**80.4.2**: CI-only change\
          \ (super-linter action bump) \u2014 no runtime impact."]
      features: ["Prometheus Service: you can now unset/omit the config-reloader port\
          \ on the Prometheus Service (useful if you don\u2019t want that port exposed/allocated)."]
      breaking_changes: ["None mentioned for 80.4.1 \u2192 80.4.2; this is a patch-level\
          \ release with CI and dependency non-major updates."]
    chart_version: 80.4.2
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.3.0', 'ghcr.io/jkroepke/kube-webhook-certgen:1.7.3',
      'quay.io/kiwigrid/k8s-sidecar:2.1.2', 'quay.io/prometheus-operator/prometheus-operator:v0.87.1',
      'quay.io/prometheus/alertmanager:v0.30.0', 'quay.io/prometheus/node-exporter:v1.10.2',
      'quay.io/prometheus/prometheus:v3.8.1', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 80.4.1
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
      '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / upgrade actions (80.2.0 \u2192 80.4.1)\n\n\
        - **No explicit value renames/deprecations called out** in the provided changelog\
        \ entries for 80.2.0\u201380.4.1.\n- **CRDs/Operator note (applies to all\
        \ 80.x upgrades):** 80.x upgrades Prometheus Operator to **v0.87.0**. Helm\
        \ does not upgrade CRDs automatically, so you must either:\n  - enable the\
        \ chart\u2019s CRD upgrade job: `crds.upgradeJob.enabled=true`, **or**\n \
        \ - manually apply the CRDs *before* `helm upgrade` using the upstream manifests\
        \ (v0.87.0):\n\n```bash\nkubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_alertmanagerconfigs.yaml\n\
        kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_alertmanagers.yaml\n\
        kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_podmonitors.yaml\n\
        kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_probes.yaml\n\
        kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_prometheusagents.yaml\n\
        kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_prometheuses.yaml\n\
        kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_prometheusrules.yaml\n\
        kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_scrapeconfigs.yaml\n\
        kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_servicemonitors.yaml\n\
        kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_thanosrulers.yaml\n\
        ```\n"
      chart_updates: [80.x line uses Prometheus Operator v0.87.0 (drives the CRD update
          requirement)., '80.2.0: kube-state-metrics Helm subchart updated to major
          version v7 (review if you override kube-state-metrics values heavily).',
        '80.4.1: allows unsetting the **prometheus service reloader port** (minor
          chart behavior/templating change).']
      features: [kube-state-metrics subchart bumped to v7 (potentially newer kube-state-metrics
          behavior and defaults)., "Option to unset the reloader port on the Prometheus\
          \ Service (helps when you don\u2019t want that port exposed/created)."]
      breaking_changes: ["No breaking changes were explicitly listed for 80.2.0\u2013\
          80.4.1 in the provided notes. The main operational risk is **CRD mismatch**\
          \ if you upgrade the operator to v0.87.0 without upgrading the CRDs first."]
    chart_version: 80.4.1
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.3.0', 'ghcr.io/jkroepke/kube-webhook-certgen:1.7.3',
      'quay.io/kiwigrid/k8s-sidecar:2.1.2', 'quay.io/prometheus-operator/prometheus-operator:v0.87.1',
      'quay.io/prometheus/alertmanager:v0.29.0', 'quay.io/prometheus/node-exporter:v1.10.2',
      'quay.io/prometheus/prometheus:v3.8.0', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 80.2.0
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
      '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / upgrade actions (79.12.0 \u2192 80.2.0)\n\n\
        - **Prometheus Operator CRDs must be upgraded to v0.87.0 before the Helm upgrade**\
        \ (Helm does not upgrade CRDs automatically).\n  - Option A (recommended if\
        \ you want the chart to handle it): enable the CRD upgrade job:\n    ```yaml\n\
        \    crds:\n      upgradeJob:\n        enabled: true\n    ```\n  - Option\
        \ B (traditional/manual): apply the v0.87.0 CRDs server-side before `helm\
        \ upgrade`:\n    ```bash\n    kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_alertmanagerconfigs.yaml\n\
        \    kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_alertmanagers.yaml\n\
        \    kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_podmonitors.yaml\n\
        \    kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_probes.yaml\n\
        \    kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_prometheusagents.yaml\n\
        \    kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_prometheuses.yaml\n\
        \    kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_prometheusrules.yaml\n\
        \    kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_scrapeconfigs.yaml\n\
        \    kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_servicemonitors.yaml\n\
        \    kubectl apply --server-side -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/v0.87.0/example/prometheus-operator-crd/monitoring.coreos.com_thanosrulers.yaml\n\
        \    ```\n\n- **No other values changes are called out in the provided 79.x\
        \ \u2192 80.x upgrade notes.**\n"
      chart_updates: [Prometheus Operator bumped to **v0.87.0** in the 80.x line (from
          the 79.x line)., 'Subchart dependency update in 80.2.0: **kube-state-metrics
          Helm release bumped to v7**.']
      features: [Optional **CRD upgrade job** (`crds.upgradeJob.enabled`) remains
          available as an alternative to manually applying CRDs during upgrades.,
        Updated bundled components via dependency bumps (notably kube-state-metrics
          chart v7 in 80.2.0).]
      breaking_changes: ['**CRD version change with Prometheus Operator v0.87.0**:
          you must upgrade the `monitoring.coreos.com` CRDs before upgrading the chart,
          otherwise the operator may not start or reconcile resources correctly.',
        "Potential behavior changes from **kube-state-metrics chart v7** (dependency\
          \ bump); if you have custom kube-state-metrics values, review that subchart\u2019\
          s changelog for any renamed/removed settings."]
    chart_version: 80.2.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.3.0', 'quay.io/kiwigrid/k8s-sidecar:2.1.2',
      'quay.io/prometheus-operator/prometheus-operator:v0.87.0', 'quay.io/prometheus/alertmanager:v0.29.0',
      'quay.io/prometheus/node-exporter:v1.10.2', 'quay.io/prometheus/prometheus:v3.8.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.6.5', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 79.12.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['kube-prometheus-stack: updated etcd image digest to `cf5a571`
          (PR #6381).', 'kube-prometheus-stack 79.8.2: bumped `prometheus-node-exporter`
          chart dependency to `v4.49.2` (PR #6358).']
      features: []
      breaking_changes: []
    chart_version: 79.12.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.3.0', 'quay.io/kiwigrid/k8s-sidecar:2.1.2',
      'quay.io/prometheus-operator/prometheus-operator:v0.86.2', 'quay.io/prometheus/alertmanager:v0.29.0',
      'quay.io/prometheus/node-exporter:v1.10.2', 'quay.io/prometheus/prometheus:v3.8.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.6.5', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 79.8.2
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
      '1.25']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 79.8.2
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.3.0', 'quay.io/kiwigrid/k8s-sidecar:1.30.10',
      'quay.io/prometheus-operator/prometheus-operator:v0.86.2', 'quay.io/prometheus/alertmanager:v0.29.0',
      'quay.io/prometheus/node-exporter:v1.10.2', 'quay.io/prometheus/prometheus:v3.7.3',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.6.4', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 79.5.0
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
      '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 78.5.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["No chart-specific changes are called out in the provided release\
          \ notes for either endpoint version; both releases are described only as\
          \ \u201CUpdate kube-prometheus-stack dependency non-major updates\u201D.",
        Plan for routine dependency bumps across subcharts/images/dashboards/rules;
          validate rendered manifests diff and run a canary upgrade in a non-prod
          cluster.]
      features: [No explicit new features are listed in the provided notes; changes
          appear to be dependency non-major updates only.]
      breaking_changes: [No breaking changes are mentioned in the provided notes;
          treat as low-risk but still verify CRDs and component compatibility after
          dependency bumps.]
    chart_version: 78.5.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.2.0', 'quay.io/kiwigrid/k8s-sidecar:1.30.10',
      'quay.io/prometheus-operator/prometheus-operator:v0.86.1', 'quay.io/prometheus/alertmanager:v0.28.1',
      'quay.io/prometheus/node-exporter:v1.9.1', 'quay.io/prometheus/prometheus:v3.7.2',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.6.3', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 77.14.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["Both 76.5.1 and 77.14.0 release notes only mention \u201CUpdate\
          \ kube-prometheus-stack dependency non-major updates\u201D via Renovate;\
          \ no explicit chart template/resource changes are called out in the provided\
          \ notes."]
      features: [No new user-facing features are described in the provided release
          notes; changes are limited to non-major dependency updates.]
      breaking_changes: [No breaking changes are mentioned in the provided release
          notes.]
    chart_version: 77.14.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.1.1', 'quay.io/kiwigrid/k8s-sidecar:1.30.10',
      'quay.io/prometheus-operator/prometheus-operator:v0.85.0', 'quay.io/prometheus/alertmanager:v0.28.1',
      'quay.io/prometheus/node-exporter:v1.9.1', 'quay.io/prometheus/prometheus:v3.6.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.6.3', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.17.0']
  - version: 76.5.1
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['75.18.1: Fixes the `prometheus.additionalScrapeConfigs` example
          in chart documentation/templates (no functional behavior change unless you
          were copying the broken example).', "76.5.1: Updates kube-prometheus-stack\
          \ chart dependencies with non-major version bumps (via Renovate). This can\
          \ change the rendered manifests due to upstream chart changes even if this\
          \ chart\u2019s own values schema is unchanged."]
      features: []
      breaking_changes: []
    chart_version: 76.5.1
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.1.0', 'quay.io/kiwigrid/k8s-sidecar:1.30.3',
      'quay.io/prometheus-operator/prometheus-operator:v0.84.1', 'quay.io/prometheus/alertmanager:v0.28.1',
      'quay.io/prometheus/node-exporter:v1.9.1', 'quay.io/prometheus/prometheus:v3.5.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.6.1', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.16.0']
  - version: 75.18.1
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 75.18.1
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.1.0', 'quay.io/kiwigrid/k8s-sidecar:1.30.3',
      'quay.io/prometheus-operator/prometheus-operator:v0.83.0', 'quay.io/prometheus/alertmanager:v0.28.1',
      'quay.io/prometheus/node-exporter:v1.9.1', 'quay.io/prometheus/prometheus:v3.5.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.6.0', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.16.0']
  - version: 74.2.2
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Chart includes maintenance-level updates: updated etcd image
          digest; refreshed kube-prometheus-stack dependency versions (non-major updates);
          CI/packaging change to bump Chart.yaml when only subdirectories change.',
        'From 73.2.3: changed default behavior to ignore EROFS (read-only filesystem)
          errors by default (likely affects node-exporter/collector error handling).']
      features: [Improved robustness by ignoring EROFS errors by default (reduces
          noisy scrape/collector errors on read-only filesystems).]
      breaking_changes: []
    chart_version: 74.2.2
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.0.1', 'quay.io/kiwigrid/k8s-sidecar:1.30.0',
      'quay.io/prometheus-operator/prometheus-operator:v0.83.0', 'quay.io/prometheus/alertmanager:v0.28.1',
      'quay.io/prometheus/node-exporter:v1.9.1', 'quay.io/prometheus/prometheus:v3.4.1',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.5.4', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0']
  - version: 73.2.3
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Admission webhook match conditions**: Chart now supports\
        \ setting `matchConditions` for `admissionWebhooks` objects (added in 72.9.1).\
        \ If you need fine-grained webhook matching, add the corresponding values\
        \ under the chart\u2019s `admissionWebhooks` configuration.\n- **Node-exporter\
        \ filesystem collector tweak**: Chart now **ignores `erofs` by default** (73.2.3).\
        \ If you previously relied on `erofs` metrics, you may need to override the\
        \ node-exporter filesystem ignore/mount filtering values to re-include it.\n"
      chart_updates: [Added ability to specify `matchConditions` for admission webhooks
          objects., Adjusted node-exporter defaults to ignore `erofs` filesystem type
          by default (bugfix/defaults change).]
      features: ['Configurable `matchConditions` for admission webhooks, enabling
          more precise selection of which API requests the webhook should evaluate.']
      breaking_changes: ['Potential behavior change: node-exporter will no longer
          report filesystem metrics for `erofs` by default; environments using EROFS
          (e.g., some container/image setups) may see those metrics disappear unless
          you override the ignore settings.']
    chart_version: 73.2.3
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.0.1', 'quay.io/kiwigrid/k8s-sidecar:1.30.0',
      'quay.io/prometheus-operator/prometheus-operator:v0.82.2', 'quay.io/prometheus/alertmanager:v0.28.1',
      'quay.io/prometheus/node-exporter:v1.9.1', 'quay.io/prometheus/prometheus:v3.4.1',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.5.4', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0']
  - version: 72.9.1
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **New optional value for webhooks:** You can now specify `matchConditions`\
        \ for `admissionWebhooks` objects (added in chart **72.9.1**). If you customize\
        \ the chart\u2019s admission webhooks, review/extend your values to include\
        \ this field where needed.\n\n_No other Helm values changes are called out\
        \ in the provided notes._"
      chart_updates: ['Chart **72.9.1**: adds support for configuring `matchConditions`
          on admission webhook objects.', 'Chart **71.2.0**: CI tooling change (GitHub
          action version bump) and routine non-major dependency updates (no functional
          chart behavior called out).']
      features: ['Ability to set `matchConditions` for admission webhooks, allowing
          more granular control over when the webhook is invoked.']
      breaking_changes: []
    chart_version: 72.9.1
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:12.0.0-security-01',
      'quay.io/kiwigrid/k8s-sidecar:1.30.0', 'quay.io/prometheus-operator/prometheus-operator:v0.82.2',
      'quay.io/prometheus/alertmanager:v0.28.1', 'quay.io/prometheus/node-exporter:v1.9.1',
      'quay.io/prometheus/prometheus:v3.4.1', 'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.5.3',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0']
  - version: 71.2.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["The 70.10.0 \u2192 71.2.0 chart bump is primarily dependency\
          \ refreshes (non\u2011major) and CI workflow updates; no functional chart\
          \ template changes are called out in the provided release snippets."]
      features: [No user-facing features are described in the provided 70.10.0 and
          71.2.0 release notes; changes are dependency/automation related.]
      breaking_changes: [No breaking changes are mentioned in the provided release
          notes.]
    chart_version: 71.2.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:11.6.1', 'quay.io/kiwigrid/k8s-sidecar:1.30.0',
      'quay.io/prometheus-operator/prometheus-operator:v0.82.0', 'quay.io/prometheus/alertmanager:v0.28.1',
      'quay.io/prometheus/node-exporter:v1.9.1', 'quay.io/prometheus/prometheus:v3.3.1',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.5.3', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0']
  - version: 70.10.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [No chart template/value changes called out in the provided release
          notes for this version jump., 70.10.0 notes indicate CI maintenance (actions/setup-python
          bump) and routine dependency non-major updates via Renovate., 69.8.2 notes
          indicate an Alertmanager image/version bump to 0.28.1.]
      features: [Alertmanager version updated to 0.28.1 (from the 69.8.2 notes in
          your snippets)., Ongoing dependency refreshes in 70.10.0 (non-major) which
          may include patch/minor updates of subcharts/images.]
      breaking_changes: []
    chart_version: 70.10.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:11.6.1', 'quay.io/kiwigrid/k8s-sidecar:1.30.0',
      'quay.io/prometheus-operator/prometheus-operator:v0.81.0', 'quay.io/prometheus/alertmanager:v0.28.1',
      'quay.io/prometheus/node-exporter:v1.9.1', 'quay.io/prometheus/prometheus:v3.3.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.5.2', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0']
  - version: 69.8.2
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Regenerated kube-prometheus mixins as part of the chart content
          (dashboards/rules) to fix the mixin update script and ensure generated artifacts
          are up to date (68.5.0)., Bumped bundled Alertmanager version to v0.28.1
          (69.8.2).]
      features: [Alertmanager updated to v0.28.1 as shipped with the chart (may include
          upstream bugfixes and minor improvements from Alertmanager).]
      breaking_changes: []
    chart_version: 69.8.2
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:11.5.2', 'quay.io/kiwigrid/k8s-sidecar:1.30.0',
      'quay.io/prometheus-operator/prometheus-operator:v0.80.1', 'quay.io/prometheus/alertmanager:v0.28.1',
      'quay.io/prometheus/node-exporter:v1.9.0', 'quay.io/prometheus/prometheus:v3.2.1',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.5.1', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0']
  - version: 68.5.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['68.5.0: Fix the mixin update/regeneration script and regenerate
          mixins (dashboards/rules artifacts).', '67.11.0: Add a configurable kubelet
          scrape flag (new chart option affecting kubelet scraping configuration).']
      features: [New kubelet scrape flag option added (lets you control how/if kubelet
          is scraped).]
      breaking_changes: []
    chart_version: 68.5.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:11.4.1', 'quay.io/kiwigrid/k8s-sidecar:1.28.0',
      'quay.io/prometheus-operator/prometheus-operator:v0.79.2', 'quay.io/prometheus/alertmanager:v0.28.0',
      'quay.io/prometheus/node-exporter:v1.8.2', 'quay.io/prometheus/prometheus:v3.1.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v1.5.1', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.14.0']
  - version: 67.11.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['66.7.1: Chore/maintenance change to the kubelet ServiceMonitor
          (PR #5061) to improve it (e.g., scraping/labels/endpoints behavior may be
          adjusted).', '67.11.0: Add a configurable kubelet scrape flag (PR #5136),
          enabling/disabling kubelet scraping via values without needing to patch
          templates.']
      features: [New kubelet scrape flag/option so you can explicitly enable or disable
          kubelet scraping from the chart values.]
      breaking_changes: []
    chart_version: 67.11.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:11.4.0', 'quay.io/kiwigrid/k8s-sidecar:1.28.0',
      'quay.io/prometheus-operator/prometheus-operator:v0.79.2', 'quay.io/prometheus/alertmanager:v0.27.0',
      'quay.io/prometheus/node-exporter:v1.8.2', 'quay.io/prometheus/prometheus:v3.1.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.14.0']
  - version: 66.7.1
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['65.8.1: Adds more information to the selector fields for `additionalPodMonitors`
          and `additionalServiceMonitors` (PR #4974).', '66.7.1: Chore/change to improve
          the kubelet `ServiceMonitor` (PR #5061).']
      features: ['Richer selector metadata/fields for `additionalPodMonitors` and
          `additionalServiceMonitors`, which can make targeting and debugging custom
          monitors clearer.']
      breaking_changes: []
    chart_version: 66.7.1
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:11.4.0', 'quay.io/kiwigrid/k8s-sidecar:1.28.0',
      'quay.io/prometheus-operator/prometheus-operator:v0.79.0', 'quay.io/prometheus/alertmanager:v0.27.0',
      'quay.io/prometheus/node-exporter:v1.8.2', 'quay.io/prometheus/prometheus:v2.55.1',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.14.0']
  - version: 65.8.1
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 65.8.1
    images: []
  - version: 64.0.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["Reverted the prior change that added \u201Cdownward compatibility\u201D\
          \ for Prometheus CRDs (PR #4883 reverting PR #4818). This means the chart\
          \ is no longer attempting to accommodate older/newer Prometheus Operator\
          \ CRD schemas automatically; you must ensure your cluster CRDs match the\
          \ operator/chart expectations before/when upgrading."]
      features: ['(From 63.1.0) Added support for configuring `alertmanager.cluster.label`
          via the chart, enabling better labeling/identification of Alertmanager clusters
          in HA setups.']
      breaking_changes: ['Potential CRD compatibility impact due to reverting the
          Prometheus CRD downward-compatibility logic; if you relied on that behavior
          for smoother upgrades/downgrades across CRD versions, you may need to manage
          CRD upgrades explicitly and validate Prometheus Operator/CRD versions during
          this chart upgrade.']
    chart_version: 64.0.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:11.2.1', 'quay.io/kiwigrid/k8s-sidecar:1.27.4',
      'quay.io/prometheus-operator/prometheus-operator:v0.76.1', 'quay.io/prometheus/alertmanager:v0.27.0',
      'quay.io/prometheus/node-exporter:v1.8.2', 'quay.io/prometheus/prometheus:v2.54.1',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0']
  - version: 63.1.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- No explicit Helm values changes were called out in the provided\
        \ release notes for 62.7.0 or 63.1.0.\n- New/updated values to consider based\
        \ on features:\n  - **Prometheus Operator ServiceAccount annotations**: ensure\
        \ you set/retain `prometheusOperator.serviceAccount.annotations` if you need\
        \ cloud IAM/workload-identity style bindings.\n  - **Alertmanager cluster\
        \ label support**: review any new value(s) related to enabling/configuring\
        \ an Alertmanager `cluster.label` (exact key not shown in the provided notes;\
        \ confirm against the chart\u2019s `values.yaml` or PR #4877 if you plan to\
        \ use it)."
      chart_updates: ['62.7.0: Added the ability to set ServiceAccount annotations
          for the Prometheus Operator (PR #4820).', '63.1.0: Added support for Alertmanager
          `cluster.label` (PR #4877).']
      features: [Ability to add annotations to the Prometheus Operator ServiceAccount
          (useful for workload identity/IAM bindings)., Support for configuring an
          Alertmanager `cluster.label` to label cluster identity in Alertmanager setups.]
      breaking_changes: []
    chart_version: 63.1.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:11.2.0', 'quay.io/kiwigrid/k8s-sidecar:1.27.4',
      'quay.io/prometheus-operator/prometheus-operator:v0.76.1', 'quay.io/prometheus/alertmanager:v0.27.0',
      'quay.io/prometheus/node-exporter:v1.8.2', 'quay.io/prometheus/prometheus:v2.54.1',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0']
  - version: 62.7.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **New option:** You can now set annotations on the Prometheus\
        \ Operator service account.\n  - Look for/enable a value similar to: `prometheusOperator.serviceAccount.annotations`\
        \ (name inferred from the release note; verify exact key in `values.yaml`\
        \ for 62.7.0).\n- **Grafana dependency bump (already present at 61.9.0):**\
        \ 61.9.0 notes mention bumping Grafana chart dependencies to `8.4.*`. If your\
        \ cluster pins/overrides Grafana chart versions, re-check that your overrides\
        \ still apply cleanly after upgrading."
      chart_updates: ['Added ability to set ServiceAccount annotations for the Prometheus
          Operator (PR #4820).', Grafana chart dependency bumped to 8.4.* (noted in
          61.9.0).]
      features: ['Can configure annotations on the Prometheus Operator ServiceAccount
          (useful for IAM roles for service accounts, workload identity, custom auditing
          labels, etc.).']
      breaking_changes: []
    chart_version: 62.7.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:11.2.0', 'quay.io/kiwigrid/k8s-sidecar:1.27.4',
      'quay.io/prometheus-operator/prometheus-operator:v0.76.1', 'quay.io/prometheus/alertmanager:v0.27.0',
      'quay.io/prometheus/node-exporter:v1.8.2', 'quay.io/prometheus/prometheus:v2.54.1',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0']
  - version: 61.9.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Grafana dependency chart bumped to the 8.4.* series (as pulled
          in by kube-prometheus-stack chart)., Grafana subchart/templates updated
          to support dual-stack clusters (IPv4/IPv6) in Grafana-related resources.]
      features: [Grafana components now support dual-stack Kubernetes clusters (IPv4/IPv6)
          via updated chart handling., 'Grafana dependency updated to 8.4.*, bringing
          in upstream fixes and improvements from the Grafana Helm chart.']
      breaking_changes: []
    chart_version: 61.9.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:11.1.3', 'quay.io/kiwigrid/k8s-sidecar:1.27.4',
      'quay.io/prometheus-operator/prometheus-operator:v0.75.2', 'quay.io/prometheus/alertmanager:v0.27.0',
      'quay.io/prometheus/node-exporter:v1.8.2', 'quay.io/prometheus/prometheus:v2.54.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.13.0']
  - version: 60.5.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **New value added:** Prometheus Operator now supports configuring
        **PVC claim retention** via a new field exposed by the chart (from PR #4570).
        If you manage Prometheus/Alertmanager volumes, review your values for the
        new retention/cleanup behavior and set it explicitly to match your desired
        lifecycle.

        - **Grafana in dual-stack clusters:** Chart adds support for **dual-stack
        (IPv4/IPv6) clusters** in Grafana-related configuration (PR #4638). If you
        run dual-stack, validate/adjust Grafana service/network settings accordingly;
        otherwise no values change is typically required.'
      chart_updates: [Prometheus Operator integration updated to expose a PVC claim
          retention configuration option (adds corresponding chart templating/values
          wiring)., Grafana templates updated to better support dual-stack Kubernetes
          clusters.]
      features: [Ability to configure PVC claim retention behavior through Prometheus
          Operator settings (more control over whether PVCs are retained or deleted
          on resource removal)., Improved Grafana support for dual-stack Kubernetes
          clusters (better compatibility in IPv4/IPv6 environments).]
      breaking_changes: []
    chart_version: 60.5.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:11.0.0', 'quay.io/kiwigrid/k8s-sidecar:1.26.1',
      'quay.io/prometheus-operator/prometheus-operator:v0.74.0', 'quay.io/prometheus/alertmanager:v0.27.0',
      'quay.io/prometheus/node-exporter:v1.8.1', 'quay.io/prometheus/prometheus:v2.53.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.12.0']
  - version: 59.1.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Adds support for setting the Prometheus Operator PVC claim retention
          field via chart values (new option exposed by the chart)., Fixes chart templating
          so `alertmanager.alertmanagerSpec.version` is set correctly from values.]
      features: ['Prometheus Operator: chart now exposes a PVC claim retention setting
          so you can control how Prometheus persistent volume claims are retained
          during scale-down/deletion scenarios.']
      breaking_changes: []
    chart_version: 59.1.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:10.4.1', 'quay.io/kiwigrid/k8s-sidecar:1.26.1',
      'quay.io/prometheus-operator/prometheus-operator:v0.74.0', 'quay.io/prometheus/alertmanager:v0.27.0',
      'quay.io/prometheus/node-exporter:v1.8.0', 'quay.io/prometheus/prometheus:v2.52.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.12.0']
  - version: 58.7.2
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['57.2.1: Fixes an issue when using kube-state-metrics 2.11.0
          (chart change to restore compatibility).', '58.7.2: Fixes Alertmanager version
          wiring by correctly setting `alertManagerSpec.version`.']
      features: []
      breaking_changes: []
    chart_version: 58.7.2
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:10.4.1', 'quay.io/kiwigrid/k8s-sidecar:1.26.1',
      'quay.io/prometheus-operator/prometheus-operator:v0.73.2', 'quay.io/prometheus/alertmanager:v0.27.0',
      'quay.io/prometheus/node-exporter:v1.8.0', 'quay.io/prometheus/prometheus:v2.52.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.12.0']
  - version: 57.2.1
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Fix issue with kube-state-metrics 2.11.0 (PR #4419).']
      features: []
      breaking_changes: []
    chart_version: 57.2.1
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:10.4.0', 'quay.io/kiwigrid/k8s-sidecar:1.26.1',
      'quay.io/prometheus-operator/prometheus-operator:v0.72.0', 'quay.io/prometheus/alertmanager:v0.27.0',
      'quay.io/prometheus/node-exporter:v1.7.0', 'quay.io/prometheus/prometheus:v2.51.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.12.0']
  - version: 56.21.4
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- No Helm values changes were called out in the provided release
        notes for the target version (56.21.4) or the starting version (55.11.0).

        - Based on the snippets you provided, this upgrade looks safe to run as a
        standard `helm upgrade` with your existing values, but you should still run
        `helm diff upgrade` to detect any indirect changes coming from dependency
        bumps.

        '
      chart_updates: ['55.11.0: Bumped the Grafana subchart to the 7.2.x series.',
        '56.21.4: Fixed the CoreDNS Grafana dashboard variables (removed circular
          label filtering; refresh values on time range change).']
      features: [Grafana dependency updated to 7.2.x (via the kube-prometheus-stack
          chart)., 'Improved CoreDNS Grafana dashboard behavior: variables no longer
          have circular label filtering and refresh when the time range changes.']
      breaking_changes: []
    chart_version: 56.21.4
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:10.3.3', 'quay.io/kiwigrid/k8s-sidecar:1.25.2',
      'quay.io/prometheus-operator/prometheus-operator:v0.71.2', 'quay.io/prometheus/alertmanager:v0.27.0',
      'quay.io/prometheus/node-exporter:v1.7.0', 'quay.io/prometheus/prometheus:v2.50.1',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.1']
  - version: 55.11.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Bumped the Grafana subchart dependency to the 7.2.x series (kube-prometheus-stack
          55.11.0).]
      features: [Grafana subchart updated to 7.2.x (new Grafana chart defaults/features
          may apply).]
      breaking_changes: []
    chart_version: 55.11.0
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:10.2.3', 'quay.io/kiwigrid/k8s-sidecar:1.25.2',
      'quay.io/prometheus-operator/prometheus-operator:v0.70.0', 'quay.io/prometheus/alertmanager:v0.26.0',
      'quay.io/prometheus/node-exporter:v1.7.0', 'quay.io/prometheus/prometheus:v2.48.1',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.1']
  - version: 54.2.2
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 54.2.2
    images: ['docker.io/bats/bats:v1.4.1', 'docker.io/grafana/grafana:10.1.5', 'quay.io/kiwigrid/k8s-sidecar:1.25.2',
      'quay.io/prometheus-operator/prometheus-operator:v0.69.1', 'quay.io/prometheus/alertmanager:v0.26.0',
      'quay.io/prometheus/node-exporter:v1.7.0', 'quay.io/prometheus/prometheus:v2.48.0',
      'registry.k8s.io/ingress-nginx/kube-webhook-certgen:v20221220-controller-v1.5.1-58-g787ea74b6',
      'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.10.1']
  name: kube-prometheus-stack
- icon: https://avatars.githubusercontent.com/u/68448710?s=48&v=4
  git_url: https://github.com/kyverno/kyverno
  release_url: https://github.com/kyverno/kyverno/releases/tag/v{vsn}
  helm_repository_url: https://kyverno.github.io/kyverno/
  versions:
  - version: 1.16.0
    kube: ['1.34', '1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '## Helm/chart actions required

        - **CRDs packaging changed**: Kyverno now provides a **standalone CRDs chart**.
        Plan how you manage CRDs during the upgrade (install/upgrade CRDs separately
        from the main chart, and ensure your GitOps/Helm flow accounts for this).

        - **Helm hooks cleanup/rename**: Several **helm hooks were cleaned up and
        hook names shortened**. If you have automation that depends on specific hook
        names or hook resources, re-validate it.

        - **Test pod customization**: New option to set **podAnnotations for test
        pods**.

        - **Migration job updated**: The **migration job includes new policy types**;
        ensure it runs successfully during upgrade.

        - **Templating scope change**: A fix made a helm templating value **global**;
        if you had workarounds for scoping issues, re-check your values overrides.

        '
      chart_updates: ['Introduced a standalone CRDs subchart/package for Kyverno CRDs,
          changing how CRDs may be installed/managed during upgrades.', 'Helm hooks
          were cleaned up and hook names shortened (less clutter, but may affect scripts
          that referenced them).', Helm chart gained configurable podAnnotations for
          Kyverno test pods., Migration job template updated to include new policy
          types., Fixed/adjusted helm templating to make a value global (scoping fix).]
      features: ['New namespaced policy types were introduced: NamespacedValidatingPolicy,
          NamespacedImageValidatingPolicy, and NamespacedDeletingPolicy (useful for
          delegating policy ownership to namespaces).', CEL policy API surface expanded
          with v1beta1 versions for ValidatingPolicy/ImageValidatingPolicy/MutatingPolicy/GeneratingPolicy/DeletingPolicy
          and fine-grained CEL exceptions support., 'Webhooks can now be built using
          matchLabels defined in policy, and CEL policy performance metrics were added
          for observability.', 'Kyverno can bind to a hostIP when running in hostNetwork
          mode, improving flexibility for networking constraints.']
      breaking_changes: ['Deprecated webhook was removed; if you relied on it (or
          had network policies/allowlists targeting it), you must update to the supported
          webhook endpoints/configuration.', UpdateRequest v1beta1 is now unserved;
          any clients/manifests still using that version must be updated to a served
          version before/with the upgrade.]
    chart_version: 3.6.0
    images: ['curlimages/curl:8.10.1', 'reg.kyverno.io/kyverno/background-controller:v1.16.0',
      'reg.kyverno.io/kyverno/cleanup-controller:v1.16.0', 'reg.kyverno.io/kyverno/kyverno-cli:v1.16.0',
      'reg.kyverno.io/kyverno/kyverno:v1.16.0', 'reg.kyverno.io/kyverno/kyvernopre:v1.16.0',
      'reg.kyverno.io/kyverno/reports-controller:v1.16.0', 'registry.k8s.io/kubectl:v1.32.7']
  - version: 1.15.0
    kube: ['1.33', '1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '## Helm values / chart behavior changes to check


        - **ServiceMonitor annotations:** chart now supports setting annotations on
        Kyverno `ServiceMonitor` resources. If you rely on custom annotations for
        scraping/tenant routing, review/enable the new values.

        - **New CRDs shipped by the chart:** chart adds **MutatingPolicy (mpol)**
        and **GeneratingPolicy (gpol)** CRDs. Ensure CRD installation/upgrade is handled
        in your process (Helm CRD install, GitOps CRD sync, or separate CRD pipeline).

        - **PDB enhancement:** chart adds support to set `unhealthyPodEvictionPolicy`
        on PodDisruptionBudgets; review if you manage PDB behavior during node drains.

        - **ServiceAccount token mounting controls:** chart adds ability to disable
        SA token automount and adds `automountServiceAccountToken` support for Kyverno
        controllers. If your cluster hardens SA tokens, set these explicitly.

        - **Service trafficDistribution:** chart adds `trafficDistribution` support
        for Services on Kubernetes **1.31+**; verify cluster version and whether you
        want this set.

        - **Test pod template scheduling knobs:** chart adds `nodeSelector` and `tolerations`
        support for test pod templates.

        - **OpenReports rendering:** chart adds OpenReports resources and propagates
        the relevant value to controller flags. If you enable OpenReports, ensure
        your downstream tooling consumes it.

        '
      chart_updates: [Adds ServiceMonitor annotation support., Includes `mpol` and
          `gpol` CRDs in the Helm chart (and related CRD packaging updates)., Adds
          PDB `unhealthyPodEvictionPolicy` support., Adds ability to disable ServiceAccount
          token automount; adds `automountServiceAccountToken` for Kyverno controllers.,
        Adds Service `trafficDistribution` support (K8s 1.31+)., Adds nodeSelector/tolerations
          support for test pod templates., Renders OpenReports resources and wires
          values to flags., 'Tooling bumps: helm/helm-docs version updates.']
      features: ['Introduces new policy types/flows: **MutatingPolicy**, **GeneratingPolicy**,
          and **DeletingPolicy** with admission flow, background reporting, and CLI
          support (mutate existing, generate existing, cleanup).', 'Policy reports
          can be emitted in **OpenReports** format (alpha), replacing/transitioning
          from prior report mechanisms.', 'CLI improvements: `skipColor`, more test
          output formats (json/yaml/markdown/junit), improved apply/test behaviors,
          and support for additional admission policy types.']
      breaking_changes: ['**ValidatingAdmissionPolicy generation is enabled by default**
          in v1.15.0; this can create additional Kubernetes resources and requires
          cluster permissions and API availability.', "CEL function/operator rename:\
          \ `image()` \u2192 `parseImageReference`, which can break existing CEL expressions\
          \ in policies.", CLI deprecated APIs removed; older scripts/automation invoking
          removed flags/APIs may need updates., Context is disabled when using CEL
          expressions in `validate` rules; policies that depended on context + CEL
          together may behave differently.]
    chart_version: 3.5.0
    images: []
  - version: 1.14.0
    kube: ['1.32', '1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm chart values / config changes to check\n\n### 1) **Policy\
        \ Exceptions default behavior (security hardening)** *(introduced in Kyverno\
        \ v1.13.0)*\nOlder Helm chart versions enabled exceptions by default for all\
        \ namespaces. In v1.13 this default was changed due to **CVE-2024-48921**.\n\
        \n**What to do:**\n- If you rely on `PolicyException` broadly, explicitly\
        \ configure which namespaces should allow exceptions per the Kyverno install\
        \ customization docs.\n- Validate that expected exceptions still apply post-upgrade\
        \ (especially in non-system namespaces).\n\n### 2) **RBAC: wildcard \u201C\
        view everything\u201D removed** *(introduced in Kyverno v1.13.0)*\nKyverno\
        \ removed wildcard view permissions and instead binds to the standard `view`\
        \ role.\n\n**What to do:**\n- If you have mutate/generate policies operating\
        \ on **custom resources**, reports, or any feature that requires Kyverno to\
        \ *list/get/watch* those CRDs, you may need to add extra RBAC to let controllers\
        \ read those resources.\n- Pay special attention to reporting controllers\
        \ and custom resource targets.\n\n### 3) **Removed Helm keys: `cleanupJobs.*`**\
        \ *(v1.13.0)*\nThe chart removed `cleanupJobs` keys.\n\n**What to do:**\n\
        - Remove/replace any values overrides referencing `cleanupJobs`.\n- Note:\
        \ cleanup jobs were also disabled by default around the reporting changes;\
        \ confirm desired cleanup behavior.\n\n### 4) Reporting / metrics / dashboards\
        \ changes *(v1.13.0)*\n- Default metrics set updated.\n- Grafana dashboard\
        \ metric rename: `kyverno_policy_results_total` \u2192 `kyverno_policy_results`.\n\
        \n**What to do:**\n- Update Prometheus recording rules / Grafana dashboards\
        \ if they reference the old metric name.\n\n### 5) New Helm options added\
        \ in v1.13 (may require no change but are useful)\n- `global.tolerations`\
        \ (global tolerations)\n- `global.image.imagePullSecrets`\n- Configurable\
        \ `hostNetwork` for admission- and cleanup-controller\n- Webhook pod annotations\n\
        - Custom ports for background- and reports-controller\n- Resync period configuration\
        \ for informers\n- Reporting configuration per rule type\n\n### 6) Helm changes\
        \ in v1.14.0\n- Added toggle to enable/disable aggregating user-facing roles\
        \ with Kyverno RBAC.\n- Admission-controller HPA support.\n- Switched to `serviceAccountName`\
        \ (instead of deprecated `serviceAccount`).\n- Added `dnsconfig` for deployments.\n\
        \n**What to do:**\n- If you previously used `serviceAccount` in values, migrate\
        \ to `serviceAccountName`.\n- If you use custom RBAC patterns, review the\
        \ new \u201Caggregate roles\u201D toggle.\n- If you want autoscaling for admission-controller,\
        \ evaluate the new HPA values.\n"
      chart_updates: ['Kyverno v1.13.0: chart removed wildcard view permissions and
          changed default exception settings; multiple reporting/cleanup/report-type
          changes landed including removal of old report types and disabling cleanup
          jobs by default.', 'Kyverno v1.13.0: Helm chart removed `cleanupJobs` values
          keys; added multiple new configuration knobs (hostNetwork, global tolerations,
          imagePullSecrets, resync periods, ports, annotations).', 'Kyverno v1.14.0:
          Helm chart added admission-controller HPA support, added `dnsconfig`, switched
          to `serviceAccountName`, and introduced a toggle for aggregating user-facing
          roles with Kyverno RBAC.']
      features: ['v1.14: Introduced new policy types `ValidatingPolicy` and `ImageValidatingPolicy`,
          including JSON payload support and auto-generation of Kubernetes `ValidatingAdmissionPolicy`
          where applicable.', 'v1.14: Extended CEL support (libraries and the ability
          to reference `PolicyException` in CEL), increasing expressiveness for validation
          logic.', 'v1.13: Significant enhancements to image verification (Cosign
          features like TSA chain, signature algorithms, OCI 1.1 signatures, bundle
          verification) and policy authoring (new `validate.assert`, `foreach` for
          generate, labelSelectors for mutate targets).', 'v1.13: Reporting enhancements
          including richer results (custom data, more rule types covered), new controller
          circuit breaker, and additional tunables for report aggregation workers.']
      breaking_changes: ['v1.13: RBAC hardening removed wildcard view permissions;
          Kyverno may no longer be able to read all resources/CRDs by default. This
          can affect reports and mutate/generate on custom resources unless additional
          RBAC is granted.', 'v1.13: Policy Exceptions are no longer enabled by default
          for all namespaces due to CVE-2024-48921. If you relied on cluster-wide
          exceptions, you must explicitly configure allowed namespaces.', 'v1.13:
          Several API migrations/deprecations occurred (e.g., moving validationFailureAction
          fields into per-rule `validate.failureAction` and removal of `validatingadmissionpolicies`
          v1alpha1). Validate CRDs and policy manifests against the new schema.',
        'v1.13: Report types and cleanup behavior changed (old intermediate report
          types removed; cleanup jobs disabled by default; some cleanup cronjobs removed).
          If you had automation depending on those objects/jobs, update it.']
    chart_version: 3.4.0
    images: ['bitnami/kubectl:1.32.3', 'busybox:1.35', 'reg.kyverno.io/kyverno/background-controller:v1.14.0',
      'reg.kyverno.io/kyverno/cleanup-controller:v1.14.0', 'reg.kyverno.io/kyverno/kyverno-cli:v1.14.0',
      'reg.kyverno.io/kyverno/kyverno:v1.14.0', 'reg.kyverno.io/kyverno/kyvernopre:v1.14.0',
      'reg.kyverno.io/kyverno/reports-controller:v1.14.0']
  - version: 1.13.0
    kube: ['1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm chart / values changes to review\n\n### 1) **Policy Exceptions\
        \ default scope changed (security fix / CVE-2024-48921)**\n* **Behavior change:**\
        \ Prior chart versions enabled exceptions by default for **all namespaces**.\
        \ In 1.13.0, **defaults are tightened**.\n* **Upgrade action:** If you rely\
        \ on exceptions being available cluster-wide \u201Cby default\u201D, you must\
        \ **explicitly set the exception-related values** to restore prior behavior.\n\
        * **Impact area:** Admission behavior shouldn\u2019t change, but **exception-driven\
        \ skips** may stop working in namespaces you didn\u2019t explicitly enable.\n\
        \n### 2) **RBAC change: wildcard view permissions removed**\n* **Behavior\
        \ change:** Kyverno no longer has broad wildcard \u201Cview\u201D permissions;\
        \ chart now binds to the standard `view` ClusterRole.\n* **Upgrade action:**\
        \ If Kyverno needs to **read custom resources** for your mutate/generate policies,\
        \ background scans, or reporting, you may need to **add explicit RBAC** (additional\
        \ rules/clusterroles) granting `get/list/watch` on those CRDs.\n\n### 3) **`cleanupJobs`\
        \ keys removed from the chart**\n* **Behavior change:** Helm values under\
        \ `cleanupJobs` are **no longer recognized**.\n* **Upgrade action:** Remove\
        \ any `cleanupJobs.*` from your values and re-check how report/UR cleanup\
        \ is configured in the new chart.\n\n### 4) Reporting / metrics / dashboards\
        \ updates\n* **Default metrics updated** in the Helm chart.\n* Grafana dashboard\
        \ changes include:\n  * Dashboard updated for **Grafana 11**.\n  * Metric\
        \ rename in dashboard config: `kyverno_policy_results_total` \u2192 `kyverno_policy_results`.\n\
        * **Upgrade action:** If you import the bundled dashboards or rely on metric\
        \ names, update your Grafana queries/alerts accordingly.\n\n### 5) New/expanded\
        \ chart configurability you may want to adopt\n* `hostNetwork` configurable\
        \ for **admission-controller** and **cleanup-controller**.\n* Webhook pod\
        \ annotations configurable.\n* Custom ports for **background-controller**\
        \ and **reports-controller**.\n* Global tolerations + `global.image.imagePullSecrets`.\n\
        * Sleep duration config to manage deployments (rollout pacing).\n* Custom\
        \ annotations on Kyverno deployments.\n* Resync period configuration for informers.\n\
        * Helm configuration for **reporting in different rules**.\n\n> Note: exact\
        \ value key names aren\u2019t present in the snippet; compare your current\
        \ `values.yaml` to the 1.13 chart `values.yaml` and run `helm diff upgrade`\
        \ to confirm the precise paths."
      chart_updates: ['Security posture tightened: exceptions default scope reduced
          (CVE-2024-48921 guidance).', 'RBAC hardening: wildcard view permissions
          removed; binding to default `view` role added.', 'Removed intermediate report
          types (`admissionreports`, `backgroundscanreports`) and older report artifacts
          removed from the chart; cleanup jobs disabled by default and several cleanup
          cronjobs removed.', 'Reports architecture changed: removed report chunking
          and other report aggregation behaviors; reports controller gains circuit
          breaker and new worker configuration flag.', 'Helm templates updated: flowcontrol
          API updated to v1; Grafana dashboards updated (Grafana 11 support, metric
          rename); Service/port and annotations configurability expanded.']
      features: ['Policy reporting improvements: `validate.podSecurity` now records
          control names/images in reports and custom data can be added to policy reports.',
        'Image verification expanded: supports multiple attestations/context entries,
          TSA cert chain support, signature algorithm selection, full regexp support,
          Sigstore bundle verification, and OCI 1.1 signatures.', 'Policy Exceptions
          enhancements: can be generated from policy reports; CLI supports inline
          exceptions and apply can continue-on-failure.', 'Admission experience: warnings
          for policy violations/mutations can be emitted during admission reviews.',
        'Generate/mutate enhancements: `foreach` support for generate policies, labelSelectors
          for mutate targets, `dumpPatch` option, and reporting added for mutate/generate
          rules.']
      breaking_changes: ['RBAC breaking change: wildcard view permissions removed;
          Kyverno may no longer be able to read some custom resources, affecting reports
          and some mutate/generate policies unless you grant explicit RBAC.', 'Helm
          breaking change: exception defaults changed (no longer enabled for all namespaces
          by default); clusters relying on broad exception enablement must explicitly
          configure it.', 'Helm breaking change: `cleanupJobs` values keys removed;
          existing values will be ignored and must be migrated/removed.', 'API migrations
          in policy schema: `spec.validationFailureAction` and overrides moved down
          to rule-level fields; other API fields migrated (generateExisting, mutateExistingOnPolicyUpdate,
          webhookTimeoutSeconds, failurePolicy), and VAP v1alpha1 removed in favor
          of v1beta1.']
    chart_version: 3.3.2
    images: ['bitnami/kubectl:1.30.2', 'busybox:1.35', 'ghcr.io/kyverno/background-controller:v1.13.0',
      'ghcr.io/kyverno/cleanup-controller:v1.13.0', 'ghcr.io/kyverno/kyverno-cli:v1.13.0',
      'ghcr.io/kyverno/kyverno:v1.13.0', 'ghcr.io/kyverno/kyvernopre:v1.13.0', 'ghcr.io/kyverno/reports-controller:v1.13.0']
  - version: 1.12.0
    kube: ['1.29', '1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm chart values/behavior changes to review\n- **New values**\n\
        \  - `revisionHistoryLimit`: chart parameters to control Deployment `revisionHistoryLimit`.\n\
        \  - **CA bundle injection**: option to define a **ca-certificates bundle**\
        \ for Kyverno deployments.\n  - **Global `extraEnvVars`**: set extra env vars\
        \ globally across Kyverno components.\n  - **Performance profiling support**:\
        \ chart option to enable profiling endpoints.\n  - **Global `nodeSelector`**:\
        \ apply a nodeSelector to all Kyverno pods.\n  - **Webhook labels**: ability\
        \ to apply custom labels to Kyverno webhooks (often needed for Argo CD sync/ownership\
        \ patterns).\n  - **Jobs backoffLimit**: configure `backoffLimit` for hook/cleanup\
        \ jobs.\n  - **Cleanup job pod labels**: ability to add pod labels to Helm\
        \ hook jobs.\n  - `config.resourceFilters` enhancements:\n    - can **exclude\
        \ resources** from `resourceFilters`\n    - can **add additional resources**\
        \ to be excluded via `resourceFilters`\n- **Changed defaults**\n  - Chart\
        \ will **omit policy applied and skipped events by default** (less Event noise;\
        \ if you relied on Events for auditing/alerts you may want to re-enable).\n\
        \  - **Default webhook exclusions** added (may change which requests Kyverno\
        \ evaluates out-of-the-box).\n- **RBAC/chart structure**\n  - Refined permissions\
        \ by removing wildcards (RBAC is stricter; check for any custom controller\
        \ behaviors that previously relied on broad access).\n  - Grafana dashboard\
        \ file renamed from `dashboard.json` to `kyverno-dashboard.json` (update any\
        \ automation referencing the old name).\n- **CRD/data migrations in Helm**\n\
        \  - Chart adds **CRD migration hooks** to migrate existing CRs to new storage\
        \ versions. Ensure hook jobs can run (RBAC, imagePull, PodSecurity, network\
        \ policies) and that Argo CD/Flux allow hooks.\n  - Sanity checks added for\
        \ **CRD/controller mismatch** when deploying specific controllers/CRDs.\n"
      chart_updates: [Introduces CRD migration hooks to move existing Kyverno custom
          resources to new storage versions (aligns with multiple APIs graduating
          to v2)., Tightens RBAC by removing wildcard permissions; expect more granular
          ClusterRoles/RoleBindings., Adds defaults and knobs to reduce Event and
          webhook scope noise (omit certain Events by default; default webhook exclusions).,
        'Multiple chart ergonomics improvements: global nodeSelector/extraEnvVars,
          CA bundle support, job backoff tuning, webhook labeling, profiling enablement,
          revisionHistoryLimit.', Renames bundled Grafana dashboard artifact to `kyverno-dashboard.json`.]
      features: ['Global resource caching via new `GlobalContextEntry` CRD, enabling
          reuse of cached resources across policy evaluations.', 'More flexible and
          narrower webhook scope configuration, including support for Kubernetes 1.27+
          CEL-based `matchConditions`.', 'Policy Exceptions enhanced: support conditions,
          exclude specific Pod Security controls, and be applied to existing resources
          when created (behavioral change).', 'New ephemeral report kinds (`EphemeralReports`,
          `ClusterEphemeralReports`) under new `reports.kyverno.io` API group to support
          the revamped reports pipeline.', 'CLI additions: `migrate` command to upgrade
          Kyverno resources to current APIs; experimental `json` command; improved
          `test/apply` support for Policy Exceptions and VAP bindings.']
      breaking_changes: ["Policies using long-deprecated/invalid operators in conditions\
          \ (e.g., `In`, `NotIn`) will now be blocked\u2014validate and update policies\
          \ before upgrading.", 'Multiple Kyverno CRDs/APIs graduate to **v2** (Policy
          Exceptions, Cleanup Policies, Reports APIs, UpdateRequests). Existing CRs
          may need migration; use Helm hook migrations or `kyverno cli migrate` and
          plan for CRD updates.', 'Operational caution: Kyverno 1.12.0 had known critical
          issues; upstream recommends upgrading to at least **v1.12.1** (and for ephemeralreports
          piling up, **v1.12.4**) rather than staying on 1.12.0.']
    chart_version: 3.2.0
    images: ['bitnami/kubectl:1.28.5', 'busybox:1.35', 'ghcr.io/kyverno/background-controller:v1.12.0',
      'ghcr.io/kyverno/cleanup-controller:v1.12.0', 'ghcr.io/kyverno/kyverno-cli:v1.12.0',
      'ghcr.io/kyverno/kyverno:v1.12.0', 'ghcr.io/kyverno/kyvernopre:v1.12.0', 'ghcr.io/kyverno/reports-controller:v1.12.0']
  - version: 1.11.0
    kube: ['1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm chart changes you must account for (1.10.0 \u2192 1.11.0)\n\
        \n### Chart structure / packaging\n- **CRDs moved to a subchart**: `kyverno-crds`\
        \ is now a dependency/subchart instead of being managed directly in the main\
        \ chart.\n  - **Upgrade impact**: verify how you manage CRDs today (Helm-managed\
        \ vs GitOps/apply). If you were relying on the old chart behavior for CRDs,\
        \ ensure your upgrade process installs/updates the CRDs via the new subchart\
        \ (or disable CRDs in Helm and manage them separately).\n- **Grafana dashboard\
        \ moved to a subchart**: the dashboard content is split out to reduce the\
        \ size of the main chart.\n  - **Upgrade impact**: if you enabled Grafana\
        \ dashboards via the Kyverno chart, confirm the new values path/subchart settings\
        \ and that your dashboard provisioning still works.\n\n### New/updated values\n\
        - **Global image registry value added** (`global.image.registry` style capability).\n\
        \  - **Upgrade impact**: if you used per-controller image registry overrides,\
        \ consider migrating to the global setting for consistency.\n\n### New resources\
        \ installed by the chart\n- **API Priority and Fairness resources** (`FlowSchema`\
        \ and `PriorityLevelConfiguration`) added.\n  - **Upgrade impact**: these\
        \ require cluster-level permissions and may conflict with existing APF configuration.\
        \ Review and decide whether to enable/disable/override them to match your\
        \ cluster governance.\n\n### Controller pod security options\n- Webhook cleanup\
        \ Pod can now have configurable security contexts.\n  - **Upgrade impact**:\
        \ if you run under strict PSS/OPA policies, set these explicitly to meet your\
        \ cluster requirements.\n\n### Helm fixes to be aware of during upgrade\n\
        - Pre-delete hook now targets only Kyverno deployments (less risk of scaling\
        \ unrelated workloads).\n- Replica fields validated more safely (non-integer\
        \ handling).\n- RBAC fixes for PolicyExceptions and Secrets access in background\
        \ controller.\n- Added/adjusted PDB enablement values.\n"
      chart_updates: [CRDs moved to a dedicated subchart to reduce main chart size
          and change how CRDs are installed/managed during upgrades., Grafana dashboard
          content moved to its own subchart to avoid Helm secret size issues and reduce
          main chart footprint., Chart now includes Kubernetes API Priority & Fairness
          objects (FlowSchema/PriorityLevelConfiguration)., Introduced a global image
          registry value to simplify image overrides across controllers., 'Webhook
          cleanup job supports configurable security contexts; multiple Helm fixes
          around hooks, RBAC, replicas, and PDB enablement.']
      features: ['ValidatingAdmissionPolicy (VAP) support (alpha): Kyverno can work
          with Kubernetes VAPs, including generating VAPs from compatible `validate.cel`
          rules and producing PolicyReports from VAP evaluations.', 'CEL-based validation
          rules: you can author Kyverno validate rules using CEL, with autogen support,
          and optionally have Kyverno generate/manage matching VAPs.', 'PolicyReports
          are now generated per-resource (UID-named) instead of per-policy, reducing
          API server/etcd pressure and improving scalability.', 'New cleanup mechanism
          via reserved label `cleanup.kyverno.io/ttl`, allowing resources to be cleaned
          up based on a TTL label rather than scheduled CronJobs.', 'Image verification
          updates: Cosign 2.0 support, Notary/OCI 1.1 updates, signature verification
          caching, and improved registry credential configuration via `imageRegistryCredentials`.',
        'CLI improvements: major refactor, formal test manifest schema, ability to
          test VAPs, new `create` commands to scaffold test resources, and improved
          `apply` output.']
      breaking_changes: ['PolicyReports behavior change: reports are now per-resource
          and named by UID rather than per-policy; any tooling/alerts/dashboards that
          assumed old naming or aggregation may break.', 'Cosign policy requirement
          change: Rekor URL must be present (may be empty string). If you previously
          did not use Rekor, you may need to explicitly disable transparency log and
          SCT verification via `rekor.ignoreTlogs` and `ctlog.IgnoreSCT` in policies
          to avoid failures.', '(Operational/behavioral change) Cleanup policies no
          longer use CronJobs; cleanup is handled internally, which can affect expectations
          around CronJob presence and scheduling visibility.']
    chart_version: 3.1.0
    images: ['bitnami/kubectl:1.26.10', 'bitnami/kubectl:1.26.4', 'busybox:1.35',
      'ghcr.io/kyverno/background-controller:v1.11.0', 'ghcr.io/kyverno/cleanup-controller:v1.11.0',
      'ghcr.io/kyverno/kyverno:v1.11.0', 'ghcr.io/kyverno/kyvernopre:v1.11.0', 'ghcr.io/kyverno/reports-controller:v1.11.0']
  - version: 1.10.0
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm chart upgrade notes (Kyverno chart v2 -> v3, required\
        \ for Kyverno 1.10)\n\n- **No in-place upgrade without manual intervention**:\
        \ Kyverno 1.10 decomposes the single Deployment into multiple controllers,\
        \ and the Helm chart moves from **v2 to v3**. Plan a **maintenance window\
        \ and downtime**.\n- **Required Helm value when upgrading**: set `upgrade.fromV2=true`\
        \ during the Helm upgrade. Without this, the chart will not perform the v2\u2192\
        v3 transition.\n- **Deployment split & per-component values**: the chart is\
        \ now structured around separate components (admission/reports/background,\
        \ plus cleanup if enabled). Expect to move old global settings into the right\
        \ component sections.\n- **New values abstractions**:\n  - New `features:`\
        \ section to enable/configure common behaviors without knowing which controller\
        \ needs which flag.\n  - New `logging.verbosity` value and also `features.logging`\
        \ helpers for consistent verbosity across controllers.\n  - `omit-events`\
        \ is surfaced in `features` for easier configuration.\n- **Key renames / structure\
        \ changes**:\n  - `webhooksCleanup.enable` \u2192 `webhooksCleanup.enabled`\n\
        \  - `namespace` \u2192 `namespaceOverride`\n  - `extraArgs` changed from\
        \ **arrays** to **objects/maps** (easier per-flag overrides, but your values\
        \ file must change).\n- **Controller naming change**: the primary Deployment\
        \ name becomes `kyverno-admission-controller`.\n- **RBAC / aggregation changes**:\
        \ Helm refactored RBAC and role aggregation; custom aggregated ClusterRoles\
        \ may need new label selectors (see breaking changes).\n- **CRD management\
        \ changed**: the chart changed how it manages CRDs; review your GitOps/Helm\
        \ CRD installation approach.\n- **Label/name behavior changes**:\n  - Chart\
        \ no longer overuses `kyverno.fullname`; uses `.Release.Name`/instance labels\
        \ more consistently.\n  - Ensure any custom selectors/NetworkPolicies/ServiceMonitors\
        \ that referenced the old labels/names are updated.\n"
      chart_updates: [Chart migrates from v2 to v3 to support Kyverno 1.10 architectural
          split (single Deployment -> multiple controllers)., Chart values are reorganized
          per controller (admission/reports/background) and supplemented with a higher-level
          `features` configuration section., 'Helm templates/refactoring: configmap
          management, RBAC/role aggregation, tests, labels, network policies, and
          CRD handling were substantially reworked.', 'Deployment naming updates:
          admission controller Deployment renamed to `kyverno-admission-controller`;
          additional controllers added.', 'Operational hardening: chart enforces at
          least 1 replica for the admission controller.', 'Improved configurability:
          ServiceAccount annotations supported for all SAs; configurable Grafana ConfigMap
          name; configurable PDB API version; configurable Sigstore TUF root volume.',
        'Monitoring fixes/additions: missing ServiceMonitor for background controller
          added; various Helm hook/imagePullSecret propagation fixes.']
      features: ['Kyverno is split into three controllers (admission, background,
          reports), improving separation of responsibilities and scaling options.',
        'Kyverno policies can now make authenticated calls to in-cluster Services
          (with verb control), enabling richer external-data and integration patterns.',
        VerifyImages gains Notary signature verification support in addition to existing
          Cosign flows., 'Mutate-existing rules now support context variables and
          preconditions, enabling more expressive background mutations.', PolicyExceptions
          now support background scanning and wildcard ruleNames for broader exception
          handling., 'New JMESPath helpers (e.g., `image_normalize()`, `to_boolean()`,
          `trim_prefix()`, enhanced `sum()`) expand policy authoring options.', Performance
          improvements to reporting aggregation (higher workers/QPS/burst and new
          cleanup jobs) reduce delays in large clusters.]
      breaking_changes: ["**No direct in-place upgrade path** from 1.9 to 1.10 due\
          \ to controller decomposition; plan downtime and use Helm v2\u2192v3 migration\
          \ steps (backup/restore policies or scale Kyverno to 0 first).", "Aggregated\
          \ ClusterRoles may need updates to match **new label selectors** for the\
          \ decomposed controllers\u2019 RBAC aggregation.", 'Policies matching subresources
          must use the standardized `Parent/subresource` form (e.g., `Pod/exec`);
          some subresource matches will be rejected when background scanning is enabled.',
        'Generate rules: several fields are now **immutable** after creation and certain
          variable usages are disallowed; additionally `generate.apiVersion` is now
          **required**.', 'Generate-existing behavior changes: `spec.generateExistingOnPolicyUpdate`
          is deprecated in favor of `spec.generateExisting`; update policies accordingly.',
        'Mutate existing enforcement: when `mutateExistingOnPolicyUpdate=true`, `mutate.targets[]`
          must be defined or policy creation is blocked.', 'VerifyImages in Audit
          mode: policy creation is rejected unless `mutateDigest=false`.', 'Mutation
          behavior change: Kyverno no longer implicitly adds `docker.io` to image
          context; adjust policies to use `images.*.registry` or `image_normalize()`
          instead.']
    chart_version: 3.0.0
    images: ['bitnami/kubectl:1.26.4', 'busybox:1.35', 'ghcr.io/kyverno/background-controller:v1.10.0',
      'ghcr.io/kyverno/cleanup-controller:v1.10.0', 'ghcr.io/kyverno/kyverno:v1.10.0',
      'ghcr.io/kyverno/kyvernopre:v1.10.0', 'ghcr.io/kyverno/reports-controller:v1.10.0']
  - version: 1.9.0
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm/chart upgrade notes (kyverno 1.8.x chart \u2192 1.9.x\
        \ chart)\n\n- **Chart registry URL changed in 1.8**: charts moved from `ghcr.io/kyverno/kyverno/kyverno`\
        \ to **`ghcr.io/kyverno/charts/kyverno`**. Ensure your Helm repo/OCI reference\
        \ is updated.\n- **Chart versions follow SemVer and omit the leading `v`**.\
        \ If you were pinning `v1.8.0` style chart versions, update to `1.9.0` format.\n\
        - **Deprecated flag removed**: `--splitPolicyReport` is removed in 1.9 (was\
        \ already deprecated in 1.8). If you set `extraArgs: [\"--splitPolicyReport=...\"\
        ]` or similar, remove it.\n- **`--autogenInternals` removed**: in 1.9 this\
        \ deprecated flag is removed; autogen no longer mutates `spec` and is automatic.\
        \ Remove any explicit `--autogenInternals` usage.\n- **New controller added\
        \ via chart**: 1.9 introduces the **cleanup controller** (alpha feature) and\
        \ includes Helm support for it. Expect new Deployments/ServiceAccounts/RBAC/ServiceMonitor\
        \ options and consider whether to enable/size it.\n- **ImagePullSecrets support\
        \ for verifyImages**: Helm now supports consuming existing `imagePullSecrets`\
        \ for verifyImages. If you verify images from private registries, consider\
        \ configuring this.\n- **Helm fixes you may hit on upgrade**:\n  - Selector-related\
        \ fix specifically mentioned for upgrading from 1.8 \u2192 1.9.\n  - CRD labels\
        \ corrected to match the Helm release name; if you manage CRDs separately,\
        \ ensure labels/ownership are consistent.\n  - `Chart.Version` label uses\
        \ `_` instead of `+` to avoid Flux reconciliation failures (relevant if you\
        \ use Flux and versions with build metadata).\n  - Helm test pod busybox image\
        \ is pinned; initContainer extraArgs handling fixed.\n"
      chart_updates: ['Reports system and CRDs were overhauled in 1.8: `ReportChangeRequest`/`ClusterReportChangeRequest`
          removed and replaced with `AdmissionReport`, `ClusterAdmissionReport`, `BackgroundScanReport`,
          `ClusterBackgroundScanReport` CRDs. Ensure CRDs are updated as part of the
          upgrade and any tooling consuming old CRDs is updated.', 'Kyverno introduced/advanced
          the **v2beta1** API for Kyverno resources, intended to remove deprecated
          fields/types. Plan a migration path for policies using deprecated fields.',
        'Autogen behavior changed: in 1.8 autogen moved to `status` (not `spec`) and
          is enabled by default; in 1.9 the deprecated `--autogenInternals` flag is
          removed and the behavior is automatic.', 'Webhooks behavior changed in 1.9:
          separate webhook rules per GVK; AdmissionReview v1 is used instead of v1beta1.
          This may affect clusters/components expecting v1beta1 AdmissionReview.',
        'New alpha CRDs/resources added in 1.9: **PolicyException** and **CleanupPolicy**
          (and associated cleanup controller components when enabled).']
      features: [PolicyException (alpha) to define exceptions to policy enforcement
          without editing the policy itself., 'CleanupPolicy (alpha) to automate cleanup/removal
          of resources matching criteria, delivered with an optional cleanup controller.',
        'Distributed tracing improvements building on OpenTelemetry support, enabling
          better end-to-end request visibility.', Nested `foreach` loops in policies
          for more complex iteration logic., Extended subresource support in webhook
          and CLI for validation/mutation across more Kubernetes subresources., ConfigMap
          caching to improve performance and reduce API load for repeated ConfigMap
          lookups., 'CLI enhancements: dump AdmissionReview payload, audit/warn flags,
          accept policies via stdin/pipes, git repo policy sources, and experimental
          OCI push/pull of policies.', 'verifyImages enhancements: key signature algorithm
          selection, attestations attestors, and (Helm) support for existing imagePullSecrets.',
        'Kubernetes version support extended (1.25 in 1.8, 1.26 in 1.9).']
      breaking_changes: ['JMESPath behavior change (introduced in 1.8): unresolved
          expressions now evaluate to `null` instead of empty string; some policies
          may need explicit existence checks to avoid unexpected denies/mutations.',
        'Reporting CRDs changed (1.8): old RCR CRDs removed and replaced; any automation
          querying old CRDs will break until updated.', 'CLI/flags: `--splitPolicyReport`
          and `--autogenInternals` are removed in 1.9; deployments using these flags
          will fail to start until removed.', 'verifyImages attestations: new `verifyImages.attestations.attestors`
          is for attestations while existing `verifyImages.attestors` remains for
          signatures; misconfiguration can cause verification failures.', 'Operational
          change (1.9): if Kyverno is down, new/changed policies are blocked until
          Kyverno returns, which can impact GitOps rollouts during outages.']
    chart_version: 2.7.0
    images: ['busybox:1.35', 'ghcr.io/kyverno/cleanup-controller:v1.9.0', 'ghcr.io/kyverno/kyverno:v1.9.0',
      'ghcr.io/kyverno/kyvernopre:v1.9.0']
  - version: 1.8.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm chart changes to account for in the upgrade\n\n- **Chart\
        \ repository/registry moved**: chart OCI URL changed from `ghcr.io/kyverno/kyverno/kyverno`\
        \ to `ghcr.io/kyverno/charts/kyverno`.\n- **Chart versions follow SemVer**:\
        \ the chart version no longer includes a leading `v`.\n- **Reporting system\
        \ changes impact CRDs installed by the chart**:\n  - `ReportChangeRequest`\
        \ and `ClusterReportChangeRequest` CRDs removed.\n  - New CRDs introduced:\
        \ `AdmissionReport`, `ClusterAdmissionReport`, `BackgroundScanReport`, `ClusterBackgroundScanReport`.\n\
        \  - (Cluster)PolicyReport CRDs updated.\n- **Flag removals/changes may affect\
        \ chart values**:\n  - `maxReportChangeRequests` container flag removed.\n\
        \  - Deprecated flags removed earlier in the 1.7 line; if you set any extraArgs/extraEnv\
        \ for removed flags, they must be cleaned up.\n- **Autogen behavior change**:\
        \ autogeneration now lives in policy `status` (not `spec`) and is enabled\
        \ by default; if you had chart settings/assumptions around autogen mutations,\
        \ re-check after upgrade.\n- **Note**: upstream release notes mention \u201C\
        several Helm chart changes with both kyverno and kyverno-policies\u201D; review\
        \ the chart changelog for your exact chart versions (not provided here).\n"
      chart_updates: [New reporting system v2 (ground-up refactor) which changes/renames
          reporting CRDs., 'Aggregated ClusterRoles are now used, simplifying adding
          custom permissions but changing RBAC shape.', 'Improved certificate management:
          dynamic certificate fetching and more graceful rotation; CA key is now included
          in the Kyverno Secret; self-signed certs no longer need annotation.', Autogen
          internals enabled by default; autogen results stored in policy status rather
          than spec., 'Build/distribution changes: Kyverno images built with `ko`
          by default and use a distroless base image.', Support added for Kubernetes
          1.25., Event RBAC tightened (reduced permissions).]
      features: [New validate subrule `podSecurity` integrates Pod Security Admission
          libraries to validate workloads against PSA controls., New validate subrule
          `manifests` supports YAML manifest signature validation., Generate rules
          can now generate multiple resources in a single rule (including selection
          via labels)., OpenTelemetry support for traces/metrics export., New policy
          field `applyRules` controls whether one or all rules are applied., New JMESPath
          functions including `x509_decode` (decode X.509 certs) and `random` (composable
          random strings).]
      breaking_changes: ['Unresolved JMESPath expressions now evaluate to `null` instead
          of empty string (`''''`), which can change preconditions/deny logic; policies
          may need existence checks to avoid unintended denies/mutations.', Reporting
          CRDs `ReportChangeRequest` and `ClusterReportChangeRequest` were removed
          and replaced by Admission/BackgroundScan report CRDs; any tooling relying
          on the old CRDs must be updated.]
    chart_version: 2.6.0
    images: [busybox, 'ghcr.io/kyverno/kyverno:v1.8.0', 'ghcr.io/kyverno/kyvernopre:v1.8.0']
  - version: 1.7.0
    kube: ['1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **PodDisruptionBudget behavior changed**: Helm charts now **enforce\
        \ a PDB for multi-replica installs**, and the **PDB was removed from the plain\
        \ install manifests**. If you were applying the upstream YAML manifests directly,\
        \ you may need to manage your own PDB; with Helm, ensure your values align\
        \ with the new behavior.\n- **Some settings moved to Helm values / chart options**\
        \ (noted across the notes):\n  - `priorityClassName` added to `values.yaml`.\n\
        \  - `affinity` can be managed via Helm values.\n- **Chart/config flags removed**:\
        \ Several flags were removed when they overlapped with ConfigMap-based configuration.\
        \ In particular, `filterK8sResources`, `excludeGroupRole`, and `excludeUsername`\
        \ must now be configured **via the Kyverno ConfigMap** rather than CLI flags.\n\
        - **Resource filters / namespace ignore defaults**: There were fixes around\
        \ `config.resourceFilters` and Helm release name/namespace interactions; review\
        \ your custom `config.resourceFilters` to ensure Kyverno isn\u2019t unintentionally\
        \ processing or skipping resources (especially in the Kyverno namespace)."
      chart_updates: [Policy status representation updated to use `status.conditions`
          internally; `status.ready` is deprecated (kept for a couple of releases).,
        Deprecated flags removed (and some config moved to ConfigMap-only)., 'Policy
          schema/behavior changes around autogen internals: Kyverno reduces/stops
          mutating policies in some cases when autogen internals are enabled.', 'CRD
          lifecycle/compat: drop `v1alpha1` PolicyReport CRD (noted as an enhancement).',
        UpdateRequest/GenerateRequest work evolved (UR controller changes; backward
          compatibility noted where GenerateRequest converts to UpdateRequest)., 'Security/operability
          hardening: seccomp profile and various controller refactors; improved webhook/config
          controller behavior and cache sync handling.']
      features: ['Major expansion of image verification capabilities: support for
          certificate chains, multiple keys, required signed images, digest enforcement/mutation,
          and better CLI testing for image verification rules.', 'Policy authoring
          improvements: inline variables in context, richer `foreach` support (including
          broader request.* JMESPath usage), and new JMESPath functions.', 'Operational
          features: webhooks object selector support and ability to disable leader
          election for the UpdateRequest controller in certain scenarios.']
      breaking_changes: ['`mutate.overlay` and `mutate.patches` (deprecated since
          1.4) were **removed in v1.6.0**; any policies still using them must be migrated
          before/while upgrading.', 'In v1.7.0, **deprecated CLI flags were removed**,
          and some options (`filterK8sResources`, `excludeGroupRole`, `excludeUsername`)
          can now be configured **only via the Kyverno ConfigMap**. This can break
          existing deployments relying on those flags.', '`status.ready` on policies
          is **deprecated** in v1.7.0 in favor of `status.conditions`/`policy.IsReady()`;
          if you have tooling/scripts reading `status.ready`, plan to migrate.']
    chart_version: 2.4.0
    images: [busybox, 'ghcr.io/kyverno/kyverno:v1.7.0', 'ghcr.io/kyverno/kyvernopre:v1.7.0']
  - version: 1.6.0
    kube: ['1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.2.0
    images: [busybox, 'ghcr.io/kyverno/kyverno:v1.6.0', 'ghcr.io/kyverno/kyvernopre:v1.6.0']
  name: kyverno
- icon: https://avatars.githubusercontent.com/u/25301026?s=200&v=4
  git_url: https://github.com/linkerd/linkerd2
  release_url: https://github.com/linkerd/linkerd2/releases/tag/{vsn}
  helm_repository_url: https://helm.linkerd.io/stable
  versions:
  - version: 2.14
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
  - version: 2.13
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
  - version: 2.12
    kube: ['1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
  - version: 2.11
    kube: ['1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
  - version: 2.1
    kube: ['1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
  name: linkerd
- icon: https://avatars.githubusercontent.com/u/51335366?s=48&v=4
  git_url: https://github.com/longhorn/longhorn
  release_url: https://github.com/longhorn/longhorn/releases/tag/v{vsn}
  helm_repository_url: https://charts.longhorn.io
  versions:
  - version: 1.10.1
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '### Helm values / upgrade notes

        - **Use the Longhorn Manager hotfix image when targeting v1.10.1:** set the
        manager image tag to `v1.10.1-hotfix-2` (the plain `v1.10.1` manager image
        has known crash/regression issues).

        - **Temporarily disable the upgrade version check if needed:** set `upgradeVersionCheck:
        false` (or `preUpgradeChecker.upgradeVersionCheck: false` depending on your
        chart values) to allow applying the hotfix image and/or performing certain
        recovery/downgrade scenarios.

        - **If upgrading from any v1.9.x to v1.10.x and your cluster may contain `v1beta1`
        stored CRs:** perform the **manual CRD storage version migration** to `v1beta2`
        *before* the Helm upgrade.

        '
      chart_updates: ['Helm chart behavior improvement: `defaultSettings` handling
          supports automatic quoting and multiple types (reduces YAML/JSON typing
          pitfalls when setting Longhorn global settings via Helm).']
      features: ['V2 Data Engine: interrupt mode now supports **NVMe disks** starting
          in v1.10.1 (v1.10.0 supported AIO disks only).', 'Improved scheduling visibility:
          `CSIStorageCapacity` objects show schedulable/allocatable capacity (helps
          capacity-aware scheduling with `WaitForFirstConsumer`).', Adds/extends installation
          variant usage metrics (observability/telemetry improvement).]
      breaking_changes: ['Longhorn v1.10.0 removes the `longhorn.io/v1beta1` API and
          removes the deprecated `replica.status.evictionRequested` field. If any
          CRs are still stored as `v1beta1`, upgrades to v1.10.x can fail until you
          migrate CRD storedVersions to `v1beta2`.', 'Kubernetes requirement: v1.10.x
          requires **Kubernetes v1.25+**; upgrading on older clusters is unsupported.']
    chart_version: 1.10.1
    images: ['longhornio/longhorn-manager:v1.10.1', 'longhornio/longhorn-share-manager:v1.10.1',
      'longhornio/longhorn-ui:v1.10.1']
  - version: 1.10.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / values changes to plan for\n\n- **Set `upgradeVersionCheck:\
        \ false` during the upgrade if you must pin a hotfix manager image** (the\
        \ release notes recommend disabling the upgrade version check when swapping\
        \ `longhorn-manager` to a hotfix tag).\n- **If you rely on private registries\
        \ or image pull secrets:** v1.10 introduces a *standardized* way to override\
        \ container image registry and specify image pull secrets (release notes:\
        \ Issues **#11064** and **#11062**). Review your current `values.yaml` overrides\
        \ for images/registry/secrets and adjust to the new/standard pattern.\n- **No\
        \ explicit mandatory Helm value renames were listed in these notes**, but\
        \ v1.10 changes the *format* of several Longhorn **Settings** (not Helm values)\
        \ to support per\u2013data-engine JSON values; if you currently set these\
        \ via Helm `defaultSettings`, validate they still apply as intended (see \u201C\
        Consolidated Global Settings\u201D below).\n"
      chart_updates: ['Hotfix guidance: v1.10.0 chart should deploy `longhorn-manager:v1.10.0-hotfix-1`
          instead of `v1.10.0` to avoid a share-manager backoff regression (manager
          crash loop / inability to deploy new share-manager pods).', 'Pre-upgrade
          requirement: ensure Longhorn CRDs no longer store `v1beta1` objects in `status.storedVersions`
          before upgrading to v1.10 (manual storage-version migration may be required).',
        'API removal: `longhorn.io/v1beta1` is removed in v1.10; clusters with leftover
          `v1beta1` stored objects can fail CRD patching during upgrade.', 'Field
          removal: deprecated `replica.status.evictionRequested` removed in v1.10.']
      features: ['V2 Data Engine: interrupt mode (AIO disks only) to reduce CPU usage
          on idle/low I/O workloads.', 'V2 Data Engine: volume & snapshot cloning
          (full-copy clone and fast linked/smart clone).', 'V2 Data Engine: replica
          rebuild QoS / bandwidth limiting (global or per volume) to reduce rebuild
          impact.', 'V2 Data Engine: volume expansion supported (PVC resize/UI).',
        'V2 Data Engine: can run without hugepages (more flexible on low-spec nodes;
          possible performance tradeoff).', 'V1 Data Engine: single-stack IPv6 support
          (dual-stack and V2 IPv6 not supported in this release).', 'Kubernetes scheduling:
          CSIStorageCapacity support for better placement with `WaitForFirstConsumer`
          StorageClasses.', 'Backups: configurable backup block size at volume creation
          time.', 'UX/observability: consolidated settings model allowing per-engine
          values via JSON; UI shows volume attachment ticket summaries.']
      breaking_changes: ['`longhorn.io/v1beta1` API is removed in v1.10; upgrades
          will fail if any CRDs still have `v1beta1` as a stored version or any objects
          persisted in `v1beta1`. Manual CRD storage-version migration is strongly
          advised before upgrading from v1.9 to v1.10, especially for clusters originally
          installed < v1.3.0 or after etcd/CRD restores.', Deprecated `replica.status.evictionRequested`
          field is removed; any tooling that reads/writes it must be updated., "Settings\
          \ consolidation: several global settings now support per\u2013data-engine\
          \ values via JSON (`{\"v1\":..., \"v2\":...}`); existing automation that\
          \ assumes simple string values may need updates.", 'Known regression: `longhorn-manager:v1.10.0`
          can crash due to share-manager backoff logic; plan to use `v1.10.0-hotfix-1`
          during upgrade to avoid instability.']
    chart_version: 1.10.0
    images: ['longhornio/longhorn-manager:v1.10.0', 'longhornio/longhorn-share-manager:v1.10.0',
      'longhornio/longhorn-ui:v1.10.0']
  - version: 1.9.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Work around v1.9.0 recurring job regression (recommended):**\n\
        \  - Set `upgradeVersionCheck: false` to allow the upgrade while using the\
        \ hotfixed manager image.\n  - Override the Longhorn Manager image tag from\
        \ `v1.9.0` to `v1.9.0-hotfix-1` (values key varies by chart; ensure the manager\
        \ image tag is explicitly set).\n\n- **New Helm option:**\n  - `volumeBindingMode`\
        \ can now be configured via Helm values (useful if you want `Immediate` vs\
        \ `WaitForFirstConsumer`).\n\n- **Chart templating additions/bugfixes:**\n\
        \  - Support for `extraObjects` (or similarly named field) to inject additional\
        \ Kubernetes objects.\n  - Fix: `persistence.backupTargetName` was not referenced\
        \ in the StorageClass template (verify your StorageClass rendering if you\
        \ relied on this).\n"
      chart_updates: [v1.9.0 removes the deprecated `environment_check.sh` script
          from the release artifacts (use `longhornctl` for preflight checks instead).,
        "CRDs: deprecated fields removed from `longhorn.io/v1beta2` CRDs; ensure CRs/manifests\
          \ don\u2019t rely on removed fields.", 'Settings migration: `orphan-auto-deletion`
          is replaced by `orphan-resource-auto-deletion` and is auto-migrated during
          upgrade.']
      features: [Recurring **system backups** can now be scheduled via recurring jobs
          (new operational safety net)., '**Offline replica rebuilding** (v1 and v2)
          can automatically rebuild replicas while volumes are detached (disabled
          by default).', '**Orphaned instance cleanup** can track and delete leftover
          engine/replica runtime resources (disabled by default).', 'Improved **observability/metrics**:
          new Prometheus metrics for replica/engine CR identity and rebuild status.',
        'V2 Data Engine enhancements: **UBLK frontend** support and **storage network**
          support (still experimental).']
      breaking_changes: [Kubernetes **v1.25+ is required** for Longhorn v1.9.x upgrades/installs
          (blocker if cluster is older)., V2 **backing images are incompatible** with
          earlier versions due to xattr naming conflicts; you must delete/recreate
          V2 backing images during upgrade and restore any dependent volumes from
          backups., '`longhorn.io/v1beta1` API is now unserved/unsupported in v1.9.0
          and will be removed in v1.10.0; any tooling using v1beta1 must move to v1beta2.',
        'Setting rename: `orphan-auto-deletion` replaced by `orphan-resource-auto-deletion`
          (auto-migrated, but automation/scripts must be updated).']
    chart_version: 1.9.0
    images: ['longhornio/longhorn-manager:v1.9.0', 'longhornio/longhorn-share-manager:v1.9.0',
      'longhornio/longhorn-ui:v1.9.0']
  - version: 1.8.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / deployment manifest notes for 1.7.0 \u279C 1.8.0\n\n\
        - **Kubernetes minimum version increases to v1.25+** in Longhorn **v1.8.0**\
        \ (driven by CSI external-snapshotter upgrade to **v8.2.0**). Ensure the cluster\
        \ is upgraded first.\n- **Image tag pitfall (only if using the *main* longhorn/longhorn\
        \ repo YAML or chart sources):** v1.8.0 repo manifests/charts mistakenly referenced\
        \ `v1.8.x-head`. Fix by setting images to **`v1.8.0`** before install/upgrade,\
        \ and if you already upgraded with `v1.8.x-head`, re-upgrade with `v1.8.0`\
        \ and update engine images for any volumes using `v1.8.x-head`.\n  - Not applicable\
        \ if you install from the **official Longhorn Helm repo** (`https://charts.longhorn.io`).\n\
        - **Environment check script removal path:** the `environment_check.sh` script\
        \ was **deprecated in 1.7.0** and is **scheduled for removal in 1.8.0**. Prefer\
        \ using **Longhorn CLI (`longhornctl`)** for preflight/environment validation\
        \ going forward.\n- **V2 (SPDK) block-type disk default block size changes\
        \ 4096 \u279C 512 bytes:**\n  - This impacts **V2 volumes on block-type disks**.\
        \ If you have existing V2 volumes on 4k-block disks, the release notes prescribe\
        \ a **backup \u279C delete V2 volumes \u279C remove disk from `node.spec.disks`\
        \ \u279C wipe disk \u279C re-add with new config \u279C restore** workflow.\n\
        - **Backup target model changes:** v1.8.0 introduces **multiple backupstores**\
        \ and creates a **default backup target named `default`** during install/upgrade.\
        \ Volumes without an explicit backup target will use `default` (also used\
        \ for system backups). Review any automation that assumes a single/global\
        \ backup target.\n- **RWX expansion behavior:** v1.8.0 supports **automatic\
        \ online RWX volume expansion** when **manager, share-manager, and CSI plugin\
        \ are all at v1.8.0** (so avoid mixed-version states longer than necessary).\n"
      chart_updates: ["Longhorn v1.8.0 includes the standard chart/app refresh plus:\
          \ (1) updated CSI external-snapshotter (v8.2.0), which drives the Kubernetes\
          \ v1.25+ requirement; (2) support for installation/upgrade via the built-in\
          \ Helm Controller for K3s/RKE2 using a HelmChart CRD; (3) a warning that\
          \ the longhorn/longhorn repo\u2019s v1.8.0 manifest and chart had an incorrect\
          \ image tag (`v1.8.x-head`), so ensure your chart source is correct (prefer\
          \ charts.longhorn.io or fix the tag before applying)."]
      features: ['Multiple backupstores support, including creation of a default backup
          target named `default` used for system backups and volumes without a specified
          target.', Automatic online RWX volume expansion (no workload scale-down/manual
          resize steps) when all Longhorn components are on v1.8.0., 'V2 Data Engine
          enhancements: configurable CPU cores, DR volumes, auto-salvage, live migration,
          volume encryption, delta replica rebuild using snapshot checksums, and backing
          image update/download.', Support installing/upgrading Longhorn on K3s/RKE2
          via the built-in Helm Controller (HelmChart CRD workflow)., V2 Data Engine
          support for Talos Linux (assuming prerequisites are met).]
      breaking_changes: [Kubernetes minimum version is now **v1.25+** for Longhorn
          v1.8.0 due to CSI external-snapshotter v8.2.0; clusters below v1.25 must
          upgrade Kubernetes before upgrading Longhorn., V2 block-type disk default
          block size changed from **4096** to **512** bytes; existing V2 volumes on
          4k-block disks require a disruptive migrate/restore procedure to align with
          the new default and avoid incompatibilities with V1-generated backing images.,
        'If you upgraded using the *main* longhorn/longhorn repo chart/manifest without
          fixing the image tag, you may have deployed `v1.8.x-head` images; you must
          correct to `v1.8.0` and update engine images for affected volumes.']
    chart_version: 1.8.0
    images: ['longhornio/longhorn-manager:v1.8.0', 'longhornio/longhorn-share-manager:v1.8.0',
      'longhornio/longhorn-ui:v1.8.0']
  - version: 1.7.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Helm chart values.yaml was simplified/cleaned up (less churn,
          but expect some keys to have moved/been renamed).', Helm chart added support
          for Gateway API and improved Ingress options., 'Chart includes updated defaults/behavior
          aligned with Longhorn v1.7.0 features (e.g., RWX storage network support,
          monitoring knobs).']
      features: ['V2 Data Engine (still preview) gained online replica rebuild, filesystem
          trim, broader SPDK block-disk driver support (AIO/NVMe/VirtIO), and live
          data-plane upgrade for V2 volumes (spdk_tgt) with no downtime.', High availability
          improvements include HA backing images and experimental RWX fast failover
          (faster Share Manager failure detection/response)., Data protection now
          supports periodic and on-demand full backups to reduce corruption risk and
          improve reliability., Scheduling enhancements improve replica auto-balancing
          under disk pressure and speed up rebuilds via local file copying when possible.,
        Storage network can now be used with RWX volumes for traffic segregation.,
        Introduced an official Longhorn CLI (longhornctl) for install/ops/troubleshooting
          via CRs and in-cluster pod execution., 'Improved platform coverage, including
          support for Container-Optimized OS (COS).']
      breaking_changes: [Longhorn v1.7.0 requires Kubernetes v1.21+ for install/upgrade
          from 1.6.x., "environment_check.sh is deprecated in v1.7.0 (overlaps with\
          \ the new Longhorn CLI) and scheduled for removal in v1.8.0\u2014don\u2019\
          t build automation around the script going forward.", 'There is a critical
          known issue in v1.7.0 affecting volume attachment for clusters with legacy
          engine resource names (pre v1.5.2/v1.4.4 pattern); if present, you must
          hold the upgrade until v1.7.1.']
    chart_version: 1.7.0
    images: ['longhornio/longhorn-manager:v1.7.0', 'longhornio/longhorn-share-manager:v1.7.0',
      'longhornio/longhorn-ui:v1.7.0']
  - version: 1.6.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / chart behavior to review before upgrading to\
        \ v1.6.0\n\n- **GitOps/Argo CD compatibility:** v1.6.0 removes or changes\
        \ the **Helm pre-upgrade hook** to better support Argo CD ([#6415]). If you\
        \ previously relied on that hook behavior, re-test your GitOps pipeline.\n\
        - **StorageClass mount options via Helm:** You can now set **StorageClass\
        \ mount options** via `values.yaml` ([#7351]). Review whether you want to\
        \ manage mount options centrally in Helm rather than editing StorageClasses\
        \ manually.\n- **Component log level configurable via Helm:** Chart adds the\
        \ ability to configure **log level** through Helm values ([#3655]). Consider\
        \ setting this explicitly for troubleshooting vs noise.\n- **ServiceMonitor\
        \ support:** Helm chart can now deploy a **Prometheus ServiceMonitor** ([#7041])\
        \ if you use Prometheus Operator.\n- **Node reserved storage percentage exposed\
        \ in chart:** Adds a Helm value for a **node reserved storage percentage**\
        \ setting ([#5958]). If you previously set this only in the UI/settings CR,\
        \ you may want to standardize it in Helm.\n- **New/updated settings surfaced\
        \ in chart:** Ensure settings exist in your values/ConfigMap for **usage metrics\
        \ collection** (`allow-collecting-longhorn-usage-metrics`) ([#7050]) and any\
        \ new snapshot/maintenance-related settings you plan to use.\n\n> Note: The\
        \ release notes provided don\u2019t list a full values.yaml diff; do a `helm\
        \ diff upgrade` between your current chart and the v1.6.0 chart to catch renamed/added/removed\
        \ values."
      chart_updates: ['Improved GitOps friendliness: validated with Flux/Argo CD/Fleet;
          chart adjusted (notably pre-upgrade hook changes) to work better with Argo
          CD.', Adds optional Prometheus Operator integration by allowing deployment
          of a ServiceMonitor., Adds chart support for configuring StorageClass mount
          options and component log level via values.yaml., 'General dependency bumps
          and manifest refactors noted in release notes (e.g., CSI component upgrades,
          Kubernetes version support updates).']
      features: ['Snapshot space management: define max snapshot count and max total
          snapshot size globally or per-volume to control space usage.', 'V2 Data
          Engine (preview) gains snapshot/revert and backup/restore, including backup/restore
          interoperability between v1 and v2 engines.', 'Platform support broadened:
          Talos support and OKD (OpenShift Origin) support added; v2 engine support
          on ARM64.', 'Node maintenance enhancements: new node drain policy options
          to proactively evict/relocate replicas during planned maintenance.', 'Data
          protection: encryption support for `volumeMode: Block` volumes.', 'Backing
          image improvements: ability to back up and restore backing images across
          clusters.']
      breaking_changes: [Potential behavior change for GitOps installs/upgrades due
          to removal/change of the Helm pre-upgrade hook (re-test Argo CD/Flux pipelines).,
        "V1/V2 data plane separation and selective v2 activation introduce new operational\
          \ modes; ensure you don\u2019t accidentally enable v2 in production unless\
          \ you intend to (v2 remains preview)."]
    chart_version: 1.6.0
    images: ['longhornio/longhorn-manager:v1.6.0', 'longhornio/longhorn-ui:v1.6.0']
  - version: 1.5.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["Upgrade path is enforced: v1.5.0 supports upgrades only from\
          \ Longhorn 1.4.x (you\u2019re currently on 1.4.0, so you\u2019re in the\
          \ supported path).", 'Instance Manager architecture change: engine+replica
          instance managers are consolidated into a single instance-manager, which
          affects pod count/resources during/after upgrade.', Admission webhook and
          recovery-backend services are merged into longhorn-manager (fewer standalone
          components/services)., 'New CRD introduced: Longhorn VolumeAttachment (used
          for exclusive attachment and headless operations like cloning/recurring
          jobs/backing image export).', 'New/expanded backup stores and backup behaviors:
          CIFS and Azure backup stores; backup compression options (lz4/gzip/none).',
        'New/expanded trim and recurring job capabilities: automatic filesystem trim
          via recurring job; RWX volume trim; new recurring job types for snapshot
          cleanup and delete.', 'New node maintenance behavior: Kubernetes Upgrade
          Node Drain Policy and use of PDBs to protect Longhorn components during
          drains.', 'Preview feature added: v2/SPDK data engine (disabled by default;
          not for production).', "Deprecations/removals called out in 1.5 notes: remove\
          \ global setting mkfs-ext4-parameters; remove system-managed component image\
          \ settings; remove deprecated volume spec recurringJobs fields; remove deprecated\
          \ allow-node-drain-with-last-healthy-replica; remove disable-replica-rebuild\
          \ feature; remove several \u201CGuaranteed * CPU\u201D settings; default\
          \ backup/restore concurrent limits reduced."]
      features: ['SPDK-based v2 data engine (preview, disabled by default) for an
          alternative datapath with new lifecycle and replica management capabilities.',
        'New VolumeAttachment CRD to ensure exclusive attachment and enable safe headless
          operations (clones, recurring jobs, backing image export).', Cluster Autoscaler
          support is GA (no longer experimental)., Consolidated instance managers
          reduce resource usage during normal operation and upgrades., 'Backup improvements:
          new compression methods (lz4/gzip/none) and additional backup stores (CIFS
          and Azure).', 'Operations improvements: automatic trim via recurring job,
          RWX volume trim, and new recurring jobs for snapshot cleanup/delete.', 'Node
          maintenance protection: node drain policy and PDB usage to improve safety
          during Kubernetes upgrades/maintenance.']
      breaking_changes: ['Upgrade path enforcement & downgrade prevention: you cannot
          downgrade after upgrading, and upgrades are only supported from 1.4.x to
          1.5.0.', "Removed/changed settings and deprecated fields may break existing\
          \ Helm values or automation if you rely on them (e.g., mkfs-ext4-parameters,\
          \ system-managed component image settings, deprecated recurringJobs fields,\
          \ allow-node-drain-with-last-healthy-replica, disable-replica-rebuild, \u201C\
          Guaranteed * CPU\u201D settings)."]
    chart_version: 1.5.0
    images: ['longhornio/longhorn-manager:v1.5.0', 'longhornio/longhorn-ui:v1.5.0']
  - version: 1.4.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / upgrade-impacting notes\n- **Kubernetes version requirement\
        \ changes:**\n  - Your current Longhorn **v1.3.2** supports **Kubernetes >=1.18\
        \ and <=1.24**.\n  - Longhorn **v1.4.0 requires Kubernetes >=1.21**.\n- **Kubernetes\
        \ 1.25 / PSP change:**\n  - In Kubernetes **1.25**, **PodSecurityPolicy (PSP)\
        \ is removed** and replaced by **Pod Security Admission (PSA)**.\n  - Longhorn\
        \ **v1.4.0 supports opt-in PSP enablement**, meaning PSP is **no longer assumed\
        \ by default**. If you previously relied on PSP, you must explicitly enable/keep\
        \ PSP support; otherwise plan to use PSA.\n- **CSI snapshot API deprecation:**\n\
        \  - Longhorn\u2019s bundled CSI snapshotter sidecar is upgraded to **v5.0.1**.\n\
        \  - **v1beta1 VolumeSnapshot CRDs are deprecated (still supported)**; you\
        \ should migrate to **snapshot.storage.k8s.io/v1** before a future snapshotter\
        \ upgrade removes v1beta1 support.\n"
      chart_updates: [Kubernetes 1.25 compatibility work (removal of deprecated API
          usage such as PodSecurityPolicy by default; PSP becomes opt-in)., Helm chart
          docs/readme updates mentioned in release notes (#4175/#4745)., 'Adds/updates
          chart-level knobs for scaling certain components (e.g., configurable replica
          counts for webhook and RWX recovery-backend) (#5087).', Adds/changes UI
          deployment affinity options in the chart (#4987).]
      features: [Kubernetes 1.25 support via PSA/optional PSP handling., ARM64 support
          promoted to General Availability (GA)., RWX (NFS) support promoted to GA
          with recovery backend to improve failover behavior., Snapshot checksum +
          periodic verification to detect corruption and support data integrity workflows.,
        Bit-rot detection and repair for snapshots when snapshot checksum is enabled.,
        Replica rebuild speed-ups (notably leveraging snapshot checksums/metadata
          to reduce unnecessary replication)., Volume trim (UNMAP) support to reclaim
          space on block volumes., Online volume expansion support via engine + CSI
          node driver filesystem resize., Strict data locality mode to keep a local
          replica and use local socket for improved performance., System Backup &
          Restore for backing up Longhorn system resources/metadata and restoring
          in-place or to a new cluster., Enhanced support bundle collection via rancher/support-bundle-kit
          integration., New tunable engine-to-replica timeout setting for low-spec/latent
          environments.]
      breaking_changes: ['Kubernetes support window shifts: upgrading to v1.4.0 requires
          Kubernetes **>=1.21** (and v1.4.0 is intended for newer clusters, including
          1.25).', "PodSecurityPolicy is no longer assumed; on Kubernetes 1.25 you\
          \ must use PSA, and if you still need PSP you must explicitly enable Longhorn\u2019\
          s opt-in PSP support.", VolumeSnapshot v1beta1 API is deprecated (still
          works now) and will be removed in a future CSI snapshotter upgrade; plan
          migration to v1.]
    chart_version: 1.4.0
    images: ['longhornio/longhorn-manager:v1.4.0', 'longhornio/longhorn-ui:v1.4.0']
  - version: 1.3.2
    kube: ['1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["Upgrade target is within the Longhorn 1.3 minor line (v1.3.0\
          \ \u2192 v1.3.2); most changes are bugfixes and operational improvements\
          \ rather than new features.", 'v1.3.2 adds an explicit Kubernetes version
          upper bound for <1.4 charts: supported Kubernetes is >=1.18 and <=1.24 (<1.25).',
        'v1.3.2 cleans up Helm chart packaging inconsistencies (e.g., values.yaml
          containing unused values; questions.yaml had outdated CSI image tags).',
        'CRD/manifest maintenance: updates around preserveUnknownFields and CRD patch
          generation/reorg; relevant if you manage CRDs outside Helm.']
      features: [Data alignment correction for existing volumes when filesystem block
          size is <4096 to prevent rare potential data corruption during replica rebuilds.,
        'Use a specific filesystem block size to reduce unnecessary read-modify-write
          between volume head and snapshots, improving write performance.', Support
          cleanup of failed/obsolete orphaned backups (backup hygiene improvements).]
      breaking_changes: ['Kubernetes compatibility constraint tightened/clarified
          for v1.3.2: cluster must be Kubernetes >=1.18 and <=1.24 (i.e., not 1.25+).
          Upgrading on newer clusters may be unsupported and should be avoided/validated
          before proceeding.']
    chart_version: 1.3.2
    images: []
  - version: 1.3.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Longhorn now requires Kubernetes >= 1.18 for install/upgrade
          (still upgrading only supported from 1.2.x to 1.3.0)., CRDs move to `longhorn.io/v1beta2`
          as the default; a conversion webhook is introduced to keep `v1beta1` access
          working post-upgrade., New/updated admission webhooks (mutating + validating)
          are added and the manager now waits for the webhook server to be ready.,
        Communication between longhorn-manager and engine/replica processes is changed
          to be proxied through instance-manager (enables storage network segregation).,
        'Optional security hardening additions: NetworkPolicies and optional mTLS
          between manager and instance-manager.', Snapshot-related API surface expands
          with a new Snapshot CRD; CSI snapshot support is extended to Longhorn snapshots.,
        Orphaned replica detection/cleanup feature added (including opt-in automatic
          cleanup)., Instance-manager lifecycle management changes; optional dynamic
          PDB management to work with Cluster Autoscaler (experimental)., 'Multiple
          operational/UX improvements: snapshot purge/prune improvement, backing image
          download support, metrics improvements, non-root default user for images,
          etc.']
      features: [Storage network / multi-network cluster support with control-plane/data-plane
          segregation via Multus (opt-in)., Managed Kubernetes compatibility improvements
          (EKS/GKE/AKS operations like upgrades and node pool replacement)., New v1beta2
          CRDs with structural schema validation and a conversion webhook (v1beta2
          becomes default)., New Snapshot CRD and extended CSI snapshot integration
          to create/restore Longhorn snapshots via CSI workflows., Orphaned replica
          detection with optional automatic cleanup to reduce manual maintenance.,
        Snapshot prune capability to delete snapshots directly behind the head to
          reclaim duplicated space., Optional mTLS between longhorn-manager and instance-manager
          for tighter control-plane security., Experimental support for Cluster Autoscaler
          via dynamic PDB handling for instance-manager pods.]
      breaking_changes: ['CRD API versioning shifts to `longhorn.io/v1beta2` as default;
          while a conversion webhook keeps `v1beta1` workable, any tooling that hard-codes
          v1beta1 manifests or relies on direct etcd objects should be validated against
          the new schemas/webhooks.', 'Networking/engine invocation path changes (manager->instance-manager
          proxy) could affect environments with strict NetworkPolicies/firewalls;
          if you run hardened clusters, ensure webhook/manager/instance-manager connectivity
          is allowed and consider the new provided NetworkPolicies.']
    chart_version: 1.3.0
    images: ['longhornio/longhorn-manager:v1.3.0', 'longhornio/longhorn-ui:v1.3.0']
  - version: 1.2.6
    kube: ['1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Longhorn v1.2.x remains within the same major/minor line; upgrade
          is primarily a patch-level move to v1.2.6., v1.2.0 introduced new CRDs/controllers
          for backups (BackupTarget/BackupVolume/Backup CRs) and for Recurring Jobs;
          upgrading to 1.2.0 triggers migration of per-volume recurring job settings
          to the new RecurringJob resources., v1.2.6 includes data-path correctness/performance
          fixes around filesystem block size alignment during rebuild and using a
          specific filesystem block size to avoid unnecessary RMW operations., 'v1.2.6
          also contains fixes around replica auto-balance/rebuild loops and some helm
          chart hygiene (removing unused values, updating outdated CSI image tags
          in questions.yaml).']
      features: [(Introduced in 1.2.0) Encrypted volumes and backups using Kubernetes
          Secrets for key storage., (Introduced in 1.2.0) CSI volume cloning support.,
        (Introduced in 1.2.0) Automatic replica rebalancing based on node/zone soft
          anti-affinity., (Introduced in 1.2.0) Asynchronous backup operations via
          new backup CRDs/controllers and improved scheduling via recurring job/groups.,
        (Patch focus in 1.2.6) Data alignment correction and filesystem block size
          handling to reduce risk of rare rebuild-related corruption and improve write
          performance.]
      breaking_changes: [Kubernetes minimum supported version becomes v1.18 in Longhorn
          v1.2.0 (and v1.2.6 supports Kubernetes <= v1.24)., 'After upgrading to v1.2.0,
          volume recurring job settings are migrated to new RecurringJob resources
          and the `RecurringJobs` field in Volume spec is deprecated.', 'Known issue
          in v1.2.0: StorageClasses using the longhorn CSI driver without specifying
          `fsType` can hit an `fsGroup`-ineffective issue for new filesystem volumes
          (resolved in 1.2.1 per notes).']
    chart_version: 1.2.6
    images: []
  - version: 1.2.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Longhorn v1.2.0 updates supported Kubernetes versions: minimum
          supported Kubernetes is now v1.18; adds compatibility up to Kubernetes v1.22
          by migrating deprecated resources and updating CSI sidecars.', 'CSI components
          are updated; known issue in v1.2.0: if a StorageClass using the `driver.longhorn.io`
          provisioner does not specify `fsType`, `fsGroup` may be ineffective for
          newly created filesystem volumes due to an external-provisioner default
          change. Workaround: explicitly set `parameters.fsType` (e.g., `ext4` or
          `xfs`) in the StorageClass; fixed in v1.2.1.', 'Recurring jobs are migrated:
          per-volume `spec.RecurringJobs` is deprecated and volume recurring job settings
          are migrated into new RecurringJob CRDs/resources during upgrade.', 'Backup
          subsystem refactor: introduces BackupTarget/BackupVolume/Backup CRDs and
          controllers enabling asynchronous backups; behavior and UI/observability
          around backups changes accordingly.']
      features: ['Kubernetes support updates: minimum K8s version becomes v1.18 and
          Longhorn supports K8s v1.22 with updated CSI sidecars.', Volume encryption
          and backup encryption using kernel crypto + Kubernetes Secrets; encrypted
          volumes are encrypted in transit and at rest and their backups are encrypted
          too., CSI volume cloning support to clone PVCs/volumes via CSI primitives.,
        Automatic replica rebalancing based on (soft) node/zone anti-affinity when
          nodes go up/down., 'Backing image enhancements: upload backing images from
          local and create backing images from existing volumes.', Asynchronous backup
          operations via new backup-related CRDs/controllers to improve backup performance
          and reduce blocking operations., Recurring job and recurring job groups
          via new CRD/controller for reusable scheduled snapshots/backups; includes
          default recurring backup policy concept.]
      breaking_changes: ['Kubernetes version compatibility change: you must be running
          Kubernetes v1.18+ before upgrading to Longhorn v1.2.0.', 'Recurring job
          model change: volume-level `RecurringJobs` in the Volume spec is deprecated
          and settings are migrated to new RecurringJob resources; automation that
          edits Volume specs directly must be updated.', 'Potential post-upgrade workload
          behavior change (known issue): StorageClasses without `fsType` may experience
          ineffective `fsGroup` on new filesystem volumes in v1.2.0; mitigate by setting
          `fsType` explicitly or upgrade to v1.2.1+.']
    chart_version: 1.2.0
    images: ['longhornio/longhorn-manager:v1.2.0', 'longhornio/longhorn-ui:v1.2.0']
  - version: 1.1.3
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Includes security fixes for CVE-2021-36779 (host operations allowed
          in privileged Longhorn-managed pods) and CVE-2021-36780 (unauthorized data
          access from replicas via vulnerable instance manager pods)., 'Improves data-plane
          behavior in low-performance environments (e.g., spinning disks, 1Gbps networks,
          low CPU).', 'Updates default advertised CSI version to CSI 1.2, improving
          compatibility with CSI consumers.']
      breaking_changes: []
    chart_version: 1.1.3
    images: []
  - version: 1.1.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Native RWX (ReadWriteMany) support via NFS provisioner is introduced
          as an experimental feature; validate with non-production workloads first.,
        Experimental ARM64 support is added so Longhorn can be deployed on ARM64 clusters
          without special modifications., CSI Snapshotter support is added (requires
          Kubernetes >=1.17) enabling kubectl-managed VolumeSnapshots that map to
          Longhorn backups/restores., Prometheus metrics endpoints and a sample Grafana
          dashboard are added to integrate Longhorn into existing monitoring/alerting
          stacks., 'Improved node failure and volume failure recovery, including automatic
          StatefulSet recovery behavior and rebuild from existing replicas after temporary
          node disconnects.', 'Expanded node maintenance operations (supports drain,
          replica eviction, pausing rebuilds, auto-removal of deleted K8s nodes, and
          disk recognition when reattached/moved).', Data Locality option is added
          to prefer keeping one replica local to the engine/workload to improve resilience
          during network interruptions., New setting to allow volume creation with
          degraded availability (default true; recommended false for production) for
          small clusters or constrained capacity environments., Experimental performance
          improvement by removing the revision counter is introduced.]
      breaking_changes: [Kubernetes minimum version increases to v1.16 for Longhorn
          v1.1.0; clusters below this must be upgraded before Longhorn., 'CSI Snapshotter
          feature requires Kubernetes v1.17+ and installation of the external CSI
          Snapshot Controller; without it, CSI snapshots will not work.']
    chart_version: 1.1.0
    images: ['longhornio/longhorn-manager:v1.1.0', 'longhornio/longhorn-ui:v1.1.0']
  - version: 1.0.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16', '1.15', '1.14']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.0.0
    images: ['longhornio/longhorn-manager:v1.0.0', 'longhornio/longhorn-ui:v1.0.0']
  name: longhorn
- icon: https://avatars.githubusercontent.com/u/49998002?s=48&v=4
  git_url: https://github.com/open-telemetry/opentelemetry-operator
  release_url: https://github.com/open-telemetry/opentelemetry-operator/releases/tag/v{vsn}
  versions:
  - version: 0.142.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.141.0
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26',
      '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.140.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.139.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.138.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.137.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.136.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.135.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.134.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.132.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.131.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.129.1
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25',
      '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.127.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.126.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.125.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.124.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.123.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.122.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.121.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.120.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.119.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.118.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.117.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24',
      '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.116.0
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.115.0
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.114.0
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.113.0
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.112.0
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.111.0
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.110.0
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.109.0
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  name: opentelemetry-operator
- icon: https://avatars.githubusercontent.com/u/22860722?s=48&v=4
  git_url: https://github.com/rook/rook
  release_url: https://github.com/rook/rook/releases/tag/v{vsn}
  helm_repository_url: https://charts.rook.io/release
  versions:
  - version: 1.18.0
    kube: ['1.34', '1.33', '1.32', '1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Minimum Helm version:** Helm **3.13+** is now explicitly\
        \ supported/tested (Rook now supports the six most recent Helm minor versions).\n\
        - **New default behavior (Helm):** The **Ceph CSI Operator is installed/enabled\
        \ by default** when deploying via Helm.\n  - New value in `rook-ceph` chart:\
        \ `csi.rookUseCsiOperator: true` (default).\n  - To revert to the previous\
        \ \u201CRook-managed CSI\u201D mode (e.g., if you hit a blocker): set `csi.rookUseCsiOperator:\
        \ false`.\n- **Install-time manifest note:** If you deploy with raw manifests,\
        \ you now need `csi-operator.yaml`. With Helm, this is handled automatically\
        \ when `csi.rookUseCsiOperator` is enabled."
      chart_updates: [Ceph CSI Operator integration is now the default/recommended
          path for configuring CSI drivers (RBD/CephFS/NFS). Rook will auto-convert
          existing Rook CSI settings to Ceph CSI Operator CRs during the v1.18 upgrade
          and throughout v1.18.x., Operator supports Kubernetes v1.29+ minimum (v1.17
          required v1.28+)., Operator validates node topology labels at CephCluster
          creation to prevent invalid CRUSH hierarchies; failures occur for new clusters
          with duplicated child topology labels across zones unless the check is skipped.,
        Adds `clusterID` support fields for certain CRDs (CephBlockPoolRadosNamespace
          and CephFilesystemSubVolumeGroup)., 'Mon failover behavior improved: if
          the assigned node no longer exists, failover is immediate (no 20-minute
          wait).']
      features: [Ceph CSI Operator becomes the default/recommended way to manage CSI
          (RBD/CephFS/NFS); Rook v1.18 auto-migrates existing CSI settings to the
          operator CRs transparently during upgrade., Ceph CSI v3.15 support (via
          CSI operator or legacy mode for now); note that the CSI operator will become
          required in the next release., Experimental CephX key rotation support with
          new `spec.security.cephx` settings; requires Ceph v19.2.3+ (admin/mon keys
          not yet rotatable)., Support specifying `clusterID` in CephBlockPoolRadosNamespace
          and CephFilesystemSubVolumeGroup CRs., Faster mon failover when the target
          node is gone (immediate instead of waiting 20 minutes).]
      breaking_changes: [Kubernetes **v1.29** is now the minimum supported version
          (v1.17 was v1.28)., 'New clusters only: CephCluster creation now validates
          topology labels to prevent misconfigured CRUSH hierarchies; creation can
          fail if child labels (e.g., `topology.rook.io/rack`) are duplicated across
          zones unless `ROOK_SKIP_OSD_TOPOLOGY_CHECK=true` is set.', 'Object storage
          changes introduced in v1.17 (relevant when coming from 1.17.0): OBC additional
          config fields are disabled by default unless `ROOK_OBC_ALLOW_ADDITIONAL_CONFIG_FIELDS`
          is enabled; CephObjectStoreUser credential management may purge undeclared
          extra S3 credentials; Kafka bucket notifications now default Kafka auth
          mechanism to `PLAIN` and cannot be set via `opaqueData` mechanism param.']
    chart_version: 1.18.0
    images: []
  - version: 1.17.0
    kube: ['1.33', '1.32', '1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Rook v1.17 raises the supported Kubernetes floor to v1.28 (v1.16
          was v1.27). Ensure your cluster/control-plane and any constrained environments
          (e.g., managed K8s versions) meet this before upgrading.', ObjectBucketClaim
          (OBC) flexibility introduced in v1.16 is now disabled by default in v1.17
          for safer defaults; enabling it requires setting the operator env var `ROOK_OBC_ALLOW_ADDITIONAL_CONFIG_FIELDS`.
          This may require updating the operator deployment/Helm values to add the
          env var if you rely on those OBC fields., 'CephObjectStoreUser behavior
          changes due to new first-class credential management: Rook will purge undeclared
          extra S3 credentials on existing users; plan to migrate to declarative credential
          management if you previously rotated credentials manually.', CephBucketTopic
          Kafka notifications now default `PLAIN` auth mechanism and no longer allow
          overriding the mechanism via `spec.endpoint.kafka.opaqueData` using `&mechanism=<auth
          type>`; update affected CephBucketTopic manifests explicitly if you use
          another mechanism.]
      features: ['OBCs can optionally set a pre-existing Ceph RGW user as bucket owner
          (via CephObjectStoreUser), avoiding one-user-per-bucket and allowing re-linking
          existing buckets to a specified owner.', 'Ceph CSI updated to v3.14 with
          multiple improvements across RBD/CephFS, snapshots, and other areas (review
          ceph-csi 3.14 release notes for specifics relevant to your workloads).',
        Experimental support for external monitors (mons) to place a mon outside the
          Kubernetes cluster for certain two-datacenter/stretch-like scenarios., 'DNS-based
          mon endpoint tracking for clients outside the cluster via `rook-ceph-active-mons.<ns>.svc.cluster.local`,
          reducing manual mon endpoint updates when mon IPs change.', 'Per-node ceph.conf
          overrides: node-specific ConfigMaps can override `ceph.conf` for OSDs and
          OSD prepare jobs on that node.']
      breaking_changes: [Minimum supported Kubernetes version is now v1.28 (was v1.27
          in v1.16)., OBC additionalConfig options that allow user-controlled bucket
          policy/etc. are now disabled by default; you must opt in with `ROOK_OBC_ALLOW_ADDITIONAL_CONFIG_FIELDS`
          if you depend on them., 'CephObjectStoreUser now has first-class credential
          management; Rook will remove (purge) any extra S3 credentials not declared
          in the resource, which can break setups where admins manually added/rotated
          credentials on the RGW user.', 'Kafka notification auth mechanism defaults
          to `PLAIN`, and overriding the mechanism via `opaqueData` query string is
          no longer supported; manifests must be adjusted for non-PLAIN auth.']
    chart_version: 1.17.0
    images: []
  - version: 1.16.0
    kube: ['1.32', '1.31', '1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Ceph-CSI driver updated to v3.13, adding volume group snapshots
          plus various CephFS/RBD improvements and sidecar updates.', 'CephBlockPoolRadosNamespace
          now supports mirroring, including optional periodic status monitoring when
          the parent pool has statusCheck enabled.', PVC-based OSDs can be migrated
          to enable/disable encryption., Ceph object storage gains multiple RGW instances
          support and more advanced configuration options (extra CLI params/ceph.conf
          settings)., ObjectBucketClaims can manage S3 bucket policy via additionalConfig.bucketPolicy;
          RGW admin ops logging can be enabled via opsLogSidecar., Kubernetes support
          is extended up to v1.32.]
      breaking_changes: [Ceph Quincy (v17) support is removed; only Ceph Reef (v18)
          and Squid (v19) are supported in Rook v1.16., "CSI network \u201Cholder\u201D\
          \ pods are removed; clusters still using csi-*plugin-holder-* must disable/remove\
          \ them before upgrading.", Minimum supported Kubernetes version increases
          to v1.27.]
    chart_version: 1.16.0
    images: []
  - version: 1.15.0
    kube: ['1.31', '1.30', '1.29', '1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Kubernetes minimum supported version increases to 1.26 in v1.15.0
          (was 1.25 in v1.14.0); verify cluster version before upgrading., 'Rook now
          uses fully-qualified image names (e.g., docker.io/rook/ceph) in operator
          manifests and Helm charts; if you mirror images or use private registries,
          ensure overrides still work as expected.', Ceph-CSI sidecars/images updated
          with Ceph-CSI v3.12; expect rolling restarts of CSI components during upgrade.]
      features: [Adds support for Ceph Squid (v19) in addition to Reef (v18) and Quincy
          (v17); note Quincy support will be removed in Rook v1.16., 'Ceph-CSI driver
          updated to v3.12, bringing new RBD options, log rotation, and updated sidecar
          images.', 'New cluster options to allow updating OSD device class (allowDeviceClassUpdate:
          true) and OSD weight (allowOsdCrushWeightUpdate: true) via the CephCluster
          CR.']
      breaking_changes: [Minimum supported Kubernetes version is now v1.26; upgrade
          Kubernetes before upgrading Rook if needed., CephBlockPool updates now error
          when an invalid deviceClass is specified; existing pools with invalid device
          class settings may fail until corrected., "CSI network \u201Cholder\u201D\
          \ pods are now deprecated and should be disabled if present; this becomes\
          \ required before upgrading to Rook v1.16.", Ceph COSI driver image changes
          can impact existing COSI Buckets/BucketClaims/BucketAccesses; follow the
          upstream migration guide before/after upgrade., Object store endpoint behavior
          changes when spec.hosting is set; use the new spec.hosting.advertiseEndpoint
          to get the desired endpoint behavior.]
    chart_version: 1.15.0
    images: []
  - version: 1.14.0
    kube: ['1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values changes (v1.13.0 \u279C v1.14.0)\n- **CSI image\
        \ values format changed (breaking):** if you previously set CSI images using\
        \ a single `image` value, you must now set **`repository`** and **`tag`**\
        \ **separately** for the CSI images in `values.yaml`.\n- **Removed operator\
        \ env var (breaking):** `CSI_ENABLE_READ_AFFINITY` was removed from the operator\
        \ config. If you relied on it (especially if set to `\"true\"`), configure\
        \ the equivalent **per-`CephCluster` CSI driver options** before upgrading\
        \ (see the v1.14 docs for `csi.driverOptions`).\n"
      chart_updates: [Kubernetes minimum version raised to **v1.25** (cluster must
          be upgraded first)., Ceph daemon pods that used the `default` service account
          now use **`rook-ceph-default`** (review any RBAC/PSA/PodSecurity policies
          or tooling that assumed `default`)., CSI network *plugin holder* pods are
          being deprecated; optional migration in v1.14 but plan to disable/migrate
          ahead of a future required removal.]
      features: ["Supports Kubernetes **v1.25\u2013v1.29** (v1.30 planned once released).",
        CephBlockPool CR can set a custom Ceph `application` value., RGW object stores
          can share metadata/data pools using RADOS namespaces to reduce pool count
          when multiple object stores exist., Adds VolumeSnapshotGroup support for
          RBD and CephFS CSI drivers., Adds S3 virtual-host-style bucket access via
          `hosting.dnsNames` in CephObjectStore., Allows configuring a static prefix
          for CSI drivers and the OBC provisioner (default prefix is the `rook-ceph`
          namespace)., Adds Azure Key Vault KMS integration for storing OSD encryption
          keys., Adds additional status columns for `kubectl get` output on Rook CRDs.]
      breaking_changes: [Minimum supported Kubernetes version is now **v1.25**; upgrade
          Kubernetes before upgrading Rook., Helm CSI image configuration changed
          from a single `image` to separate `repository` + `tag` fields; existing
          values must be updated., CSI network *holder* pods are deprecated; v1.14
          migration is optional but will be required in a future release (plan remediation).,
        Operator config `CSI_ENABLE_READ_AFFINITY` removed; configure read-affinity
          via each `CephCluster` CSI driver options before upgrading if you previously
          enabled it.]
    chart_version: 1.14.0
    images: []
  - version: 1.13.0
    kube: ['1.29', '1.28', '1.27', '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Default Ceph-CSI driver moves from v3.9 (in 1.12) to v3.10 in 1.13.,
        Added experimental `cephConfig` in the `CephCluster` CR to set Ceph config
          options via the CR; these settings override existing ceph.conf override
          mechanisms., CSI read-affinity settings are now configured per-cluster in
          the `CephCluster` CR instead of the operator ConfigMap., CephFS default
          SubvolumeGroup now enables pinning by default to spread load predictably
          across MDS ranks., Ceph exporter now uses a reduced-privilege keyring instead
          of the admin keyring., MONs will automatically fail over when `hostNetwork`
          is changed in the `CephCluster` CR., Rook will honor the label `ceph.rook.io/do-not-reconcile`
          on all Ceph daemons to allow advanced maintenance/debug workflows.]
      breaking_changes: [Ceph Pacific (v16) support is removed; only Ceph Quincy (v17)
          and Reef (v18) are supported in 1.13., Minimum Kubernetes version increases
          to v1.23 (from v1.22 in 1.12)., 'Minimum supported Ceph-CSI driver increases
          to 3.9 (1.12 already required 3.8+, but 1.13 requires 3.9+).', 'Rook admission
          controller is removed; if you had enabled it, disable it before upgrading
          per the 1.13 upgrade guide.']
    chart_version: 1.13.0
    images: []
  - version: 1.12.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Support for Ceph Reef (v18)., Ceph CSI default version bumped to
          v3.9 (minimum supported v3.8)., Experimental Ceph COSI driver added to provision
          object buckets., Automation to recover RBD (RWO) volumes after node loss
          (requires CSI-addons and K8s v1.26 non-graceful node shutdown feature).,
        Multus network validation tool and improvements to external Ceph cluster configuration
          script., Security hardening by dropping container capabilities., Ability
          to disable ObjectBucketClaim and ObjectBucketNotification controllers.,
        'NFS enhancements: experimental RGW backend for CephNFS, NFS-Ganesha v5.1
          monitoring endpoint support, and kerberos bug fixes.']
      breaking_changes: [Minimum supported Kubernetes version is now v1.22 (was v1.21
          in v1.11)., 'Minimum supported Ceph-CSI driver is now 3.8; if you pin CSI
          images/versions, update them accordingly.', 'For CephObjectStores, a manually-set
          `rgw_run_sync_thread` (via `ceph config set`) will be overridden based on
          `disableMultisiteSyncTraffic`; validate multisite/sync behavior after upgrade.']
    chart_version: 1.12.0
    images: []
  - version: 1.11.0
    kube: ['1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **PodSecurityPolicy defaults changed:** the Helm value `pspEnable`\
        \ now defaults to **`false`** (and docs for enabling PSP were removed). If\
        \ you still rely on PSP on older clusters, refer to the v1.10 docs and explicitly\
        \ set `pspEnable=true` during the upgrade.\n- **Removed values/CR fields:**\
        \ settings related to **MachineDisruptionBudgets** were removed (see breaking\
        \ changes). If you previously set these via chart values/CR, remove them before\
        \ upgrading:\n  - `manageMachineDisruptionBudgets`\n  - `machineDisruptionBudgetNamespace`\n"
      chart_updates: [Charts should no longer assume/enable PodSecurityPolicy by default
          (`pspEnable` default is `false`)., Any chart templating/values that referenced
          MachineDisruptionBudgets-related settings must be removed/updated accordingly.,
        Expect updated manifests/images for the new default Ceph-CSI version (now
          v3.8).]
      features: ['Ceph-CSI default version is now v3.8, bringing new storage features
          and fixes compared to v3.7.', 'New `requireMsgr2` option on `CephCluster`
          allows enforcing msgr2-only communication (kernel 5.11+), enabling wire
          features like encryption/compression.', RGW bucket notifications and topics
          are now considered stable., 'Ceph exporter daemon becomes the preferred
          metrics source (performance counters), reducing load on the Ceph mgr and
          improving scalability.', RBD read affinity is available via krbd map options
          to prefer nearby OSDs based on CRUSH/topology labels., 'Multi-cluster mirroring
          with overlapping networks is supported via MCS-compatible solutions (e.g.,
          Submariner globalnet) for Ceph v17.2.6+.', 'Standby Ceph mgr readiness is
          now handled via readiness probes (active passes, standby fails) instead
          of a sidecar.']
      breaking_changes: [Kubernetes minimum supported version increased to **v1.21**
          (ensure the cluster control plane and nodes meet this before upgrading).,
        'Minimum supported Ceph-CSI version is **v3.7**; Rook 1.11 deploys **v3.8**
          by default, so pinning older CSI versions will not be supported.', 'MachineDisruptionBudgets
          support was removed; delete/stop using related `CephCluster` fields (`manageMachineDisruptionBudgets`,
          `machineDisruptionBudgetNamespace`) and any dependent automation.', 'If
          you relied on PodSecurityPolicy being enabled by default, you must now explicitly
          enable it (older K8s only) or migrate to Pod Security Standards/admission
          alternatives.']
    chart_version: 1.11.0
    images: []
  - version: 1.10.0
    kube: ['1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart behavior changes to account for\n- **MDS\
        \ probes moved to `CephFilesystem`**: If you previously set MDS liveness/startup\
        \ probes on `CephCluster`, move them into each `CephFilesystem` CR under the\
        \ metadata server settings.\n- **Default pod resources now set in Helm charts**:\
        \ Rook Ceph components will get default requests/limits from the chart. If\
        \ you had tuned resources implicitly (or relied on \u201Cno defaults\u201D\
        ), review and override/remove resource settings in `values.yaml` as needed.\n\
        - **Prometheus rules creation moved to Helm values**: If you relied on `CephCluster.spec.monitoring.enabled`\
        \ to create Prometheus rules, you now must enable them via the cluster chart\
        \ value `monitoring.createPrometheusRules`.\n\n### Version prerequisites that\
        \ impact cluster/helm upgrade planning\n- **Ceph Octopus removed (v1.10)**:\
        \ Ensure your Ceph cluster is **>= v16 (Pacific)** before upgrading to Rook\
        \ **v1.10**.\n- **Kubernetes minimum version**: Rook **v1.10** requires **Kubernetes\
        \ >= 1.19**."
      chart_updates: [Prometheus alerting rules are now installed/managed by the **cluster
          Helm chart** when enabled via `monitoring.createPrometheusRules` (instead
          of being created via the `CephCluster` CR setting)., Helm charts now ship
          with **default resource requests/limits** for Ceph component pods (review
          and tune for your environment).]
      features: [Ceph-CSI **v3.7** becomes the default CSI driver version with Rook
          v1.10 (brings CSI feature updates per upstream v3.7 notes)., 'RGW adds support
          for **AWS Server Side Encryption** (AWS-SSE:S3) configuration.', '`customEndpoints`
          added for Object Multi-site connections in `CephObjectZone`.', Host-based
          clusters can use OSDs on **logical volumes (LVM)** in addition to raw devices/partitions.,
        'Toolbox pod now uses the **Ceph image directly**, matching the Ceph version
          running in your cluster.', (From v1.9) Network **encryption** and **compression**
          settings are configurable via `CephCluster` (with kernel/Ceph version prerequisites).]
      breaking_changes: ['MDS liveness/startup probes must be configured on **`CephFilesystem`**,
          not `CephCluster` (update your CR manifests accordingly).', Ceph Octopus
          (v15) is **no longer supported** in v1.10; upgrade Ceph to **>= v16** first.,
        Rook v1.10 requires **Kubernetes >= 1.19**., 'If you depended on `CephCluster.spec.monitoring.enabled`
          to create Prometheus rules, switch to Helm value **`monitoring.createPrometheusRules`**.',
        Helm charts now apply **default pod resources** for Ceph components; this
          can change scheduling/limits if you were not explicitly setting them.]
    chart_version: 1.10.0
    images: []
  - version: 1.9.0
    kube: ['1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm chart changes to plan for\n- **Default pod resources\
        \ now set for all Ceph components** in the Helm charts (new defaults in `values.yaml`).\
        \ If you previously relied on \u201Cno requests/limits\u201D (or set them\
        \ via custom templates), review and override/remove these defaults to match\
        \ your cluster sizing.\n- **Prometheus rules installation moved to the cluster\
        \ Helm chart.** If you previously enabled rules via `CephCluster.spec.monitoring.enabled`,\
        \ you must now enable them via the chart value **`monitoring.createPrometheusRules`**.\n\
        \n## CRD/manifest configuration changes that affect Helm users\n- **MDS probes\
        \ moved:** MDS liveness/startup probes are no longer configured via `CephCluster`;\
        \ they are configured via the **`CephFilesystem` CR**. If you set or tuned\
        \ MDS probes, migrate those settings accordingly."
      chart_updates: [Prometheus alerting rules are now deployed by the rook-ceph-cluster
          Helm chart (when enabled) rather than being created based on `CephCluster.spec.monitoring.enabled`.,
        Helm charts now include default CPU/memory resource requests/limits (or requests)
          for all Ceph component pods; these may change scheduling behavior and should
          be reviewed before upgrade.]
      features: [Example clusters now run **2 mgr daemons** (active + standby) for
          higher availability; services labeled `app=rook-ceph-mgr` will be updated
          to point to the new active mgr after failover., '**Network encryption**
          can be configured via `CephCluster` network settings (requires Linux kernel
          5.11+).', '**Network compression** can be configured via `CephCluster` network
          settings (requires Ceph Quincy/v17 plus a newer kernel, similar to encryption
          requirements).', CSI pods can be configured with a **custom `ceph.conf`**.,
        Updated/added **Ceph Prometheus rules** aligned with upstream Ceph recommendations;
          can be created via Helm with `monitoring.createPrometheusRules`., RGW pods
          now use a dedicated **`rook-ceph-rgw` service account**., New **`CephBlockPoolRadosNamespace`
          CRD** to manage RADOS namespaces within a pool.]
      breaking_changes: [MDS liveness/startup probes configuration moved from `CephCluster`
          to `CephFilesystem`; existing `CephCluster` probe settings will no longer
          apply until migrated., 'Helm charts now set default pod resources for Ceph
          components, which can cause scheduling/admission changes (e.g., pods may
          not schedule on small nodes) unless values are adjusted.', Prometheus rules
          are no longer created by `CephCluster.spec.monitoring.enabled`; Helm users
          must enable rule creation with `monitoring.createPrometheusRules` (or manage
          rules externally)., 'The obsolete cross-build container was removed (mostly
          impacts CI/build workflows, not runtime clusters).']
    chart_version: 1.9.0
    images: []
  - version: 1.8.0
    kube: ['1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.8.0
    images: []
  - version: 1.7.0
    kube: ['1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 1.6.0
    kube: ['1.22', '1.21', '1.20', '1.19', '1.18', '1.17', '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 1.5.0
    kube: ['1.21', '1.20', '1.19', '1.18', '1.17', '1.16', '1.15']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 1.4.0
    kube: ['1.20', '1.19', '1.18', '1.17', '1.16', '1.15', '1.14']
    requirements: []
    incompatibilities: []
    summary: null
  name: rook
- icon: https://avatars.githubusercontent.com/u/34767428?s=48&v=4
  git_url: https://github.com/strimzi/strimzi-kafka-operator
  release_url: https://github.com/strimzi/strimzi-kafka-operator/releases/tag/{vsn}
  versions:
  - version: 0.49.1
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.49.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.48.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.47.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.46.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.45.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.44.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.43.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.42.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.41.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.40.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.39.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.38.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.37.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.36.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.35.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.34.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.33.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.32.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.31.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.30.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.29.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.28.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.27.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.26.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.25.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.24.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.23.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.22.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.21.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.20.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16', '1.15', '1.14', '1.13', '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.19.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16', '1.15', '1.14', '1.13', '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.18.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16', '1.15', '1.14', '1.13', '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.17.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16', '1.15', '1.14', '1.13', '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.16.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16', '1.15', '1.14', '1.13', '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.15.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16', '1.15', '1.14', '1.13', '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.14.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16', '1.15', '1.14', '1.13', '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.13.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16', '1.15', '1.14', '1.13', '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 0.12.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18', '1.17',
      '1.16', '1.15', '1.14', '1.13', '1.12', '1.11']
    requirements: []
    incompatibilities: []
    summary: null
  name: strimzi-kafka
- icon: https://github.com/traefik/traefik/raw/master/docs/content/assets/img/traefik.logo-dark.png
  git_url: https://github.com/traefik/traefik
  release_url: https://github.com/traefik/traefik/releases/tag/v{vsn}
  helm_repository_url: https://traefik.github.io/charts
  versions:
  - version: 3.6.5
    kube: ['1.35', '1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['From v3.6.0 (baseline): added new ACME certificatesResolvers options;
          added least-time and HighestRandomWeight load-balancing strategies; added
          TCP (active) healthchecks and passive health checks; added Knative provider
          and improvements to Kubernetes/Gateway API and Ingress publishing (including
          ExternalName services); added multi-layer routing; added HTTP/2 HPACK table
          size options; and several dashboard/UI tweaks.', v3.6.5 is a patch release
          with no new features called out in the notes you provided; it focuses on
          fixes/behavior clarifications.]
      breaking_changes: ['Access logs will now also be printed for rejected requests;
          the release note explicitly warns about this new behavior, so log volume/content
          may change and could affect log-based alerts/costs.']
    chart_version: 38.0.1
    images: []
  - version: 3.6.0
    kube: ['1.35', '1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['ACME: new certificate resolver options, following earlier v3.5 OCSP
          stapling and HTTP challenge delay/timeout improvements.', 'Health checks:
          adds TCP health checks and passive health checks (in addition to v3.5 healthcheck
          improvements).', 'Load balancing: adds "least time" strategy and HighestRandomWeight
          algorithm (plus CRD support for HighestRandomWeight).', 'Kubernetes: Gateway
          API bumped to v1.4.0; Ingress can publish ExternalName services; adds a
          Knative provider.', 'Docker/ECS: can discover non-running Docker containers;
          ECS gains IPv6 support.', "Middleware/server: multi-layer routing; warning\
          \ when maxBodySize isn\u2019t set.", 'Plugins: adds syscall support; earlier
          v3.5 allowed enabling unsafe yaegi via plugin manifest.', 'HTTP/2: adds
          HPACK table size tuning options.', 'Web UI: dashboard continues React migration
          and adds Hub demo plus layout tweaks.']
      breaking_changes: ['Potential behavior change risk: multi-layer routing and
          new load-balancing/healthcheck features may alter request routing/traffic
          patterns if enabled.', Gateway API bump may expose/require updated CRDs
          or behavior differences depending on cluster/controller versions., 'Ingress
          prefix-matching behavior was made consistent with Kubernetes docs in v3.5;
          if you rely on the old behavior, routes may match differently after upgrading
          to >=3.5 (including 3.6).']
    chart_version: 37.3.0
    images: ['docker.io/traefik:v3.6.0']
  - version: 3.5.0
    kube: ['1.35', '1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['ACME improvements: OCSP stapling support plus new tuning options
          for HTTP-01 challenge delay and ACME HTTP client timeout.', 'Kubernetes-related
          additions: new NGINX Ingress provider and Gateway API dependency bumped
          to v1.3.0.', 'Ingress behavior change: Prefix path matching is now consistent
          with Kubernetes documentation (may affect which Ingress rules match).',
        'Observability improvements for OpenTelemetry: more resource attribute detectors,
          automatic k8s resource attributes, new resourceAttributes option for OTel
          metrics, and reduced default tracing span volume with trace verbosity control.',
        'Dashboard updates: UI migrated to React and improved visualization for Errors
          middleware StatusRewrites.', 'TLS enhancement: adds X25519MLKEM768 (post-quantum)
          key exchange option.', 'Plugin system: plugin manifests can now allow enabling
          unsafe mode in Yaegi.', 'ForwardAuth middleware: better handling of context-canceled
          scenarios.']
      breaking_changes: ['Potential behavioral change for Kubernetes Ingress Prefix
          matching; verify your Ingress rules/routes still match as expected after
          upgrade, especially for overlapping prefixes.', Trace output may change
          because Traefik produces fewer spans by default due to new trace verbosity
          behavior; dashboards/alerts based on span counts may need adjustment.]
    chart_version: 37.0.0
    images: ['docker.io/traefik:v3.5.0']
  - version: 3.4.0
    kube: ['1.35', '1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Security hardening in v3.3.6: request path is now sanitized (collapses
          /../, /./ and duplicate slashes) before router matching and before forwarding
          to backends.', v3.4.0 adds ACME options `acme.profile` and `acme.emailAddresses`.,
        v3.4.0 adds a Redis-backed rate limiter middleware., v3.4.0 adds `p2c` (power-of-two-choices)
          load-balancing strategy for services., v3.4.0 extends forwardAuth to optionally
          preserve the original request method., 'v3.4.0 improves Kubernetes support:
          better CRD CEL validations, Gateway API TLSRoute rule priority, and ingress
          status for ClusterIP/NodePort services.', 'v3.4.0 adds TLS features: add
          root CAs via ConfigMaps and ability to disable TLS session tickets.', v3.4.0
          adds sticky-session cookie domain configuration and WebUI auto theme option.]
      breaking_changes: ['Potential behavior change starting v3.3.6: request path
          sanitization can change routing/backends for paths containing dot-segments
          or duplicate slashes; validate against your existing router rules and any
          apps that rely on raw paths.', 'v3.4.0 removes the default load-balancing
          strategy from Kubernetes IngressRoute/CRD resources; if you relied on the
          implicit default, you may need to set an explicit strategy.', '`defaultRuleSyntax`
          and `ruleSyntax` are deprecated in v3.4.0 (plan to remove/avoid using them
          going forward).']
    chart_version: 35.4.0
    images: ['docker.io/traefik:v3.4.0']
  - version: 3.3.6
    kube: ['1.34', '1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 35.2.0
    images: ['docker.io/traefik:v3.3.6']
  - version: 3.3.0
    kube: ['1.33', '1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 3.2.0
    kube: ['1.33', '1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 33.0.0
    images: ['docker.io/traefik:v3.2.0']
  - version: 3.1.7
    kube: ['1.33', '1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 3.1.4
    kube: ['1.32', '1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Datadog metrics output now better handles `unix://` endpoints by
          guessing the socket type when the prefix is `unix` (improves compatibility
          for Datadog socket configurations).']
      breaking_changes: []
    chart_version: 31.1.1
    images: ['docker.io/traefik:v3.1.4']
  - version: 3.1.3
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Security fixes included in this upgrade: v3.0.2 addressed GHSA-7jmw-8259-q9jx
          (CVE-2024-24790 related) and v3.1.3 includes CVE-2024-45410 (GHSA-62c8-mh53-4cqv).',
        'Kubernetes Ingress improvements: you can configure rule syntax via Ingress
          annotation, and empty configuration for the Kubernetes Ingress provider
          is allowed again.', 'Observability improvements and fixes: updated OpenTelemetry
          dependencies, fixed Grafana label_replace for service-name in metrics, and
          multiple tracing/OTLP documentation + stability fixes.', 'Compression middleware
          behavior improvements: better Accept-Encoding handling (including weights)
          and correct status code forwarding when Brotli compression is disabled.',
        'Plugins internal change: removed goexport dependency and added _initialize
          (plugin loading/runtime change).']
      breaking_changes: ["Potentially breaking for monitoring: the v3 migration guide\
          \ notes missing metrics removal\u2014verify any dashboards/alerts that rely\
          \ on Traefik metrics that may have been removed/renamed in v3.x.", 'Kubernetes
          API version expectations: documentation removes mentions of traefik.io/v1;
          ensure your CRDs/manifests align with the supported API versions for Traefik
          v3 (commonly traefik.io/v1alpha1 depending on resource).']
    chart_version: 31.1.0
    images: ['docker.io/traefik:v3.1.3']
  - version: 3.0.2
    kube: ['1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 28.3.0
    images: ['docker.io/traefik:v3.0.2']
  - version: 2.11.13
    kube: ['1.33', '1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 2.11.10
    kube: ['1.32', '1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 2.11.4
    kube: ['1.31', '1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 2.10.3
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
  name: traefik
- icon: https://velero.io/img/Velero.svg
  git_url: https://github.com/vmware-tanzu/velero
  release_url: https://github.com/vmware-tanzu/velero/releases/tag/v{vsn}
  helm_repository_url: https://vmware-tanzu.github.io/helm-charts
  versions:
  - version: 1.17.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['fs-backup (file system backup) is redesigned into a micro-service
          architecture, enabling concurrency control, cancel/resume, better isolation,
          and steadier node-agent resource usage.', File system backup now supports
          Windows workloads by running data mover pods on Windows nodes., 'Support
          for Kubernetes VolumeGroupSnapshot (beta upstream) is added for both CSI
          snapshot backups and CSI snapshot data movement, enabling crash-consistent
          snapshots across multiple volumes.', 'PriorityClass can now be configured
          across Velero components (server, node-agent, data movers, and repository
          maintenance jobs) to influence scheduling/eviction.', 'Data mover scalability/resiliency
          improvements: throttle creation via node-agent PrepareQueueLength; resume/cancel
          behavior improved across node-agent restarts; restore node-selection matches
          backup and can be set per storage class.', Resource policies gain an includeExcludePolicy
          so reusable include/exclude filters can be centralized in a configmap.,
        'CLI can auto-discover and use ca cert from the BackupStorageLocation for
          download requests; added BSL availability metric; added s390x support. ']
      breaking_changes: ['Restic-based fs-backup is removed: --uploader-type=restic
          is no longer a valid installation configuration (restores from existing
          restic backups still supported until v1.19).', 'Repository maintenance job
          tuning flags are removed from the velero server args (--keep-latest-maintenance-jobs,
          --maintenance-job-*-request/limit); these settings move to a repository
          maintenance job ConfigMap.', 'PVC restore behavior change: selected-node
          annotation is now always removed when there is no node mapping (previously
          it could be preserved if the node existed).']
    chart_version: 11.3.1
    images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
  - version: 1.17.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / install-time config changes to check\n\n###\
        \ 1) **Restic uploader removed (breaking)**\n* `--uploader-type=restic` is\
        \ **no longer valid** in v1.17.\n  * If your Helm chart values set anything\
        \ equivalent (commonly `configuration.uploaderType`, `uploaderType`, `deployRestic`,\
        \ `deployNodeAgent`/`restic` toggles, etc.), remove/disable Restic and use\
        \ the current fs-backup path.\n  * You can **still restore old Restic-based\
        \ backups until v1.19**, but you cannot create new ones.\n\n### 2) **Repository\
        \ maintenance job flags removed from velero server (breaking)**\nThe following\
        \ server parameters were removed and must be configured via the **repository\
        \ maintenance job ConfigMap** instead:\n* `--keep-latest-maintenance-jobs`\n\
        * `--maintenance-job-cpu-request`\n* `--maintenance-job-mem-request`\n* `--maintenance-job-cpu-limit`\n\
        * `--maintenance-job-mem-limit`\n\nIf you previously set these via chart values\
        \ that map to `server.extraArgs`, move them to the chart\u2019s maintenance-job\
        \ configmap values (name varies by chart).\n\n### 3) New/updated **node-agent**\
        \ configuration knobs worth reviewing\nThese are additive but may require\
        \ Helm values if you want to use them:\n* `PrepareQueueLength` (node-agent):\
        \ throttles creation of data mover pods to avoid large numbers stuck Pending.\n\
        * `priorityClassName` support across modules (server, node-agent, data mover\
        \ pods, maintenance jobs): you may want to set these explicitly.\n* Parameterized\
        \ kubelet mount path for node-agent install (only if you run non-standard\
        \ kubelet paths).\n\n### 4) Modernized fs-backup (architecture change)\nfs-backup\
        \ is now micro-service based. In Helm terms this may translate into:\n* more/changed\
        \ pod templates for data mover / fs-backup components,\n* potential new configmaps/args\
        \ for concurrency/cancel/resume behavior.\n\n(Exact value keys depend on your\
        \ chart; validate rendered manifests before applying.)"
      chart_updates: ['fs-backup moved to a micro-service architecture (better concurrency
          control, cancel/resume, and resiliency across node-agent restarts).', 'Windows
          support expands: fs-backup now supports Windows workloads; data mover pods
          can run on Windows nodes with required tolerations.', Volume Group Snapshots
          support added (Kubernetes beta feature) for CSI snapshot backup and CSI
          snapshot data movement., 'PriorityClass support added across Velero components
          (server, node-agent, data mover pods, maintenance jobs).', 'Data mover scalability
          improvements: throttled pod creation via node-agent `PrepareQueueLength`,
          improved restart/orphan handling, expanded node-selection for restore and
          per-storageclass node-selection.', Resource policy enhanced with reusable
          include/exclude filters via `includeExcludePolicy`., 'Operational changes:
          repository maintenance job configuration moved from server flags to a ConfigMap;
          additional config validation added for install CLI and server start.']
      features: [Modernized fs-backup into a micro-service architecture with concurrency
          control plus cancel/resume and improved resiliency across node-agent restarts.,
        'fs-backup now supports Windows workloads, enabling full Windows backup/restore
          scenarios (with CSI data movement support introduced earlier).', Adds support
          for Kubernetes Volume Group Snapshots to take point-in-time consistent snapshots
          across multiple related volumes., 'Adds PriorityClass support so you can
          control scheduling priority for server, node-agent, data movers, and maintenance
          jobs.', 'Improves data mover scalability with a node-agent prepare queue
          to avoid flooding the cluster with Pending pods, plus better restart/orphan
          handling and node-selection (including per-storageclass).', Adds reusable
          resource include/exclude filtering via `includeExcludePolicy` in resource
          policies.]
      breaking_changes: ["Restic uploader path is removed: `--uploader-type=restic`\
          \ is no longer a valid install configuration; you can\u2019t create new\
          \ Restic-based backups (restores remain supported until v1.19).", Repository
          maintenance job settings are no longer configured via Velero server flags;
          the maintenance job CPU/memory and keep-latest settings must be moved to
          the repository maintenance job ConfigMap., 'PVC restore behavior change:
          selected-node annotation is now removed during PVC restore when no node
          mapping exists (previously it could be preserved in some cases).']
    chart_version: 11.2.0
    images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.17.1']
  - version: 1.16.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Windows cluster support: Velero components (server/node-agent/data
          mover/maintenance jobs) can run in hybrid Linux/Windows clusters and back
          up/restore Windows workloads using the built-in data mover (with documented
          Windows limitations).', 'Parallel Item Block backup: item blocks (and their
          pre/post hooks) can be processed concurrently to improve backup throughput;
          parallelism is configurable via the new `--item-block-worker-count` server
          flag (default 1).', 'Data mover restore scalability: a new node-agent config
          option `ignoreDelayBinding` lets restores for WaitForFirstConsumer volumes
          spread across nodes instead of being constrained to an attached node, improving
          parallelism and resource balance.', 'Improved data mover observability:
          node-agent logs now include richer diagnostics for failures and cleanup
          issues of intermediate objects by default.', "CSI snapshot usability improvement:\
          \ unnecessary retained `VolumeSnapshotContent` objects are excluded from\
          \ backups so they aren\u2019t synced/restored to other clusters sharing\
          \ a BSL.", 'BackupRepository maintenance resiliency/observability: BackupRepository
          CRs now track `RecentMaintenance` history; maintenance jobs are recaptured
          after server restart; maintenance/init is skipped for readOnly BSLs; Kopia
          maintenance cadence can be tuned via `fullMaintenanceInterval` (normal/fast/eager
          GC).', 'Volume Policy enhancement: volume policy can filter volumes by PVC
          labels.', 'Object-level resource status restore control: annotate individual
          objects with `velero.io/restore-status` to opt in/out of restoring status
          per object.', 'Velero restore-helper binary now ships inside the main Velero
          image (velero/velero includes velero, velero-helper, velero-restore-helper).']
      breaking_changes: ['No explicit breaking changes were called out in the provided
          v1.16.0 notes; however, behavior changes to note include parallelized item-block
          processing (new concurrency knob) and removal of retained VolumeSnapshotContent
          from backups, which may affect any workflows that depended on those objects
          being present.']
    chart_version: 10.1.3
    images: ['docker.io/bitnamilegacy/kubectl:1.35', 'velero/velero:v1.16.2']
  - version: 1.15.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Data mover micro service: CSI snapshot data movement shifts from
          node-agent pods to dedicated per-backup/restore pods, improving security
          (no hostPath), resource isolation, and resilience.', "Item Block concepts\
          \ + ItemBlockAction (IBA) plugin type: resources can be grouped into \u201C\
          item blocks\u201D for future concurrent backup processing; built-in IBAs\
          \ for Pods and PVCs are included (multi-threading not yet enabled).", 'Repository
          maintenance node selection: new ConfigMap lets you constrain where repo
          maintenance Jobs run, so heavy maintenance can be scheduled on non-critical/idle
          nodes.', 'Backup PVC configuration for data movement: new ConfigMap supports
          read-only mounts (can speed expose for some storage like Ceph) and choosing
          a different StorageClass for backup PVCs.', 'Backup repository cache limit
          configuration: new ConfigMap lets you cap client-side cache size per repository
          to reduce ephemeral-storage pressure/evictions.', 'Performance/operability
          improvements: fixed a server memory leak after plugin calls; plugin executions
          inherit velero server client QPS/burst; Kopia maintenance memory improvements
          upstream. ']
      breaking_changes: ['Restic uploader path is now deprecated starting in 1.15:
          backups/restores still succeed, but Velero will emit warnings if installed
          with --uploader-type=restic or if Restic is used for fs-backup.', 'Node-agent
          configuration ConfigMap name is no longer fixed: if you use a custom config
          map you must pass --node-agent-configmap to point Velero at it.', 'Repository
          maintenance job settings are moving from Velero server flags to a dedicated
          repository maintenance ConfigMap; if both are set, ConfigMap values take
          precedence (flags remain for backward compatibility).', Changing PVC selected-node
          restore feature is deprecated and will be removed in a future release; avoid
          relying on it going forward.]
    chart_version: 8.7.2
    images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.15.2']
  - version: 1.14.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Velero v1.14.0 ships with Golang 1.22.2 and Kopia v0.17.0 (runtime/dependency
          update)., Repository (kopia/restic) maintenance work is moved out of the
          Velero server pod into separate Kubernetes Jobs to avoid Velero pod OOM
          during maintenance., CSI plugin code is merged into the core Velero repo
          and is installed by default as an internal plugin (deployment/plugin packaging
          change)., Restore workflow now includes a new "Finalizing" phase; some operations
          (PV label patching and post-restore hooks after data movement) occur in
          this phase., Restore metadata now persists per-volume VolumeInfo similar
          to backups; CLI output is enhanced to show restored volume info and CSI
          snapshot restores., Namespace filtering behavior changes when label selectors
          are used without explicit included/excluded namespaces (more restrictive).,
        Default resource requests/limits for node-agent are removed to make node-agent
          pods BestEffort by default (resource/QoS change).]
      features: ['Repository maintenance for kopia/restic backups now runs in separate
          Jobs, reducing risk of the Velero server pod being OOM-killed during maintenance.',
        'VolumePolicies now support actions beyond skipping volumes, allowing per-volume
          selection of filesystem backup (fs-backup) vs snapshot based on policy rules.',
        'Data movement (datamover) backup pods can be constrained to eligible nodes
          via a ConfigMap, helping control resource placement for long-running/high-resource
          jobs.', 'Restore operations now persist VolumeInfo metadata per restored
          volume, and `velero restore describe` shows more detailed restored volume
          information.', Restores include a new "Finalizing" phase to ensure PV label
          restoration and hook execution timing are correct after snapshot/data movement
          restores complete., Azure authentication adds support for certificate-based
          service principal auth as an alternative to client-secret auth.]
      breaking_changes: [CSI plugin is now built-in and installed by default in v1.14;
          do not install it separately via `velero install --plugins ...` or you may
          end up with duplicate/conflicting CSI plugins., 'Node-agent default CPU/memory
          requests and limits are removed, so pods become BestEffort unless you explicitly
          set resources; this can change scheduling/eviction behavior and performance
          under contention.', 'Backup namespace selection changes when `labelSelector`/`orLabelSelectors`
          are set but `includedNamespaces`/`excludedNamespaces` are not: only namespaces
          containing matching resources are included (previously all namespaces were
          included).', 'During restores, patching PVs in the new Finalizing state
          can cause restores to end as `PartiallyFailed` if a PV is stuck `Pending`,
          whereas earlier versions might have reported `Complete`.']
    chart_version: 7.2.2
    images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.14.1']
  - version: 1.13.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Resource Modifiers now support JSON Merge Patch and Strategic Merge
          Patch in addition to JSON Patch, enabling more flexible restore-time mutations
          using the same ConfigMap rules.', Node-agent concurrency controls let you
          cap how many data-movement activities run per node (globally and/or per-node)
          to manage cluster CPU/memory/network usage during fs-backups and CSI snapshot
          data movement., 'Kopia uploader parallel file upload options are now configurable,
          improving backup/data-mover throughput.', 'Restore can optionally write
          sparse files for fs-restore and CSI snapshot data movement restores, potentially
          improving performance and storage efficiency for sparse data.', "`velero\
          \ backup describe` now includes a dedicated \u201CBackup Volumes\u201D section\
          \ and can always display CSI snapshot/data-movement volume info without\
          \ relying on the client-side EnableCSI gate.", New VolumeInfo metadata file
          is written into each backup to record PVC/PV and volume method/snapshot/status
          details and drive PV restore decisions; downstream tools can also consume
          this summary., 'Improved resiliency for CSI snapshot data movement when
          the Velero server pod or node-agent restarts, reducing chances of stuck
          or interrupted backup/restore.', Backup/Restore CR status and `describe`
          output now include hook execution stats (HooksAttempted/HooksFailed) for
          better observability., AWS SDK for Go moved to v2 for better CPU/memory
          performance., Azure AD/Workload Identity is now supported for Kopia operations
          (filesystem backup/data mover) in addition to prior Azure plugin support.,
        'Runtime/dependency updates: Go 1.21.6 and Kopia 0.15.0, plus various library
          bumps for CVEs.']
      breaking_changes: ["`velero backup describe` output format changed: some existing\
          \ snapshot/fs-backup information moved into the new \u201CBackup Volumes\u201D\
          \ section and formatting differs, which may break scripts parsing the output.",
        'API type change: `DataUploadSpec.DataMoverConfig` changed from `*map[string][string]`
          to `map[string]string`, requiring updates for any code/tools that create/patch
          DataUpload resources.', '`velero install` behavior change: informer cache
          is now enabled by default (previously disabled), which can increase memory
          usage and may require adjusting limits or explicitly disabling it.']
    chart_version: 6.7.0
    images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.13.2']
  - version: 1.12.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm chart / values changes to plan for\n- **Chart v4.0.0+\
        \ changes BSL/VSL shape (breaking):** `configuration.backupStorageLocation`\
        \ and `configuration.volumeSnapshotLocation` changed **from a map to a list/slice**.\
        \ Update your `values.yaml` to the new list format **before** upgrading the\
        \ chart/app to 1.12.\n- **If you rely on Restic as default uploader:** v1.12\
        \ changes the default `uploader-type` from `restic` to `kopia`. In Helm values,\
        \ ensure you explicitly set the uploader type you want (or confirm Kopia is\
        \ acceptable) so behavior doesn\u2019t change unintentionally.\n- **Finalizers\
        \ impact uninstall/delete:** with v1.12 finalizers on Velero CRs, avoid deleting\
        \ the namespace directly; plan to use `velero uninstall` or remove finalizers\
        \ as part of teardown procedures."
      chart_updates: [Velero Helm chart v4.0.0+ supports multiple BackupStorageLocations
          (BSL) and VolumeSnapshotLocations (VSL); corresponding configuration structure
          is now a list (not backward compatible).]
      features: ['CSI Snapshot Data Movement: supports moving CSI snapshot data into
          durable backup storage and restoring across environments/clouds.', 'Resource
          Modifiers (JSON substitutions): apply JSON patch-style modifications to
          resources during restore without writing a RestoreItemAction plugin.', 'Multiple
          VolumeSnapshotClasses: allows selecting a specific VolumeSnapshotClass per
          backup instead of relying on a single labeled class.', 'Restore finalizer:
          `velero restore delete` now cleans up associated external/backup-storage
          data, not just Kubernetes objects.']
      breaking_changes: [Default `uploader-type` changes from `restic` to `kopia`;
          file-system backup behavior changes unless you pin the uploader type., 'CSI
          snapshot timing behavior changed: snapshot creation sync timeout is now
          configurable via `backup.spec.csiSnapshotTimeout`, and async `ReadyToUse`
          waits use operation timeout (default 4h).', Helm chart v4.0.0+ changes BSL/VSL
          values from map to list; existing `values.yaml` will not apply cleanly without
          conversion., Finalizers on resources like restores/data uploads/downloads
          can cause namespace deletion to hang if you delete the namespace directly;
          use `velero uninstall` or handle finalizers first.]
    chart_version: 5.2.2
    images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.12.3']
  - version: 1.11.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 5.0.2
    images: ['docker.io/bitnami/kubectl:1.35', 'velero/velero:v1.11.1']
  - version: 1.10.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 1.9.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 1.8.0
    kube: ['1.28', '1.27', '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20',
      '1.19', '1.18']
    requirements: []
    incompatibilities: []
    summary: null
  name: velero
- icon: https://avatars.githubusercontent.com/u/33043890?s=48&v=4
  git_url: https://github.com/vitessio/vitess
  release_url: https://github.com/vitessio/vitess/releases/tag/v{vsn}
  versions:
  - version: 23.0.0
    kube: ['1.34', '1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 22.0.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 21.0.0
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 20.0.0
    kube: ['1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 19.0.0
    kube: ['1.28', '1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 18.0.0
    kube: ['1.25', '1.24', '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 17.0.0
    kube: ['1.25', '1.24', '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 16.0.0
    kube: ['1.24', '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 15.0.0
    kube: ['1.24', '1.23', '1.22']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 14.0.0
    kube: ['1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 13.0.0
    kube: ['1.22', '1.21', '1.20']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 12.0.0
    kube: ['1.22', '1.21', '1.20', '1.19', '1.18', '1.17']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 10.0.0
    kube: ['1.17', '1.16', '1.15']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 9.0.0
    kube: ['1.17', '1.16', '1.15']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 8.0.0
    kube: ['1.17', '1.16', '1.15']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 7.0.0
    kube: ['1.17', '1.16', '1.15']
    requirements: []
    incompatibilities: []
    summary: null
  - version: 6.0.0
    kube: ['1.15', '1.14', '1.13']
    requirements: []
    incompatibilities: []
    summary: null
  name: vitess
- icon: https://avatars.githubusercontent.com/u/16468693?s=48&v=4
  git_url: https://github.com/open-policy-agent/gatekeeper
  release_url: https://github.com/open-policy-agent/gatekeeper/releases/tag/v{vsn}
  helm_repository_url: https://open-policy-agent.github.io/gatekeeper/charts
  chart_name: gatekeeper
  versions:
  - version: 3.21.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm chart values / config changes to review\n- **New `extraEnvs`\
        \ support**: chart can now inject additional env vars into Gatekeeper pods\
        \ (PR #4185). If you previously used chart patching or extra container args\
        \ for envs, you can migrate to `extraEnvs`.\n- **Automount SA token & deployment\
        \ annotations configurable**: chart now allows configuring `automountServiceAccountToken`\
        \ and adding deployment annotations, plus **extra volumes/volumeMounts** (PR\
        \ #4124). Review your existing values/patches and move them into these supported\
        \ knobs.\n- **Mutating/validating webhook surface changes**:\n  - Webhook\
        \ service **dual-stack** support (PR #4043) may change Service fields (e.g.,\
        \ `ipFamilies`/`ipFamilyPolicy`) depending on cluster networking.\n  - **PodSecurityPolicy\
        \ removed from the chart** (PR #4131). If you relied on PSPs, ensure your\
        \ cluster uses Pod Security Admission (PSA) or another mechanism.\n\n### Gatekeeper\
        \ runtime flags to review\n- **New flag `--sync-vap-enforcement-scope`** (v3.21.0\
        \ notable change): optional in 3.21.0 but will **default to true in v3.22**\
        \ and later be removed. Decide now whether to enable it in 3.21.0 to match\
        \ future behavior and avoid a surprise scope change.\n"
      chart_updates: [PodSecurityPolicy manifests were removed from the Helm chart
          (PSP is deprecated/removed upstream)., 'Chart adds configuration hooks for
          automounting SA tokens, deployment annotations, and injecting extra volumes/volumeMounts.',
        Chart adds `extraEnvs` support for injecting environment variables into Gatekeeper
          components., Chart includes changes to support dual-stack webhook Service
          behavior in clusters using dual-stack networking.]
      features: ["`--sync-vap-enforcement-scope` flag introduced to align ValidatingAdmissionPolicy\
          \ (VAP) enforcement scope with Gatekeeper\u2019s webhook/config/namespace\
          \ exemptions for consistent enforcement.", 'ConstraintTemplates can now
          specify which operations (CREATE/UPDATE/DELETE) they apply to, enabling
          operation-level enforcement granularity.', External Data / Provider API
          gains new metrics and status reporting for improved observability., Webhook
          Service adds dual-stack support for IPv4/IPv6 clusters., 'Helm chart supports
          configurable automountServiceAccountToken, deployment annotations, extra
          volumes/volumeMounts, and `extraEnvs` injection.']
      breaking_changes: [Helm chart removes PodSecurityPolicy resources; clusters
          or installs depending on PSP must transition to Pod Security Admission or
          alternative controls., 'VAP behavior is trending toward a breaking change
          in v3.22+: if you currently set `--sync-vap-enforcement-scope=false`, future
          versions will change how Gatekeeper generates/scopes VAP resources (flag
          will default true then be removed).']
    chart_version: 3.21.0
    images: ['curlimages/curl:8.12.0', 'openpolicyagent/gatekeeper-crds:v3.21.0',
      'openpolicyagent/gatekeeper:v3.21.0']
  - version: 3.20.1
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Patch/minor app release update from Gatekeeper v3.20.0 to v3.20.1;
          no functional chart behavior changes called out in the provided notes.,
        'Component/toolchain refresh: kubectl and Go versions bumped via cherry-picks;
          internal frameworks dependency bumped to v0.18.1.']
      features: []
      breaking_changes: []
    chart_version: 3.20.1
    images: ['curlimages/curl:8.12.0', 'openpolicyagent/gatekeeper-crds:v3.20.1',
      'openpolicyagent/gatekeeper:v3.20.1']
  - version: 3.20.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm/chart values & manifest behavior to review\n\n- **Operations\
        \ flag**: v3.19.0 introduced a requirement that the **`generate` operation**\
        \ be enabled for **CRD generation** and **VAP/VAPB generation**. Ensure your\
        \ Gatekeeper deployments that do generation include `--operation=generate`\
        \ (notably **controller-manager**, and **audit** if you run a singleton audit\
        \ deployment). If you previously relied on default operations, verify your\
        \ chart values still render the `--operation` args you expect.\n\n- **Mutating\
        \ subresources**: v3.20.0 includes Helm work to add an option for **mutating\
        \ subresources** (release notes mention adding `pods/resize` to webhook rules\
        \ and a Helm variable for mutating subresources). If your cluster uses subresources\
        \ like `pods/resize`, confirm the rendered **MutatingWebhookConfiguration**\
        \ includes the subresources you need and that any new value defaults match\
        \ your policy.\n\n- **Readiness probe change**: v3.20.0 removes/adjusts the\
        \ **webhook readinessProbe at pod start**. If you had custom probe overrides\
        \ in values, re-check them after upgrade.\n\n- **Export backend config**:\
        \ v3.20.0 replaces a prior **ConfigMap-based** connection mechanism with a\
        \ **`Connection` CRD** for export backends. If you configured violation export\
        \ via ConfigMaps, plan to migrate to the new CRD-based configuration.\n\n\
        - **VAP integration default**: v3.20.0 makes **VAP integration beta and enabled\
        \ by default**, generating **VAP/VAPB resources by default** for ConstraintTemplates/Constraints\
        \ using the `K8sNativeValidation` engine with CEL. If you do *not* want automatic\
        \ VAP resource generation, you\u2019ll likely need to set the relevant flags/values\
        \ to disable it (and validate your operations include `generate` only where\
        \ desired).\n"
      chart_updates: [Introduces/uses a new `Connection` CRD to configure connections
          to violation export backends (replacing a ConfigMap-based approach)., Webhook
          rules updated to include the `pods/resize` subresource; Helm templating
          gained a knob/variable to manage mutating subresources., Webhook startup
          behavior changed by removing the webhook readinessProbe at pod start (affects
          rendered Deployment/Pod spec).]
      features: [New driver to export violations to disk (useful for local retention
          or sidecar pickup)., VAP (Validating Admission Policy) integration is now
          beta and enabled by default; Gatekeeper can generate VAP/VAPB resources
          for CEL-based native validation., Export connections are now modeled via
          a `Connection` custom resource instead of a ConfigMap.]
      breaking_changes: ['If you previously configured export connections via a ConfigMap,
          you must migrate to the new `Connection` CRD or exports may stop working.',
        "Because VAP generation is enabled by default in v3.20.0, new VAP/VAPB resources\
          \ may be created automatically (and require appropriate RBAC/operations\
          \ configuration), which can change admission behavior if you weren\u2019\
          t previously using VAP."]
    chart_version: 3.20.0
    images: ['curlimages/curl:8.12.0', 'openpolicyagent/gatekeeper-crds:v3.20.0',
      'openpolicyagent/gatekeeper:v3.20.0']
  - version: 3.19.1
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **New required flag for generation:** Starting with **v3.19.0**\
        \ (and therefore still required in **v3.19.1**), Gatekeeper requires `--operation=generate`\
        \ for CRD and VAP/VAPB generation. Update your singleton deployment (typically\
        \ `gatekeeper-audit`) to include `--operation=generate`. If you **do not run\
        \ audit**, add `--operation=generate` to the **controller-manager** deployment\
        \ instead.\n  - Reference: https://open-policy-agent.github.io/gatekeeper/website/docs/operations/#generation\n\
        \n- **Optional behavior toggle:** A flag was added to enable/disable **referential\
        \ constraints** (introduced in v3.19.0). If you rely on referential constraints,\
        \ confirm the default behavior in your current values/manifests and set the\
        \ flag explicitly if needed."
      chart_updates: [v3.19.1 is a patch release with no user-facing feature additions;
          it primarily contains a bug fix related to deleting Gatekeeper resources
          when the delete operation is enabled., 'CI/test updates only: v3.19.1 bumps
          Kubernetes versions used in testing/CRD Dockerfile; no direct runtime impact
          expected.']
      features: [(v3.19.0) Gatekeeper ConstraintTemplates can use OPA **Rego v1**
          syntax via the updated Rego driver., '(v3.19.0) Pub/Sub was generalized
          into an **export mechanism**, enabling additional violation export backends
          (e.g., disk).', (v3.19.0) `gator test` gained a `--deny-only` flag to focus
          on deny results.]
      breaking_changes: ['(v3.19.0) **Breaking/behavioral change:** `--operation=generate`
          is now required for CRD and VAP/VAPB generation. Missing this flag can prevent
          expected generation behavior and may impact upgrades/installations that
          depended on implicit generation.']
    chart_version: 3.19.1
    images: ['curlimages/curl:8.12.0', 'openpolicyagent/gatekeeper-crds:v3.19.1',
      'openpolicyagent/gatekeeper:v3.19.1']
  - version: 3.19.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [No Helm chart-specific changelog was provided in the notes;
          treat this as an application upgrade summary only., v3.19.0 adds/adjusts
          operational flags and mechanisms (notably generation operations and export
          mechanism changes) that may require deployment arg updates in your Helm
          values if you set extraArgs/extraContainers.]
      features: [OPA Rego v1 syntax support is now available for ConstraintTemplates
          (via updated Rego driver)., 'Pub/Sub violation distribution has been generalized
          into an export mechanism to enable additional backends (e.g., disk) for
          exporting violations.', '`gator test` gained a `--deny-only` flag to focus
          tests on deny outcomes.']
      breaking_changes: ["`--operation=generate` is now required to guard CRD and\
          \ VAP/VAPB generation; ensure your singleton deployment (commonly gatekeeper-audit)\
          \ includes `--operation=generate`, and if you don\u2019t run audit you must\
          \ add it to the controller-manager deployment."]
    chart_version: 3.19.0
    images: ['curlimages/curl:8.12.0', 'openpolicyagent/gatekeeper-crds:v3.19.0',
      'openpolicyagent/gatekeeper:v3.19.0']
  - version: 3.18.3
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **Required flag change:** Ensure at least one Gatekeeper Pod\
        \ that performs *generation* is started with `--operation=generate`.\n  -\
        \ If you run the singleton `gatekeeper-audit` deployment, add `--operation=generate`\
        \ there.\n  - If you **do not** run audit, add `--operation=generate` to the\
        \ `gatekeeper-controller-manager` deployment.\n  - This is required to guard\
        \ **CRD generation** and **ValidatingAdmissionPolicy / ValidatingAdmissionPolicyBinding\
        \ (VAP/VAPB) generation**.\n- **Values that exist since 3.18.0:** Helm chart\
        \ supports `logStatsAdmission` and `logStatsAudit` values (new in 3.18.0).\
        \ No additional values changes were called out in the 3.18.3 notes you provided."
      chart_updates: ['3.18.0 chart: added Helm values for `logStatsAdmission` and
          `logStatsAudit`.', '3.18.x: no chart template changes were explicitly listed
          in the 3.18.3 snippet beyond cherry-picked bugfixes; treat as patch-level
          maintenance update.']
      features: [(3.18.0) CEL-based policies enforced through Gatekeeper (ValidatingAdmissionPolicy
          support) reached GA., (3.18.0) Added support for `generate` operation and
          waiting for VAPB generation (generation controller behavior)., (3.18.0)
          Added config pod status reporting (observability/status improvements).,
        (3.18.0) Helm chart gained `logStatsAdmission` / `logStatsAudit` toggles for
          stats logging.]
      breaking_changes: ['`--operation=generate` is now required on a singleton deployment
          to handle CRD and VAP/VAPB generation; without it, generated artifacts may
          not be created/guarded as expected. This impacts deployments that previously
          relied on default operations behavior.']
    chart_version: 3.18.3
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.18.3',
      'openpolicyagent/gatekeeper:v3.18.3']
  - version: 3.18.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / deployment changes to plan for\n\n- **New required\
        \ `--operation=generate` for generation** (CRDs + VAP/VAPB): Gatekeeper now\
        \ requires the `generate` operation to be enabled on the component that performs\
        \ generation.\n  - If you run a **singleton** deployment (commonly `gatekeeper-audit`)\
        \ you must add `--operation=generate` there.\n  - If you **do not** run audit,\
        \ add `--operation=generate` to the **controller-manager**.\n  - Doc: https://open-policy-agent.github.io/gatekeeper/website/docs/operations/#generation\n\
        \n- **New Helm chart values for logging stats**:\n  - `logStatsAdmission`\n\
        \  - `logStatsAudit`\n\n- **Labeling enhancements in the Helm chart**:\n \
        \ - `commonLabels` added to Deployments.\n\n- **(From 3.17.0 notes, relevant\
        \ if you use VAP generation)**: VAP generation configuration moved from annotations\
        \ to explicit fields.\n  - ConstraintTemplates/Constraints should use the\
        \ **`generateVAP` field** (annotations removed).\n\n- **Optional chart behavior\
        \ change**: \u201Cremoving alpha flags out of the box\u201D / \u201Cnot setting\
        \ alpha flags unless explicitly set through Helm\u201D. If you previously\
        \ relied on alpha feature gates being enabled implicitly, you may need to\
        \ set the corresponding Helm flags explicitly."
      chart_updates: [CEL-based policies (Kubernetes native validation / VAP integration)
          moved from **beta** to **GA** in 3.18.0., 'A new operations model requirement
          was introduced: generation (CRDs, VAP/VAPB) is now gated behind the explicit
          `generate` operation.', 'Helm chart gained new knobs for stats logging (`logStatsAdmission`,
          `logStatsAudit`) and added `commonLabels` support on Deployments.', 'Several
          chart/manifest quality fixes: PDB lint fix; NetworkPolicy ingress rule Helm
          warning fix.', Internal refactors around CEL driver/framework extraction;
          OPA bumped to 0.68.0; CI now pushes images to ghcr.io as well.]
      features: ['CEL-based policy enforcement via ValidatingAdmissionPolicy (VAP)
          is now GA, making the Kubernetes-native validation path a first-class, production-ready
          option.', 'Gatekeeper now supports an explicit `generate` operation and
          can wait for ValidatingAdmissionPolicyBinding (VAPB) generation, improving
          determinism around generated resources.', 'Helm chart adds `logStatsAdmission`
          and `logStatsAudit` to control stats logging in admission/audit components,
          and adds `commonLabels` for consistent labeling across Deployments.', Gator
          gains additional capabilities (sync test support and expansion in `gator
          verify`) useful for policy testing workflows.]
      breaking_changes: ['**Generation is now opt-in via operations**: you must enable
          `--operation=generate` on whichever Gatekeeper deployment is responsible
          for generating CRDs and VAP/VAPB resources, or generation will not occur.',
        "If you were using Gatekeeper\u2019s VAP generation via annotations (older\
          \ behavior highlighted in 3.17.0 notes), you must migrate to the `generateVAP`\
          \ fields in ConstraintTemplates/Constraints; annotations are no longer the\
          \ mechanism."]
    chart_version: 3.18.0
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.18.0',
      'openpolicyagent/gatekeeper:v3.18.0']
  - version: 3.17.2
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Gatekeeper 3.17 introduces/solidifies Kubernetes-native validation
          (CEL/VAP) support and related manifest/chart wiring: CEL-based policies
          via ValidatingAdmissionPolicy are beta; VAP/VAPBinding generation moved
          from annotations to explicit fields in ConstraintTemplate/Constraint; and
          constraint enforcement can now be scoped per enforcement point via `spec.scopedEnforcementActions`.',
        Helm chart gains knobs to make the ServiceAccount name configurable and optionally
          disable SA creation (useful when binding to pre-created RBAC/IRSA/GSA).,
        'Helm chart adds optional RollingUpdate strategy parameters for the controller-manager/audit
          deployments, enabling finer control of maxUnavailable/maxSurge during upgrades.',
        'Controller-manager and audit deployments can now receive separate podLabels,
          improving labeling/selection and observability alignment.', 'Various CEL/VAP
          wiring fixes: include CEL flags on audit deployment; only set webhook matchConditions
          when non-empty; updated VAP/VAPBinding API generation behavior (0.30 API;
          create v1 or v1beta1 VAP/VAPB) and avoid setting alpha flags unless explicitly
          enabled via Helm.', '3.17.2 is a patch release with a key bugfix: fixes
          a nil-pointer when converting VAPBinding from v1beta1 to v1, plus security/library
          updates (crypto/net).']
      features: ["CEL-based policies enforced via Gatekeeper\u2019s ValidatingAdmissionPolicy\
          \ integration (beta in 3.17.0).", 'Constraints can now specify different
          enforcement actions per enforcement point (webhook, audit, gator, VAP) using
          `spec.scopedEnforcementActions`.', Support for Kubernetes CONNECT operations
          in request matching., 'More flexible Helm operations: configurable ServiceAccount
          (and ability to opt out of creating it), plus optional RollingUpdate strategy
          tuning, and separate podLabels for controller-manager vs audit.']
      breaking_changes: ['If you previously generated VAP/VAPBinding via annotations,
          3.17.0 changes this to use explicit fields in ConstraintTemplate and Constraint;
          you must update those resources or VAP generation may stop working/behave
          differently.', 'VAP/VAPBinding generation behavior and API versions are
          more strict/explicit in 3.17.x (v1 vs v1beta1 selection and alpha flags
          only when configured), so clusters/templates relying on prior implicit defaults
          may need review.']
    chart_version: 3.17.2
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.17.2',
      'openpolicyagent/gatekeeper:v3.17.2']
  - version: 3.17.0
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm / values changes to watch\n\n- **VAP generation config\
        \ moved from annotations to fields**: If you enabled Gatekeeper\u2019s ValidatingAdmissionPolicy\
        \ (VAP) generation in 3.16 via annotations on `ConstraintTemplate`/`Constraint`,\
        \ **update your policy manifests** to use the new explicit fields (e.g., `generateVAP`\
        \ and related config) rather than annotations.\n- **ServiceAccount is now\
        \ configurable**: Chart now supports choosing an existing ServiceAccount and\
        \ **opting out of SA creation**. If you currently manage SA/RBAC outside Helm,\
        \ set the new values accordingly.\n- **RollingUpdate strategy knobs added**:\
        \ Optional parameters were added to control `rollingUpdate` behavior for Gatekeeper\
        \ Deployments; you can now tune surge/unavailable if desired.\n- **Pod labels\
        \ split per component**: Values/templating allow **separate pod labels** for\
        \ `controller-manager` vs `audit` Deployment; if you relied on one shared\
        \ label block, verify the rendered labels after upgrade.\n- **VAP/VAPB API\
        \ version & flags behavior**:\n  - Gatekeeper updated its VAP/VAPBinding generation\
        \ to newer APIs (v1 or v1beta1 depending on cluster).\n  - Gatekeeper **no\
        \ longer sets alpha flags for VAP/VAPB generation by default**; if you previously\
        \ relied on Helm enabling those feature gates implicitly, you may now need\
        \ to set them explicitly (or ensure your cluster supports the beta/stable\
        \ API you want).\n"
      chart_updates: [Expose configurable ServiceAccount name + allow disabling SA
          creation., Add optional `rollingUpdate` strategy parameters to the Helm
          chart., Split pod label configuration between controller-manager and audit
          Deployments., Stop enabling alpha VAP/VAPB feature-gates implicitly unless
          explicitly set via Helm., 'Update generated manifests to include YAML document
          separators (affects rendered output, not behavior).']
      features: [CEL-based policies enforced through Gatekeeper (via Kubernetes ValidatingAdmissionPolicy
          integration) are **beta** in 3.17; Gatekeeper can generate/enforce CEL/VAP
          resources., 'New `scopedEnforcementActions` lets you enforce different actions
          per enforcement point (webhook, audit, gator, VAP) within the same Constraint.',
        Support for Kubernetes `CONNECT` operations was added to admission handling.,
        'Improved control over VAP generation intent: Gatekeeper checks template intent
          before generating VAPBindings.']
      breaking_changes: ["If you used VAP generation via **annotations**, those are\
          \ no longer the mechanism in 3.17\u2014policy manifests must be updated\
          \ to the new fields-based configuration.", 'If you depended on Helm implicitly
          setting **alpha** feature flags for VAP/VAPB generation, that default behavior
          is removed; you may need to explicitly configure feature gates or rely on
          the appropriate Kubernetes API version support.']
    chart_version: 3.17.0
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.17.0',
      'openpolicyagent/gatekeeper:v3.17.0']
  - version: 3.16.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '## Helm chart / values changes to plan for

        - **New value: `disableAudit`** (added in v3.16.0). Use this if you need to
        **turn off the audit component** (e.g., reduce load or you only care about
        admission enforcement). Default behavior is unchanged unless you set it.

        - **VAP integration can be enabled via Helm** (alpha): v3.16.0 adds Helm support
        to **enable Kubernetes Validating Admission Policy (VAP)** integration.

        - **Webhook `matchConditions` support**: chart now supports configuring `matchConditions`
        on the **ValidatingWebhookConfiguration and MutatingWebhookConfiguration**.


        ### Upgrade checklist for Helm values

        - Review your current values for anything related to template Rego validation
        (see breaking change below). There is **no replacement Helm flag**; use Gator
        instead.

        - If adopting VAP, plan values changes to enable it (alpha) and test in non-prod
        first.

        - If you have custom webhook matching/namespace exclusions, consider whether
        moving to/adding `matchConditions` improves correctness or performance.

        '
      chart_updates: ['Helm: added `disableAudit` option to disable the audit deployment/job/component.',
        'Helm: added ability to enable/configure VAP integration (alpha).', 'Helm:
          added `matchConditions` support in ValidatingWebhookConfiguration and MutatingWebhookConfiguration
          manifests.']
      features: ['Alpha: integration with Kubernetes Validating Admission Policy (VAP),
          including support for generating VAP artifacts and enabling it via Helm.',
        'Operational flexibility: ability to disable Gatekeeper audit via a Helm option
          (`disableAudit`).', 'Webhook configurability: support for Kubernetes webhook
          `matchConditions` to refine when Gatekeeper webhooks trigger.']
      breaking_changes: ['`validate-template-rego` flag has been removed; Gatekeeper
          will no longer validate ConstraintTemplate Rego via that flag. Use Gator
          for shift-left template validation to avoid unexpected failures/behavior
          changes in CI/CD or admission workflows.']
    chart_version: 3.16.0
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.16.0',
      'openpolicyagent/gatekeeper:v3.16.0']
  - version: 3.15.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **PodSecurityPolicy no longer enabled by default**: v3.15.0\
        \ includes a change to *disable PSP by default* (`#3179`). If your cluster\
        \ is pre-1.25 and you still rely on PSP, you may need to explicitly re-enable\
        \ the chart\u2019s PSP resources (if your chart version still supports it)\
        \ or migrate to Pod Security Admission.\n- **Helm value defaults related to\
        \ Pub/Sub audit**: v3.15.0 adds default Helm values for the Pub/Sub audit\
        \ connection/channel (`#3097`). Review your `values.yaml` for new pubsub-related\
        \ keys so you don\u2019t unintentionally change audit behavior.\n\n_No other\
        \ explicit Helm values changes were called out in the provided notes for v3.15.0.\
        \ (Some Helm-related exposure was in v3.14.0, e.g. external data provider\
        \ cache TTL, but that\u2019s already in your current version.)"
      chart_updates: [Adds/introduces **SyncSets** support (alpha) including a new
          SyncSet controller and readiness tracking (`#3030`)., 'Switches telemetry/instrumentation
          plumbing: **moving to OpenTelemetry from OpenCensus** (`#3011`). This may
          impact how metrics/traces are emitted/collected depending on your setup.',
        'CI/build change: **drops arm/v7 builds for the CRD image** (`#3074`), which
          can affect users running Gatekeeper components on 32-bit ARM nodes.', 'Validation
          hardening: Gatekeeper now **only validates Gatekeeper resources**, adds
          support for validating DELETE config operations, and adds name length checks/limits
          for certain resources (e.g., ExpansionTemplate names <64).']
      features: ['**SyncSets (alpha)**: New mechanism to replicate/sync data into
          Gatekeeper via SyncSets, plus readiness reporting so you can tell when required
          data has been replicated.', '**Improved resource validation behaviors**:
          Additional validation around Gatekeeper resources and operations (including
          DELETE validation and stricter naming constraints) to prevent invalid configs
          from being accepted.']
      breaking_changes: ['**PodSecurityPolicy default behavior changed**: PSP is disabled
          by default in v3.15.0; clusters relying on Gatekeeper-created PSP objects
          will need to adjust installation/values or move to PSA.', "**arm/v7 CRD\
          \ image no longer built**: If you deploy the CRD image on 32-bit ARM (arm/v7),\
          \ you\u2019ll need an alternative architecture or image strategy after upgrading."]
    chart_version: 3.15.0
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.15.0',
      'openpolicyagent/gatekeeper:v3.15.0']
  - version: 3.14.2
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['v3.14.1: Audit and controller-manager pods gained updated labels,
          which may affect label selectors used by monitoring/NetworkPolicies.', 'v3.14.2:
          No new functional features; this patch release is primarily security dependency
          updates addressing multiple CVEs/advisories.']
      breaking_changes: []
    chart_version: 3.14.2
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.14.2',
      'openpolicyagent/gatekeeper:v3.14.2']
  - version: 3.14.1
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '## Helm values / chart behavior changes to consider

        - **New pod labels added by default** in `v3.14.1`: audit and controller-manager
        pods get additional labels (PRs #3240/#3284). If you have tooling that matches
        on exact labels/selectors (e.g., NetworkPolicies, PodMonitors, log/metric
        relabeling), verify it still works.

        - **Recommended Helm/Kubernetes labels introduced** in `v3.14.0` (PR #2788).
        Expect more standardized `app.kubernetes.io/*` labels on Gatekeeper resources;
        adjust any custom label-based automation if it assumes older labels.

        - **Revision history limit configurable** in `v3.14.0` (PR #2920): a new chart
        value likely controls `revisionHistoryLimit` for Deployments. Set explicitly
        if you need to constrain ReplicaSet history.

        - **External data provider cache TTL exposed** in `v3.14.0` (PR #2978) and
        **TTL=0 disables cache** (PR #3028 + fix #3134). Review/set the new value
        if you use external data providers and need deterministic behavior.

        - **Webhook name flag handling fixed** in `v3.14.0` (PR #2879). If you override
        webhook names via values/flags, re-test after upgrade.

        - **Audit cert rotation enabled by default** in `v3.14.0` (PR #2875). If your
        environment has strict cert/secret management expectations, confirm the generated/rotated
        cert behavior is acceptable.'
      chart_updates: ['`v3.14.1` is a patch release with a small surface area: adds
          pod labels and includes a panic-logging fix.', '`v3.14.0` contains the bulk
          of chart/app changes for this upgrade path, including label standardization
          and new/changed flags exposed via Helm.', 'Default behaviors to note from
          `v3.14.0`: audit cert rotation enabled by default; external data provider
          caching behavior clarified/fixed.']
      features: [(v3.14.1) Audit and controller-manager pods updated to include additional
          pod labels; mainly affects observability/selection/label-based policies.,
        (v3.14.0) Improved experimental Validating Admission Policy (VAP) support
          and updated bundled OPA to v0.57.1., (v3.14.0) Support multiple sync sources
          and enhancements to replay/testing output., (v3.14.0) External data provider
          response cache TTL configurable; TTL=0 disables caching.]
      breaking_changes: ['No explicit breaking changes are called out in the provided
          notes for v3.14.0 or v3.14.1. However, label changes (recommended labels
          + new pod labels) can be *operationally breaking* if you rely on exact label
          matches/selectors in policies, monitoring, or automation.']
    chart_version: 3.14.1
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.14.1',
      'openpolicyagent/gatekeeper:v3.14.1']
  - version: 3.14.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / chart behavior changes to review\n- **New standard\
        \ labels:** chart now adds the recommended Helm/Kubernetes app labels (`app.kubernetes.io/*`,\
        \ `helm.sh/chart`, etc.). If you have tooling that matches/selects by labels\
        \ (NetworkPolicies, PodMonitors/ServiceMonitors, log scraping, RBAC selectors,\
        \ custom scripts), verify it still works and that any label-based selectors\
        \ aren\u2019t overly restrictive.\n- **`revisionHistoryLimit` is now configurable:**\
        \ you can set the Deployment\u2019s `revisionHistoryLimit` via values (new\
        \ option). Consider pinning it explicitly if you rely on a specific rollout\
        \ history behavior.\n- **External data provider cache TTL exposed:** the controller\
        \ flag `--external-data-provider-response-cache-ttl` is now configurable through\
        \ Helm values. Also note behavior: **TTL=0 disables the cache**.\n\nNo explicit\
        \ breaking Helm values removals/renames were present in the provided notes;\
        \ treat the above as additive changes and validate with `helm diff`."
      chart_updates: [Updated OPA dependency to **v0.57.1**., Improved experimental
          **Validating Admission Policy (VAP)** support (CEL-based / native validation
          demo and driver improvements)., Constraint framework upgraded to include
          a new **Kubernetes Native Validation** driver schema., Support for **multiple
          sync sources** (sync subsystem enhancements)., Audit certificate rotation
          enabled by default (bug fix) and other chart/controller flag fixes around
          webhook name flags.]
      features: ['Adds recommended Helm/Kubernetes application labels to resources,
          improving consistency with common tooling and dashboards.', Allows configuring
          the controller-manager Deployment `revisionHistoryLimit` through Helm values.,
        'Adds support for multiple sync sources, improving how Gatekeeper syncs external
          or cluster objects into OPA.', Upgrades the constraint framework with a
          new Kubernetes Native Validation driver schema (relevant to VAP/CEL workflows).,
        Exposes external data provider response cache TTL via Helm; TTL can be tuned
          or set to 0 to disable caching.]
      breaking_changes: []
    chart_version: 3.14.0
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.14.0',
      'openpolicyagent/gatekeeper:v3.14.0']
  - version: 3.13.2
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **v3.13.2 is the first 3.13.x tag that ships a Helm chart**;\
        \ v3.13.1 did not include one.\n- **No Helm values changes were called out**\
        \ in the v3.13.2 application release notes; expect the same behavior as v3.13.1.\n\
        - For the 3.13.0 jump, note the new/updated Helm-facing knobs implied by the\
        \ release notes:\n  - `webhookURL` Helm option added.\n  - Ability to choose\
        \ **deployment strategy** for `controller-manager`.\n  - Support adding **PriorityClass**\
        \ to Jobs.\n  - Pre-upgrade hook job: retries configured (helps reliability\
        \ during upgrades).\n"
      chart_updates: ['v3.13.2 release is functionally identical to v3.13.1, but **adds/publishes
          the Helm chart artifact** for the release tag.', 'In 3.13.0 line, chart-related
          fixes/robustness improvements mentioned include webhook retry logic for
          Helm probes and retry configuration on the pre-upgrade hook job.']
      features: ['Audit: added PubSub support for audit eventing/integration.', ExpansionTemplates
          graduated to **beta** (more stable API/behavior expectations)., Added an
          experimental **ValidatingAdmissionPolicy (VAP) driver** prototype., Added
          support for **External Data Provider audit response cache** (performance/availability
          improvement)., 'Added **observability statistics/metrics** for admission,
          audit, and gator CLI.']
      breaking_changes: []
    chart_version: 3.13.2
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.13.2',
      'openpolicyagent/gatekeeper:v3.13.2']
  - version: 3.13.0
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '### Helm / values changes to check

        - **New `webhookURL` Helm value**: v3.13.0 adds a `webhookURL` Helm option
        (PR #2722). If you use non-standard networking / external webhook endpoints,
        review whether you should set this; otherwise defaults should keep working.

        - **Controller-manager deployment strategy is now configurable** (PR #2777):
        chart supports choosing a deployment strategy. If you previously relied on
        default rolling update behavior, confirm the default matches your expectations
        and set explicitly if needed.

        - **Helm hook reliability improvements**: pre-upgrade/probe webhook retry
        logic was improved (PRs #2710, #2873). No values change required, but upgrades
        may behave differently (more resilient rather than failing fast).

        '
      chart_updates: [Adds support for configuring the controller-manager Deployment
          strategy (chart-level capability)., Adds `webhookURL` configuration option
          to the chart., Improves Helm hook jobs/probe-webhook behavior with retries
          (more robust upgrades).]
      features: ['Audit gained PubSub support, enabling external event-driven integrations
          for audit output/processing.', 'ExpansionTemplate moved to beta and expansion
          gained recursive expansion capabilities, improving workload validation workflows.',
        Experimental Kubernetes ValidatingAdmissionPolicy (VAP) driver/prototype was
          added as a step toward CEL-based admission integration., 'External Data
          Provider Audit Cache was added to cache external data responses during audit,
          reducing repeated calls and improving performance.', 'New observability
          statistics are available for admission, audit, and the gator CLI for improved
          monitoring and troubleshooting.']
      breaking_changes: [ExpansionTemplate CRD graduation to **beta** may involve
          CRD schema/behavior changes; verify your existing ExpansionTemplates against
          the new CRD and re-apply CRDs during upgrade., 'Gatekeeper dependencies
          were upgraded to Kubernetes v1.27.2 / controller-runtime v0.15.0; if you
          run very old Kubernetes versions, confirm compatibility before upgrading.']
    chart_version: 3.13.0
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.13.0',
      'openpolicyagent/gatekeeper:v3.13.0']
  - version: 3.12.0
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm chart / values considerations\n- **NetworkPolicy added\
        \ for controller-manager**: v3.12.0 introduces a Helm-managed NetworkPolicy\
        \ for the controller manager. If your clusters enforce default-deny, this\
        \ may help; if you already manage policies, verify it doesn\u2019t conflict\
        \ and decide whether to enable/disable/override it.\n- **Webhook probe container\
        \ change**: the Helm chart switches `probeWebhook` to use **`curl` as the\
        \ ENTRYPOINT**. If you had customizations around that container/image/command,\
        \ re-check them.\n- **WebhookConfiguration naming is configurable**: bug fix\
        \ adds support to **change the `WebhookConfiguration` name** and also changes\
        \ the **pre-install CRD image** behavior. If you rely on a fixed name (RBAC,\
        \ automation, monitoring), validate after upgrade.\n- **Template/namespace\
        \ fixes**: Helm templates now include missing namespaces in \u201Cstatic\u201D\
        \ templates; this can show up as resource diffs on upgrade.\n\n_No explicit\
        \ breaking Helm values removals are called out in the provided notes, but\
        \ expect diffs due to the above additions/templating fixes._"
      chart_updates: [Adds a NetworkPolicy manifest for the controller-manager (Helm
          chart feature)., Probe webhook job/container behavior updated to run with
          `curl` as entrypoint., Fixes Helm static templates to include missing namespaces
          (may change rendered manifests)., Adds support to configure the WebhookConfiguration
          name; updates pre-install CRD image handling.]
      features: ['New `AssignImage` mutator enables image mutation use-cases (e.g.,
          rewriting images to an approved registry).', "Gatekeeper can emit admission/audit\
          \ events into the **involved object\u2019s namespace**, improving discoverability\
          \ during debugging.", OPA dependency updated to **v0.49.2** (behavior/performance/security
          changes come from OPA)., Multi-engine groundwork added to support future
          integration with Kubernetes CEL `ValidatingAdmissionPolicy`., New `--exempt-namespace-suffix`
          flag allows exempting namespaces by suffix pattern., 'Logging improvements:
          ability to write logs to a custom file and more verbose audit logging.']
      breaking_changes: []
    chart_version: 3.12.0
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.12.0',
      'openpolicyagent/gatekeeper:v3.12.0']
  - version: 3.11.1
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm chart / values changes\n- No explicit **values.yaml**\
        \ changes are called out in the provided notes for `v3.11.1`.\n- For `v3.11.0`,\
        \ two Helm-related fixes may affect installs/upgrades:\n  - Post-install/post-upgrade\
        \ jobs are allowed again (fix for Helm hook/job behavior).\n  - Chart avoids\
        \ mixing `pod-security.kubernetes.io/*` labels with `ignore` labels (may change\
        \ rendered namespace labels if you set either).\n\n### Upgrade implications\n\
        - If you rely on Helm hooks/jobs (CRD install jobs, certgen jobs, etc.), `v3.11.0`\
        \ includes a fix that may change whether those run as expected during upgrade.\n\
        - If you set Pod Security Admission (PSA) labels on the Gatekeeper namespace\
        \ via values, verify the resulting labels after upgrade to ensure you\u2019\
        re not depending on the previously mixed/invalid combination.\n"
      chart_updates: ['Helm: allow installation of post-install and post-upgrade jobs
          (fixes hook/job install behavior).', 'Helm: avoid mixing Pod Security `ignore`
          labels with PSA podSecurity labels (label rendering/validation fix).', 'Chart
          metadata: adds an icon to Chart.yaml (cosmetic).']
      features: [External Data is promoted to beta; external data providers now require
          TLS/mTLS., 'Gator CLI is promoted to beta and now supports tracing, AdmissionReview
          input, and specifying an OCI image.', Audit logs can include resource labels
          to improve log context and filtering.]
      breaking_changes: [External Data providers must be accessed over TLS/mTLS starting
          in v3.11.0; plaintext providers will stop working until updated.]
    chart_version: 3.11.1
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.11.1',
      'openpolicyagent/gatekeeper:v3.11.1']
  - version: 3.11.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / chart configuration changes to review\n\nFrom\
        \ the notes you provided, there are several **new/changed Helm knobs** introduced\
        \ around v3.10 and a couple of Helm behavior fixes in v3.11. When upgrading\
        \ from **Gatekeeper 3.10.0 \u2192 3.11.0**, the *must-review* item is external\
        \ data TLS; the rest are optional improvements.\n\n### v3.10 chart/value additions\
        \ (you may want to adopt)\n- `controllerManager.tlsMinVersion`: new value\
        \ to set the minimum TLS version for the controller manager webhook server.\n\
        - **Webhook config annotations**: new options to set annotations on **ValidatingWebhookConfiguration**\
        \ and **MutatingWebhookConfiguration**.\n- **Probe timeout configuration**:\
        \ options to configure readiness/liveness/startup probe timeouts in the chart.\n\
        - **Hook jobs options**: chart adds options for Helm hook jobs (install/upgrade\
        \ hooks) and extends/unifies hook job pod labels.\n- `controllerManager.topologySpreadConstraints`\
        \ (or similar): topology spread support added to the controller deployment.\n\
        - **External certificates injection**: values/options to allow injecting externally-provided\
        \ TLS certs (useful if you manage certs outside of the chart).\n\n### v3.11\
        \ chart-related fixes (may affect existing installs)\n- **Helm hooks**: chart\
        \ bugfix to allow installation of **post-install** and **post-upgrade** jobs\
        \ (if you rely on these hooks, verify they now run as expected).\n- **Pod\
        \ security labeling logic**: fix to not mix `pod-security.kubernetes.io/*`\
        \ labels with `ignore` labels; review your namespace labels/values if you\
        \ set either.\n\n### External data: TLS/mTLS requirement (app-level, but impacts\
        \ Helm values)\n- In **v3.11**, when using **External Data providers**, it\
        \ is now **required** to use **TLS/mTLS**. If you have external data enabled,\
        \ you will likely need to provide CA bundles and client certs/keys (via chart\
        \ values or secrets) and ensure the provider endpoints are HTTPS with proper\
        \ trust.\n"
      chart_updates: [Gatekeeper migrated away from PodSecurityPolicy (PSP) toward
          Pod Security Admission (PSA) in the v3.10 timeframe; ensure your chart install
          no longer expects PSP resources on Kubernetes >=1.25., 'Helm chart includes
          enhancements for scheduling (topology spread), hook jobs configurability/labels,
          and better webhook/probe configurability from v3.10.', v3.11 chart bugfixes
          improve Helm hook job installation behavior and correct pod security label
          handling.]
      features: [External Data promoted to beta; external data providers must now
          be accessed with TLS/mTLS., 'Gator CLI promoted to beta; adds tracing support,
          AdmissionReview support, and the ability to specify an OCI image for test/expand
          workflows.', Audit logs can include resource labels (helpful for correlating
          violations).]
      breaking_changes: ['If you use External Data, TLS/mTLS is now required for provider
          communication; non-TLS provider endpoints/configs will stop working until
          updated.', 'If you previously depended on PSP objects being installed by
          the chart, Kubernetes v1.25+ clusters will require PSA-based configuration
          instead (PSP removal may require policy/process changes).']
    chart_version: 3.11.0
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.11.0',
      'openpolicyagent/gatekeeper:v3.11.0']
  - version: 3.10.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm chart / values changes to review\n\n* **PodSecurityPolicy\
        \ removed / Pod Security Admission migration**: if you\u2019re on **Kubernetes\
        \ v1.25+**, PSP is gone. Ensure the chart is **not relying on PSP** and that\
        \ your namespaces have the appropriate **Pod Security Admission labels** (or\
        \ your cluster policy allows Gatekeeper pods to run). This release includes\
        \ chart updates to support disabling PSP.\n* **New Helm values added/expanded\
        \ (v3.10.0):**\n  * `controllerManager.tlsMinVersion` (new): lets you set\
        \ the minimum TLS version used by the controller manager.\n  * **Webhook configuration\
        \ annotations**: values to set annotations on mutating/validating `WebhookConfiguration`\
        \ objects.\n  * **Probe timeouts**: values to configure readiness/liveness\
        \ probe timeouts.\n  * **Controller topology spread**: add `topologySpreadConstraints`-style\
        \ config to the controller.\n  * **Hook jobs options/labels**: more options\
        \ for Helm hook jobs and unified/extended pod labels.\n  * **External certificate\
        \ injection options**: expose knobs to inject external certs.\n\n* **Behavioral/value\
        \ default change to be aware of:**\n  * `--max-serving-threads` now defaults\
        \ to `GOMAXPROCS` (performance-related). If you explicitly tuned serving threads\
        \ previously, revalidate.\n\n### Upgrade action items (values.yaml)\n* If\
        \ you run k8s v1.25+, **verify PSA compliance** for the `gatekeeper-system`\
        \ namespace and any constraints around privileged settings.\n* Decide whether\
        \ to set `controllerManager.tlsMinVersion` (e.g., `1.2`).\n* If you need to\
        \ add org-required metadata, configure **webhook annotations** via the new\
        \ values.\n* If you experienced probe-related restarts/timeouts, consider\
        \ tuning the new **probe timeout** values.\n* If you run multiple replicas\
        \ across zones/nodes, consider enabling **topology spread** for HA.\n"
      chart_updates: [Chart updates to support Kubernetes v1.25+ by removing PodSecurityPolicy
          resources and aligning with Pod Security Admission (PSA)., 'Helm chart enhancements
          to make operational settings configurable: probe timeout configuration,
          webhook configuration annotations, controller topology spread constraints,
          and more hook-job options/standardized labels.', Chart fixes related to
          labeling exempted namespaces and general helm upgrade reliability (helm
          upgrade test additions)., 'Chart changes to explicitly specify `curl` usage
          in webhook probing job, improving portability across images/environments.']
      features: [PodSecurityPolicy removal and migration guidance toward Pod Security
          Admission for Kubernetes v1.25+ clusters., 'Mutation promoted to stable
          (v1), indicating API/behavior stability for mutation features.', 'Alpha
          feature introduced: validation of workload resources (new workload-focused
          validation capability).', 'Operational and security hardening knobs: ability
          to inject external certs and configure minimum TLS version for the controller
          manager.', 'Helm usability improvements: configurable webhook annotations,
          probe timeout tuning, and topology spread constraints for controller scheduling.',
        New audit metric `audit_last_run_end_time` to improve observability of audit
          execution.]
      breaking_changes: [Clusters relying on PodSecurityPolicy (especially Kubernetes
          v1.25+) must migrate to Pod Security Admission; PSP resources are removed
          in this release and will no longer be applied/created by the chart.]
    chart_version: 3.10.0
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.10.0',
      'openpolicyagent/gatekeeper:v3.10.0']
  - version: 3.9.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm chart/value changes to review\n- **Webhook uninstall\
        \ ordering**: chart supports removing webhooks *before* uninstalling Gatekeeper\
        \ (from v3.8.0 notes). If you previously had trouble uninstalling due to dangling\
        \ webhook configs, check the chart value/flag introduced by that change.\n\
        - **Webhook configuration flexibility**:\n  - v3.8.0: support **custom rules**\
        \ for ValidatingWebhookConfiguration/MutatingWebhookConfiguration.\n  - v3.8.0:\
        \ add **reinvocationPolicy** option for the MutatingWebhookConfiguration.\n\
        \  - v3.9.0: chart adds **objectSelector** support for webhooks.\n- **Namespace\
        \ exemption behavior**:\n  - v3.8.0: additional labels can be exempted in\
        \ webhooks.\n  - v3.9.0: introduces/uses **labeling of exempted namespaces**\
        \ and includes a **post-upgrade job** to label namespaces; also fixes templating\
        \ for the exempt-namespace label.\n  - Action: if you use namespace exemptions,\
        \ verify your label keys/values and confirm the upgrade job has permissions\
        \ and runs successfully.\n- **SecurityContext overrides** (v3.8.0): chart\
        \ allows overriding securityContexts; v3.9.0 adds a **pod security context\
        \ variable**. Action: reconcile any custom pod/container securityContext you\
        \ set in values.\n- **Upgrade jobs configuration**:\n  - v3.9.0: allow setting\
        \ **affinity for upgradeCRDs** jobs.\n  - v3.9.0: adds **job annotations**\
        \ support.\n- **Metrics/exporters configuration**:\n  - v3.9.0: adds a **metrics\
        \ backend flag** to the Helm chart (to support OpenCensus/Stackdriver exporters).\
        \ Action: confirm your metrics setup and any additional flags/values required.\n\
        \n> Note: The provided notes don\u2019t include exact Helm value keys; use\
        \ `helm show values` for the target chart version and diff your current `values.yaml`\
        \ against it."
      chart_updates: [Adds post-upgrade job to label exempted namespaces (and fixes
          templating for that label)., Adds webhook `objectSelector` support in chart
          templates., Adds gatekeeper-webhook post-install hook., Allows overriding
          securityContexts; adds podSecurityContext value support., Adds ability to
          configure affinity for `upgradeCRDs` jobs and to set job annotations., Adds
          Helm chart support for selecting metrics backend / exporters.]
      features: [External Data gains TLS/mTLS support for calling external providers.,
        Gatekeeper can validate Kubernetes subresources (more granular admission control).,
        Adds OpenCensus and Stackdriver exporters for metrics/telemetry., Performance
          improvements including automaxprocs integration and earlier compilation/memory
          optimizations from 3.8.x., 'Helm chart gains richer webhook targeting controls
          (objectSelector, custom rules, reinvocationPolicy) and improved upgrade/uninstall
          hooks.']
      breaking_changes: ['Avoid deploying **Gatekeeper v3.8.0**: it is marked **DO
          NOT USE** due to a bug that can cause unenforced violations when using the
          `config` resource without sync; upgrade via **v3.8.1+** before moving to
          v3.9.0.', 'If you rely on namespace exemption behavior, the introduction
          of namespace labeling and related hooks/jobs may change how exemptions are
          applied; verify labels and RBAC for the upgrade job/webhook hooks before
          upgrading.']
    chart_version: 3.9.0
    images: ['curlimages/curl:7.83.1', 'openpolicyagent/gatekeeper-crds:v3.9.0', 'openpolicyagent/gatekeeper:v3.9.0']
  - version: 3.8.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '## Helm / chart values to review

        - **Webhook uninstall ordering**: Chart can now **remove validating/mutating
        webhook configurations before Gatekeeper is uninstalled**. If you want this
        behavior, look for/enable the new Helm value introduced by this feature (PR
        **#1770**).

        - **Webhook rule customization**: You can now set **custom `rules`** on `ValidatingWebhookConfiguration`
        / `MutatingWebhookConfiguration` (PR **#1806**). Review if you previously
        relied on chart defaults.

        - **Mutating webhook reinvocationPolicy**: New chart config for `reinvocationPolicy`
        on the `MutatingWebhookConfiguration` (PR **#1844**).

        - **Webhook service health port**: Chart adds a **health port on the webhook
        Service** (PR **#1839**). Ensure any NetworkPolicies / firewalls / ServiceMonitors
        allow it if relevant.

        - **Security context overrides**: Chart now allows **overriding securityContexts**
        (PR **#1938**). If you had to patch manifests previously, migrate to values.

        - **Default webhook TLS minimum version**: Gatekeeper v3.8.0 updates the **default
        minimum TLS to 1.3** (PR **#1866**). If your API server cannot negotiate TLS
        1.3 to the webhook, set the controller flag/value to keep TLS 1.2.

        - **Mutation-status webhook operation**: Deployment updated to include the
        `mutation-status` operation (PR **#1966**). If you pin/customize webhook rules,
        make sure this operation remains included.


        > Note: v3.8.0 is marked **DO NOT USE** upstream due to an enforcement bug
        when using `config` without sync; prefer **v3.8.1+** for the upgrade.'
      chart_updates: ["Performance-focused release: significant improvements to constraint\
          \ template compilation (~16%) and major reductions in webhook CPU/memory\
          \ (1.5x\u20134x) plus audit memory (~2x).", Adds a TLS checker for the webhook
          and bumps default TLS min version to 1.3., Adds metric and operational improvements
          around mutation (conflicting mutators metric; mutation-status operation).,
        Improves matching capabilities (suffix-based matching; additional webhook
          label exemptions)., 'CLI/tooling changes: `gktest` renamed to `gator`; `gator
          test` renamed to `gator verify` (docs/UX updates).', Dependency updates
          include upgrading embedded OPA to **v0.39.0**.]
      features: ['External Data now supports **mutation**, enabling mutation responses
          driven by external providers.', 'New Prometheus metric for **conflicting
          mutators**, improving observability of mutation configuration issues.',
        Customizable webhook configuration rules and reinvocation policy allow tighter
          integration with cluster admission policies., Suffix-based resource matching
          expands how constraints/targets can match resource kinds/names.]
      breaking_changes: ['**Do not deploy v3.8.0**: upstream warns of a bug that can
          cause **unenforced violations** when using the `config` resource without
          sync; upgrade to **v3.8.1+** instead.', Default minimum TLS for webhooks
          changes to **TLS 1.3**; clusters/components that only support TLS 1.2 may
          fail webhook calls unless you explicitly configure the min TLS version.,
        'CLI rename: `gator test` becomes `gator verify` (and `gktest` renamed to
          `gator`), which can break scripts/CI pipelines relying on old command names.']
    chart_version: 3.8.0
    images: ['openpolicyagent/gatekeeper-crds:v3.8.0', 'openpolicyagent/gatekeeper:v3.8.0']
  - version: 3.7.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **RBAC resources are now conditional**: RBAC manifests are
        wrapped behind `values.rbac.create` (PR #1625). If you previously relied on
        the chart always creating Roles/RoleBindings/ClusterRoles, ensure `rbac.create=true`
        (default may vary by your chart version) or provide your own RBAC.

        - **External Data (alpha) Helm flag**: Helm can now enable the external data
        validation feature via a chart value/flag (PR #1633). Only enable if you intend
        to use it and have reviewed networking/security implications.

        - **Audit cache disk/RAM-disk options**: New chart options added for audit
        to write cache to disk and optionally to a RAM disk (`writeToRAMDisk`) to
        reduce memory (PRs #1634, #1660).

        - No explicit value key removals were called out in the provided notes; validate
        your existing `values.yaml` against the new chart defaults before upgrading.'
      chart_updates: ['Mutation feature status updated: mutation is now **Beta** in
          v3.7.0 (was earlier stage in v3.6.x).', 'New mutator type: **ModifySet**
          mutator added.', 'New alpha feature: **External Data** for validation added
          (gated behind a flag).', 'Webhook TLS hardening: minimum TLS version raised
          to **1.2**; configurable via `--tls-min-version` (with TLS 1.3 planned as
          default in v3.8.0).', 'Audit memory improvements: audit can write cache
          to disk to reduce memory usage; Helm adds knobs for RAM-disk option.', 'New
          alpha tooling: **Gator CLI** introduced for local testing of ConstraintTemplates/Constraints
          without a Kubernetes cluster.']
      features: ['Mutation is now Beta, making mutation capabilities more production-ready
          and supported than prior versions.', 'ModifySet mutator added, enabling
          set-style modifications as part of mutation.', External Data for validation
          (alpha) allows Gatekeeper policies to consult out-of-process providers for
          decisions., Gator CLI (alpha) provides a way to test templates/constraints
          locally without Kubernetes., Audit memory usage reduced via cache-to-disk
          capability; optional RAM-disk support via Helm values.]
      breaking_changes: [Webhook TLS minimum version is now TLS 1.2; clients using
          TLS 1.0/1.1 will fail to connect unless updated. (You can configure the
          minimum via `--tls-min-version`.)]
    chart_version: 3.7.0
    images: ['openpolicyagent/gatekeeper-crds:v3.7.0', 'openpolicyagent/gatekeeper:v3.7.0']
  - version: 3.6.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- **CRD upgrade handling:** v3.6.0 adds **Helm hooks to upgrade\
        \ CRDs**. If you previously managed CRDs manually (or via separate tooling),\
        \ review how your chart handles CRDs during `helm upgrade` so you don\u2019\
        t end up with competing ownership/upgrade paths.\n- **Configurable ports via\
        \ Helm:** Helm can now **configure controller-manager and audit ports**. If\
        \ you set custom ports or scrape metrics, align your values with the new options.\n\
        - **PDB API version auto-selection:** Helm chart dynamically selects the **PodDisruptionBudget\
        \ API version** based on cluster version; remove any workarounds/overrides\
        \ you carried for older/newer K8s.\n"
      chart_updates: [ConstraintTemplate CRD moves to **v1** (requires CRD update
          in the cluster)., Gatekeeper and controller-runtime metrics are unified
          into a **single endpoint** (affects scraping/ServiceMonitor/Prometheus config).,
        'Mutation subsystem improvements: large **System.Mutate runtime reduction**,
          watch/constraint controller **race condition fixes**, and new mutation features
          (namespace prefix matching; integer `keyValue` support in mutation path
          parser).', Removed **non-specific webhook request metrics**; request duration
          metric buckets updated (upper limit 3s)., Adds metrics reporting for mutation.,
        Updates Kubernetes dependency/support matrix (notably K8s v1.22 updates).]
      features: ['ConstraintTemplate CRD is now served as v1, modernizing the API
          and aligning with newer Kubernetes CRD versions.', Mutation performance
          improved significantly (reported ~87% reduction for System.Mutate runtime).,
        Namespace and excludedNamespaces matching now supports prefix-based matching
          for more flexible scoping., 'Mutation path parser/mutators support integer
          keyValue, enabling more precise mutations on numeric keys.', 'Helm chart
          improvements: configurable controller-manager/audit ports and hooks to upgrade
          CRDs.', 'Metrics enhancements: unified metrics endpoint and mutation metrics
          reporting.']
      breaking_changes: ['**ConstraintTemplate CRD moves to v1**; clusters must have
          updated CRDs before/with the upgrade, and any tooling expecting the older
          CRD version may need adjustment.', 'Metrics surface changes: **non-specific
          webhook request metrics removed** and metrics endpoint behavior changes
          (unified endpoint), which can break existing dashboards/alerts/scrape configs.']
    chart_version: 3.6.0
    images: ['line/kubectl-kustomize:1.20.4-4.0.5', 'openpolicyagent/gatekeeper-crds:v3.6.0',
      'openpolicyagent/gatekeeper:v3.6.0']
  - version: 3.5.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '- **Helm 2 is removed as of v3.4.0**: ensure you are using the
        Helm v3 chart/repo; Helm 2-based installs cannot be upgraded in-place.

        - **CRD install hook removed** (v3.4.0): the chart no longer relies on the
        `crd-install` hook; manage CRDs using Helm v3 CRD behavior or apply CRDs separately
        as part of your upgrade workflow.

        - **Mutation (alpha) can be enabled via Helm** (v3.4.0): set `experimentalEnableMutation=true`
        if you intend to deploy the mutation components.

        - **v3.5.0 webhook defaults**: v3.5.0 adds default configs to the `MutatingWebhookConfiguration`;
        review any custom webhook settings/overrides to ensure they still match your
        desired behavior.'
      chart_updates: [Helm v2 chart removed; Helm v3 chart is the supported path (v3.4.0).,
        'Helm: removed `crd-install` hook (v3.4.0).', 'Helm: mutation components added
          to chart behind `experimentalEnableMutation` flag (v3.4.0).', 'Helm: removed
          duplicate `affinity` key (bugfix in v3.4.0).', MutatingWebhookConfiguration
          now ships with default configuration values (v3.5.0).]
      features: [Kubernetes v1.22+ compatibility (v3.5.0)., Mutation support available
          as an alpha feature and deployable via Helm with `experimentalEnableMutation`
          (introduced in v3.4.0)., Improved user feedback for invalid inputs (v3.4.0).]
      breaking_changes: [Helm v2 chart removed starting in v3.4.0; you must use Helm
          v3 for install/upgrade going forward., Validation metrics `request_count`
          and `request_duration_seconds` are deprecated in favor of `validation_request_count`
          and `validation_request_duration_seconds` (introduced in v3.4.0); update
          dashboards/alerts before the old names are removed in a future release.]
    chart_version: 3.5.0
    images: ['line/kubectl-kustomize:1.20.4-4.0.5', 'openpolicyagent/gatekeeper:v3.5.0']
  - version: 3.4.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '## Helm values / chart behavior changes to account for

        - **Helm v2 chart removed** in Gatekeeper **v3.4.0**. Upgrades must use the
        **Helm v3 chart** from the Helm repo.

        - **Mutation (alpha) can be enabled via Helm** using `experimentalEnableMutation:
        true`.

        - **CRD install hook removed**: the chart **removes the `crd-install` Helm
        hook**. Ensure CRDs are installed/managed in a Helm v3-compatible way (e.g.,
        CRDs in the chart `crds/` directory, or applied separately in your pipeline)
        before/with the upgrade.


        ## Notes for monitoring

        - Validation metrics `request_count` and `request_duration_seconds` are **planned
        for deprecation** in favor of `validation_request_count` and `validation_request_duration_seconds`;
        update dashboards/alerts accordingly (not an immediate break in 3.4.0, but
        plan ahead).'
      chart_updates: [Helm v2 chart support removed; Helm v3 chart is the supported
          install/upgrade path., Helm chart gains support for mutation (alpha) behind
          `experimentalEnableMutation`., 'Helm chart fix: removed duplicate `affinity`
          key.', 'Helm chart change: removed `crd-install` hook (Helm v3 CRD handling).']
      features: [Mutation is available as an alpha feature and can be deployed via
          experimental manifests or enabled in the Helm v3 chart with `experimentalEnableMutation`.,
        "Added better \u201Cinvalid input\u201D feedback to help users diagnose bad\
          \ policy/constraint inputs."]
      breaking_changes: [Helm v2 chart has been removed as of v3.4.0; any Helm v2-based
          install/upgrade process must be migrated to Helm v3.]
    chart_version: 3.4.0
    images: ['line/kubectl-kustomize:1.20.4-4.0.5', 'openpolicyagent/gatekeeper:v3.4.0']
  - version: 3.3.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: '## Helm values / chart behavior changes to review

        - **Namespace creation can be optional**: Chart adds a toggle to control whether
        it creates the Gatekeeper namespace (PR #981). If you previously relied on
        the chart to create the namespace, verify the new default and set the value
        accordingly (commonly something like `namespace.create: true/false`).

        - **PriorityClass is now configurable** for both `controller-manager` and
        `audit` workloads (PR #1008). If you want non-default scheduling priority,
        set the new values (often `controllerManager.priorityClassName` / `audit.priorityClassName`).

        - **`readOnlyRootFilesystem` support** in the chart (PR #1048). If your cluster
        enforces restricted PodSecurity/PSP-like policies, consider enabling it; if
        you have custom sidecars/volumes needing write access, test first.

        - **Webhook delete operations/timeout are parameterized** (PR #1051). If you
        hit webhook timeouts during upgrades or policy rollouts, tune the new values.

        - **Validation webhook max worker threads is configurable** (PR #1021). Useful
        if you need to throttle/scale admission throughput.

        - **Audit vs controller settings can diverge** (PR #1006). If you previously
        set shared values, you may now need to set both blocks explicitly depending
        on your desired behavior.

        '
      chart_updates: ['Helm chart feature additions focused on configurability: optional
          namespace creation, configurable PriorityClass, read-only root filesystem
          option, tunable webhook timeouts/delete behavior, configurable validation
          webhook workers, and ability to set different settings for audit vs controller
          components.']
      features: ['Helm chart can optionally create the namespace, improving compatibility
          with GitOps or pre-provisioned namespaces.', PriorityClass can be set for
          controller-manager and audit deployments to control scheduling precedence.,
        New `readiness-retries` flag allows tuning how many readiness checks/retries
          Gatekeeper performs before declaring failure., 'Config resource is now validated
          to be named `config`, reducing misconfiguration drift.', 'Audit and controller
          can now have different settings, enabling more precise performance vs enforcement
          tuning.', Admission validation webhook worker count is configurable to control
          concurrency and throughput., 'Experimental mutation system improvements:
          CRD validation, mutation cache, assign/assignmetadata controllers, and better
          mutation webhook behavior.']
      breaking_changes: []
    chart_version: 3.3.0
    images: ['openpolicyagent/gatekeeper:v3.3.0']
  - version: 3.2.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Gatekeeper library was moved out of the main Gatekeeper repository
          into its own repository: https://github.com/open-policy-agent/gatekeeper-library.']
      breaking_changes: ['If you relied on Gatekeeper constraint templates/constraints
          from the in-repo library or referenced it as part of your upgrade process,
          you now need to pull those artifacts from the separate gatekeeper-library
          repository instead.']
    chart_version: 3.2.0
    images: ['openpolicyagent/gatekeeper:v3.2.0']
  - version: 3.1.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.1.0
    images: ['openpolicyagent/gatekeeper:v3.1.0']
  name: gatekeeper
- icon: https://docs.tigera.io/img/calico-logo.webp
  git_url: https://github.com/projectcalico/calico
  release_url: https://github.com/projectcalico/calico/releases/tag/v{vsn}
  helm_repository_url: https://docs.tigera.io/calico/charts
  chart_name: tigera-operator
  versions:
  - version: 3.31.3
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.31.3
    images: ['quay.io/tigera/operator:v1.40.3']
  - version: 3.31.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.31.0
    images: ['quay.io/tigera/operator:v1.40.0']
  - version: 3.30.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.30.0
    images: ['quay.io/tigera/operator:v1.38.0']
  - version: 3.29.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.29.0
    images: ['quay.io/tigera/operator:v1.36.0']
  - version: 3.28.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.28.0
    images: ['quay.io/tigera/operator:v1.34.0']
  - version: 3.27.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.27.0
    images: ['quay.io/tigera/operator:v1.32.3']
  - version: 3.26.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.26.0
    images: ['quay.io/tigera/operator:v1.30.0']
  - version: 3.25.0
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.25.0
    images: ['quay.io/tigera/operator:v1.29.0']
  - version: 3.24.1
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.24.1
    images: ['quay.io/tigera/operator:v1.28.1']
  - version: 3.23.4
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.23.4
    images: ['quay.io/tigera/operator:v1.27.14']
  - version: 3.22.5
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.22.5
    images: ['quay.io/tigera/operator:v1.25.13']
  - version: 3.20.6
    kube: ['1.30', '1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.20.6
    images: ['quay.io/tigera/operator:v1.20.9']
  name: tigera-operator
- icon: https://raw.githubusercontent.com/pluralsh/plural-artifacts/main/argo-cd/plural/icons/argo-stacked-color-square.png?raw=true
  git_url: https://github.com/argoproj/argo-cd
  release_url: https://github.com/argoproj/argo-cd/releases/tag/v{vsn}
  helm_repository_url: https://argoproj.github.io/argo-helm
  versions:
  - version: 3.2.3
    kube: ['1.35', '1.34', '1.33']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ["v3.2.3: Dependency update only \u2013 bumped golang.org/x/crypto\
          \ from 0.42.0 to 0.46.0 (security/crypto library refresh).", 'v3.2.1: Repo-server
          fix for a concurrency issue with Git detached HEAD processing, reducing
          intermittent repo refresh/manifest generation errors.', 'v3.2.1: Multiple
          UI fixes (status panel null-safety, tooltip resource units, layout overlap,
          conditional rendering of ApplicationSelector) improving UI stability and
          correctness.', 'v3.2.1: Health assessment tweak for ISVC resources: allow
          healthy when the Stopped condition is False.']
      breaking_changes: []
    chart_version: 9.2.4
    images: ['ecr-public.aws.com/docker/library/redis:8.2.2-alpine', 'ghcr.io/dexidp/dex:v2.44.0',
      'quay.io/argoproj/argocd:v3.2.3']
  - version: 3.2.1
    kube: ['1.35', '1.34', '1.33']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Repo Server: fixes a concurrency issue when processing detached
          git states, reducing chance of stuck/failed refreshes in busy repos.', 'UI:
          multiple small fixes (null-safe status panel rendering, prevent overlapping
          elements, add resource units in tooltips, avoid rendering ApplicationSelector
          when panel hidden).']
      breaking_changes: []
    chart_version: 9.1.8
    images: ['ecr-public.aws.com/docker/library/redis:8.2.2-alpine', 'ghcr.io/dexidp/dex:v2.44.0',
      'quay.io/argoproj/argocd:v3.2.1']
  - version: 3.2.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Internal tooling bumps: embedded Helm upgraded to 3.18.4 (via
          3.18.3) and embedded Kustomize upgraded to 5.7.0.', 'New/updated health
          check scripts and resource_customizations shipped with the release (CronJob
          actions/health changes, plus additional CRD health checks such as Coralogix,
          DatadogMetric, ClickHouse operator, ExtensionService, GitOps Promoter, 3scale,
          etc.).', 'Security fix included: repository.GetDetailedProject no longer
          exposes repository secrets.', 'Performance/behavioral fixes around auto-sync
          loops and controller CPU (reduced settings DB calls), plus webhook handler
          hardening (panic recovery; informer usage to reduce memory).', 'Source Hydrator
          enhancements: commit message templating, credential templates, preserve
          non-hydrated files, repo URL normalization, parallelized repo-server calls.']
      features: ['ApplicationSet: pprof endpoints added; progressive sync deletion
          can happen in order; improved status/debug logging; concurrency ceiling
          effectively removed.', 'CLI: server-side diff is supported; new `argocd
          get-resource` command; password can be read from stdin / prompted for bcrypt
          operations.', 'Controller: when retrying a failed sync, Argo CD can sync
          a newer revision than the original failed revision.', 'Observability: OpenTelemetry
          trace context propagation added for HTTP requests; new metrics to track
          number of users.', 'Server/UI: gRPC health check endpoint for argocd-server;
          UI improvements like sortable columns and prune option during rollback,
          plus richer repo connection status messages.']
      breaking_changes: []
    chart_version: 9.1.4
    images: ['ecr-public.aws.com/docker/library/redis:8.2.2-alpine', 'ghcr.io/dexidp/dex:v2.44.0',
      'quay.io/argoproj/argocd:v3.2.0']
  - version: 3.1.1
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [No Helm chart-specific changelog was provided in the notes you
          pasted; the v3.1.1 notes are application release notes only., "If you are\
          \ upgrading via Helm, verify the argo-cd Helm chart version that corresponds\
          \ to app v3.1.1 and review that chart\u2019s CHANGELOG for values/schema\
          \ changes, hook/job changes, and CRD handling."]
      features: [No new user-facing features called out for v3.1.1; this is a patch
          release focused on fixes and small manifest tweaks., Manifests add OCI-related
          environment variables (helps OCI/registry integrations when using upstream
          install manifests).]
      breaking_changes: []
    chart_version: 8.3.3
    images: ['ecr-public.aws.com/docker/library/redis:7.2.8-alpine', 'ghcr.io/dexidp/dex:v2.44.0',
      'quay.io/argoproj/argocd:v3.1.1']
  - version: 3.1.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Application version bump from v3.0.x to v3.1.0 (new images/manifests).,
        'Tooling bundled with Argo CD updated: Helm upgraded to 3.18.x; Kustomize
          upgraded to 5.7.0.', 'Various health-check/resource customization additions
          (Karpenter, Crossplane/Upbound, Kyverno, Logstash, RabbitMQ topology, OpenTelemetryCollector,
          Grafana Operator, Gateway API, Contour HTTPProxy, etc.).', Security hardening
          around static assets/commit-server traversal protection and other fixes.,
        UI enhancements including Progressive Sync integration and improved repo/pod
          views., CLI improvements including plugin support and additional commands/aliases.]
      features: ['CLI: adds official plugin support and a new whoami alias.', 'UI:
          Progressive Sync feature integrated and additional usability improvements
          (sorting, resource display toggles, autosync enabled field).', 'ApplicationSet:
          enhancements such as Bitbucket Cloud PR generator target-branch support
          and git file generator file-exclusion support.', 'Repo/OCI: OCI support
          continues (beta) plus related UI polish and OCI client fixes; also adds
          GitHub API rate limit metrics.', 'Operations/Health: many new built-in health
          checks/resource customizations for popular CRDs (Crossplane, Kyverno, KEDA,
          Grafana Operator, OpenTelemetryCollector, etc.).']
      breaking_changes: ['Potential API/schema change around SyncPolicy automated
          sync: field is `enabled` (and a UI field was added); ensure any manifests/automation
          referencing older field names are updated.', 'Toolchain bumps (Helm 3.18.x,
          Kustomize 5.7.0) can change rendering/diff behavior compared to 3.0.x; validate
          any edge-case charts/kustomize builds in staging.']
    chart_version: 8.3.0
    images: ['ecr-public.aws.com/docker/library/redis:7.2.8-alpine', 'ghcr.io/dexidp/dex:v2.43.1',
      'quay.io/argoproj/argocd:v3.1.0']
  - version: 3.0.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Argo CD 3.0.0 is a major release with multiple default-behavior
          changes (RBAC, diffing/compare, tracking method, logging, controller processing)
          that can affect existing installations during upgrade.', 'Repo-server tooling
          bumped (Helm 3.17.0, kubectl 1.32.1) and Kubernetes support updated (supports
          Kubernetes 1.32; older versions removed from e2e).', 'Redis usage changed:
          application health status is stored in Redis by default; Redis image upgraded
          (7.0.15-alpine -> 7.2.7-alpine).', 'Security posture and supply chain: images
          signed with cosign and SLSA3 provenance; some dependency CVE bumps included.',
        Legacy repo support removed; behavior of ApplicationSet selectors and diff
          ignore defaults changed; some deprecated metrics removed.]
      features: [Azure Workload Identity support added for Git/OCI repositories and
          for Microsoft Entra (Azure AD) SSO flows., 'Application controller now stores
          application health status in Redis by default, improving performance/scalability
          for large installs.', Batch event processing enabled by default in the controller
          to reduce event storm impact., 'Helm tooling upgraded to Helm v3.17.0 and
          kubectl upgraded to 1.32.x, improving compatibility with newer clusters.',
        Bearer token authentication support added (including UI/Helm repo connect
          flows)., 'Kustomize enhancements: ignore missing components and support
          --include-templates for label processing.', 'UI improvements: better log
          search (match case), log highlighting, sync-wave display, repo filtering,
          and various UX fixes.', More metrics exposed (including additional kubectl
          metrics and cluster name/labels in cluster metrics).]
      breaking_changes: [RBAC enforcement for logs is enabled by default; users/roles
          that previously could view logs may be denied until RBAC is updated., 'Fine-grained
          RBAC inheritance is disabled by default, which can change effective permissions
          for inherited roles/policies.', "Compare/diff defaults changed: compare\
          \ options default values updated, known interim resources excluded by default,\
          \ and Argo CD now ignores .status updates and other high-churn diffs by\
          \ default\u2014this can change sync/diff outcomes.", 'Default resource tracking
          method changed to annotation, which can affect how existing resources are
          associated with applications if you relied on the prior default.', 'Default
          logging switched to JSON, which can break log parsers/alerts expecting text
          logs.', Legacy repo support removed; any clusters/repos relying on legacy
          repository handling must be migrated., Deprecated metrics removed; dashboards/alerts
          referencing old metric names will break., 'ApplicationSet behavior change:
          nested selectors are always applied, potentially altering generated ApplicationSets/app
          selection.', Default jitter added (60s) which can change timing/behavior
          of periodic operations and reconciliation cadence.]
    chart_version: 8.0.1
    images: ['ghcr.io/dexidp/dex:v2.42.1', 'public.ecr.aws/docker/library/redis:7.2.8-alpine',
      'quay.io/argoproj/argocd:v3.0.0']
  - version: 2.14.11
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Hydrator: webhook handling now understands `sourceHydrator` fields,
          improving support for hydration workflows triggered via webhooks.']
      breaking_changes: []
    chart_version: 7.9.1
    images: ['ghcr.io/dexidp/dex:v2.42.1', 'public.ecr.aws/docker/library/redis:7.2.8-alpine',
      'quay.io/argoproj/argocd:v2.14.11']
  - version: 2.14.1
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 7.8.0
    images: ['ghcr.io/dexidp/dex:v2.41.1', 'public.ecr.aws/docker/library/redis:7.4.2-alpine',
      'quay.io/argoproj/argocd:v2.14.1']
  - version: 2.13.2
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['(v2.13.0) UI extensions: Argo CD now supports configuring extensions
          individually, allowing per-extension settings rather than a single shared
          config.', '(v2.13.0) Self-heal exponential backoff: self-heal retries can
          use an exponential backoff between attempts to reduce thrash during repeated
          drift.']
      breaking_changes: []
    chart_version: 7.7.12
    images: ['ghcr.io/dexidp/dex:v2.41.1', 'public.ecr.aws/docker/library/redis:7.4.1-alpine',
      'quay.io/argoproj/argocd:v2.13.2']
  - version: 2.13.0
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['v2.13.0: UI extensions can now be configured individually, allowing
          more granular extension setup per extension rather than a single shared
          config.', 'v2.13.0: Self-heal can use exponential backoff between attempts,
          reducing thrash on frequently-drifting resources and smoothing controller
          load.', 'v2.12.0: Added a custom health check for Cluster API AWSManagedControlPlane
          resources (useful if you manage CAPI AWS clusters via Argo CD).']
      breaking_changes: []
    chart_version: 7.7.3
    images: ['ghcr.io/dexidp/dex:v2.41.1', 'public.ecr.aws/docker/library/redis:7.4.1-alpine',
      'quay.io/argoproj/argocd:v2.13.0']
  - version: 2.12.0
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ["Adds a custom health check for Cluster API\u2019s AWSManagedControlPlane\
          \ resource, improving health reporting for that CRD when managed by Argo\
          \ CD."]
      breaking_changes: ['Known issue in 2.12.0: ApplicationSets using git generators
          with a templated `spec.template.spec.project` can fail to reconcile due
          to a bug in the new git signature verification feature (fixed in 2.12.2).
          Consider upgrading to >=2.12.2 or avoiding that pattern during the upgrade.']
    chart_version: 7.4.3
    images: ['ghcr.io/dexidp/dex:v2.38.0', 'public.ecr.aws/docker/library/redis:7.2.4-alpine',
      'quay.io/argoproj/argocd:v2.12.0']
  - version: 2.11.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 6.9.3
    images: ['ghcr.io/dexidp/dex:v2.38.0', 'public.ecr.aws/docker/library/redis:7.2.4-alpine',
      'quay.io/argoproj/argocd:v2.11.0']
  - version: 2.10.7
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['2.10.0 is the base for this patch-line upgrade; it introduced
          multiple controller/server/repo-server features and fixes, plus a known
          HA controller issue in 2.10.0 that is fixed in 2.10.1+.', v2.10.7 is a patch
          release; the GitHub release page primarily points to the compare view (v2.10.6...v2.10.7)
          rather than listing highlights on the page itself.]
      features: ['In 2.10.0, Application Controller added sync jitter (to reduce sync
          thundering herd) and a grace period for repo errors to avoid overly aggressive
          Unknown sync states.', 'In 2.10.0, Argo CD added Server-Side Diff and improved
          support for Server-Side Apply scenarios (notably around auto-creating namespaces).',
        'In 2.10.0, ApplicationSets gained advanced templating via templatePatch and
          additional sprig functions (e.g., slugify).', 'In 2.10.0, Argo CD added
          PostDelete hook support and improved UI capabilities (e.g., status panel
          extensions, better prompts around pruning, recursive Helm values file detection).',
        'In 2.10.0, security/SSO improvements included PKCE web login flow and optional
          OIDC UserInfo group-claim retrieval, plus better security logging when access
          is blocked.']
      breaking_changes: [No explicit breaking changes are shown in the provided notes
          for 2.10.0 or 2.10.7; treat this as 'none called out' rather than 'none
          exist' and still follow the upstream upgrading guide when jumping minor
          versions (not applicable here since it's a patch upgrade within 2.10).]
    chart_version: 6.7.15
    images: ['ghcr.io/dexidp/dex:v2.38.0', 'public.ecr.aws/docker/library/redis:7.2.4-alpine',
      'quay.io/argoproj/argocd:v2.10.7']
  - version: 2.10.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['No Helm chart changelog was provided in the notes you pasted
          (these are Argo CD application release notes), so there are no chart-specific
          template/RBAC/Service changes I can accurately call out from this input
          alone.']
      features: ['Server-Side Diff: Argo CD can compute diffs using Kubernetes server-side
          apply semantics, improving diff accuracy for SSA-managed fields.', 'PostDelete
          hook support: adds a new hook type so you can run cleanup jobs after an
          app is deleted.', 'Controller sync jitter: introduces jitter to reconciliation
          timing to reduce thundering-herd behavior across many apps/controllers.',
        'UI status panel extensions: allows adding/using UI extensions in the application
          status panel without modifying core UI.', 'OIDC UserInfo group claims (optional):
          can query the OIDC UserInfo endpoint to populate group claims when they
          are not present in the ID token.', "Kustomize Components support: supports\
          \ Kustomize \u201Ccomponents\u201D for more modular overlays.", 'Notifications
          self-service: adds functionality enabling users to manage certain notifications
          behavior via Argo CD.', 'Improved observability and networking options:
          supports secured OTLP endpoints/headers for OpenTelemetry and adds support
          for ALL_PROXY.']
      breaking_changes: ['Known issue (operationally impactful): Argo CD 2.10.0 has
          a major issue with the application-controller when running in HA mode; upstream
          indicates the fix is in 2.10.1, so upgrading straight to 2.10.0 in HA is
          risky and may be effectively a breaking change for HA deployments.', "API\
          \ hardening change: content-type enforcement for API requests was introduced\
          \ (with an option to disable the check); clients/proxies that don\u2019\
          t set Content-Type correctly may start failing until adjusted."]
    chart_version: 6.0.13
    images: ['ghcr.io/dexidp/dex:v2.38.0', 'public.ecr.aws/docker/library/redis:7.0.15-alpine',
      'quay.io/argoproj/argocd:v2.10.0']
  - version: 2.9.4
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['No Helm chart changelog was provided in the notes you pasted,
          so there are no chart-specific changes I can summarize from source data.']
      features: ['**v2.9.0** introduced a large set of new capabilities across Argo
          CD and ApplicationSet, including PKCE auth flow for web logins, dynamic
          cluster sharding/rebalancing (must be explicitly enabled), improved UI features
          (e.g., recursive Helm values file detection), and multiple new/expanded
          health checks for additional CRDs.', 'Operational/observability additions
          in **v2.9.0** include more reconciliation timing metrics/log fields, additional
          OpenTelemetry attributes support, and new knobs like `ARGOCD_CLUSTER_CACHE_LIST_PAGE_BUFFER_SIZE`
          and GRPC keepalive configuration.']
      breaking_changes: ['**v2.9.4 includes a security fix (GHSA-92mw-q256-5vwg) that
          introduces a breaking API change**; you must read the advisory and validate
          any custom clients/integrations against the new API behavior before upgrading.',
        '**v2.9.4 has a known issue causing major UI breakage** (many UI actions fail).
          The upstream note says a fix will be available in 2.9.5, so consider skipping
          2.9.4 if the UI is critical.']
    chart_version: 5.53.1
    images: ['ghcr.io/dexidp/dex:v2.37.0', 'public.ecr.aws/docker/library/redis:7.0.13-alpine',
      'quay.io/argoproj/argocd:v2.9.4']
  - version: 2.9.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Upgrade Argo CD components from v2.8.4 to v2.9.0 (new container
          images/manifests)., 'Redis image bumped to 7.0.14; various dependency bumps
          (k8s/client-go, kustomize, helm, Go 1.21) that may change runtime behavior
          and manifest generation edge cases.', Notifications engine upgraded (may
          affect notification templates/triggers behavior)., 'Extensions: extension
          configs can now be applied without restarting the API server (operational
          behavior change).', ApplicationSet controller and generators received multiple
          functional updates and bug fixes (behavior changes noted below).]
      features: [PKCE authentication flow for web logins (OIDC) to improve security
          and compatibility with providers requiring PKCE., 'ApplicationSet enhancements:
          new template functions (fromYaml/fromYamlArray/toYaml), ignoreApplicationDifferences
          support, label preservation options, and expanded SCM/webhook support (Azure
          DevOps, GitLab improvements).', 'Git and repo behavior improvements: configurable
          git requests and a grace period for repo errors to reduce flapping to Unknown
          sync state.', Dynamic cluster sharding/rebalancing support to distribute
          clusters across controller shards more evenly (must be explicitly enabled).,
        'UI/CLI improvements: Helm values files detected recursively; tree-view output
          for several CLI commands; better log viewer (line wrap toggle).', 'Observability
          improvements: new reconciliation timing fields in logs; extra OpenTelemetry
          attributes support; new/extended metrics (e.g., autosync_enabled gauge).']
      breaking_changes: []
    chart_version: 5.51.1
    images: ['ghcr.io/dexidp/dex:v2.37.0', 'public.ecr.aws/docker/library/redis:7.0.13-alpine',
      'quay.io/argoproj/argocd:v2.9.0']
  - version: 2.8.4
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Includes several bugfixes in Argo CD 2.8.4: reverts ApplicationSet
          application-name labels behavior; fixes handling of annotations for resources
          with '':'' in the name; prevents ApplicationSet GoTemplate nil dereference
          panics; stops appending '':443'' to server address when using grpc-web;
          allows retrieving UI badges across namespaces; fixes GitLab SCM provider
          transport creation; makes managed namespaces more resistant to being pruned;
          expands the controller ClusterRole to permit cronjob and Argo Workflows
          triggers.', Argo CD 2.8.3 (current) was a security patch release addressing
          CVE-2023-40029 and CVE-2023-40584.]
      breaking_changes: []
    chart_version: 5.47.0
    images: ['ghcr.io/dexidp/dex:v2.37.0', 'public.ecr.aws/docker/library/redis:7.0.13-alpine',
      'quay.io/argoproj/argocd:v2.8.4']
  - version: 2.8.3
    kube: ['1.28', '1.27', '1.24']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 5.46.2
    images: ['ghcr.io/dexidp/dex:v2.37.0', 'public.ecr.aws/docker/library/redis:7.0.11-alpine',
      'quay.io/argoproj/argocd:v2.8.3']
  name: argo-cd
- icon: https://avatars.githubusercontent.com/u/16866914
  git_url: https://github.com/vectordotdev/vector/
  release_url: https://github.com/vectordotdev/vector/releases/tag/v{vsn}
  helm_repository_url: https://helm.vector.dev/
  versions:
  - version: 0.52.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Added new internal metrics for source/transform buffer utilization
          (capacity, usage, and historical levels) to improve observability during
          backpressure/buffering scenarios.', Introduced a new `trace_to_log` transform
          to convert traces into log events., 'Blackhole sink now supports end-to-end
          acknowledgements, enabling ack-based delivery semantics even when discarding
          output.', 'GELF decoder gained a `validation` mode (`strict` default, `relaxed`
          to accept non-compliant GELF senders).', '`docker_logs` source now retries
          Docker daemon communication failures using exponential backoff, improving
          resilience.']
      breaking_changes: []
    chart_version: 0.49.0
    images: ['timberio/vector:0.52.0-distroless-libc']
  - version: 0.51.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['New `otlp` codec for bidirectional conversion between Vector events
          and OTLP, improving interoperability with OpenTelemetry collectors/instrumentation.',
        'Improved internal telemetry/metrics correctness: fixes negative utilization
          metrics and buffer counter underflows.', Memory enrichment tables now support
          an `expired` output to export expired cache items; enrichment table outputs
          are also visible via `vector tap`., "(From 0.50.0 context) The `opentelemetry`\
          \ source can decode standard OTLP for logs/metrics/traces, simplifying OTEL\u2192\
          Vector\u2192OTEL pipelines."]
      breaking_changes: ['Upstream release notes for 0.51.0 mention breaking changes
          exist, but the provided excerpt does not list them; review the full changelog
          before upgrading.', "Note from 0.50.0: `azure_blob` sink now requires `connection_string`\
          \ authentication (relevant if you\u2019re coming from <0.50.0).", 0.51.0
          was superseded and maintainers recommend upgrading to 0.51.1 instead of
          0.51.0.]
    chart_version: 0.47.0
    images: ['timberio/vector:0.51.0-distroless-libc']
  - version: 0.50.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ["OpenTelemetry source can now decode standard OTLP for logs, metrics,\
          \ and traces, reducing the need for remap transforms in OTEL\u2192Vector\u2192\
          OTEL or forwarding pipelines.", Added `varint_length_delimited` framing
          for compatibility with protobuf streaming tools/implementations such as
          ClickHouse., 'New `incremental_to_absolute` transform to convert incremental
          metrics into absolute values, helpful when data loss is possible or for
          historical recording.', New `okta` source to ingest Okta System Log events
          via the Okta Management API., Exec secrets option now supports protocol
          version v1.1 (compatible with Datadog Secret Backend).]
      breaking_changes: ['`azure_blob` sink authentication changed: it now requires
          `connection_string` and this is currently the only supported auth method;
          existing configs using other auth options must be updated.']
    chart_version: 0.46.0
    images: ['timberio/vector:0.50.0-distroless-libc']
  - version: 0.49.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Introduced a new `websocket` source to ingest real-time data from
          services exposing WebSocket APIs., 'HTTP sink now supports templating in
          `uri` and `request.headers`, enabling dynamic request construction based
          on event data.', '`--watch-config` now also watches enrichment table files
          for changes and reload triggers.', '`prometheus_remote_write` sink adds
          a TTL-based cache for metrics sets plus an `expire_metrics_secs` option
          to prevent unbounded memory growth.', Fixed a race condition that could
          cause negative values in `vector_buffer_byte_size` and `vector_buffer_events`
          gauges.]
      breaking_changes: [Some VRL functions have breaking changes in v0.49.0; review
          and test VRL transforms/conditions against the 0.49.0 upgrade guide before
          deploying.]
    chart_version: 0.45.0
    images: ['timberio/vector:0.49.0-distroless-libc']
  - version: 0.48.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.44.0
    images: ['timberio/vector:0.48.0-distroless-libc']
  - version: 0.47.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.43.0
    images: ['timberio/vector:0.47.0-distroless-libc']
  - version: 0.46.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.42.0
    images: ['timberio/vector:0.46.0-distroless-libc']
  - version: 0.45.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.41.0
    images: ['timberio/vector:0.45.0-distroless-libc']
  - version: 0.44.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.40.0
    images: ['timberio/vector:0.44.0-distroless-libc']
  - version: 0.43.0
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Vector v0.43.0 release notes not included in the provided text beyond
          a packaging/asset change; no concrete new runtime features can be extracted
          from what was pasted.]
      breaking_changes: ['The `vector-0.43.0-x86_64-apple-darwin.tar.gz` release asset
          was removed (per #22129). If you rely on that specific macOS Intel tarball
          for installs or CI artifacts, you must switch to another supported artifact
          (e.g., a different archive format/target, Homebrew, or container image).']
    chart_version: 0.38.0
    images: ['timberio/vector:0.43.0-distroless-libc']
  - version: 0.42.0
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.37.0
    images: ['timberio/vector:0.42.0-distroless-libc']
  - version: 0.41.0
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.36.0
    images: ['timberio/vector:0.41.0-distroless-libc']
  - version: 0.40.1
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.35.2
    images: ['timberio/vector:0.40.1-distroless-libc']
  - version: 0.40.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.35.0
    images: ['timberio/vector:0.40.0-distroless-libc']
  - version: 0.39.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.34.0
    images: ['timberio/vector:0.39.0-distroless-libc']
  - version: 0.38.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.33.0
    images: ['timberio/vector:0.38.0-distroless-libc']
  - version: 0.37.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.32.0
    images: ['timberio/vector:0.37.0-distroless-libc']
  - version: 0.36.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.31.0
    images: ['timberio/vector:0.36.0-distroless-libc']
  - version: 0.35.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.30.0
    images: ['timberio/vector:0.35.0-distroless-libc']
  - version: 0.34.2
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.29.1
    images: ['timberio/vector:0.34.2-distroless-libc']
  - version: 0.34.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.28.0
    images: ['timberio/vector:0.34.0-distroless-libc']
  - version: 0.33.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.26.0
    images: ['timberio/vector:0.33.0-distroless-libc']
  - version: 0.32.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.24.0
    images: ['timberio/vector:0.32.0-distroless-libc']
  - version: 0.31.0
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.23.0
    images: ['timberio/vector:0.31.0-distroless-libc']
  - version: 0.30.0
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.22.1
    images: ['timberio/vector:0.30.0-distroless-libc']
  - version: 0.29.0
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.21.0
    images: ['timberio/vector:0.29.0-distroless-libc']
  - version: 0.28.0
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.20.0
    images: ['timberio/vector:0.28.0-distroless-libc']
  - version: 0.27.1
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.19.2
    images: ['timberio/vector:0.27.1-distroless-libc']
  - version: 0.27.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.19.0
    images: ['timberio/vector:0.27.0-distroless-libc']
  - version: 0.26.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.18.0
    images: ['timberio/vector:0.26.0-distroless-libc']
  - version: 0.25.1
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.17.0
    images: ['timberio/vector:0.25.1-distroless-libc']
  - version: 0.24.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.16.0
    images: ['timberio/vector:0.24.0-distroless-libc']
  - version: 0.23.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.15.0
    images: ['timberio/vector:0.23.0-distroless-libc']
  - version: 0.22.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.13.0
    images: ['timberio/vector:0.22.0-distroless-libc']
  - version: 0.21.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.10.0
    images: ['timberio/vector:0.21.0-distroless-libc']
  - version: 0.20.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.7.0
    images: ['timberio/vector:0.20.0-distroless-libc']
  - version: 0.19.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.4.0
    images: ['timberio/vector:0.19.0-distroless-libc']
  - version: 0.18.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.2.1
    images: ['timberio/vector:0.18.0-distroless-libc']
  - version: 0.17.3
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.1.1
    images: ['timberio/vector:0.17.3-distroless-libc']
  - version: 0.16.1
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.1.0-alpha.4
    images: ['timberio/vector:0.16.1-distroless-libc']
  name: vector
- git_url: https://github.com/VictoriaMetrics/operator
  release_url: https://github.com/VictoriaMetrics/operator/releases/tag/v{vsn}
  helm_repository_url: https://victoriametrics.github.io/helm-charts
  readme_url: https://github.com/VictoriaMetrics/operator/blob/master/README.md
  icon: https://dashboard.snapcraft.io/site_media/appmedia/2020/11/output-onlinepngtools.png
  versions:
  - version: 0.66.1
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['v0.66.0 adds `spec.managedMetadata` support for VMUser (including
          Secrets), an `incident.io` receiver in VMAlertmanagerConfig, HTTPRoute support
          for VMAuthorization, an IPv6 mode toggle via `VM_ENABLETCP6`, and config-reloader
          now defaults its image tag to the operator version.', v0.66.0 updates default
          bundled VictoriaMetrics app versions to v1.131.0 and VictoriaTraces defaults
          to v0.5.0., 'v0.66.1 is primarily a patch/security release: Go builder updated
          to 1.25.5 plus bugfixes for RBAC cleanup and VMAnomaly config parsing/robustness.']
      breaking_changes: [v0.66.0 removes deprecated labels/annotations inheritance;
          you must move required metadata to `spec.managedMetadata` fields., 'v0.66.0
          removes deprecated status fields: `VMCluster.status.clusterStatus` and `VMSingle.status.singleStatus`
          (may break dashboards/scripts that read them).']
    chart_version: 0.57.1
    images: ['victoriametrics/operator:config-reloader-v0.66.1', 'victoriametrics/operator:v0.66.1']
  - version: 0.66.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Config reloader now defaults its image tag to the operator version,
          reducing drift between operator and reloader images.', VMAuth gains HTTPRoute
          (Gateway API) support and can override the default path for its embedded
          ingress., VMAlertmanagerConfig adds an incident.io receiver integration.,
        VMOperator can run all managed CR workloads in IPv6 mode via the VM_ENABLETCP6
          environment variable., VMUser introduces spec.managedMetadata for adding
          labels/annotations to the generated Secret and adds query_args for appending
          query parameters to backend URL generation., VMAgent in ingestOnly mode
          no longer sets promscrape.cluster.membersCount and promscrape.cluster.memberNum
          flags.]
      breaking_changes: [Removed labels/annotations inheritance (deprecated since
          v0.51.0). You must move any relied-upon labels/annotations into the spec.managedMetadata
          fields on the relevant CRs., Removed VMCluster status.clusterStatus and
          VMSingle status.singleStatus fields (deprecated since v0.51.0). Any tooling
          that reads these status fields must be updated to use the current status
          structure.]
    chart_version: 0.57.0
    images: ['victoriametrics/operator:config-reloader-v0.66.0', 'victoriametrics/operator:v0.66.0']
  - version: 0.65.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['VMAuth: adds HorizontalPodAutoscaler support via new `spec.hpa`
          field on the VMAuth CRD.', 'Converter: now supports Prometheus Operator
          `ServiceMonitor.spec.role` / ServiceDiscoveryRole during object conversion.']
      breaking_changes: ['Scrape CRDs now use `int` (instead of `uint64`) for `seriesLimit`
          and `sampleLimit` on VMPodScrape, VMNodeScrape, VMServiceScrape, VMScrapeConfig,
          VMProbe (and related). This is a schema/type change that may require updating
          manifests/clients or re-applying CRDs if validation fails.']
    chart_version: 0.56.4
    images: ['victoriametrics/operator:config-reloader-v0.65.0', 'victoriametrics/operator:v0.65.0']
  - version: 0.64.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "### Helm values / deployment changes to check\n- **Config reloader\
        \ default changed**: v0.64.0 switches the operator\u2019s default to its own\
        \ sidecar `victoriametrics/operator:config-reloader` by setting `VM_USECUSTOMCONFIGRELOADER=true`\
        \ by default.\n  - If your Helm values previously referenced **3rd-party reloaders**\
        \ (`jimmidyson/configmap-reload` or `quay.io/prometheus-operator/prometheus-config-reloader`),\
        \ expect a behavioral/image change after upgrade.\n  - To revert to the old\
        \ behavior, set operator env var: `VM_USECUSTOMCONFIGRELOADER=false`.\n- **PodDisruptionBudget\
        \ schema**: new `unhealthyPodEvictionPolicy` field supported under the operator-managed\
        \ PDB spec; no action needed unless you want to use it.\n- **Update strategy\
        \ knobs**: new `rollingUpdate` / `updateStrategy` fields for `VMAuth.spec`\
        \ and `*.spec.requestsLoadBalancer.spec` across VM/VL/VT clusters; again optional\
        \ unless you want to tune rollouts.\n"
      chart_updates: [Operator now prefers its bundled config-reloader implementation;
          this can change the sidecar image and how reloads are performed across managed
          resources., "Controller reconcile behavior changed to **preserve third\u2011\
          party labels** on objects (previously it tended to drop non-managed labels\
          \ unless in `managedMetadata.labels`).", Service reconciliation improvements
          around `Service.spec.loadBalancerClass` tracking to prevent errors/loops.]
      features: [Operator-bundled config reloader is now the default (can be disabled
          via `VM_USECUSTOMCONFIGRELOADER=false`)., New `podDisruptionBudget.unhealthyPodEvictionPolicy`
          support for finer control of eviction behavior., New rollout tuning fields
          (`updateStrategy`/`rollingUpdate`) added to `VMAuth` and requests load balancer
          specs for VM/VL/VT clusters., "Label preservation during reconcile: operator\
          \ keeps third\u2011party labels rather than pruning them to only managed\
          \ labels.", '`VLCluster.spec.vlselect.extraStorageNodes` and `VTCluster.spec.vtselect.extraStorageNodes`
          allow select components to read from additional storage nodes.', vmagent
          scraping can now use `scrapeClass` / `scrapeClassName` across multiple scrape
          CRDs., vmanomaly adds UI preset mode and supports `vlogs` reader type.]
      breaking_changes: ['**Default config reloader changed** from 3rd-party images
          to `victoriametrics/operator:config-reloader`. If you relied on the old
          reloader behavior/image (e.g., policies, allowlists, image pinning, compliance
          scanning), you must either accept the new image or set `VM_USECUSTOMCONFIGRELOADER=false`
          to keep prior behavior.']
    chart_version: 0.55.2
    images: ['victoriametrics/operator:v0.64.0']
  - version: 0.63.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["Bumped bundled default VictoriaMetrics app versions from **v1.123.0\
          \ \u2192 v1.125.0**.", "Bumped bundled default VictoriaLogs app versions\
          \ from **v1.28.0 \u2192 v1.33.0**.", 'Operator behavior fixes: VMAlert finalizer
          is now reliably released on delete; Service reconciliation now handles `loadBalancerClass`
          changes without hitting the immutable-field error.', VMUser routing logic
          was simplified for `src_paths` when targeting `VMCluster/vminsert` or `VMCluster/vmselect`.]
      features: ['VMUser `targetRef.crd.kind` now supports VictoriaLogs (VLSingle,
          VLAgent, VLCluster components) and VictoriaTraces (VTSingle, VTCluster components)
          resources, enabling VMUser to reference these CRDs directly.', 'New CRDs/resources
          are introduced: `VLSingle` and `VTCluster` for managing VictoriaLogs single-node
          and VictoriaTraces cluster deployments via the operator.', 'VMAgent stream
          aggregation gains `ignore_first_sample_interval` support, improving aggregation
          behavior right after restarts/rollouts.', 'VMAlert admission webhook adds
          validation to ensure notifier configuration options are mutually exclusive,
          catching misconfigurations earlier.', VMAlertmanager adds `enforcedNamespaceLabel`
          to customize the label key used in the top-route namespace matcher for VMAlertmanagerConfig.]
      breaking_changes: []
    chart_version: 0.54.1
    images: ['victoriametrics/operator:v0.63.0']
  - version: 0.62.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Default component versions were bumped: VictoriaMetrics apps to
          v1.123.0, VictoriaLogs apps to v1.28.0, and VMAnomaly to v1.25.2.', "PrometheusRule\u2192\
          VMRule converter now supports converting `spec.limit`, `spec.labels`, `spec.query_offset`,\
          \ and `spec.group[*].keep_firing_for`.", 'Operator reconcile latency was
          reduced, improving responsiveness during sync/redeploy cycles.', 'Operator
          now exposes its configuration as Prometheus metrics (`flag` and `config_parameter`
          with `name`, `is_set`, `value` labels).']
      breaking_changes: []
    chart_version: 0.52.1
    images: ['victoriametrics/operator:v0.62.0']
  - version: 0.61.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "## Helm values / install-time changes to plan for\n- **RBAC:**\
        \ add permission for `pods/eviction` to the operator\u2019s ClusterRole/Role\
        \ (Update Note 2). If you deploy the operator via Helm, ensure the chart version\
        \ you use includes this; otherwise patch your RBAC.\n- **CRDs:** upgrade/apply\
        \ updated CRDs before/with the operator upgrade (Update Note 3). New CustomResource\
        \ **`VLAgent`** is introduced, which requires CRD updates.\n- **VLogs migration:**\
        \ `VLogs` becomes **read-only** in v0.61.0 (Update Note 1). Plan migration\
        \ to **`VLSingle`** following the upstream docs: https://docs.victoriametrics.com/operator/resources/vlsingle/#migration-from-vlogs\n\
        - **Image tag behavior:** if you set `license` on a CustomResource, the operator\
        \ may now default image tags with an `-enterprise` suffix. Validate you\u2019\
        re explicitly pinning `spec.image.tag` where required.\n\n## Version bumps\
        \ (defaults managed by operator)\n- Default VictoriaMetrics apps: **v1.120.0\
        \ \u2192 v1.121.0**.\n- Default VictoriaLogs apps: **v1.24.0 \u2192 v1.25.1**."
      chart_updates: [Introduces new CRD/resource **VLAgent** (apply new CRDs)., Transitions
          **VLogs** CR to read-only; operator ignores create/update for it; migration
          path is to **VLSingle**., Operator now requires **pods/eviction** RBAC to
          respect PDB during StatefulSet updates., Fixes/changes rolling update behavior
          controls by adding `maxUnavailable` fields for VMCluster/VLCluster storage/select
          components., 'Adds `persistentVolumeClaimRetentionPolicy` support for StatefulSet-mode
          CRs (VMAnomaly, VMCluster, VMAlertmanager, VMAgent).']
      features: [VLogs is now treated as read-only by the operator; migration support
          guidance is provided to move to VLSingle., 'New CustomResource/CRD: VLAgent
          for VictoriaLogs agent functionality.', VMCluster and VLCluster now support
          `maxUnavailable` on key components to tune rolling update disruption., VLSingle
          adds `spec.syslogSpec` to configure syslog ingestion., VMAgent adds a global
          scrape config and an AWS section for remoteWrite; also adjusts default `remoteWrite.maxDiskUsagePerURL`
          when using stateful storage., StatefulSet-mode CRs gain `persistentVolumeClaimRetentionPolicy`
          for PVC retention behavior control., 'If a license is configured on a CR,
          the operator can default image tags with an `-enterprise` suffix.']
      breaking_changes: ['**VLogs CR becomes read-only** in v0.61.0; create/update
          requests are ignored, so existing GitOps flows managing VLogs will effectively
          stop applying changes until migrated to VLSingle.', '**CRD update required**
          due to new `VLAgent` resource; upgrading the operator without CRDs may break
          reconciliation or fail validation.', '**Additional RBAC needed** (`pods/eviction`);
          without it, operator actions involving evictions/PDB-respecting StatefulSet
          updates may fail.']
    chart_version: 0.51.2
    images: ['victoriametrics/operator:v0.61.0']
  - version: 0.60.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['(v0.59.0) New CRDs: `VLSingle` (replacement for deprecated `VLogs`)
          and `VLCluster` for VictoriaLogs deployments.', (v0.59.0) `VMagent.remoteWriteSpec`
          gains `proxyURL` support; leader-election config gains new flags for lease
          duration and renew deadline., '(v0.59.0) GitHub release manifests add `app.kubernetes.io/instance:
          default` and rename `app.kubernetes.io/name` to `victoria-metrics-operator`.',
        '(v0.60.0) New CRD: `VMAnomaly` plus vmanomaly feature: online models now
          support the `decay` field.', '(v0.60.0) Default bundled app versions bumped:
          VM apps to v1.120.0; VictoriaLogs apps to v1.24.0 (victorialogs).']
      breaking_changes: ['`VLogs` is deprecated as of v0.59.0 and will become read-only
          after v0.61.0; migrate to `VLSingle` before then.', 'Metric rename in v0.60.0:
          `operator_vmagent_config_fetch_secret_errors_total` -> `operator_fetch_errors_total`
          (and semantics broaden to all secret/configmap fetch failures), which can
          break dashboards/alerts.']
    chart_version: 0.52.0
    images: ['victoriametrics/operator:v0.60.0']
  - version: 0.59.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Default VM app versions bumped from v1.117.0 (operator v0.58.0)
          to v1.118.0 (operator v0.59.0)., 'Manifests distributed via GitHub release
          artifacts now include label `app.kubernetes.io/instance: default`, and `app.kubernetes.io/name`
          value changed to `victoria-metrics-operator`.', Operator adds new leader
          election flags `leader-elect-lease-duration` and `leader-elect-renew-deadline`
          (in addition to the v0.58.0 flags `leader-elect-namespace` and `leader-elect-id`).,
        Config-reloader now excludes hidden directories from watch to avoid errors
          with hidden symlinks., '`spec.configMaps` are now mounted as `volumeMounts`
          and watched by config-reloader for VMAgent and VMAlert.', 'New API fields/resources:
          `proxyURL` for VMagent `remoteWriteSpec`; new CRDs/resources `VLSingle`
          and `VLCluster`; `VLogs` deprecated with migration guidance to VLSingle.',
        Removed alerting rule `BadObjects` because metric `operator_controller_bad_objects_count`
          is no longer exposed., 'HPA validation fixed: `metrics` and `behaviour`
          are optional fields.', "VMCluster defaulting typo fixed to avoid panic when\
          \ VMInsert isn\u2019t configured."]
      features: ['New log storage CRDs: `VLSingle` (replacement for `VLogs`) and `VLCluster`
          for clustered logs deployments.', VMagent `remoteWriteSpec` gains `proxyURL`
          to route remote write traffic via an HTTP proxy., 'Additional leader election
          tuning flags (`leader-elect-lease-duration`, `leader-elect-renew-deadline`)
          for better HA behavior.', 'Config-reloader improvements: ignores hidden
          directories and can watch ConfigMaps mounted via `spec.configMaps` for VMAgent/VMAlert.']
      breaking_changes: ['`VLogs` is deprecated in v0.59.0 and will become read-only
          after v0.61.0; plan migration to `VLSingle` before that cutoff.', "If you\
          \ rely on the `BadObjects` alert or the `operator_controller_bad_objects_count`\
          \ metric, they\u2019re no longer available and any dashboards/alerts must\
          \ be updated.", 'GitHub release artifact manifests change standard labels
          (`app.kubernetes.io/name` and add `app.kubernetes.io/instance`); if you
          select resources by these labels in tooling/policies, update selectors accordingly.']
    chart_version: 0.49.0-rc1
    images: ['victoriametrics/operator:v0.59.0']
  - version: 0.58.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Leader election configuration: new operator flags `leader-elect-namespace`
          and `leader-elect-id` allow controlling where the leader election Lease
          lives and how it is identified.', 'Prometheus config reloader image was
          bumped from 0.68.0 to 0.82.1, which may change reloader behavior and should
          be validated in your environment.']
      breaking_changes: ['Operational risk: v0.58.0 defaults to deploying a vmagent
          version with a known bug (VictoriaMetrics#8941). Recommended to skip this
          release; if you must upgrade, override vmagent to `v1.117.1` via `VM_VMAGENTDEFAULT_VERSION=v1.117.1`.']
    chart_version: 0.47.0
    images: ['victoriametrics/operator:v0.58.0']
  - version: 0.57.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Introduced FIPS-compliant builds for the operator and config-reloader
          images (use images tagged with the -fips prefix when required)., Added spec.configReloadAuthKeySecret
          to VMAgent/VMAlert/VMAuth to supply a secret value used as the -configReload
          auth key., Converter now supports msteamsv2_configs conversion from Prometheus
          AlertmanagerConfig., VMAlertmanagerConfig webhook_configs gained a timeout
          field (requires Alertmanager v0.28.0+)., VMSingle Service now exposes an
          additional named port/alias for 8428., 'VMSingle and VMCluster retentionPeriod
          is now optional and defaults to 1 month; retentionPeriod is validated against
          ^[0-9]+(h|d|y)?$.', 'Operator default component versions updated: VictoriaMetrics
          apps to v1.116.0, VictoriaLogs to v1.21.0, Alertmanager to v0.28.1.', 'Build
          tooling updated: Go builder upgraded from Go 1.24.0 to Go 1.24.4.']
      breaking_changes: [retentionPeriod in VMSingle/VMCluster now has strict validation
          and defaults to 1 month when omitted; previously accepted values may now
          be rejected by the webhook/CRD validation.]
    chart_version: 0.46.0
    images: ['victoriametrics/operator:v0.57.0']
  - version: 0.56.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Default VM component images bumped: VictoriaMetrics -> v1.115.0;
          VLogs -> v1.18.0 (from prior v1.114.0/v1.17.0).', New support for env vars
          `VM_METRICS_VERSION` and `VM_LOGS_VERSION` to control images for all VM/VL-related
          CRs., 'Config-reloader behavior change: it no longer uses proxy-protocol
          for its internal web-server even when `reload-use-proxy-protocol` is set
          (plus a bugfix around that flag).', 'Added additional validations: vmalertmanager
          runtime config validation; StatefulSet volumeMount name validation; stricter
          vmalertmanagerconfig validation for unknown fields; shard count bounds fix.']
      features: ['Can set all VM and VLogs image versions via `VM_METRICS_VERSION`
          and `VM_LOGS_VERSION` environment variables, reducing per-CR version pinning.',
        vmauth can now serve internal routes on a separate port (`internalListenPort`)
          for improved security/isolation., vmauth can optionally enable HAProxy PROXY
          protocol support via `useProxyProtocol`., 'vmalertmanager now validates
          runtime configuration, catching invalid configs earlier.']
      breaking_changes: ['Config-reloader no longer uses proxy-protocol for its internal
          web server even if `reload-use-proxy-protocol` is enabled; if you relied
          on proxy-protocol on that internal endpoint, adjust your setup or remove
          the expectation.']
    chart_version: 0.45.0
    images: ['victoriametrics/operator:v0.56.0']
  - version: 0.55.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Default VictoriaMetrics app versions updated to VM v1.114.0 (from
          v1.113.0) and VictoriaLogs (VLogs) to v1.17.0 (from v1.15.0)., Scrape target
          OAuth2 configs now support `tls_config` and `proxy_url` fields., All VM
          apps now support `extraEnvsFrom` to source env vars from a Secret or ConfigMap.,
        'Services for vmstorage/vmselect/vmalertmanager now set `publishNotReadyAddresses:
          true` to improve discovery/cluster formation during rollouts.', Operator
          now logs a diff of field changes for key objects (Deployment/StatefulSet/Service/PDB/HPA/VMServiceScrape)
          during reconcile for easier debugging., 'New global env vars control config-reloader
          resources: `VM_CONFIG_RELOADER_LIMIT_CPU/MEMORY` (default `unlimited`) and
          `VM_CONFIG_RELOADER_REQUEST_CPU/MEMORY` (default empty); per-resource request
          env vars are deprecated.', VMAgent adds beta `daemonSetMode` for running
          as a DaemonSet., VMAgent reduces Kubernetes API load by removing selectors
          from VMPodScrape kubernetes_sd_configs; original behavior can be restored
          with `VMAgent.spec.enableKubernetesAPISelectors`., 'VMAgent remote write
          disk usage fields improved: `remoteWrite.MaxDiskUsage` can be integer with
          validation; `remoteWriteSettings.maxDiskUsagePerURL` supports byte-suffix
          strings with validation.', 'Alertmanager config CRD gains new/updated receivers:
          Discord adds `content`, `username`, `avatar_url`; new `jira_configs`, `rocketchat_configs`,
          `msteamsv2_configs` (Alertmanager v0.28.0+).']
      breaking_changes: ['VMPodScrape-generated kubernetes_sd_configs no longer include
          `selectors` by default, which can change scrape target selection; set `VMAgent.spec.enableKubernetesAPISelectors=true`
          to restore the prior behavior.', 'Per-resource config-reloader request env
          vars are now deprecated in favor of the new global `VM_CONFIG_RELOADER_REQUEST_CPU/MEMORY`
          controls (not an immediate break, but update values/automation accordingly).']
    chart_version: 0.44.0
    images: ['victoriametrics/operator:v0.55.0']
  - version: 0.54.1
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['vmalertmanagerconfig: added `thread_message_id` to `telegram_configs`
          (requires Alertmanager v0.28.0+).', VMUser `targetRefs` can now reference
          VLogs resources (VLogs support in VMUser).]
      breaking_changes: []
    chart_version: 0.43.1
    images: ['victoriametrics/operator:v0.54.1']
  - version: 0.53.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Adds `thread_message_id` to `telegram_configs` in `VMAlertmanagerConfig`
          (requires Alertmanager v0.28.0+)., Adds support for VLogs as a targetRef
          in `VMUser` (VLogs can now be referenced in VMUser targetRefs)., "Updates\
          \ the operator\u2019s default VictoriaMetrics application versions to v1.110.0\
          \ (from v1.109.1).", Rebuilds operator with Go 1.23.5 (security patch upgrade).]
      breaking_changes: []
    chart_version: 0.42.5
    images: ['victoriametrics/operator:v0.53.0']
  - version: 0.52.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Default component versions bumped: VictoriaMetrics apps to v1.109.1
          and VictoriaLogs to v1.6.1 (if you rely on chart/operator defaults, workloads
          may roll to these images).', 'VMScrapeConfig: GCE SD `zone` now supports
          multiple values (may broaden discovery if you previously had to workaround).',
        'Operator performance/scale improvements: faster config regeneration (decoupled
          from child status updates), reduced prometheus-converter API load, and higher
          default Kubernetes client limits (`client.qps=50`, `client.burst=100`).',
        New operator flag `controller.statusLastUpdateTimeTTL` (default 1h) to control
          staleness detection for `status.conditions`; increase for very large fleets
          (>>5k objects)., 'Richer failure diagnostics: `failed` status now includes
          reason and crashed container logs.', 'VMServiceScrape generation: now exposes
          only the well-known `http` port; job name for vmbackupmanager gets `-vmbackupmanager`
          suffix.']
      breaking_changes: ['Metadata inheritance removal: `labels`/`annotations` inheritance
          from CRD metadata is removed in v0.52.0. Move required labels/annotations
          to `spec.managedMetadata`; after upgrade, inherited labels will be dropped
          and annotation changes may be ignored (except preserved).', 'Potential scrape/job
          changes: VMServiceScrape port exposure and job naming changes may affect
          dashboards/alerts that match on port names or job names (especially vmbackupmanager).',
        'Behavioral change for large installs: new staleness detection may mark conditions
          stale if `controller.statusLastUpdateTimeTTL` too low for your object count;
          tune accordingly.']
    chart_version: 0.41.2
    images: ['victoriametrics/operator:v0.52.0']
  - version: 0.51.1
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Default VictoriaMetrics component versions bumped (v0.50.0
          -> VM 1.106.1; v0.51.1 -> VM apps 1.108.1, and VL default 1.3.2 as shown
          in release notes).', Operator now supports generating manifests without
          the admission webhook (useful for restricted clusters / simpler installs).,
        'Operator logging changed: structured logging fields moved into msg; logger
          field adjusted to show controller.CRD name; new loggerJSONFields option
          (introduced in v0.50.0) lets you customize JSON encoder field names.', 'Security
          context handling adjusted: when useStrictSecurity=false, securityContext
          is now properly applied; when useStrictSecurity=true, default privileged:false
          is set for containers.', 'Generated object metadata improvements: VMCluster-generated
          objects get label app.kubernetes.io/part-of=vmcluster; PodDisruptionBudget
          and HorizontalPodAutoscaler generated by operator now include annotations.',
        'Scrape config generation/selection bugfixes for VMAgent selectors and namespaceSelectors,
          especially around selectAllByDefault true/false and VMScrapeConfig inclusion
          rules.', 'License options support added: license.forceOffile and license.reloadInterval.',
        'VMServiceScrape endpointSlice discovery enhancements: missing container labels
          added to discovered metrics; new env var VM_VMSERVICESCRAPEDEFAULT_ENFORCEENDPOINTSLICES
          to default to endpointslices discovery role instead of endpoints.', 'API/CRDs
          updated: new managedMetadata field added to several specs to control labels/annotations
          on generated objects; status subresource reworked for multiple CRDs adding
          conditions; new observedGeneration status field; updateStatus field unified
          for some CRDs (replacing status/clusterStatus/singleStatus in VLogs/VMCluster/VMSingle).',
        VMAuth/VMUser config generation improvements and new fields (unauthorizedUserAccessSpec;
          dump_request_on_errors; fixed missing src_headers/src_query_args/discover_backend_ips
          when using targetRefs).]
      features: ['Option to enforce EndpointSlice-based discovery for VMServiceScrape
          via VM_VMSERVICESCRAPEDEFAULT_ENFORCEENDPOINTSLICES, plus added container
          labels in discovered metrics.', New operator logger configuration flag loggerJSONFields
          and updated structured logging output., managedMetadata field in multiple
          CRDs to explicitly manage labels/annotations applied to operator-generated
          resources., VMAuth gains unauthorizedUserAccessSpec (new structured way
          to define unauthorized access behavior) and VMUser adds dump_request_on_errors;
          VMUser targetRefs config generation fixes., Support for enterprise license
          options license.forceOffile and license.reloadInterval., Ability to deploy
          operator manifests without webhook., 'Security hardening defaults: privileged:false
          when useStrictSecurity=true, plus corrected securityContext application
          when not strict.']
      breaking_changes: ['CRD/API surface changes: new status/conditions/observedGeneration
          and updateStatus unification may require updating any automation that reads/writes
          status fields or relies on old status field names.', 'Deprecations introduced
          (not removed yet): labels/annotations inheritance from CRD metadata is deprecated
          in favor of spec.managedMetadata and will be removed in v0.52.0; VMAuth.spec.unauthorizedAccessConfig
          and several inlined VMAuth.spec fields are deprecated in favor of unauthorizedUserAccessSpec
          (supported until v1.0).']
    chart_version: 0.40.1
    images: ['victoriametrics/operator:v0.51.1']
  - version: 0.50.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Added missing `container` labels for metrics discovered via `VMServiceScrape`
          when using `endpointslices` discovery, improving metric labeling consistency.',
        Operator now defaults VictoriaMetrics component images/versions to v1.106.1
          (from v1.106.0)., New env var `VM_VMSERVICESCRAPEDEFAULT_ENFORCEENDPOINTSLICES`
          to force `endpointslices` (instead of `endpoints`) as the discovery role
          for `VMServiceScrape` when generating VMAgent scrape config., New operator
          logger option/flag `loggerJSONFields` to customize JSON encoder field names
          in logs., CRDs now expose `status.observedGeneration` to help clients understand
          whether status reflects the latest spec generation., 'CRD status fields
          were unified: `status` / `clusterStatus` / `singleStatus` for `VLogs`, `VMCluster`,
          `VMSingle` replaced by a generic `updateStatus` field.']
      breaking_changes: ['CRD status schema change: `VLogs`, `VMCluster`, and `VMSingle`
          status fields (`status`, `clusterStatus`, `singleStatus`) are replaced by
          `updateStatus`. Anything reading these old fields (dashboards, scripts,
          controllers) must be updated accordingly.', "`VMAuth` spec change (already\
          \ in v0.49.0 but relevant if you\u2019re upgrading across it): `spec.configSecret`\
          \ moved to `spec.externalConfig.secretRef.name`, and `spec.externalConfig.localPath`\
          \ was added. Existing manifests must be updated or they will fail validation/behavior\
          \ will change."]
    chart_version: 0.39.1
    images: ['victoriametrics/operator:v0.50.0']
  - version: 0.49.0
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Operator behavior/security fix: `useStrictSecurity: true` is
          now properly applied to initContainers for VMAuth, VMAgent, and VMAlertmanager
          (may cause previously-working permissive initContainers to become restricted).',
        'VMAuth CRD schema change: `spec.configSecret` moved to `spec.externalConfig.secretRef.name`;
          new `spec.externalConfig.localPath` added for providing custom configs via
          sidecar.', 'VMCluster CRD enhancement: add `spec.requestsLoadBalancer` configuration.',
        'VMCluster monitoring: fixes/adjustments when `backup` is enabled so monitoring
          is configured correctly.', 'VMAlertmanager: config reload now triggers when
          a ConfigMap referenced via `.spec.configMap` changes.', 'Operator reconciliation
          fixes: handles storage size changes correctly; fixes conversion from AlertmanagerConfig
          to VMAlertmanagerConfig.', Default VictoriaMetrics component versions bumped
          to 1.106.0 (release tag referenced 1.106.6).]
      features: ['InitContainers now honor strict security settings (`useStrictSecurity`)
          for VMAuth/VMAgent/VMAlertmanager, improving hardening consistency.', VMAuth
          can consume external config via `externalConfig` (secretRef + optional localPath)
          enabling sidecar-driven config delivery., VMCluster can be configured with
          `requestsLoadBalancer` to influence service/load balancer request behavior.,
        Improved monitoring wiring for VMCluster deployments that enable backups.,
        'VMAlertmanager now reloads when the referenced ConfigMap changes, reducing
          need for manual restarts.']
      breaking_changes: ["VMAuth spec change: `spec.configSecret` is replaced by `spec.externalConfig.secretRef.name`\
          \ (you must migrate manifests/Helm values or VMAuth config won\u2019t be\
          \ found).", 'Security behavior change: enabling `useStrictSecurity: true`
          now affects initContainers too; clusters relying on more permissive initContainer
          security settings may see pods fail to start until securityContext/permissions
          are adjusted.']
    chart_version: 0.37.0
    images: ['victoriametrics/operator:v0.49.0']
  - version: 0.48.0
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Operator now supports enabling/disabling use of VM config-reloader
          per resource (VMAgent/VMAlert/VMAuth/VMAlertmanager) and configuring reloader
          image tag/resources via CRD fields (`useVMConfigReloader`, `configReloaderImageTag`,
          `configReloaderResources`).', Webhook port is now configurable (ensure your
          Helm values/Service/NetworkPolicy match if you override defaults)., 'Operator
          enables controller-runtime cache for Secrets/ConfigMaps again; can be disabled
          via flag `-controller.disableCacheFor=seccret,configmap` (spelling per release
          note).', Operator now trims spaces from Secret/ConfigMap values by default;
          can be disabled via flag `disableSecretKeySpaceTrim`., Default VictoriaMetrics
          app versions bumped to v1.103.0 (expect downstream image tag changes if
          you rely on chart defaults)., PVCs for VMSingle/VLogs gain ownerReferences
          to improve Argo CD compatibility (may affect GitOps drift/garbage-collection
          behavior)., PDB enabled status is now respected (behavior change if you
          previously relied on operator creating PDBs even when disabled).]
      features: ['Per-resource control over using VM config-reloader and its image/resources
          for VMAgent, VMAlert, VMAuth, and VMAlertmanager.', VMAlertmanager can enforce
          top-level route matchers via `enforcedTopRouteMatchers` applied to all VMAlertmanagerConfig
          objects., 'New/extended API knobs: `host_aliases` (underscore form prioritized),
          per-app `useDefaultResources` and `disableSelfServiceScrape`, `clusterDomainName`
          for VMCluster/VMAlertmanager, and expanded securityContext propagation to
          containers.', 'Operational improvements: reduced reconcile latency and lower
          kube-apiserver load; re-enabled caching for Secrets/ConfigMaps to improve
          performance.']
      breaking_changes: [Default behavior now trims whitespace in Secret/ConfigMap
          values used for generated configs; this can change credentials/URLs if they
          relied on trailing/leading spaces., 'If you deploy behind strict NetworkPolicies/firewalls,
          the webhook port being configurable may require you to adjust any policies/services
          if you change it from the default.', 'PVC ownerReferences added for VMSingle/VLogs
          can change deletion/GC semantics in GitOps setups (e.g., Argo CD pruning)
          if you previously managed PVCs separately.']
    chart_version: 0.35.0
    images: ['victoriametrics/operator:v0.48.0']
  - version: 0.47.0
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Operator behavior changes for VMAlertmanagerConfig: forbids
          cross-resource or global receiver references; config must only reference
          local receivers.', 'VMAlertmanagerConfig API change: removed deprecated
          `spec.mute_time_intervals`; use `spec.time_intervals` instead.', 'VMAlertmanager
          default routing change: if root route receiver is empty, operator now sets
          `blackhole` receiver instead of choosing the first VMAlertmanagerConfig
          receiver.', 'New CRD/resource support: adds `VLogs` for managing VictoriaLogs
          via the operator.', 'Config reloader: new TLS flags for securing the reload
          endpoint (`tlsCaFile`, `tlsCertFile`, `tlsKeyFile`, `tlsServerName`, `tlsInsecureSkipVerify`).',
        'VMUser: adds `status.lastSyncError`; adds validation for `spec.targetRefs.crd.kind`;
          can skip generating VMAuth config for invalid VMUser refs (recommended to
          enable validation webhook).', 'Scrape objects: adds `status` and `lastSyncError`
          to `VMServiceScrape`, `VMPodScrape`, `VMNodeScrape`, `VMStaticScrape`, and
          `VMScrapeConfig` to track vmagent config generation.', VMAgent config builder
          refactor; fixes incorrect skipping logic for scrape objects with bad Secret/ConfigMap
          refs., 'Operator metrics endpoint: can secure `metrics-bind-address` with
          TLS/mTLS via flags (`tls.*`, `mtls.*`).', 'TLS asset naming fix: adds `configmap`
          prefix to ConfigMap-referenced TLS assets to avoid Secret/ConfigMap name
          clashes.', 'PodDisruptionBudget finalizer fix: properly releases PDB finalizer
          (previously could stick due to typo); plus general finalizer refactor.',
        'Auto-created VMServiceScrape for CRD objects from `extraArgs`: adds `tls_config`
          and `authKey` settings.', 'VMAlertmanagerConfig: improved validation and
          adds `status`/`lastSyncError` fields.', 'VMAlertmanager: adds `webConfig`
          for easier TLS configuration and correct probe/URL generation; adds `gossipConfig`
          for client/server TLS on gossip.', 'VMAgent/VMSingle: stream aggregation
          options synced with upstream (`dropInputLabels`, `ignoreFirstIntervals`,
          `ignoreOldSamples`) and supports configMap as aggregation rules source.',
        'Operator: adds `-client.qps` and `-client.burst` flags to tune Kubernetes
          API client behavior.']
      features: [Adds a new `VLogs` custom resource to manage VictoriaLogs through
          the operator., Adds TLS configuration options to the config-reloader so
          reload endpoints can be secured., Adds status and lastSyncError fields across
          scrape-related resources to help troubleshoot vmagent config generation.,
        Adds operator TLS/mTLS support for the metrics endpoint and improves TLS asset
          handling to avoid naming clashes., Enhances VMAlertmanager with webConfig
          and gossipConfig for simpler TLS and secure gossip communication., Adds
          additional stream aggregation options and supports configMap-based aggregation
          rules for vmagent/vmsingle., 'Adds Kubernetes client tuning flags (`client.qps`,
          `client.burst`) for large clusters or API rate limiting scenarios.']
      breaking_changes: [VMAlertmanagerConfig can no longer reference receivers across
          other VMAlertmanagerConfig objects or use global receiver references; receivers
          must be local to the object., '`VMAlertmanagerConfig.spec.mute_time_intervals`
          has been removed; migrate to `VMAlertmanagerConfig.spec.time_intervals`.',
        'If a VMAlertmanager root route has an empty receiver, the operator now sets
          it to `blackhole` (previously it picked the first VMAlertmanagerConfig receiver),
          which can change alert delivery until you set an explicit receiver.']
    chart_version: 0.34.0
    images: ['victoriametrics/operator:v0.47.0']
  - version: 0.46.4
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Operator base image switched from distroless to scratch (v0.46.4);
          this can affect debugging/exec tooling and image scanning expectations.,
        Operator manifests no longer set an explicit `runAsUser`; it must be defined
          via image defaults or pod security context/profile (v0.46.4)., Config-reloader
          container no longer specifies `command`; it is defined in the image now
          (v0.46.4)., 'OperatorHub bundle change: `VMAgent` deployment `ServiceAccount
          vmagent` is no longer shipped; operator will recreate a new SA with required
          permissions after removal (v0.46.4).', 'OperatorHub manifests: `webhook.enable`
          is properly wired for OperatorHub deployments (v0.46.4).', "kubebuilder\
          \ upgrade v2 \u2192 v4 (v0.46.0) and Kubernetes code-generator upgrade v0.27.11\
          \ \u2192 v0.30.0 (v0.46.0) \u2014 implies regenerated CRDs/webhooks and\
          \ potential RBAC/manager flag changes.", "cert-manager API upgrade `certificates.cert-manager.io/v1alpha2`\
          \ \u2192 `certificates.cert-manager.io/v1` (v0.46.0).", 'Selector behavior
          fix: `xxNamespaceSelector` and `xxSelector` were previously inverted and
          are corrected (v0.46.0).', 'VMNodeScrape scrape_config generation fix: de-dup
          `series_limit` / `sample_limit` fields (v0.46.0).']
      features: [VMUser service discovery can now be configured to use HTTPS via a
          TLS flag check in `AsURL` (v0.46.0)., 'VMRule supports syncing group attributes
          `eval_offset`, `eval_delay`, and `eval_alignment` from upstream vmalert
          group settings (v0.46.0).', VMAlertmanagerConfig reconcile loop now includes
          a `handleReconcileErr` callback to better handle errors and deregister objects
          (v0.46.0).]
      breaking_changes: ["Operator flag deprecations: `--metrics-addr` \u2192 `--metrics-bind-address`,\
          \ `--enable-leader-election` \u2192 `--leader-elect`, `--http.readyListenAddr`\
          \ \u2192 `--health-probe-bind-address` (v0.46.0).", 'Remote write multitenancy
          change: when using `remoteWriteSettings.useMultiTenantMode`, `remoteWrite.url`
          must include `/insert/multitenant/<suffix>` because upstream vmagent deprecated
          `-remoteWrite.multitenantURL` (v0.46.0).', "OperatorHub VMAgent deployment\
          \ change: remove the `vmagent` ServiceAccount since it\u2019s no longer\
          \ shipped; operator will create a new SA with needed permissions (v0.46.4).",
        Manifests no longer pin `runAsUser`; you must set user at image or security
          context/profile level if required by your policies (v0.46.4)., 'Container
          entrypoints changed: operator base image is now `scratch` and config-reloader
          no longer sets `command` explicitly; any assumptions about shell/tools/command
          overrides may break (v0.46.4).']
    chart_version: 0.33.6
    images: ['victoriametrics/operator:v0.46.4']
  - version: 0.46.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ["Operator CLI flags deprecated/renamed: `--metrics-addr`\u2192\
          `--metrics-bind-address`, `--enable-leader-election`\u2192`--leader-elect`,\
          \ `--http.readyListenAddr`\u2192`--health-probe-bind-address` (update your\
          \ deployment/Helm chart args if you set these).", 'vmagent multitenancy:
          when `remoteWriteSettings.useMultiTenantMode` is enabled, `remoteWrite.url`
          must include the `/insert/multitenant/<suffix>` path (upstream vmagent deprecated
          `-remoteWrite.multitenantURL` since v1.102.0).', 'VMUser service discovery:
          operator now checks `tls` flag in `AsURL`, enabling `https` config for VMUser
          SD.', "Kubebuilder upgraded v2\u2192v4 (operator scaffolding/tooling change;\
          \ may affect CRDs generation/behavior).", Operator images switched to distroless
          base (may impact debugging/exec into container; ensure tooling expectations).,
        "cert-manager API upgraded `certificates.cert-manager.io/v1alpha2`\u2192`certificates.cert-manager.io/v1`\
          \ (update CRDs/manifests if you use cert-manager resources).", "code-generator\
          \ upgraded v0.27.11\u2192v0.30.0.", "Fix selector logic: VM CRs\u2019 `xxNamespaceSelector`\
          \ and `xxSelector` were inverted previously; behavior changes after upgrade\
          \ (may alter which targets/rules are selected).", 'VMAlertmanagerConfig
          reconcile loop: adds missing `handleReconcileErr` to properly handle errors/deregister
          objects.', 'VMRule: group attributes `eval_offset`, `eval_delay`, `eval_alignment`
          synced with upstream vmalert.', 'VMNodeScrape: remove duplicated `series_limit`
          and `sample_limit` fields in generated `scrape_config`.']
      features: [VMUser service discovery can now be configured for HTTPS via `tls`
          handling in URL generation., 'VMRule supports additional group scheduling
          attributes (`eval_offset`, `eval_delay`, `eval_alignment`) aligned with
          upstream vmalert.', Improved reconciliation robustness for VMAlertmanagerConfig
          via proper error handling and object deregistration.]
      breaking_changes: ['Operator flag names have changed (old flags are deprecated);
          Helm values/args must be updated if you set metrics address, leader election,
          or readiness/health probe listen address flags.', 'vmagent multitenancy
          configuration changes: multitenant write URLs must include `/insert/multitenant/<suffix>`
          when `useMultiTenantMode` is enabled, otherwise remote write may fail or
          write to wrong endpoint.', 'Selector inversion fix changes behavior: resources
          selected by `xxSelector`/`xxNamespaceSelector` may differ after upgrade,
          potentially adding/removing scrape targets or rules.']
    chart_version: 0.33.1
    images: ['victoriametrics/operator:v0.46.0']
  - version: 0.45.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Operator CLI surface changed: only operator-related flags are
          exposed; transitive dependency flags removed (may affect Helm chart values
          that pass extra args).', 'Finalizer handling adjusted: uses Patch for finalizer
          set/unset (0.44.0) and removes finalizers for child objects with non-empty
          DeletionTimestamp (0.45.0) to avoid stuck deletions.', "PVC/storageClass\
          \ reconciliation logic changed: storageClass checks are skipped when PVC\
          \ size doesn\u2019t change (0.45.0).", 'VMAgent status enhancements: status.selector
          is set to better support VPA; new streamAggrConfig fields added (requires
          vmagent v1.100+ to use).', 'Pause support added: spec.pause field added
          across multiple CRDs to suspend reconciliation.', "VMAlertmanager secret-name\
          \ collision behavior changed: if cr.spec.configSecret name clashes with\
          \ operator-managed secret, the CR\u2019s secret content is ignored to prevent\
          \ overwriting.", 'VMAuth fixes: targetRef URL building when default http
          port changes; deployment fix when using custom reloader.', 'Converters improved:
          ScrapeConfig converter copies only spec and fixes ownerRef type; AlertmanagerConfig
          converter fix for opsgenie_configs; reduced API discovery scope to monitoring.coreos.com/*
          only.', 'VMScrapeConfig: authorization.type defaulting to Bearer works with
          empty type.']
      features: [New `spec.pause` field on multiple VictoriaMetrics CRDs to suspend
          operator reconciliation when needed., 'Additional `vmagent.streamAggrConfig`
          tuning fields (dedup interval, ignore old samples, keep metric names, no-align
          flush) available when running vmagent v1.100+.', '`vmagent` now populates
          `status.selector`, improving compatibility with Vertical Pod Autoscaler
          (VPA).', Improved and safer conversion tooling for Prometheus Operator resources
          and AlertmanagerConfig (including opsgenie receiver configs)., Reduced cluster
          API discovery footprint for prometheus-converter by querying only required
          API groups.]
      breaking_changes: ['Operator command-line flags exposed by the container changed:
          transitive dependency flags were removed. Helm charts that set extraArgs/flags
          may fail to start if they pass now-unknown flags.', 'VMAlertmanager behavior
          change on configSecret name collision: if you previously relied on using
          the same secret name as the operator-managed secret, your provided config
          may now be ignored.']
    chart_version: 0.32.3
    images: ['victoriametrics/operator:v0.45.0']
  - version: 0.44.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Adds `spec.pause` to multiple CRDs (VMAgent, VMAlert, VMAuth, VMCluster,
          VMAlertmanager, VMSingle) to suspend reconciliation.', 'Extends `VMAgent.spec.streamAggrConfig`
          with new options (`dedup_interval`, `ignore_old_samples`, `keep_metric_names`,
          `no_align_flush_to_interval`); requires vmagent v1.100+.', Sets `VMAgent.status.selector`
          to support correct integration with Vertical Pod Autoscaler (VPA)., 'Syncs
          VMAuth/VMUser config fields with upstream vmauth (e.g., `src_query_args`,
          `discover_backend_ips`).', Fixes prometheus-operator ScrapeConfig converter
          behavior and corrects VMScrapeConfig owner reference handling., Improves
          VMScrapeConfig SD `authorization` handling when `type` is empty (defaults
          to Bearer).]
      breaking_changes: [New `streamAggrConfig` fields are only usable with vmagent
          v1.100+; using older vmagent versions will prevent using these options (upgrade
          vmagent first or avoid setting them)., 'If you relied on older operator
          behavior around finalizer updates, behavior changes to Patch-based operations
          may affect custom automation that assumes full-object updates (generally
          a fix, but verify).']
    chart_version: 0.31.2
    images: ['victoriametrics/operator:v0.44.0']
  - version: 0.43.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Removes deprecated `VMClusterSpec.VMInsert.Name`, `VMClusterSpec.VMStorage.Name`,
          and `VMClusterSpec.VMSelect.Name` fields (deprecated since v0.21.0).', PodSecurityPolicy
          (PSP) support removed; operator no longer creates PSP objects., PodDisruptionBudget
          API switched from `policy/v1beta1` to stable `policy/v1`., Alertmanager
          versions < v0.22.0 are no longer supported; default bumped to v0.27.0.,
        'ServiceAccount reconcile behavior changed: operator only creates/updates
          ServiceAccounts when SA field is omitted in CRD; avoids ownership race conditions.',
        'Operator watches fewer owned resources (no longer watches Service/Secret/ConfigMap
          changes), reducing log/CPU/memory usage.', 'Config-reloader: exposes HTTP
          port 8435; new `configReloaderExtraArgs` field for several CRDs; adds new
          config-reloader container for VMAlertmanagerConfig and adds metrics.', 'Reconcile
          behavior improved: Kubernetes Events emitted on reconcile errors; retries
          on conflict errors.', '`serviceSpec.useAsDefault=true` allows adjusting
          operator-generated Services.', 'VMAgent statefulMode service behavior changed:
          now headless; `serviceName` customizable for custom Service.', 'Scrape CRDs
          updated: add `attach_metadata`; add `series_limit`; fix `disable_keep_alive`
          field name; deprecate `relabel_debug` and `metric_relabel_debug`.', Adds
          new CRD `VMScrapeConfig` for arbitrary SD-based scrape configs., 'Other
          CRD additions: VMUser `targetRefBasicAuth`, VMProbe `proxy_url`, VMAgent
          multiline regex relabeling; Sigv4Config tag fix.', Base images/dependencies
          updated for CVE fixes; VictoriaMetrics images bumped to v1.100.1.]
      features: [New `VMScrapeConfig` CRD enables defining scrape configs with any
          SD mechanism supported by VictoriaMetrics., Scrape CRDs gained `attach_metadata`
          (Prometheus-like) and `series_limit` to control label metadata attachment
          and cap per-target series., 'Config reloader improvements: dedicated reloader
          for VMAlertmanagerConfig, new error/health metrics, exposed HTTP port 8435,
          and per-CRD extra args via `configReloaderExtraArgs`.', VMUser can now configure
          basic auth for `target_url` via `targetRefBasicAuth`; VMProbe supports `proxy_url`.,
        VMAgent relabeling supports multi-line regex; stateful mode service can be
          customized.]
      breaking_changes: [Removed deprecated `Name` fields from VMCluster component
          specs; manifests using them must be updated/removed., PodSecurityPolicy
          objects are no longer managed/created by the operator; clusters relying
          on PSP must migrate to Pod Security Admission/other policy controls., PodDisruptionBudget
          `policy/v1beta1` is no longer supported; ensure your cluster and any custom
          manifests use `policy/v1`., Alertmanager versions below v0.22.0 are unsupported;
          upgrade Alertmanager (or use operator defaults) before/with this operator
          upgrade., VMAgent statefulMode Service changed to headless; any consumers
          assuming a ClusterIP Service may need updates (DNS/discovery/load-balancing
          behavior changes).]
    chart_version: 0.30.0
    images: ['victoriametrics/operator:v0.43.0']
  - version: 0.42.4
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.29.6
    images: ['victoriametrics/operator:v0.42.4']
  - version: 0.42.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Operator now supports watching multiple namespaces via comma-separated
          `WATCH_NAMESPACE` (enables multi-namespace mode without cluster-wide permissions);
          requires appropriate namespace-scoped RBAC (see `config/examples/operator_rbac_for_single_namespace.yaml`).,
        'Logging: operator adds more context to log messages to improve debugging
          and log quality.', 'Runtime dependencies updated (controller-runtime, controller-gen);
          may affect build/runtime behavior if you vendor/pin these elsewhere.', All
          pod-producing CRs now expose a `status.updateStatus` field to better track
          rollouts., All pod-producing CRs now get annotation `operator.victoriametrics/last-applied-spec`
          to track applied spec and enable proper resource cleanup later., VictoriaMetrics
          component image tags updated to v1.99.0 (from v1.97.1 in 0.41.1)., 'vmalertmanager:
          default router changes to `blackhole` when no config is provided (previously
          dummy webhook).', 'vmalertmanager: template path assignment fixed when templates
          are set both in config file and via `spec.templates`.', 'vmauth: new `spec.configSecret`
          to load external config from a Secret key `config.yaml`; changes can be
          watched with `extraArgs.configCheckInterval` or a config-reloader sidecar.',
        'vmagent: `streamAggrConfig.flush_on_shutdown` added.', 'vmagent: experimental
          `spec.ingestOnlyMode` added (runs without scrape config/config reloaders;
          currently also disables TLS and auth for remoteWrites).', "vmcluster/vmstorage:\
          \ PVC resize disabling annotation `operator.victoriametrics.com/pvc-allow-volume-expansion`\
          \ behavior changed\u2014now evaluated at StatefulSet storage spec level\
          \ (not per-PVC); enables adding a PVC autoscaler.", 'APIs: missing static
          config relabeling added with tests.']
      features: [Multi-namespace watch support via comma-separated `WATCH_NAMESPACE`
          without needing cluster-wide permissions (with namespace RBAC)., Improved
          rollout observability via `status.updateStatus` on all resources that create
          pods., Spec change tracking via `operator.victoriametrics/last-applied-spec`
          annotation on pod-producing resources., 'New vmagent options: `flush_on_shutdown`
          for stream aggregation, and experimental `ingestOnlyMode` to run without
          scrapes/config reloaders.', New vmauth `spec.configSecret` to source config
          from a Secret and optionally reload/check periodically., vmstorage/vmcluster
          gains better control of PVC expansion policy at storage spec level and supports
          PVC autoscaler workflows.]
      breaking_changes: ["vmalertmanager default routing behavior changes: if no configuration\
          \ is provided, it now uses `blackhole` instead of a dummy webhook\u2014\
          could change how unconfigured alerts are handled (dropped vs previously\
          \ sent somewhere).", PVC expansion disabling check moved from per-PVC to
          StatefulSet storage spec level; clusters relying on the old per-PVC annotation
          behavior may see different resize outcomes after upgrade., "`vmagent.spec.ingestOnlyMode`\
          \ is experimental and currently disables TLS/auth for remoteWrite endpoints\
          \ when enabled\u2014treat as a behavioral change if you plan to use it."]
    chart_version: 0.29.0
    images: ['victoriametrics/operator:v0.42.0']
  - version: 0.41.1
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Operator-managed VictoriaMetrics component image tags are updated
          to VictoriaMetrics v1.97.1 (via operator v0.41.1), which may pull in changes
          from the VictoriaMetrics application release.', '(From the starting version
          v0.40.0) VMUser gained new fields: drop_src_path_prefix_parts, tls_insecure_skip_verify,
          metric_labels, and load_balancing_policy (note: metric_labels requires VMAuth
          >= v1.97.0).', (From the starting version v0.40.0) Added revisionHistoryLimitCount
          and MinReadySeconds parameters for VictoriaMetrics workload CRDs., '(From
          the starting version v0.40.0) VMAlertmanagerConfig gained additional receiver
          type support: discord_configs, msteams_configs, sns_configs, webex_configs.',
        (From the starting version v0.40.0) Added alerting rules for the operator
          itself.]
      breaking_changes: []
    chart_version: 0.28.0
    images: ['victoriametrics/operator:v0.41.1']
  - version: 0.40.0
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [Fix VMAlertmanagerConfig discovery to match documented behavior.,
        Add optional built-in alerting rules for vmoperator itself (operator self-monitoring).,
        'Add new CRD fields for workloads: `revisionHistoryLimitCount` and `minReadySeconds`
          across Victoriametrics workload CRDs.', 'Extend VMAlertmanagerConfig CRD
          to support additional receiver types: `discord_configs`, `msteams_configs`,
          `sns_configs`, `webex_configs`.', 'Extend VMUser CRD with new fields: `drop_src_path_prefix_parts`,
          `tls_insecure_skip_verify`, `metric_labels`, `load_balancing_policy`.']
      features: ['Operator can now ship alerting rules for itself, improving observability
          of operator health and reconciliation issues.', 'VMUser adds new auth/routing
          knobs (drop path prefix parts, TLS skip verify, metric label injection,
          load balancing policy); note `metric_labels` requires VMAuth >= v1.97.0.',
        'VMAlertmanagerConfig supports more receiver integrations (Discord, MS Teams,
          AWS SNS, Webex) and has corrected discovery behavior.', Workload CRDs gain
          `minReadySeconds` and `revisionHistoryLimitCount` to control rollout readiness
          and ReplicaSet history retention.]
      breaking_changes: ['`VMAlertmanagerConfig` discovery behavior is fixed to match
          docs; if you relied on the previous (incorrect) discovery semantics, existing
          AlertmanagerConfig objects selected/discovered by vmalertmanager may change
          and should be revalidated after upgrade.']
    chart_version: 0.27.10
    images: ['victoriametrics/operator:v0.40.0']
  - version: 0.39.4
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.27.9
    images: ['victoriametrics/operator:v0.39.3']
  - version: 0.39.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [vmagent/vmauth default config-reloader image was upgraded (impacts
          the sidecar/init behavior and image pull)., 'VMUser gained new vmauth options:
          `retry_status_codes`, `max_concurrent_requests`, and `response_headers`
          (requires vmauth >= v1.94.0).', New per-component `useStrictSecurity` flag
          allows gradual migration from insecure to strict security without breaking
          all components at once., Operator can now accept/provide an enterprise license
          key for VictoriaMetrics enterprise components.]
      breaking_changes: []
    chart_version: 0.27.3
    images: ['victoriametrics/operator:v0.39.0']
  - version: 0.38.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Adds the ability for vmoperator to print the default values for all
          operator environment variables (useful for debugging/config discovery).]
      breaking_changes: []
    chart_version: 0.27.1
    images: ['victoriametrics/operator:v0.38.0']
  - version: 0.37.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['VMAlert/VMRule/VMagent/VMSingle: streaming aggregation enhancements
          introduced in v0.36.0 (dropInput, list support for match, staleness_interval).',
        'VMRule: new rule fields update_entries_limit and keep_firing_for supported
          (v0.36.0).', 'Operator: new VM_ENABLESTRICTSECURITY env var; strict security
          context enabled by default (v0.36.0).', 'VMagent: multiple `if` conditions
          for relabeling supported (v0.37.0).']
      breaking_changes: ['VMAlert CRD: field `OAuth2` renamed to `oauth2` in several
          VMAlert spec sections; manifests must be updated and reapplied after upgrade
          (v0.36.0).', 'VMAlert CRD: field `bearerTokenFilePath` renamed to `bearerTokenFile`
          in several VMAlert spec sections; manifests must be updated and reapplied
          after upgrade (v0.36.0).']
    chart_version: 0.26.0
    images: ['victoriametrics/operator:v0.37.0']
  - version: 0.36.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: "- No Helm chart changelog was provided in the notes you pasted.\
        \ Only application/operator release notes are available here, so Helm values\
        \ changes can\u2019t be confirmed from this input.\n- If your Helm chart exposes\
        \ operator env vars, note new/changed operator parameters in v0.36.0:\n  -\
        \ `VM_ENABLESTRICTSECURITY`: **new**, and **strict security context is enabled\
        \ by default**.\n  - `VM_PSPAUTOCREATEENABLED`: default changed from `true`\
        \ -> `false` (PSP is deprecated since k8s v1.25).\n"
      chart_updates: []
      features: ['Streaming aggregation support updates for vmagent/vmsingle: `streamAggr.dropInput`,
          list support for `match`, and `staleness_interval`.', VMRule supports `update_entries_limit`
          and `keep_firing_for` fields (vmalert rule features)., 'New example manifests:
          vmagent stateful mode with sharding; vmcluster with additional/custom storage
          claims.', Operator can run with strict security context by default via new
          `VM_ENABLESTRICTSECURITY` parameter.]
      breaking_changes: ['VMAlert CRD field rename: `OAuth2` -> `oauth2` across datasource/notifier/notifiers/remoteRead/remoteWrite;
          any existing configs must be reapplied with the new field name after upgrade.',
        'VMAlert CRD field rename: `bearerTokenFilePath` -> `bearerTokenFile` across
          datasource/notifier/notifiers/remoteRead/remoteWrite; any existing configs
          must be reapplied with the new field name after upgrade.']
    chart_version: 0.25.0
    images: ['victoriametrics/operator:v0.36.0']
  - version: 0.35.0
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['vmagent: adds validation when generating static scrape config (may
          reject previously accepted invalid configs).', 'vmalertmanagerconfig: adds
          validation for Slack receiver URL.', 'vmauth/vmagent: implement config initiation
          flow for a custom config reloader (changes how custom reloader is bootstrapped).',
        Adds more generators (additional supported config/resource generation options).,
        'vmsingle: adds a status field to the CR status (more observable state).']
      breaking_changes: []
    chart_version: 0.24.0
    images: ['victoriametrics/operator:v0.35.0']
  - version: 0.34.0
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [VMAlertmanager now defaults/bundles Alertmanager v0.25.0., VMCluster
          adds `clusterNativePort` on VMSelect/VMInsert to support multi-level cluster
          topologies., VMRule gains `notifierHeader` to attach custom headers for
          notifications., VMPodScrape adds `FilterRunning` option (similar to Prometheus)
          to scrape only running pods., VMAuth incorporates latest upstream VMAuth
          feature set (behavior depends on VMAuth version used).]
      breaking_changes: ['If you run the operator in single-namespace mode via `WATCH_NAMESPACE`,
          behavior changes: it will no longer access cluster-wide resources and will
          only create single-namespace config for VMAgent. This may require revisiting
          RBAC/ClusterRole assumptions and any setups relying on cluster-wide discovery.']
    chart_version: 0.23.0
    images: ['victoriametrics/operator:v0.34.0']
  - version: 0.33.0
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['VMAlertmanager: new option to disable route `continue` enforcement
          (lets you keep Alertmanager-style routing semantics if you rely on `continue:
          true`).', 'VMAlertmanagerConfig: can now set `require_tls: false` for email
          receivers and adds sanity checks to validate configs earlier.', 'VMAlertmanagerConfig:
          adds `sound` field support for Pushover notifications.', 'VMAgent/VMAuth:
          can download initial config via an initContainer, improving first-start
          reliability when config is generated/served externally.', 'Build: Alpine
          base image bumped to v3.17.3 (security/patch updates).']
      breaking_changes: []
    chart_version: 0.21.0
    images: ['victoriametrics/operator:v0.33.0']
  - version: 0.32.1
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [No new features in v0.32.1; it is a patch release focused on fixes.,
        "v0.32.1 makes vmsingle\u2019s stream aggregation config conditional, preventing\
          \ it from being injected when not configured/needed."]
      breaking_changes: []
    chart_version: 0.20.1
    images: ['victoriametrics/operator:v0.32.1']
  - version: 0.32.0
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['**vmauth**: `config-reloader` is now auto-configured with `proxy-protocol`
          client support and `reloadAuthKey` handling, reducing manual config for
          auth reload behavior.', '**vmagent**: new global `scrapeTimeout` setting
          can be set via the VMAgent CR to control scrape timeouts consistently.',
        '**vmagent remoteWrite**: adds support for streaming aggregation configuration
          for remoteWrite targets (see VictoriaMetrics stream aggregation docs).',
        '**vmsingle**: adds global streaming aggregation configuration for the database,
          enabling server-side aggregation pipelines.']
      breaking_changes: []
    chart_version: 0.20.0
    images: ['victoriametrics/operator:v0.32.0']
  - version: 0.31.0
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['vmalertmanager: adds support for `vmalertmanager.spec.templates`,
          including auto-reload directories for templates and configmaps.', 'vmagent:
          adds support for the `%SHARD_NUM%` placeholder when generating/templating
          vmagent StatefulSet/Deployment (useful for sharded setups).']
      breaking_changes: ['HPA API handling changed to avoid deprecated autoscaling
          v2beta on Kubernetes 1.26+; if you have custom manifests/overrides expecting
          v2beta, they may need adjustment.']
    chart_version: 0.19.0
    images: ['victoriametrics/operator:v0.31.0']
  - version: 0.30.3
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['v0.30.0 added the Scaling subresource for `VMAgent`, enabling use
          of the Kubernetes scale API (e.g., `kubectl scale`) against the CRD.', 'v0.30.0
          introduced optional namespace label matching for inhibit rules, improving
          alert inhibition scoping.', 'v0.30.0 started publishing CRDs YAML as a release
          asset, making CRD management outside Helm easier.', v0.30.0 added child
          labels filtering to control which labels propagate to generated child resources.,
        v0.30.0 added OAuth2 and bearer auth support for vmalert remote DB connections.]
      breaking_changes: ['Kubernetes 1.26+ deprecates `autoscaling/v2beta2`; v0.30.3
          adds an API-availability check, which may change HPA behavior if your cluster
          only supports certain autoscaling API versions.', 'PVC resize logic in v0.30.3
          now uses corrected selector labels; if you relied on the previous (incorrect)
          labels for automation/monitoring, behavior/metrics selection may differ.']
    chart_version: 0.17.2
    images: ['victoriametrics/operator:v0.30.3']
  - version: 0.30.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Adds a Scaling subresource for `VMAgent`, enabling kubectl/HPA-style
          scaling interactions without editing the full spec.', 'Adds an optional
          namespace label matcher to inhibit rules (Alertmanager config), giving finer
          control over inhibition behavior across namespaces.', 'Publishes CRDs YAML
          as a release asset, simplifying CRD installation/updates outside of Helm
          or Git checkout.', Introduces child labels filtering to better control which
          labels propagate from parent/owner resources to generated objects., '`vmalert`
          controller adds OAuth2 and bearer-token auth support for remote read/query
          databases, improving secured integrations.']
      breaking_changes: []
    chart_version: 0.17.0
    images: ['victoriametrics/operator:v0.30.0']
  - version: 0.29.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Operator fix: VMCluster now reconciles VMStorage even when
          the PodDisruptionBudget object is missing.', Fix for Kubernetes 1.25 crash.,
        'vmagent/vmalert: reduce/handle throttling issues more safely.', 'vmalertmanagerconfig:
          fixes for parsing nested routes plus correct OwnerReference handling.',
        'vmagent: allow maxDiskUsage values > 1GB.', 'vmagent: correctly merge ports
          when using an additional Service.', 'vmprobe: correctly set labels for ingress
          targets.', 'PodDisruptionBudget: add configurable selectors (new capability
          in how PDBs are generated/selected).']
      features: ['PodDisruptionBudget support gains configurable selectors, allowing
          more control over which pods a PDB targets.']
      breaking_changes: []
    chart_version: 0.15.0
    images: ['victoriametrics/operator:v0.29.0']
  - version: 0.28.3
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [TLS endpoint support for the vmauth config reloader (improves secure
          reload hookups)., 'New/expanded CRD capabilities: `claimTemplates` supported
          for `VMCluster`, `VMAlertmanager`, and `VMAgent`; `readinessGates` supported
          on CRD objects; health checks now respect TLS settings on CRDs.', Option
          to add ArgoCD ignore annotations when converting Prometheus CRDs via `VM_PROMETHEUSCONVERTERADDARGOCDIGNOREANNOTATIONS=true`
          to reduce drift/noise in ArgoCD-managed clusters.]
      breaking_changes: []
    chart_version: 0.14.0
    images: ['victoriametrics/operator:v0.28.3']
  - version: 0.27.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Adds support for `claimTemplates` on `VMCluster`, `VMAlertmanager`,
          and `VMAgent` to simplify PVC templating for stateful workloads.', 'Adds
          `readinessGates` support across CRD objects, enabling integration with custom
          readiness conditions.', 'HealthChecks now respect TLS settings defined on
          CRD objects, improving correctness for secured endpoints.', Adds an env
          var `VM_PROMETHEUSCONVERTERADDARGOCDIGNOREANNOTATIONS=true` to ignore Argo
          CD objects converted from Prometheus CRDs., Adds TLS endpoint support for
          the `vmauth` config reloader for secured reload operations.]
      breaking_changes: []
    chart_version: 0.12.0
    images: ['victoriametrics/operator:v0.27.0']
  - version: 0.26.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['VMUser: adds `name` field (v0.25.0) and `tokenRef` (v0.26.0) for
          improved user identification and secret-based token management.', 'VMAgent:
          adds `StatefulMode` to run as a StatefulSet, plus new per-remote-storage
          `headers` configuration and multitenant mode support.', 'VMRule: adds a
          validation webhook to catch rule errors at admission time.', 'Scrape/target
          config: adds `authorization` support and `headers` fields for passing custom
          headers to targets.', 'vmauth/ingress: adds `host` parameter for ingress
          configuration.', 'VMCluster: reworks/expands cluster volume expansion behavior
          and improves expansion handling overall.', 'Operator/ops: adds new operator
          metrics (log messages, controller object counts, throttling, app version/uptime/start
          timestamp) and introduces/adjusts reconciliation rate limiting.', 'Global:
          adds a setting to override the container registry globally for images.']
      breaking_changes: ["VMRule API change (v0.25.0): `expr` must be a string; integer\
          \ expressions are no longer supported\u2014existing rules with numeric `expr`\
          \ will fail validation/apply.", v0.26.0 is flagged by upstream as containing
          breaking changes that were fixed in v0.26.2; upgrading directly to 0.26.0
          is not recommended (use 0.26.2+ instead).]
    chart_version: 0.11.1
    images: ['victoriametrics/operator:v0.26.0']
  - version: 0.25.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['VMUser CRD: added a `name` field (useful for explicitly naming VMUser
          objects).', 'VMAgent CRD: added `statefulMode` to run VMAgent as a StatefulSet
          instead of a Deployment.', 'VMRule: added a validation webhook to catch
          rule errors at admission time (fails fast on invalid rules).', 'Operator
          metrics: added additional metrics such as `operator_log_messages_total`,
          `operator_controller_objects_count`, `operator_reconcile_throttled_events_total`,
          and app info metrics (`vm_app_version`, `vm_app_uptime_seconds`, `vm_app_start_timestamp`).',
        'Reconciliation: added rate limiting for VMAgent and VMAlert reconciliations
          to reduce churn under frequent updates.']
      breaking_changes: ['VMRule API change: `expr` must be a string; integer values
          are no longer accepted. Audit and update any VMRule manifests or generated
          rules that used numeric expressions.']
    chart_version: 0.10.0
    images: ['victoriametrics/operator:v0.25.0']
  - version: 0.24.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Operator can filter converted Prometheus CRD objects, helping control
          which migrated resources are reconciled.', 'Default CLI args/params can
          be overridden via configuration, enabling per-install tuning without patching
          manifests.', "Operator-generated VMServiceScrape objects can now be customized\
          \ for the operator\u2019s managed resources.", CRD-managed workloads can
          set `terminationGracePeriodSeconds` and `dnsConfig` for finer pod-level
          behavior control., VMAlertmanagerConfig adds support for `telegram_configs`
          notification receiver blocks., Retention period can be set to less than
          one month (previously constrained).]
      breaking_changes: ['From v0.23.0, the `job` name label for scrape/probe resources
          changed to include a CRD-type prefix (probe, podScrape, serviceScrape, nodeScrape,
          staticScrape). This can affect alerting/recording rules and dashboards that
          match on the old job label value.']
    chart_version: 0.9.0
    images: ['victoriametrics/operator:v0.24.0']
  - version: 0.23.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Operator now checks the Kubernetes API server version and automatically
          uses the appropriate API versions for deprecated objects (notably PodSecurityPolicy
          and PodDisruptionBudget)., Fixes include correcting bearerToken handling
          for VMAgent remoteWriteSpec and adjusting job name labeling to avoid collisions.]
      breaking_changes: ['Job name label format changed: a CRD-type prefix is added
          (probe, podScrape, serviceScrape, nodeScrape, staticScrape), which can affect
          dashboards/alerts/relabeling that depend on the old job label values.']
    chart_version: 0.7.1
    images: ['victoriametrics/operator:v0.23.0']
  - version: 0.22.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Operator API objects were moved into a separate Go package, allowing
          consumers to use the API without importing the whole operator codebase.',
        "Support was added to configure `rollingUpdateStrategy` for StatefulSets;\
          \ when set to `rollingUpdate`, Kubernetes\u2019 native controller-manager\
          \ handles rolling updates, enabling `kubectl rollout restart` for both Deployments\
          \ and StatefulSets.", VMAlertmanager gained a global option `disableNamespaceMatcher`
          to disable the namespace label matcher behavior.]
      breaking_changes: []
    chart_version: 0.6.0
    images: ['victoriametrics/operator:v0.22.0']
  - version: 0.21.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Alertmanager ServiceScrape auto-generation was added, reducing manual
          scrape configuration when alertmanager is managed by the operator.', 'VMUser
          now automatically adds routing for VMCluster components (vminsert and vmselect),
          simplifying multi-tenant access setup.', 'VMAgent can now have its default
          disk space usage adjusted, making it easier to tune persistent storage behavior.',
        'VMUser target references can now include custom HTTP headers, enabling additional
          auth/metadata to be passed to upstreams.']
      breaking_changes: ["Selector default behavior changed again: v0.21.0 rolls back\
          \ the v0.20.x \u201Cselect all when selector is nil\u201D behavior unless\
          \ you explicitly set `spec.selectAllByDefault: true`. This can silently\
          \ reduce what gets scraped/selected after upgrade if you relied on nil selectors\
          \ selecting everything.", 'VMAuth Ingress API moved to `networking.k8s.io/v1`,
          which effectively raises the minimum Kubernetes version for VMAuth Ingress
          usage to 1.19. Clusters older than 1.19 (or manifests still using v1beta1)
          will fail to apply.']
    chart_version: 0.5.1
    images: ['victoriametrics/operator:v0.21.0']
  - version: 0.20.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Custom headers can be set on the VMUser targetRef (useful when integrating
          with auth/proxies that require extra headers).]
      breaking_changes: ["CR selector defaults changed (e.g., vmagent.spec.serviceScrapeSelector\
          \ and similar): if a selector field is omitted, it now selects *all* matching\
          \ objects rather than selecting none. This can drastically increase scrape\
          \ targets if you relied on the old implicit \u2018select nothing\u2019 behavior.",
        Operator no longer appends the cluster domain name for in-cluster communication;
          the cluster domain value is now empty by default. This fixes clusters with
          non-standard DNS domains but may break setups that depended on the previous
          explicit domain concatenation.]
    chart_version: 0.4.0
    images: ['victoriametrics/operator:v0.20.0']
  - version: 0.19.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Single-namespace mode for the operator, allowing it to watch and
          reconcile resources only in a specified namespace instead of cluster-wide.',
        'VMAlert Notifier service discovery support, enabling discovery of notifier
          endpoints for vmalert integrations.', VMRule updates to support vmalert-specific
          features (expanded rule capabilities when managed by vmalert)., 'Reduced
          operator memory usage by disabling client-side caching for Pods, Deployments,
          and StatefulSets.', 'Improved end-to-end tests (internal quality improvement,
          no expected user-facing config change).']
      breaking_changes: []
    chart_version: 0.3.0
    images: ['victoriametrics/operator:v0.19.0']
  - version: 0.18.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: [CRDs are now generated for `apiextensions.k8s.io/v1`; `apiextensions.k8s.io/v1beta1`
          is deprecated/legacy. Ensure your cluster is on a Kubernetes version that
          supports v1 CRDs and that your Helm upgrade applies the updated CRDs (often
          via `crds/` or a separate `kubectl apply -f` step)., 'Major API updates
          to CRDs: `VMServiceScrape`, `VMPodScrape`, `VMProbe`, `VMStaticScrape`,
          `VMNodeScrape` gained additional fields (e.g., `sampleLimit` and other missing
          scrape config params) and new `vm_scrape_params` options; manifests may
          need to be adjusted to use the new schema/fields.', '`spec.selector` is
          now optional for `VMPodScrape` and `VMServiceScrape`; review existing resources
          if you were relying on selector-required validation or admission behavior.',
        "New CRD `VMAlertmanagerConfig` introduced; it only supports Alertmanager\
          \ v0.22+\u2014plan component version alignment if you intend to use it."]
      features: [OAuth2 configuration added for `VMagent` remoteWrite and scrape endpoints;
          you can now authenticate outbound remote writes and protected scrape targets
          via OAuth2., '`TLSConfig` support added for `VMProbe`, enabling TLS settings
          for blackbox-style probing targets.', 'New `vm_scrape_params` options and
          expanded scrape config surface (e.g., `sampleLimit`, proxy authentication)
          across multiple scrape-related CRDs, bringing them closer to vmagent configuration
          capabilities.', New `VMAlertmanagerConfig` CRD for managing Alertmanager
          config via Kubernetes resources (requires Alertmanager >= v0.22).]
      breaking_changes: ["CRD API versioning shifts to `apiextensions.k8s.io/v1` as\
          \ the primary format; clusters relying on `v1beta1` CRDs must treat them\
          \ as legacy and may fail upgrades on newer Kubernetes if CRDs aren\u2019\
          t migrated/applied correctly.", "The \u201Cmajor API update\u201D to several\
          \ CRDs can break upgrades if existing custom resources no longer validate\
          \ against the updated OpenAPI schema; validate your existing `VMServiceScrape`/`VMPodScrape`/`VMProbe`/`VMStaticScrape`/`VMNodeScrape`\
          \ manifests against the new CRDs before upgrading."]
    chart_version: 0.2.0
    images: ['victoriametrics/operator:v0.18.0']
  - version: 0.17.1
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Adds an experimental custom config reloader to mitigate long configuration
          sync; enable it via env var `VM_USECUSTOMCONFIGRELOADER=true`., Reduces
          Kubernetes API server load when handling `VMPodScrape` resources., 'Exposes
          a `/debug/pprof` endpoint on `0.0.0.0:8435` for profiling/troubleshooting.',
        Updates default versions for VictoriaMetrics apps to v1.63.0., Documentation
          updates.]
      breaking_changes: ['`VMAgent` `RemoteWriteSpec` was changed: some options were
          moved into `RemoteWriteSettings`, so existing CRs may need field/path updates
          before/after upgrade.']
    chart_version: 0.1.18
    images: ['victoriametrics/operator:v0.17.1']
  - version: 0.16.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: [Experimental custom config-reloader to mitigate long config sync;
          enable with env var `VM_USECUSTOMCONFIGRELOADER=true`., Reduced Kubernetes
          API server load when handling `VMPodScrape` resources., 'Added `/debug/pprof`
          handler served on `0.0.0.0:8435` for profiling/debugging.']
      breaking_changes: ['`VMAgent` `RemoteWriteSpec` changed: some options moved
          into `RemoteWriteSettings`; existing manifests may need updates to match
          the new schema.']
    chart_version: 0.1.17
    images: ['victoriametrics/operator:v0.16.0']
  - version: 0.15.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['All CRD-backed resources now support `nodeSelector`, allowing you
          to pin operator-managed workloads to specific nodes.', '`vminsert` and `vmselect`
          can now be autoscaled via HorizontalPodAutoscaler (HPA).', 'Two new CRDs
          were added: `VMAuth` and `VMUser`, enabling operator-managed auth/user resources.',
        'HostPath volumes are now supported, and you can override the `storageDataPath`
          setting when using them.']
      breaking_changes: []
    chart_version: 0.1.14
    images: ['victoriametrics/operator:v0.15.0']
  - version: 0.14.2
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.1.13
    images: ['victoriametrics/operator:v0.14.2']
  - version: 0.13.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['Adds probe customization via CRD, allowing you to tune readiness/liveness/startup
          probes for managed components without patching generated manifests.']
      breaking_changes: []
    chart_version: 0.1.12
    images: ['victoriametrics/operator:v0.13.0']
  - version: 0.12.2
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.1.10
    images: ['victoriametrics/operator:v0.12.2']
  - version: 0.11.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.1.9
    images: ['victoriametrics/operator:v0.11.0']
  - version: 0.9.1
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: []
      features: ['VMPodScrape: basic auth, bearer token, and TLS connection support
          were added, enabling secure scraping configurations.', 'VMSingle/VMCluster:
          new `insertPorts` option allows configuring ingestion ports for OpenTSDB,
          Graphite, and Influx protocols.', 'vmalert: support for `externalLabels`
          was added to attach extra labels to generated alerts/metrics.']
      breaking_changes: ['RBAC changes: role/namespace handling was adjusted; verify
          the operator has the expected permissions in the target namespace(s) after
          upgrade.']
    chart_version: 0.1.8
    images: ['victoriametrics/operator:v0.9.1']
  - version: 0.8.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary:
      helm_changes: ''
      chart_updates: ['Operator v0.8.0 includes additional VMPodScrape connection/auth
          options (basic auth, bearer token, TLS) and new ingestion port configuration
          via `insertPorts` for VMSingle and VMCluster.', Includes minor documentation
          fixes (operator-hub broken links) and stability fixes (panic fixes around
          VMCluster).]
      features: ['VMPodScrape now supports basic auth, bearer token authentication,
          and TLS configuration for scraping endpoints.', 'VMSingle and VMCluster
          add `insertPorts` to configure ingestion ports for OpenTSDB, Graphite, and
          Influx protocols.']
      breaking_changes: []
    chart_version: 0.1.7
    images: ['victoriametrics/operator:v0.8.0']
  - version: 0.7.3
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.1.5
    images: ['victoriametrics/operator:v0.7.3']
  - version: 0.6.1
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.1.4
    images: ['victoriametrics/operator:v0.6.1']
  - version: 0.2.1
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 0.1.1
    images: ['victoriametrics/operator:v0.2.1']
  name: victoria-metrics-operator
- icon: https://raw.githubusercontent.com/pluralsh/plural-artifacts/main/nvidia-operator/plural/icons/nvidia.png?raw=true
  git_url: https://github.com/NVIDIA/gpu-operator
  release_url: https://github.com/NVIDIA/gpu-operator/releases/tag/{vsn}
  helm_repository_url: https://nvidia.github.io/gpu-operator
  readme_url: https://github.com/NVIDIA/gpu-operator/blob/main/README.md
  versions:
  - version: 25.10.1
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 25.10.1
    images: ['nvcr.io/nvidia/cloud-native/k8s-driver-manager:v0.9.1', 'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v25.10.1', 'registry.k8s.io/nfd/node-feature-discovery:v0.18.2']
  - version: 25.10.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 25.10.0
    images: ['nvcr.io/nvidia/cloud-native/k8s-driver-manager:v0.9.0', 'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v25.10.0', 'registry.k8s.io/nfd/node-feature-discovery:v0.18.2']
  - version: 25.3.2
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 25.3.2
    images: ['nvcr.io/nvidia/cloud-native/k8s-driver-manager:v0.8.0', 'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v25.3.2', 'registry.k8s.io/nfd/node-feature-discovery:v0.17.3']
  - version: 25.3.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 25.3.0
    images: ['nvcr.io/nvidia/cloud-native/k8s-driver-manager:v0.8.0', 'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v25.3.0', 'registry.k8s.io/nfd/node-feature-discovery:v0.17.2']
  - version: 24.9.1
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 24.9.1
    images: ['nvcr.io/nvidia/cloud-native/k8s-driver-manager:v0.7.0', 'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v24.9.1', 'registry.k8s.io/nfd/node-feature-discovery:v0.16.6']
  - version: 24.9.0
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 24.9.0
    images: ['nvcr.io/nvidia/cloud-native/k8s-driver-manager:v0.7.0', 'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v24.9.0', 'registry.k8s.io/nfd/node-feature-discovery:v0.16.6']
  - version: 24.6.1
    kube: ['1.31', '1.30', '1.29']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 24.6.1
    images: ['nvcr.io/nvidia/cloud-native/k8s-driver-manager:v0.6.10', 'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v24.6.1', 'registry.k8s.io/nfd/node-feature-discovery:v0.16.3']
  - version: 24.6.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 24.6.0
    images: ['nvcr.io/nvidia/cloud-native/k8s-driver-manager:v0.6.10', 'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v24.6.0', 'registry.k8s.io/nfd/node-feature-discovery:v0.16.3']
  - version: 24.3.0
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 24.3.0
    images: ['nvcr.io/nvidia/cloud-native/k8s-driver-manager:v0.6.8', 'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v24.3.0', 'registry.k8s.io/nfd/node-feature-discovery:v0.15.4']
  - version: 23.9.2
    kube: ['1.30', '1.29', '1.28']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 23.9.2
    images: ['nvcr.io/nvidia/cloud-native/k8s-driver-manager:v0.6.5', 'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v23.9.2', 'registry.k8s.io/nfd/node-feature-discovery:v0.14.2']
  - version: 23.9.1
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 23.9.1
    images: ['nvcr.io/nvidia/cloud-native/k8s-driver-manager:v0.6.2', 'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v23.9.1', 'registry.k8s.io/nfd/node-feature-discovery:v0.14.2']
  - version: 23.9.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 23.9.0
    images: ['nvcr.io/nvidia/cloud-native/k8s-driver-manager:v0.6.2', 'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v23.9.0', 'registry.k8s.io/nfd/node-feature-discovery:v0.14.2']
  - version: 23.6.2
    kube: ['1.29', '1.28', '1.27']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 23.6.2
    images: ['nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v23.6.2', 'registry.k8s.io/nfd/node-feature-discovery:v0.13.1']
  - version: 23.6.0
    kube: ['1.28', '1.27', '1.26']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 23.6.0
    images: ['nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.54.03',
      'nvcr.io/nvidia/cloud-native/kata-gpu-artifacts:ubuntu22.04-535.86.10-snp',
      'nvcr.io/nvidia/gpu-operator:v23.6.0', 'registry.k8s.io/nfd/node-feature-discovery:v0.13.1']
  - version: 23.3.1
    kube: ['1.27', '1.26', '1.25']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 23.3.1
    images: ['nvcr.io/nvidia/gpu-operator:v23.3.1', 'registry.k8s.io/nfd/node-feature-discovery:v0.12.1']
  - version: 23.3.0
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 23.3.0
    images: ['nvcr.io/nvidia/gpu-operator:v23.3.0', 'registry.k8s.io/nfd/node-feature-discovery:v0.12.1']
  - version: 22.9.1
    kube: ['1.26', '1.25', '1.24']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 22.9.1
    images: []
  - version: 22.9.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 22.9.0
    images: []
  - version: 1.11.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.11.0
    images: []
  - version: 1.10.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.10.0
    images: []
  - version: 1.9.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.9.0
    images: []
  - version: 1.8.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.8.0
    images: []
  - version: 1.7.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.7.0
    images: []
  - version: 1.6.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.6.0
    images: []
  - version: 1.5.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.5.0
    images: []
  - version: 1.4.0
    kube: ['1.25', '1.24', '1.23']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 1.4.0
    images: []
  name: gpu-operator
- icon: https://raw.githubusercontent.com/pluralsh/plural-artifacts/main/elasticsearch/plural/icons/elastic.png?raw=true
  git_url: https://github.com/elastic/elasticsearch
  release_url: https://github.com/elastic/elasticsearch/releases/tag/{vsn}
  helm_repository_url: https://helm.elastic.co
  readme_url: https://github.com/elastic/elasticsearch/blob/main/README.asciidoc
  versions:
  - version: 9.2.3
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 9.2.3
    images: ['docker.elastic.co/elastic-agent/elastic-agent:9.2.3', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.16.0']
  - version: 9.2.0
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 9.2.0
    images: ['docker.elastic.co/elastic-agent/elastic-agent:9.2.0', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.16.0']
  - version: 9.1.4
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 9.1.4
    images: ['docker.elastic.co/elastic-agent/elastic-agent:9.1.4', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.16.0']
  - version: 9.1.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 9.1.0
    images: ['docker.elastic.co/elastic-agent/elastic-agent:9.1.0', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0']
  - version: 9.0.7
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 9.0.7
    images: ['docker.elastic.co/elastic-agent/elastic-agent:9.0.7', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.16.0']
  - version: 9.0.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 9.0.0
    images: ['docker.elastic.co/elastic-agent/elastic-agent:9.0.0', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0']
  - version: 8.19.3
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 8.19.3
    images: ['docker.elastic.co/elastic-agent/elastic-agent:8.19.3', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.16.0']
  - version: 8.19.0
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 8.19.0
    images: ['docker.elastic.co/elastic-agent/elastic-agent:8.19.0', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0']
  - version: 8.18.7
    kube: ['1.34', '1.33', '1.32']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 8.18.7
    images: ['docker.elastic.co/elastic-agent/elastic-agent:8.18.7', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.16.0']
  - version: 8.18.1
    kube: ['1.33', '1.32', '1.31']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 8.18.1
    images: ['docker.elastic.co/elastic-agent/elastic-agent:8.18.1', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0']
  - version: 8.18.0
    kube: ['1.32', '1.31', '1.30']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 8.18.0
    images: ['docker.elastic.co/elastic-agent/elastic-agent:8.18.0', 'registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0']
  name: elastic-agent
- icon: https://avatars.githubusercontent.com/u/96669?s=48&v=4
  git_url: https://github.com/rabbitmq/cluster-operator
  release_url: https://github.com/rabbitmq/cluster-operator/releases/tag/v{vsn}
  helm_repository_url: https://charts.bitnami.com/bitnami
  chart_name: rabbitmq-cluster-operator
  versions:
  - version: 2.16.1
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 4.4.34
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.16.1-debian-12-r0', 'docker.io/bitnami/rabbitmq:4.1.3-debian-12-r1',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.8-debian-12-r0', 'docker.io/bitnami/rmq-messaging-topology-operator:1.17.4-debian-12-r0']
  - version: 2.16.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 4.4.32
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.16.0-debian-12-r2', 'docker.io/bitnami/rabbitmq:4.1.3-debian-12-r1',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.7-debian-12-r3', 'docker.io/bitnami/rmq-messaging-topology-operator:1.17.3-debian-12-r2']
  - version: 2.15.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 4.4.26
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.15.0-debian-12-r1', 'docker.io/bitnami/rabbitmq:4.1.2-debian-12-r1',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.7-debian-12-r1', 'docker.io/bitnami/rmq-messaging-topology-operator:1.17.3-debian-12-r0']
  - version: 2.14.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 4.4.22
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.14.0-debian-12-r3', 'docker.io/bitnami/rabbitmq:4.1.1-debian-12-r2',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.6-debian-12-r3', 'docker.io/bitnami/rmq-messaging-topology-operator:1.17.1-debian-12-r3']
  - version: 2.13.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 4.4.13
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.13.0-debian-12-r0', 'docker.io/bitnami/rabbitmq:4.1.0-debian-12-r3',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.6-debian-12-r0', 'docker.io/bitnami/rmq-messaging-topology-operator:1.17.0-debian-12-r1']
  - version: 2.12.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 4.4.2
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.12.0-debian-12-r1', 'docker.io/bitnami/rabbitmq:4.0.5-debian-12-r1',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.4-debian-12-r33', 'docker.io/bitnami/rmq-messaging-topology-operator:1.15.0-debian-12-r5']
  - version: 2.11.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 4.4.0
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.11.0-debian-12-r4', 'docker.io/bitnami/rabbitmq:4.0.4-debian-12-r1',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.4-debian-12-r31', 'docker.io/bitnami/rmq-messaging-topology-operator:1.15.0-debian-12-r2']
  - version: 2.10.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 4.3.24
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.10.0-debian-12-r2', 'docker.io/bitnami/rabbitmq:4.0.2-debian-12-r0',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.4-debian-12-r28', 'docker.io/bitnami/rmq-messaging-topology-operator:1.14.2-debian-12-r6']
  - version: 2.9.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 4.3.20
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.9.0-debian-12-r8', 'docker.io/bitnami/rabbitmq:3.13.7-debian-12-r0',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.4-debian-12-r26', 'docker.io/bitnami/rmq-messaging-topology-operator:1.14.2-debian-12-r5']
  - version: 2.8.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 4.2.7
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.8.0-debian-12-r4', 'docker.io/bitnami/rabbitmq:3.13.2-debian-12-r1',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.4-debian-12-r18', 'docker.io/bitnami/rmq-messaging-topology-operator:1.14.0-debian-12-r0']
  - version: 2.7.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 4.2.0
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.7.0-debian-12-r8', 'docker.io/bitnami/rabbitmq:3.12.13-debian-12-r2',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.4-debian-12-r14', 'docker.io/bitnami/rmq-messaging-topology-operator:1.13.0-debian-12-r7']
  - version: 2.6.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.14.0
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.6.0-debian-11-r3', 'docker.io/bitnami/rabbitmq:3.12.12-debian-11-r3',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.4-debian-11-r5', 'docker.io/bitnami/rmq-messaging-topology-operator:1.12.2-debian-11-r1']
  - version: 2.5.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.10.5
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.5.0-debian-11-r39', 'docker.io/bitnami/rabbitmq:3.11.26-debian-11-r0',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.4-debian-11-r2', 'docker.io/bitnami/rmq-messaging-topology-operator:1.12.1-debian-11-r2']
  - version: 2.4.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.7.1
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.4.0-debian-11-r15', 'docker.io/bitnami/rabbitmq:3.11.21-debian-11-r0',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.2-debian-11-r14', 'docker.io/bitnami/rmq-messaging-topology-operator:1.12.0-debian-11-r14']
  - version: 2.3.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.6.2
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.3.0-scratch-r3', 'docker.io/bitnami/rabbitmq:3.11.19-debian-11-r18',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.2-scratch-r23', 'docker.io/bitnami/rmq-messaging-topology-operator:1.12.0-scratch-r2']
  - version: 2.2.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.4.1
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.2.0-scratch-r7', 'docker.io/bitnami/rabbitmq:3.11.16-debian-11-r3',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.2-scratch-r21', 'docker.io/bitnami/rmq-messaging-topology-operator:1.10.3-scratch-r1']
  - version: 2.1.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.2.5
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.1.0-scratch-r6', 'docker.io/bitnami/rabbitmq:3.10.18-debian-11-r4',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.2-scratch-r16', 'docker.io/bitnami/rmq-messaging-topology-operator:1.10.1-scratch-r2']
  - version: 2.0.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 3.1.5
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:2.0.0-scratch-r6', 'docker.io/bitnami/rabbitmq:3.10.13-debian-11-r6',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.2-scratch-r12', 'docker.io/bitnami/rmq-messaging-topology-operator:1.10.0-scratch-r0']
  - version: 1.14.0
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.7.4
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:1.14.0-scratch-r6', 'docker.io/bitnami/rabbitmq:3.10.7-debian-11-r8',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.2-scratch-r8', 'docker.io/bitnami/rmq-messaging-topology-operator:1.8.0-scratch-r1']
  - version: 1.13.1
    kube: ['1.35', '1.34', '1.33', '1.32', '1.31', '1.30', '1.29', '1.28', '1.27',
      '1.26', '1.25', '1.24', '1.23', '1.22', '1.21', '1.20', '1.19']
    requirements: []
    incompatibilities: []
    summary: null
    chart_version: 2.6.6
    images: ['docker.io/bitnami/rabbitmq-cluster-operator:1.13.1-scratch-r3', 'docker.io/bitnami/rabbitmq:3.10.5-debian-11-r2',
      'docker.io/bitnami/rmq-default-credential-updater:1.0.2-scratch-r2', 'docker.io/bitnami/rmq-messaging-topology-operator:1.6.0-scratch-r0']
  name: rabbitmq-cluster-operator
